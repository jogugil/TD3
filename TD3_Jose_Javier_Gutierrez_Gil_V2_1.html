<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>TD3_Jose_Javier_Gutierrez_Gil_V2_1</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,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);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '•';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.6.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        const { svg } = await mermaid.render(id, raw, el);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=0e99c767-45d0-4607-9f0d-3b152077be77">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
<h1 id="Title:TRABAJO-AP.-DDPG-TD(3)-(Gradiente-de-pol%C3%ADtica-determinista-profunda-(TD3)-de-doble-retardo.-Entornos-de-estados-continuos:-Humanoide).-+-Conexi%C3%B3n-Chatgpt-(o-similar)--+-modelo-dalle-(similr)"><strong>Title</strong>:TRABAJO AP. DDPG TD(3) (Gradiente de política determinista profunda (TD3) de doble retardo. Entornos de estados continuos: Humanoide). + Conexión Chatgpt (o similar)  + modelo dalle (similr)<a class="anchor-link" href="#Title:TRABAJO-AP.-DDPG-TD(3)-(Gradiente-de-pol%C3%ADtica-determinista-profunda-(TD3)-de-doble-retardo.-Entornos-de-estados-continuos:-Humanoide).-+-Conexi%C3%B3n-Chatgpt-(o-similar)--+-modelo-dalle-(similr)">¶</a></h1><h1 id="Author:-Jos%C3%A9-Javier-Guti%C3%A9rrez-Gil"><strong>Author</strong>: José Javier Gutiérrez Gil<a class="anchor-link" href="#Author:-Jos%C3%A9-Javier-Guti%C3%A9rrez-Gil">¶</a></h1><h1 id="Date:-2024-02-18"><strong>Date</strong>: 2024-02-18<a class="anchor-link" href="#Date:-2024-02-18">¶</a></h1><h1 id="*Univeridad-de-Valencia.-Grado-de-Ciencia-de-Datos*">*<strong>Univeridad de Valencia. Grado de Ciencia de Datos</strong>*<a class="anchor-link" href="#*Univeridad-de-Valencia.-Grado-de-Ciencia-de-Datos*">¶</a></h1><hr/>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=af2cc5c5-06ce-4d3b-98c2-fcf65da40a3e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span> <span class="p">(</span><span class="s1">'/content/drive'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=e4cb48b5-7944-484d-86e2-db2442f1e142">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">'/content/drive/MyDrive/td3'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=652d3241-1d25-43fc-bf6d-b30ceec5e36f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">'/content/drive/MyDrive/td3'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=b98ca0fc-f908-46ac-bea4-402b52106e97">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pybullet
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span><span class="nv">gym</span><span class="o">==</span><span class="m">0</span>.22.0<span class="w"> </span>#<span class="w"> </span>Versión<span class="w"> </span>más<span class="w"> </span>actual<span class="w"> </span>que<span class="w"> </span>contiene<span class="w"> </span>la<span class="w"> </span>calse<span class="w"> </span>Monitor<span class="w"> </span>y<span class="w"> </span>así<span class="w"> </span>poder<span class="w"> </span>crear<span class="w"> </span>los<span class="w"> </span>videos<span class="w"> </span>del<span class="w"> </span>entrenamiento.<span class="w"> </span>Al<span class="w"> </span>monos<span class="w"> </span>en<span class="w"> </span>la<span class="w"> </span><span class="m">0</span>.23<span class="w"> </span>me<span class="w"> </span>da<span class="w"> </span>error
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Collecting pybullet
  Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">103.2/103.2 MB</span> <span class="ansi-red-fg">6.5 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Installing collected packages: pybullet
Successfully installed pybullet-3.2.6
Collecting gym==0.22.0
  Downloading gym-0.22.0.tar.gz (631 kB)
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">631.1/631.1 kB</span> <span class="ansi-red-fg">6.4 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Preparing metadata (pyproject.toml) ... done
Requirement already satisfied: numpy&gt;=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.22.0) (1.25.2)
Requirement already satisfied: cloudpickle&gt;=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.22.0) (2.2.1)
Requirement already satisfied: gym-notices&gt;=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.22.0) (0.0.8)
Building wheels for collected packages: gym
  Building wheel for gym (pyproject.toml) ... done
  Created wheel for gym: filename=gym-0.22.0-py3-none-any.whl size=708364 sha256=894a34ab0091e5ac006564e0162cd94f6e1028c4d5086cd234f4f6a2ad943026
  Stored in directory: /root/.cache/pip/wheels/42/e8/e8/6dfbc92a1dcd76c1a5e2bb982750fd6b7e792239f46039e6b1
Successfully built gym
Installing collected packages: gym
  Attempting uninstall: gym
    Found existing installation: gym 0.25.2
    Uninstalling gym-0.25.2:
      Successfully uninstalled gym-0.25.2
Successfully installed gym-0.22.0
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=d1f2438c-79e2-440a-b42f-0d0b55f131f4">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Step-0:-Cargamos-las-funciones-necesarias-de-nuestra-libreria-y-de-python"><strong>Step 0:</strong> Cargamos las funciones necesarias de nuestra libreria y de python<a class="anchor-link" href="#Step-0:-Cargamos-las-funciones-necesarias-de-nuestra-libreria-y-de-python">¶</a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=96b52b6e-2a56-4d65-b098-7257b1d7bd81">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1">#####</span>
<span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">pybullet_envs</span>
<span class="kn">from</span> <span class="nn">gym</span> <span class="kn">import</span> <span class="n">wrappers</span>
<span class="c1">##</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="c1">#####</span>
<span class="kn">from</span> <span class="nn">TD3</span> <span class="kn">import</span> <span class="n">TD3</span><span class="p">,</span> <span class="n">ReplayBuffer</span>
<span class="kn">from</span> <span class="nn">TD3</span> <span class="kn">import</span> <span class="n">created_models_directory</span><span class="p">,</span> <span class="n">mkdir</span>
<span class="kn">from</span> <span class="nn">TD3</span> <span class="kn">import</span> <span class="n">evaluate_train_policy</span><span class="p">,</span> <span class="n">evaluate_policy</span>
<span class="kn">from</span> <span class="nn">TD3</span> <span class="kn">import</span> <span class="n">noisy_action_wrapper</span><span class="p">,</span> <span class="n">save_env</span><span class="p">,</span> <span class="n">load_env</span><span class="p">,</span> <span class="n">create__metrics_imagen</span>
<span class="kn">from</span> <span class="nn">TD3</span> <span class="kn">import</span> <span class="n">serialize_object</span><span class="p">,</span> <span class="n">lists_to_serializable_object</span><span class="p">,</span> <span class="n">serialize_training</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=d2abfbcd-1534-4894-9d4c-ab55bceb028a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Step-1:-Inicializamos-los-hiperpar%C3%A1metros-del-modelo-e-implementaci%C3%B3n"><strong>Step 1:</strong> Inicializamos los hiperparámetros del modelo e implementación<a class="anchor-link" href="#Step-1:-Inicializamos-los-hiperpar%C3%A1metros-del-modelo-e-implementaci%C3%B3n">¶</a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=cf9e1e60-97b7-4483-b65a-16e7318f2ac4">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">env_name</span>            <span class="o">=</span>  <span class="s2">"HumanoidBulletEnv-v0"</span>  <span class="c1"># Nombre del entorno que vamos a entrena. Con forme se ha implementado el modelo TD3 poría ser cuaalquier entorno (preferiblemente de estados de acciones continuos)</span>
<span class="n">seed</span>                <span class="o">=</span> <span class="mi">0</span>        <span class="c1"># Semilla utilizada para garantizar la reproducibilidad de los resultados</span>
<span class="n">initial_memory_prob</span> <span class="o">=</span> <span class="mf">0.1</span>      <span class="c1"># Define la probabilidad inicial de tomar una acción de la memoria de repetición</span>
<span class="n">max_start_steps</span>     <span class="o">=</span> <span class="mf">1e4</span>      <span class="c1"># Define el número máximo de pasos iniciales</span>
<span class="c1">#start_steps         = 1e4#1e4  --123-- lo modificamos por un decaimiento según los pasos de entrenamiento # Número de iteraciones/timesteps antes de que el modelo comience a utilizar la red de políticas en lugar de elegir acciones al azar</span>
<span class="n">eval_frequency</span>      <span class="o">=</span> <span class="mf">5e3</span>      <span class="c1"># Frecuencia de evaluación, es decir, cada cuántos pasos/timesteps se evalúa el desempeño del modelo</span>
<span class="n">max_timesteps</span>       <span class="o">=</span> <span class="mf">1e6</span>      <span class="c1"># Número máximo de iteraciones/timesteps permitidos</span>
<span class="n">save_models</span>         <span class="o">=</span> <span class="kc">True</span>     <span class="c1"># Booleano que indica si se deben guardar los modelos pre-entrenados o no</span>
<span class="n">max_explore_noise</span>   <span class="o">=</span> <span class="mf">0.1</span>      <span class="c1"># Desviación estándar del ruido gaussiano utilizado para la exploración...--123-- CaMBIO  0.01 por 0.2 y creo un current_noise_explore dependiendo del steo en el que estamos</span>
<span class="n">batch_size</span>          <span class="o">=</span> <span class="mi">100</span>      <span class="c1"># Tamaño del lote de muestras utilizadas en cada iteración de entrenamiento</span>
<span class="n">gamma</span>               <span class="o">=</span> <span class="mf">0.99</span>     <span class="c1"># Factor de descuento gamma que afecta la importancia de las recompensas futuras en la función de pérdida</span>
<span class="n">target_update_freq</span>  <span class="o">=</span> <span class="mf">0.005</span>    <span class="c1"># Tasa de actualización para suavizar los parámetros de la red objetivo</span>
<span class="n">policy_noise</span>        <span class="o">=</span> <span class="mf">0.2</span>      <span class="c1"># Desviación estándar del ruido gaussiano agregado a las acciones para promover la exploración</span>
<span class="n">noise_clip</span>          <span class="o">=</span> <span class="mf">0.5</span>      <span class="c1"># Valor máximo permitido para el ruido gaussiano agregado a las acciones (política)</span>
<span class="n">policy_freq</span>         <span class="o">=</span> <span class="mi">2</span>        <span class="c1"># Número de iteraciones entre actualizaciones de la red de políticas (modelo actor)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=48fc757e-1f59-4156-8f8d-ef70f6f73ef5">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Step-2:-Creamos-los-directorios-y-cargamos-el-entorno-de-trabajo"><strong>Step 2:</strong> Creamos los directorios y cargamos el entorno de trabajo<a class="anchor-link" href="#Step-2:-Creamos-los-directorios-y-cargamos-el-entorno-de-trabajo">¶</a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=1d64e59c-0696-40b5-b558-8eb8e96c362a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#Creamos los directorios de almacenamento de resultados y métricas</span>
<span class="n">file_model_name</span> <span class="o">=</span> <span class="n">created_models_directory</span> <span class="p">(</span><span class="n">env_name</span><span class="p">,</span> <span class="n">seed</span><span class="p">,</span> <span class="n">save_models</span><span class="p">,</span> <span class="s2">"v2_1"</span><span class="p">)</span>

<span class="c1"># Cargamos el entorno sobre el cual ejecutaremso el modelo DDPG TD3</span>
<span class="c1">###############################################################################</span>
<span class="c1">##  CARGAMOS EL ENTORNO HUMANOIDE V0 Y LE INTRODUCIMOS EL WRAPPER PARA AÑADIR RUIDO A</span>
<span class="c1">##  LAS ACCIONES OBTENIDAS POR EXPLORACIÓN.</span>
<span class="c1">################################################################################</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span> <span class="p">(</span><span class="n">env_name</span><span class="p">)</span>
<span class="n">max_episode_steps</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">_max_episode_steps</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">noisy_action_wrapper</span> <span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">noise_level</span> <span class="o">=</span> <span class="n">policy_noise</span><span class="p">)</span> <span class="c1">#le agregamos ruido a la accion obtenida del entorno para darle ms estabilidad al entrenamiento</span>
<span class="c1"># Fijamos la semilla y obtenemos información del entorno (Estados, acciones)</span>
<span class="n">env</span><span class="o">.</span><span class="n">seed</span> <span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span> <span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span> <span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">state_dim</span>  <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">action_dim</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">shape</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">max_action</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">high</span> <span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1">#Creamos los directorios de trabajo donde guardará los videos del entrenamiento</span>
<span class="n">work_dir</span>          <span class="o">=</span> <span class="n">mkdir</span> <span class="p">(</span><span class="s1">'exp'</span><span class="p">,</span> <span class="s1">'brs'</span><span class="p">)</span>
<span class="n">monitor_dir</span>       <span class="o">=</span> <span class="n">mkdir</span> <span class="p">(</span><span class="n">work_dir</span><span class="p">,</span> <span class="s1">'monitor'</span><span class="p">)</span>

<span class="n">save_env_vid</span>      <span class="o">=</span> <span class="kc">False</span>
<span class="k">if</span> <span class="n">save_env_vid</span><span class="p">:</span>
  <span class="n">env</span> <span class="o">=</span> <span class="n">wrappers</span><span class="o">.</span><span class="n">Monitor</span> <span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">monitor_dir</span><span class="p">,</span> <span class="n">force</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
  <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>---------------------------------------
Fichero de los modelos entrenados: TD3_HumanoidBulletEnv-v0_0_v2_1
---------------------------------------
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=cb6ceeb0-ff57-4215-8401-aabefcf31305">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Step-3:-Proceso-de-entrenamiento-:-e.gredy"><strong>Step 3:</strong> Proceso de entrenamiento : e.gredy<a class="anchor-link" href="#Step-3:-Proceso-de-entrenamiento-:-e.gredy">¶</a></h1><p><strong>Estrategia ε-greedy adaptativa:</strong></p>
<p>Durante el entrenamiento, utilizamos una estrategia ε-greedy para equilibrar la exploración y la explotación.</p>
<ul>
<li><p>En la fase de exploración inicial (cuando total_steps &lt; max_start_steps), seleccionamos acciones al azar con una probabilidad alta de exploración (ε), lo que nos permite recopilar información sobre el entorno.</p>
</li>
<li><p>A medida que el agente acumula más experiencia, disminuimos gradualmente la probabilidad de exploración (ε) utilizando una función de decaimiento lineal, pasando de ε_start a ε_end en ε_decay_steps pasos.</p>
</li>
<li><p>En la fase de explotación (cuando total_steps &gt;= max_start_steps), seleccionamos acciones principalmente explotando las estimaciones actuales de los valores Q. Sin embargo, aún mantenemos la capacidad de explorar introduciendo un pequeño nivel de ruido en las acciones seleccionadas, controlado por max_explore_nois. Este ruido garantiza que el agente continúe explorando incluso durante la fase de explotación, aunque en menor medida que durante la fase inicial de exploración.</p>
</li>
<li><p>Al final de cada episodio, actualizamos el valor de ε para garantizar que disminuya con el tiempo, lo que refleja la idea de que a medida que el agente adquiere más experiencia, confiamos menos en la exploración aleatoria y más en la explotación de las estimaciones aprendidas.</p>
</li>
<li><p>Este enfoque nos permite equilibrar eficazmente la exploración y la explotación durante el entrenamiento, lo que facilita el descubrimiento de políticas óptimas en entornos complejos.</p>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=fc8e914c-0170-4af2-8cce-4ad02252b0c8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">EGreedyPolicy</span><span class="p">:</span>
<span class="w">    </span><span class="sd">'''</span>
<span class="sd">        - __init__: Este método inicializa los parámetros de la política ε-greedy, como</span>
<span class="sd">          los valores iniciales y finales de ε, y el número de pasos de decaimiento de ε.</span>

<span class="sd">        - select_action: Este método elige una acción de acuerdo con la estrategia ε-greedy.</span>
<span class="sd">        Si un número aleatorio es menor que ε, se selecciona una acción al azar; de lo contrario,</span>
<span class="sd">        se selecciona la mejor acción según los valores Q.</span>

<span class="sd">        - update_epsilon: Este método actualiza el valor de ε durante el entrenamiento. Disminuye</span>
<span class="sd">        linealmente desde el valor inicial hasta el valor final a lo largo del número</span>
<span class="sd">        especificado de pasos de decaimiento</span>
<span class="sd">    '''</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">policy</span><span class="p">,</span> <span class="n">epsilon_start</span><span class="p">,</span> <span class="n">epsilon_end</span><span class="p">,</span> <span class="n">epsilon_decay_steps</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span>    <span class="o">=</span> <span class="n">env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">policy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_start</span> <span class="o">=</span> <span class="n">epsilon_start</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_end</span> <span class="o">=</span> <span class="n">epsilon_end</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_decay_steps</span> <span class="o">=</span> <span class="n">epsilon_decay_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon_start</span>

    <span class="k">def</span> <span class="nf">select_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">:</span>
            <span class="nb">print</span> <span class="p">(</span><span class="s2">"Exploracion 2"</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span> <span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span> <span class="p">(</span><span class="s2">"Explotacion"</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">select_action</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span> <span class="p">(</span><span class="n">obs</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">update_epsilon</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
        <span class="c1"># Disminuye epsilon linealmente desde epsilon_start hasta epsilon_end</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_decay_steps</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_start</span> <span class="o">-</span> <span class="p">(</span><span class="n">step</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_decay_steps</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epsilon_start</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_end</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_end</span>

<span class="k">class</span> <span class="nc">AdaptiveEGreedyPolicy</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">policy</span><span class="p">,</span> <span class="n">epsilon_start</span><span class="p">,</span> <span class="n">epsilon_end</span><span class="p">,</span> <span class="n">epsilon_decay_steps</span><span class="p">,</span> <span class="n">max_timesteps</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span>    <span class="o">=</span> <span class="n">env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">policy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_start</span> <span class="o">=</span> <span class="n">epsilon_start</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_end</span> <span class="o">=</span> <span class="n">epsilon_end</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_decay_steps</span> <span class="o">=</span> <span class="n">epsilon_decay_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_timesteps</span> <span class="o">=</span> <span class="n">max_timesteps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon_start</span>

    <span class="k">def</span> <span class="nf">select_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">total_steps</span><span class="p">,</span> <span class="n">obs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">:</span>
            <span class="c1">#print ("Exploracion 2")</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1">#print ("Explotacion 1")</span>
            <span class="c1"># Acceder a la experiencai del agente</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">select_action</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span> <span class="p">(</span><span class="n">obs</span><span class="p">))</span>
            <span class="c1"># print('Acción de la experiencia del agente:', action)</span>
            <span class="n">current_explore_noise</span> <span class="o">=</span> <span class="n">max_explore_noise</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">total_steps</span> <span class="o">/</span> <span class="n">max_timesteps</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">current_explore_noise</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">action</span> <span class="o">=</span> <span class="p">(</span><span class="n">action</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_explore_noise</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">action_dim</span><span class="p">))</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">low</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
            <span class="c1"># print('Acción seleccionada por el modelo:', action)</span>
        <span class="k">return</span> <span class="n">action</span>

    <span class="k">def</span> <span class="nf">update_epsilon</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">total_steps</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">total_steps</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_decay_steps</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_start</span> <span class="o">-</span> <span class="p">(</span><span class="n">total_steps</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_decay_steps</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epsilon_start</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_end</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_end</span>

<span class="c1"># Creamos el objeto DDPG TD3 con los hiperparámetros definidos anteriormente</span>
<span class="n">policy</span> <span class="o">=</span> <span class="n">TD3</span> <span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">max_action</span><span class="p">,</span><span class="n">max_timesteps</span><span class="p">,</span> <span class="n">initial_lr</span> <span class="o">=</span>  <span class="mf">1e-4</span><span class="p">)</span> <span class="c1"># Notar que realmente el objeto entrenado definirá la política a seguir por el agente</span>

<span class="c1"># Creamos un objeto EGreedyPolicy para la exploración</span>
<span class="n">epsilon_start</span>       <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">epsilon_end</span>         <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">epsilon_decay_steps</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">exploration_policy</span>  <span class="o">=</span> <span class="n">AdaptiveEGreedyPolicy</span> <span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">policy</span><span class="p">,</span> <span class="n">epsilon_start</span><span class="p">,</span> <span class="n">epsilon_end</span><span class="p">,</span> <span class="n">epsilon_decay_steps</span><span class="p">,</span><span class="n">max_timesteps</span><span class="p">)</span> <span class="c1">#EGreedyPolicy(epsilon_start, epsilon_end, epsilon_decay_steps)</span>

<span class="c1"># Nos creamos la memoria de repetición de experiencias</span>
<span class="n">replay_buff</span> <span class="o">=</span> <span class="n">ReplayBuffer</span> <span class="p">(</span> <span class="n">max_capacity</span> <span class="o">=</span> <span class="mf">2e4</span><span class="p">)</span> <span class="c1"># Notar que la máxima capacidad de la memoria por defecto es: max_capacity = 1e4</span>
<span class="c1"># replay_buff = SimplePrioritizedReplayBuffer()</span>

<span class="c1"># Lista donde se guardarán las evaluaciones de la política durante el entrenamiento</span>
<span class="n">evaluations</span> <span class="o">=</span> <span class="p">[</span><span class="n">evaluate_train_policy</span> <span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">env</span><span class="p">)]</span>

<span class="c1"># Inicialización de variables utilizadas en el entrenamiento</span>
<span class="n">total_steps</span>        <span class="o">=</span> <span class="mi">0</span>     <span class="c1"># Número total de pasos de entrenamiento que llevamos realizados</span>
<span class="n">episode_steps</span>      <span class="o">=</span> <span class="mi">0</span>     <span class="c1"># Número de pasos realizados en el epidodeo</span>
<span class="n">steps_since_eval</span>   <span class="o">=</span> <span class="mi">0</span>     <span class="c1"># Número de pasos desde la última evaluación de la política</span>
<span class="n">episode_num</span>        <span class="o">=</span> <span class="mi">0</span>     <span class="c1"># Número de episodios completados durante el entrenamiento</span>
<span class="n">done</span>               <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># Indica si el episodio actual ha finalizado, nos lo devuelve el entorno de gym</span>

<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Tiempo inicial de referencia para medir el tiempo de entrenamiento</span>
<span class="n">n_steps_epochs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_rewards</span>    <span class="o">=</span> <span class="p">[]</span>
<span class="n">avg_losses_c</span>   <span class="o">=</span> <span class="p">[]</span>
<span class="n">avg_losses_a</span>   <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_losses_c</span>   <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_losses_a</span>   <span class="o">=</span> <span class="p">[]</span>
<span class="n">target_qs_c1</span>   <span class="o">=</span> <span class="p">[]</span>
<span class="n">target_qs_c2</span>   <span class="o">=</span> <span class="p">[]</span>
<span class="n">target_qs</span>      <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_exploration_factor</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1">############################################################################</span>
<span class="c1"># step 0: Bucle principal del entrenameinto de nuestro modelo.</span>
<span class="c1">##  REalizamos tantos pasos como indica el hiperparámetro "max_timesteps"</span>
<span class="c1">## A no ser que se estanque en un maximo local (mínimo) el humanoide aprenderá</span>
<span class="c1">## mejor cuantos mñas pasos realiza. Eta implementacición V2 utiliza una estrategia e-grady</span>
<span class="c1">## cuando finaliza el periodo de exploración. Es un entorno muy complicado con</span>
<span class="c1">## muchos grados de libertad y acciones infinitas por lo que es facil estancarse.</span>
<span class="c1">## Por ello, es muy importante el ruido aladido a las acciones.</span>
<span class="c1">#############################################################################</span>

<span class="k">while</span> <span class="n">total_steps</span> <span class="o">&lt;</span> <span class="n">max_timesteps</span><span class="p">:</span> <span class="c1"># son pasos de tiempo</span>
    <span class="c1"># step 1: Se comprueba si el episodio ha concluido. Si lo ha hehco, realiamso el entrenamiento del modelo</span>
    <span class="c1"># con las acciones almacenadas en ReplayBuffer</span>
    <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
        <span class="c1"># Comienza el entrenamiento del modelo si no es la primera iteración</span>
        <span class="k">if</span> <span class="n">total_steps</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span> <span class="c1">#Ya que no se tendrá nada en la memoria de repetición</span>
            <span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s1">'Número de pasos del episodio </span><span class="si">{</span><span class="n">episode_num</span><span class="si">}</span><span class="s1"> son episode_steps:</span><span class="si">{</span><span class="n">episode_steps</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
            <span class="n">n_steps_epochs</span><span class="o">.</span><span class="n">append</span> <span class="p">(</span><span class="n">episode_steps</span><span class="p">)</span>
            <span class="c1"># Realizamos el entrenamiento del modelo con las aciones almacenadas en ReplayBuffer</span>
            <span class="n">rewards</span><span class="p">,</span> <span class="n">losses_c</span><span class="p">,</span><span class="n">losses_a</span><span class="p">,</span> <span class="n">target_qs_critic1</span><span class="p">,</span> <span class="n">target_qs_critic2</span><span class="p">,</span> <span class="n">target_qs</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">train</span> <span class="p">(</span><span class="n">replay_buff</span><span class="p">,</span> <span class="n">episode_steps</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span>
                                                                               <span class="n">target_update_freq</span><span class="p">,</span> <span class="n">policy_noise</span><span class="p">,</span> <span class="n">noise_clip</span><span class="p">,</span> <span class="n">policy_freq</span><span class="p">)</span>
            <span class="c1">#############</span>
            <span class="c1"># Nos guardamos las métricas del entrenamiento a estudio</span>
            <span class="c1">#############</span>
            <span class="n">avg_reward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span> <span class="p">(</span><span class="n">rewards</span><span class="p">)</span>
            <span class="n">avg_loss_c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span> <span class="p">(</span><span class="n">losses_c</span><span class="p">)</span>
            <span class="n">avg_loss_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span> <span class="p">(</span><span class="n">losses_a</span><span class="p">)</span>
            <span class="c1"># avg_expl_fact = np.mean(expl_fact)</span>

            <span class="n">all_rewards</span><span class="o">.</span><span class="n">append</span> <span class="p">(</span><span class="n">avg_reward</span><span class="p">)</span>
            <span class="n">avg_losses_c</span><span class="o">.</span><span class="n">append</span> <span class="p">(</span><span class="n">avg_loss_c</span><span class="p">)</span>
            <span class="n">avg_losses_a</span><span class="o">.</span><span class="n">append</span> <span class="p">(</span><span class="n">avg_loss_a</span><span class="p">)</span>
            <span class="n">all_losses_c</span><span class="o">.</span><span class="n">append</span> <span class="p">(</span><span class="n">losses_c</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
            <span class="n">all_losses_a</span><span class="o">.</span><span class="n">append</span> <span class="p">(</span><span class="n">losses_a</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

            <span class="n">target_qs_c1</span><span class="o">.</span><span class="n">append</span> <span class="p">(</span><span class="n">target_qs_critic1</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
            <span class="n">target_qs_c2</span><span class="o">.</span><span class="n">append</span> <span class="p">(</span><span class="n">target_qs_critic2</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
            <span class="n">target_qs</span><span class="o">.</span><span class="n">append</span> <span class="p">(</span><span class="n">target_qs</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

            <span class="c1"># all_exploration_factor.append(avg_expl_fact)</span>

            <span class="nb">print</span><span class="p">(</span><span class="s2">"Total Steps: </span><span class="si">{}</span><span class="s2"> Episode Num: </span><span class="si">{}</span><span class="s2"> Reward: </span><span class="si">{}</span><span class="s2"> avg_loss_c: </span><span class="si">{}</span><span class="s2"> avg_loss_a: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">total_steps</span><span class="p">,</span> <span class="n">episode_num</span><span class="p">,</span> <span class="n">episode_reward</span><span class="p">,</span> <span class="n">avg_loss_c</span><span class="p">,</span> <span class="n">avg_loss_a</span><span class="p">))</span>


        <span class="c1"># step 2: Se evalúa el rendimiento del episodio actual y se guarda la política</span>
        <span class="c1"># si se cumplen ciertas condiciones o criterios predefinidos.</span>
        <span class="k">if</span> <span class="n">steps_since_eval</span> <span class="o">&gt;=</span> <span class="n">eval_frequency</span><span class="p">:</span>
            <span class="n">steps_since_eval</span> <span class="o">%=</span> <span class="n">eval_frequency</span>
            <span class="n">evaluations</span><span class="o">.</span><span class="n">append</span> <span class="p">(</span><span class="n">evaluate_train_policy</span> <span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">env</span><span class="p">))</span>
            <span class="c1"># Almacenamos el modelo en el estado de entrenamiento en el que se encuentra</span>
            <span class="n">policy</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">file_model_name</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s2">"./pytorch_models"</span><span class="p">)</span>

            <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">"./results/</span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">file_model_name</span><span class="p">),</span> <span class="n">evaluations</span><span class="p">)</span>

            <span class="n">save_env</span><span class="p">(</span><span class="n">file_model_name</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s2">"./results"</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span> <span class="c1"># Guardamos el entorno en el estado actual</span>
            <span class="c1"># Serializar el ReplayBufferMemory y guardarlo en un archivo</span>
            <span class="n">serialize_object</span><span class="p">(</span><span class="n">replay_buff</span><span class="p">,</span> <span class="s1">'./results/replay_buffer_memory_v2_1.pickle'</span><span class="p">)</span>
            <span class="c1"># Serializamos las métricas del entrenamiento</span>
            <span class="n">lists_train_metrics</span> <span class="o">=</span> <span class="p">[</span><span class="n">all_rewards</span><span class="p">,</span> <span class="n">avg_losses_c</span><span class="p">,</span> <span class="n">avg_losses_a</span><span class="p">,</span> <span class="n">all_losses_c</span><span class="p">,</span> <span class="n">all_losses_a</span><span class="p">]</span>
            <span class="n">attribute_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'rewards'</span><span class="p">,</span> <span class="s1">'losses'</span><span class="p">]</span>
            <span class="n">lists_to_serializable_object</span><span class="p">(</span><span class="n">lists_train_metrics</span><span class="p">,</span> <span class="n">attribute_names</span><span class="p">,</span> <span class="s1">'./results/serialized_list_train_metrics_v2_1.pickle'</span><span class="p">)</span>


        <span class="c1"># step3: Reiniciar el entorno cuando finaliza el episodio de entrenamiento</span>
        <span class="c1"># Notar que según la logica del bucle, en el primer ciclo, este serña el primer paso.</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

        <span class="c1"># Establecer "done" a Falso para parar el episodio</span>
        <span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Restablecer la recompensa del episodio y el contador de pasos del episodio</span>
        <span class="n">episode_reward</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">episode_steps</span>  <span class="o">=</span> <span class="mi">0</span>
        <span class="n">episode_num</span>   <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># step 4: Tomar acciones aleatorias antes de alcanzar el número de pasos iniciales</span>
    <span class="k">if</span> <span class="n">total_steps</span> <span class="o">&lt;</span> <span class="n">max_start_steps</span><span class="p">:</span>
        <span class="c1">#print ("Exploracion 1")</span>
        <span class="c1"># Si estamos en los primeros pasos, acceder al entorno real (exploración) con una probabilidad inversamente proporcional</span>
        <span class="c1"># a la probabilidad de tomar una acción de la experiencia del agente</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
     <span class="c1"># Después de superar los primeros pasos, usar el modelo entrenado con una probabilidad inversamente proporcional</span>
    <span class="c1"># a la probabilidad de tomar una acción de la experiencia</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># Seleccionar la acción según la política ε-greedy</span>
      <span class="n">exploration_policy</span><span class="o">.</span><span class="n">update_epsilon</span> <span class="p">(</span><span class="n">total_steps</span><span class="p">)</span>
      <span class="n">action</span> <span class="o">=</span> <span class="n">exploration_policy</span><span class="o">.</span><span class="n">select_action</span> <span class="p">(</span><span class="n">total_steps</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span> <span class="p">(</span><span class="n">obs</span><span class="p">))</span>


    <span class="c1"># step 5: El agente ejecuta una acción en el entorno, lo que resulta en una transición</span>
    <span class="c1"># de estado. Además, el agente recibe una recompensa del entorno como resultado</span>
    <span class="c1"># de su acción. Esta acción puede cambiar el estado del entorno y, por lo tanto,</span>
    <span class="c1"># influir en las futuras observaciones y recompensas del agente.</span>
    <span class="c1">#print (f' * nueva action:  -- tamaño:{len (action)}')</span>
    <span class="n">new_obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span> <span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="c1">#print (f' * nuevo reward:{reward}')</span>
    <span class="c1"># Comprueba si el episodio ha terminado</span>
    <span class="n">done_bool</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">episode_steps</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">==</span> <span class="n">max_episode_steps</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="n">done</span><span class="p">)</span>

    <span class="c1"># Aumenta la recompensa total del episodio</span>
    <span class="n">episode_reward</span> <span class="o">+=</span> <span class="n">reward</span>

    <span class="c1"># step 6: Almacenar nueva transición en el búfer de repetición de experiencias</span>
    <span class="c1">## Hemos desestimado el buffer de repeticion con prioridad por el costo computacional</span>
    <span class="n">replay_buff</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">obs</span><span class="p">,</span> <span class="n">new_obs</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done_bool</span><span class="p">))</span>

    <span class="c1">#error_explora = 0.01 # añadimos un error muy bajo para asegurarnos que al menos se utiliza una vez</span>
    <span class="c1">#replay_buff.add(error_explora, (obs, new_obs, action, reward, done_bool))</span>

    <span class="c1"># Actualizar estado, tiempo de paso del episodio, tiempo total de pasos y pasos desde la última evaluación de la política</span>
    <span class="n">obs</span> <span class="o">=</span> <span class="n">new_obs</span>
    <span class="n">episode_steps</span>    <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">total_steps</span>      <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">steps_since_eval</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># Llamamos a la funcion para crear graficas de entrenamiento</span>
    <span class="n">create__metrics_imagen</span> <span class="p">(</span><span class="n">evaluations</span><span class="p">,</span> <span class="n">all_rewards</span><span class="p">,</span>  <span class="n">avg_losses_c</span><span class="p">,</span><span class="n">avg_losses_a</span><span class="p">,</span> <span class="n">all_losses_c</span><span class="p">,</span>
                                                    <span class="n">all_losses_a</span><span class="p">,</span> <span class="n">target_qs_c1</span><span class="p">,</span>
                                                    <span class="n">target_qs_c2</span><span class="p">,</span> <span class="n">target_qs</span><span class="p">,</span>
                                                    <span class="n">n_steps_epochs</span><span class="p">,</span> <span class="s2">"v2_1"</span><span class="p">,</span> <span class="n">episode_num</span><span class="p">,</span> <span class="n">total_steps</span><span class="p">)</span>

<span class="n">tf</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Tiempo final de referencia para medir el tiempo de entrenamiento</span>
<span class="n">serialize_training</span> <span class="p">(</span><span class="n">t0</span><span class="p">,</span> <span class="n">tf</span><span class="p">,</span> <span class="n">total_steps</span><span class="p">,</span><span class="s2">"v2"</span><span class="p">)</span>
<span class="c1"># Añadir la última actualización de la política a la lista de evaluaciones previa y guardar nuestro modelo</span>
<span class="n">evaluations</span><span class="o">.</span><span class="n">append</span> <span class="p">(</span><span class="n">evaluate_train_policy</span> <span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">env</span><span class="p">))</span>
<span class="k">if</span> <span class="n">save_models</span><span class="p">:</span>
    <span class="n">policy</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">"gready_</span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">file_model_name</span><span class="p">),</span> <span class="n">directory</span><span class="o">=</span><span class="s2">"./pytorch_models"</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">"./results/gready_</span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">file_model_name</span><span class="p">),</span> <span class="n">evaluations</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre><span class="ansi-black-intense-fg ansi-yellow-bg ansi-bold">Se han truncado las últimas 5000 líneas del flujo de salida.</span>
Número de pasos del episodio 12030 son episode_steps:193
Total Steps: 753892 Episode Num: 12030 Reward: 155.2293385380441 avg_loss_c: 18.88262728952991 avg_loss_a: -57.12634623235989
Número de pasos del episodio 12031 son episode_steps:122
Total Steps: 754014 Episode Num: 12031 Reward: 66.72290640438632 avg_loss_c: 19.09537341164761 avg_loss_a: -57.60784780783732
Número de pasos del episodio 12032 son episode_steps:135
Total Steps: 754149 Episode Num: 12032 Reward: 48.32532222263281 avg_loss_c: 18.186251845183197 avg_loss_a: -56.42457131279839
Número de pasos del episodio 12033 son episode_steps:124
Total Steps: 754273 Episode Num: 12033 Reward: 108.08807126337342 avg_loss_c: 18.86636011831222 avg_loss_a: -56.962593201668035
Número de pasos del episodio 12034 son episode_steps:72
Total Steps: 754345 Episode Num: 12034 Reward: -20.37904941982382 avg_loss_c: 19.341667188538445 avg_loss_a: -56.636052237616646
Número de pasos del episodio 12035 son episode_steps:55
Total Steps: 754400 Episode Num: 12035 Reward: 22.68399510477453 avg_loss_c: 19.355775954506615 avg_loss_a: -56.88952921087092
Número de pasos del episodio 12036 son episode_steps:51
Total Steps: 754451 Episode Num: 12036 Reward: -17.539409154126414 avg_loss_c: 19.18207946478152 avg_loss_a: -56.6005002190085
Número de pasos del episodio 12037 son episode_steps:53
Total Steps: 754504 Episode Num: 12037 Reward: -76.28607291874118 avg_loss_c: 18.5026144891415 avg_loss_a: -57.16225116657761
Número de pasos del episodio 12038 son episode_steps:101
Total Steps: 754605 Episode Num: 12038 Reward: 41.26931278781212 avg_loss_c: 19.530136769360833 avg_loss_a: -56.99039039989509
Número de pasos del episodio 12039 son episode_steps:100
Total Steps: 754705 Episode Num: 12039 Reward: 32.2931664227201 avg_loss_c: 19.782255935668946 avg_loss_a: -57.34229049682617
Número de pasos del episodio 12040 son episode_steps:89
Total Steps: 754794 Episode Num: 12040 Reward: 17.36584516368747 avg_loss_c: 19.735457645373398 avg_loss_a: -56.61319398344233
Número de pasos del episodio 12041 son episode_steps:73
Total Steps: 754867 Episode Num: 12041 Reward: -36.077194227778186 avg_loss_c: 20.072535057590432 avg_loss_a: -56.84756778037711
Número de pasos del episodio 12042 son episode_steps:219
Total Steps: 755086 Episode Num: 12042 Reward: 115.0228289986498 avg_loss_c: 18.825443446364034 avg_loss_a: -57.30255975244252
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 82.140060
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12043 son episode_steps:73
Total Steps: 755159 Episode Num: 12043 Reward: -6.186183552085415 avg_loss_c: 19.825795892166767 avg_loss_a: -57.083353330011235
Número de pasos del episodio 12044 son episode_steps:151
Total Steps: 755310 Episode Num: 12044 Reward: 123.72886668506767 avg_loss_c: 19.33657716283735 avg_loss_a: -57.307500851864845
Número de pasos del episodio 12045 son episode_steps:71
Total Steps: 755381 Episode Num: 12045 Reward: 16.47509448358952 avg_loss_c: 18.797936426082128 avg_loss_a: -57.55075777080697
Número de pasos del episodio 12046 son episode_steps:92
Total Steps: 755473 Episode Num: 12046 Reward: -11.79884335482712 avg_loss_c: 18.397723063178685 avg_loss_a: -56.94241847162662
Número de pasos del episodio 12047 son episode_steps:230
Total Steps: 755703 Episode Num: 12047 Reward: -8.745614761511842 avg_loss_c: 20.07935605671095 avg_loss_a: -56.926164743174674
Número de pasos del episodio 12048 son episode_steps:78
Total Steps: 755781 Episode Num: 12048 Reward: -21.794754075978094 avg_loss_c: 19.72765239079793 avg_loss_a: -57.64505112476838
Número de pasos del episodio 12049 son episode_steps:88
Total Steps: 755869 Episode Num: 12049 Reward: -1.114820513798016 avg_loss_c: 18.702199491587553 avg_loss_a: -56.81774044036865
Número de pasos del episodio 12050 son episode_steps:63
Total Steps: 755932 Episode Num: 12050 Reward: 23.386879446469134 avg_loss_c: 19.48923104906839 avg_loss_a: -58.26669753543914
Número de pasos del episodio 12051 son episode_steps:52
Total Steps: 755984 Episode Num: 12051 Reward: -68.0880497524666 avg_loss_c: 19.934539758242092 avg_loss_a: -57.840888243455154
Número de pasos del episodio 12052 son episode_steps:65
Total Steps: 756049 Episode Num: 12052 Reward: 13.52811587455681 avg_loss_c: 20.696036280118502 avg_loss_a: -57.43301696777344
Número de pasos del episodio 12053 son episode_steps:62
Total Steps: 756111 Episode Num: 12053 Reward: -113.79877626417858 avg_loss_c: 22.990415619265647 avg_loss_a: -57.88013359808153
Número de pasos del episodio 12054 son episode_steps:90
Total Steps: 756201 Episode Num: 12054 Reward: 26.89748791749821 avg_loss_c: 22.657632308536105 avg_loss_a: -57.890387217203774
Número de pasos del episodio 12055 son episode_steps:159
Total Steps: 756360 Episode Num: 12055 Reward: -0.5075487086388044 avg_loss_c: 20.79877130640378 avg_loss_a: -57.22146860758463
Número de pasos del episodio 12056 son episode_steps:53
Total Steps: 756413 Episode Num: 12056 Reward: -34.470568442651796 avg_loss_c: 23.51373294614396 avg_loss_a: -56.9642495209316
Número de pasos del episodio 12057 son episode_steps:93
Total Steps: 756506 Episode Num: 12057 Reward: 50.954987910958394 avg_loss_c: 21.15914378627654 avg_loss_a: -57.81705286169565
Número de pasos del episodio 12058 son episode_steps:280
Total Steps: 756786 Episode Num: 12058 Reward: 278.6340832352653 avg_loss_c: 21.243546785627093 avg_loss_a: -57.589665167672294
Número de pasos del episodio 12059 son episode_steps:110
Total Steps: 756896 Episode Num: 12059 Reward: -14.418565111635713 avg_loss_c: 21.625218547474255 avg_loss_a: -58.181065021861684
Número de pasos del episodio 12060 son episode_steps:106
Total Steps: 757002 Episode Num: 12060 Reward: 20.229293002750683 avg_loss_c: 20.896178605421532 avg_loss_a: -56.59503389754385
Número de pasos del episodio 12061 son episode_steps:63
Total Steps: 757065 Episode Num: 12061 Reward: -106.09205914791369 avg_loss_c: 20.860283230978347 avg_loss_a: -58.35600541129945
Número de pasos del episodio 12062 son episode_steps:40
Total Steps: 757105 Episode Num: 12062 Reward: -9.350028281032431 avg_loss_c: 20.247003841400147 avg_loss_a: -57.15200843811035
Número de pasos del episodio 12063 son episode_steps:61
Total Steps: 757166 Episode Num: 12063 Reward: -27.085602620716895 avg_loss_c: 21.740898226128248 avg_loss_a: -57.57482115948787
Número de pasos del episodio 12064 son episode_steps:40
Total Steps: 757206 Episode Num: 12064 Reward: -14.82330496109803 avg_loss_c: 22.621682953834533 avg_loss_a: -57.62979869842529
Número de pasos del episodio 12065 son episode_steps:32
Total Steps: 757238 Episode Num: 12065 Reward: -14.904206261951646 avg_loss_c: 21.12155157327652 avg_loss_a: -57.87931442260742
Número de pasos del episodio 12066 son episode_steps:87
Total Steps: 757325 Episode Num: 12066 Reward: 41.12007186836488 avg_loss_c: 22.05375026834422 avg_loss_a: -57.53900865576733
Número de pasos del episodio 12067 son episode_steps:48
Total Steps: 757373 Episode Num: 12067 Reward: -18.236960051155968 avg_loss_c: 22.828923106193542 avg_loss_a: -56.958557764689125
Número de pasos del episodio 12068 son episode_steps:26
Total Steps: 757399 Episode Num: 12068 Reward: -15.298620125276491 avg_loss_c: 22.287109044881966 avg_loss_a: -57.68755516639123
Número de pasos del episodio 12069 son episode_steps:63
Total Steps: 757462 Episode Num: 12069 Reward: -55.15313858758334 avg_loss_c: 21.96138412233383 avg_loss_a: -56.65607076977927
Número de pasos del episodio 12070 son episode_steps:26
Total Steps: 757488 Episode Num: 12070 Reward: -21.768632550072006 avg_loss_c: 24.285501810220573 avg_loss_a: -57.20680941068209
Número de pasos del episodio 12071 son episode_steps:81
Total Steps: 757569 Episode Num: 12071 Reward: 45.62623926865508 avg_loss_c: 22.84923850165473 avg_loss_a: -57.23901089326835
Número de pasos del episodio 12072 son episode_steps:44
Total Steps: 757613 Episode Num: 12072 Reward: -6.343988624651956 avg_loss_c: 21.386200883171774 avg_loss_a: -57.90351954373446
Número de pasos del episodio 12073 son episode_steps:22
Total Steps: 757635 Episode Num: 12073 Reward: -38.12441413220322 avg_loss_c: 23.957277167927135 avg_loss_a: -57.0856274691495
Número de pasos del episodio 12074 son episode_steps:63
Total Steps: 757698 Episode Num: 12074 Reward: -71.3651271433832 avg_loss_c: 23.25432084098695 avg_loss_a: -56.98079051668682
Número de pasos del episodio 12075 son episode_steps:50
Total Steps: 757748 Episode Num: 12075 Reward: -13.453174452589803 avg_loss_c: 21.753096866607667 avg_loss_a: -56.84944702148437
Número de pasos del episodio 12076 son episode_steps:270
Total Steps: 758018 Episode Num: 12076 Reward: 194.5559121233229 avg_loss_c: 22.50321727682043 avg_loss_a: -57.59843374181677
Número de pasos del episodio 12077 son episode_steps:169
Total Steps: 758187 Episode Num: 12077 Reward: 96.45950179249043 avg_loss_c: 21.3072941345576 avg_loss_a: -58.28133175641122
Número de pasos del episodio 12078 son episode_steps:399
Total Steps: 758586 Episode Num: 12078 Reward: 286.3146826018275 avg_loss_c: 21.630182259064867 avg_loss_a: -58.76303037485682
Número de pasos del episodio 12079 son episode_steps:167
Total Steps: 758753 Episode Num: 12079 Reward: 48.60192645800794 avg_loss_c: 21.213968322662538 avg_loss_a: -59.17148740848381
Número de pasos del episodio 12080 son episode_steps:264
Total Steps: 759017 Episode Num: 12080 Reward: 195.5943108620924 avg_loss_c: 21.411292509599164 avg_loss_a: -59.89385165590228
Número de pasos del episodio 12081 son episode_steps:141
Total Steps: 759158 Episode Num: 12081 Reward: 44.17974389628719 avg_loss_c: 21.180962853397883 avg_loss_a: -60.17920841731078
Número de pasos del episodio 12082 son episode_steps:279
Total Steps: 759437 Episode Num: 12082 Reward: 152.58208768329823 avg_loss_c: 21.53790064780943 avg_loss_a: -60.20383502591041
Número de pasos del episodio 12083 son episode_steps:70
Total Steps: 759507 Episode Num: 12083 Reward: -63.15497924141281 avg_loss_c: 21.559206908089774 avg_loss_a: -60.68031365530832
Número de pasos del episodio 12084 son episode_steps:39
Total Steps: 759546 Episode Num: 12084 Reward: -36.64620609588906 avg_loss_c: 23.635829143035107 avg_loss_a: -60.5200205093775
Número de pasos del episodio 12085 son episode_steps:136
Total Steps: 759682 Episode Num: 12085 Reward: 5.7531287048153565 avg_loss_c: 21.840453694848453 avg_loss_a: -59.85172597099753
Número de pasos del episodio 12086 son episode_steps:57
Total Steps: 759739 Episode Num: 12086 Reward: 8.993373068530458 avg_loss_c: 22.343759269045112 avg_loss_a: -60.59674306501422
Número de pasos del episodio 12087 son episode_steps:140
Total Steps: 759879 Episode Num: 12087 Reward: 111.1860306059111 avg_loss_c: 21.072060550962174 avg_loss_a: -60.47515051705496
Número de pasos del episodio 12088 son episode_steps:44
Total Steps: 759923 Episode Num: 12088 Reward: -4.355173875204872 avg_loss_c: 20.725455435839567 avg_loss_a: -60.33112421902743
Número de pasos del episodio 12089 son episode_steps:79
Total Steps: 760002 Episode Num: 12089 Reward: 33.856008735921236 avg_loss_c: 21.731398956685126 avg_loss_a: -61.40495792823502
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 269.549314
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12090 son episode_steps:40
Total Steps: 760042 Episode Num: 12090 Reward: -66.83431519700657 avg_loss_c: 23.343159461021422 avg_loss_a: -61.19685249328613
Número de pasos del episodio 12091 son episode_steps:170
Total Steps: 760212 Episode Num: 12091 Reward: 84.51894433814255 avg_loss_c: 22.217195005977857 avg_loss_a: -61.15964225320255
Número de pasos del episodio 12092 son episode_steps:23
Total Steps: 760235 Episode Num: 12092 Reward: -22.705621215290712 avg_loss_c: 22.228992047517195 avg_loss_a: -63.08469822095788
Número de pasos del episodio 12093 son episode_steps:128
Total Steps: 760363 Episode Num: 12093 Reward: -12.105772122776571 avg_loss_c: 22.313255548477173 avg_loss_a: -60.8729550242424
Número de pasos del episodio 12094 son episode_steps:75
Total Steps: 760438 Episode Num: 12094 Reward: -16.156150335680195 avg_loss_c: 22.605263544718426 avg_loss_a: -61.44446111043294
Número de pasos del episodio 12095 son episode_steps:82
Total Steps: 760520 Episode Num: 12095 Reward: 51.36506812217586 avg_loss_c: 22.334135136953215 avg_loss_a: -60.93097947283489
Número de pasos del episodio 12096 son episode_steps:52
Total Steps: 760572 Episode Num: 12096 Reward: -38.75841643765094 avg_loss_c: 24.948267679948074 avg_loss_a: -60.076642109797554
Número de pasos del episodio 12097 son episode_steps:88
Total Steps: 760660 Episode Num: 12097 Reward: -66.23875066212356 avg_loss_c: 23.410589294000104 avg_loss_a: -60.36400162089955
Número de pasos del episodio 12098 son episode_steps:63
Total Steps: 760723 Episode Num: 12098 Reward: -14.482866755459145 avg_loss_c: 25.403810168069505 avg_loss_a: -60.153769175211586
Número de pasos del episodio 12099 son episode_steps:95
Total Steps: 760818 Episode Num: 12099 Reward: 64.63849858588378 avg_loss_c: 23.525981461374382 avg_loss_a: -62.18368072509766
Número de pasos del episodio 12100 son episode_steps:155
Total Steps: 760973 Episode Num: 12100 Reward: -22.237474675850763 avg_loss_c: 23.500902434318295 avg_loss_a: -61.204117633450416
Número de pasos del episodio 12101 son episode_steps:73
Total Steps: 761046 Episode Num: 12101 Reward: -25.125848347718264 avg_loss_c: 22.23436768414223 avg_loss_a: -61.00141577524682
Número de pasos del episodio 12102 son episode_steps:107
Total Steps: 761153 Episode Num: 12102 Reward: 8.411254193833956 avg_loss_c: 24.114906917108552 avg_loss_a: -61.089390799263924
Número de pasos del episodio 12103 son episode_steps:142
Total Steps: 761295 Episode Num: 12103 Reward: 131.94073452281916 avg_loss_c: 23.840034202790598 avg_loss_a: -61.062371643496235
Número de pasos del episodio 12104 son episode_steps:245
Total Steps: 761540 Episode Num: 12104 Reward: 153.46568162585837 avg_loss_c: 23.369918745391224 avg_loss_a: -60.01336679263991
Número de pasos del episodio 12105 son episode_steps:129
Total Steps: 761669 Episode Num: 12105 Reward: 55.84562658804952 avg_loss_c: 23.969429297040598 avg_loss_a: -61.452042542686755
Número de pasos del episodio 12106 son episode_steps:68
Total Steps: 761737 Episode Num: 12106 Reward: -16.022008795973466 avg_loss_c: 23.14705130633186 avg_loss_a: -62.11177062988281
Número de pasos del episodio 12107 son episode_steps:77
Total Steps: 761814 Episode Num: 12107 Reward: -72.94163678580769 avg_loss_c: 23.41222514115371 avg_loss_a: -59.78415655160879
Número de pasos del episodio 12108 son episode_steps:72
Total Steps: 761886 Episode Num: 12108 Reward: 39.23375398403468 avg_loss_c: 24.106993834177654 avg_loss_a: -61.03109900156657
Número de pasos del episodio 12109 son episode_steps:157
Total Steps: 762043 Episode Num: 12109 Reward: 107.83884627970838 avg_loss_c: 23.691588025184195 avg_loss_a: -60.83529364227489
Número de pasos del episodio 12110 son episode_steps:182
Total Steps: 762225 Episode Num: 12110 Reward: 128.01249324332068 avg_loss_c: 23.064763367831052 avg_loss_a: -61.83826572292454
Número de pasos del episodio 12111 son episode_steps:95
Total Steps: 762320 Episode Num: 12111 Reward: -44.25532506375885 avg_loss_c: 23.351569456803173 avg_loss_a: -60.98446129246762
Número de pasos del episodio 12112 son episode_steps:117
Total Steps: 762437 Episode Num: 12112 Reward: 70.11752148355988 avg_loss_c: 23.703106285160423 avg_loss_a: -60.891976739606285
Número de pasos del episodio 12113 son episode_steps:41
Total Steps: 762478 Episode Num: 12113 Reward: -26.773337626544336 avg_loss_c: 24.2544230019174 avg_loss_a: -59.98858400670493
Número de pasos del episodio 12114 son episode_steps:84
Total Steps: 762562 Episode Num: 12114 Reward: 8.406105571886698 avg_loss_c: 24.216098138264247 avg_loss_a: -60.27760814485096
Número de pasos del episodio 12115 son episode_steps:43
Total Steps: 762605 Episode Num: 12115 Reward: -11.734619935476235 avg_loss_c: 24.82050132751465 avg_loss_a: -59.40983723485193
Número de pasos del episodio 12116 son episode_steps:126
Total Steps: 762731 Episode Num: 12116 Reward: 97.07869948442266 avg_loss_c: 24.65824299766904 avg_loss_a: -61.02929124378023
Número de pasos del episodio 12117 son episode_steps:187
Total Steps: 762918 Episode Num: 12117 Reward: 121.01794497646505 avg_loss_c: 24.03189295498445 avg_loss_a: -60.98671444979581
Número de pasos del episodio 12118 son episode_steps:64
Total Steps: 762982 Episode Num: 12118 Reward: 12.485080123142893 avg_loss_c: 23.998377233743668 avg_loss_a: -61.07677984237671
Número de pasos del episodio 12119 son episode_steps:58
Total Steps: 763040 Episode Num: 12119 Reward: -8.97910030517812 avg_loss_c: 23.86141489292013 avg_loss_a: -60.939570854450096
Número de pasos del episodio 12120 son episode_steps:207
Total Steps: 763247 Episode Num: 12120 Reward: 89.52525108510137 avg_loss_c: 24.295470039625673 avg_loss_a: -60.2733541848003
Número de pasos del episodio 12121 son episode_steps:141
Total Steps: 763388 Episode Num: 12121 Reward: 51.34542825354852 avg_loss_c: 24.336490685212695 avg_loss_a: -60.61788063860954
Número de pasos del episodio 12122 son episode_steps:61
Total Steps: 763449 Episode Num: 12122 Reward: -19.966936566551997 avg_loss_c: 23.778123667982758 avg_loss_a: -60.16235926893891
Número de pasos del episodio 12123 son episode_steps:61
Total Steps: 763510 Episode Num: 12123 Reward: 22.98366967218903 avg_loss_c: 23.384369865792696 avg_loss_a: -62.000981315237574
Número de pasos del episodio 12124 son episode_steps:75
Total Steps: 763585 Episode Num: 12124 Reward: 30.894247173602913 avg_loss_c: 24.008041000366212 avg_loss_a: -59.31238087972005
Número de pasos del episodio 12125 son episode_steps:111
Total Steps: 763696 Episode Num: 12125 Reward: 56.055159717493595 avg_loss_c: 23.68689167606938 avg_loss_a: -60.98247593372792
Número de pasos del episodio 12126 son episode_steps:131
Total Steps: 763827 Episode Num: 12126 Reward: 131.06216026180016 avg_loss_c: 23.68011457865475 avg_loss_a: -61.16709276738057
Número de pasos del episodio 12127 son episode_steps:114
Total Steps: 763941 Episode Num: 12127 Reward: 61.446671077578415 avg_loss_c: 23.873442122810765 avg_loss_a: -61.00267811825401
Número de pasos del episodio 12128 son episode_steps:56
Total Steps: 763997 Episode Num: 12128 Reward: -36.940670668726575 avg_loss_c: 23.255117859159196 avg_loss_a: -60.2335695539202
Número de pasos del episodio 12129 son episode_steps:67
Total Steps: 764064 Episode Num: 12129 Reward: -9.269076210843648 avg_loss_c: 24.13865189054119 avg_loss_a: -61.38269395970587
Número de pasos del episodio 12130 son episode_steps:270
Total Steps: 764334 Episode Num: 12130 Reward: 190.8543763188619 avg_loss_c: 23.663575818803576 avg_loss_a: -60.32043377911603
Número de pasos del episodio 12131 son episode_steps:52
Total Steps: 764386 Episode Num: 12131 Reward: -32.70471404267711 avg_loss_c: 23.791095110086296 avg_loss_a: -62.01409178513747
Número de pasos del episodio 12132 son episode_steps:98
Total Steps: 764484 Episode Num: 12132 Reward: -5.27839559996693 avg_loss_c: 24.602583602983124 avg_loss_a: -60.44518474656709
Número de pasos del episodio 12133 son episode_steps:169
Total Steps: 764653 Episode Num: 12133 Reward: -9.835380002145811 avg_loss_c: 23.58028850329698 avg_loss_a: -60.69872437426324
Número de pasos del episodio 12134 son episode_steps:110
Total Steps: 764763 Episode Num: 12134 Reward: -4.237010381091824 avg_loss_c: 23.91922201676802 avg_loss_a: -60.139162028919564
Número de pasos del episodio 12135 son episode_steps:58
Total Steps: 764821 Episode Num: 12135 Reward: 4.781499989862901 avg_loss_c: 23.269216817000817 avg_loss_a: -60.61793228675579
Número de pasos del episodio 12136 son episode_steps:479
Total Steps: 765300 Episode Num: 12136 Reward: 417.2013472391988 avg_loss_c: 23.33036922661895 avg_loss_a: -61.63378872801715
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 210.224512
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12137 son episode_steps:93
Total Steps: 765393 Episode Num: 12137 Reward: 63.1475866100778 avg_loss_c: 22.237786569902973 avg_loss_a: -62.42700790077127
Número de pasos del episodio 12138 son episode_steps:177
Total Steps: 765570 Episode Num: 12138 Reward: 62.908200707251225 avg_loss_c: 22.179266482423255 avg_loss_a: -62.035482072560804
Número de pasos del episodio 12139 son episode_steps:82
Total Steps: 765652 Episode Num: 12139 Reward: -17.248360311180406 avg_loss_c: 22.583364207570146 avg_loss_a: -61.22001815423733
Número de pasos del episodio 12140 son episode_steps:50
Total Steps: 765702 Episode Num: 12140 Reward: 5.935591124897917 avg_loss_c: 22.850711669921875 avg_loss_a: -61.58166275024414
Número de pasos del episodio 12141 son episode_steps:248
Total Steps: 765950 Episode Num: 12141 Reward: 149.59590146320272 avg_loss_c: 23.282872634549296 avg_loss_a: -61.79920679523099
Número de pasos del episodio 12142 son episode_steps:83
Total Steps: 766033 Episode Num: 12142 Reward: -19.76627015114378 avg_loss_c: 22.778795483600664 avg_loss_a: -62.387641630977036
Número de pasos del episodio 12143 son episode_steps:98
Total Steps: 766131 Episode Num: 12143 Reward: 48.10388472476388 avg_loss_c: 23.24303165747195 avg_loss_a: -62.537334208585776
Número de pasos del episodio 12144 son episode_steps:77
Total Steps: 766208 Episode Num: 12144 Reward: 21.8951301754958 avg_loss_c: 22.627133035040522 avg_loss_a: -61.64290049168971
Número de pasos del episodio 12145 son episode_steps:220
Total Steps: 766428 Episode Num: 12145 Reward: 165.37260669650112 avg_loss_c: 23.59208728616888 avg_loss_a: -61.53303257335316
Número de pasos del episodio 12146 son episode_steps:62
Total Steps: 766490 Episode Num: 12146 Reward: 35.915546978093396 avg_loss_c: 22.63508939743042 avg_loss_a: -62.81939598821825
Número de pasos del episodio 12147 son episode_steps:39
Total Steps: 766529 Episode Num: 12147 Reward: -11.84547108551251 avg_loss_c: 23.004475911458332 avg_loss_a: -63.7641234764686
Número de pasos del episodio 12148 son episode_steps:124
Total Steps: 766653 Episode Num: 12148 Reward: 58.87096333818913 avg_loss_c: 22.659724950790405 avg_loss_a: -62.863260207637666
Número de pasos del episodio 12149 son episode_steps:190
Total Steps: 766843 Episode Num: 12149 Reward: 118.26103813159335 avg_loss_c: 23.02775169171785 avg_loss_a: -62.51999439440276
Número de pasos del episodio 12150 son episode_steps:111
Total Steps: 766954 Episode Num: 12150 Reward: 6.79741961766814 avg_loss_c: 23.188875163997615 avg_loss_a: -63.64385398658546
Número de pasos del episodio 12151 son episode_steps:93
Total Steps: 767047 Episode Num: 12151 Reward: 15.31165420776605 avg_loss_c: 23.21206795272007 avg_loss_a: -62.905828250351774
Número de pasos del episodio 12152 son episode_steps:156
Total Steps: 767203 Episode Num: 12152 Reward: 99.7008040482085 avg_loss_c: 23.82601868800628 avg_loss_a: -62.86396564581455
Número de pasos del episodio 12153 son episode_steps:177
Total Steps: 767380 Episode Num: 12153 Reward: 106.80283352398064 avg_loss_c: 23.47261917523745 avg_loss_a: -63.312235406563104
Número de pasos del episodio 12154 son episode_steps:59
Total Steps: 767439 Episode Num: 12154 Reward: 14.564927695385595 avg_loss_c: 23.934751575276003 avg_loss_a: -63.04635232181872
Número de pasos del episodio 12155 son episode_steps:100
Total Steps: 767539 Episode Num: 12155 Reward: 14.47080710903866 avg_loss_c: 22.484314308166503 avg_loss_a: -62.19028045654297
Número de pasos del episodio 12156 son episode_steps:175
Total Steps: 767714 Episode Num: 12156 Reward: 89.1001048394001 avg_loss_c: 23.687835317339214 avg_loss_a: -64.04800728934151
Número de pasos del episodio 12157 son episode_steps:84
Total Steps: 767798 Episode Num: 12157 Reward: -12.611241068993891 avg_loss_c: 23.76086732319423 avg_loss_a: -64.55132993062337
Número de pasos del episodio 12158 son episode_steps:157
Total Steps: 767955 Episode Num: 12158 Reward: 41.66854266817934 avg_loss_c: 23.75093973366318 avg_loss_a: -63.67359292583101
Número de pasos del episodio 12159 son episode_steps:140
Total Steps: 768095 Episode Num: 12159 Reward: 70.76038348770427 avg_loss_c: 22.964177315575736 avg_loss_a: -63.36719589233398
Número de pasos del episodio 12160 son episode_steps:30
Total Steps: 768125 Episode Num: 12160 Reward: -35.48451448141823 avg_loss_c: 23.418983459472656 avg_loss_a: -62.91551513671875
Número de pasos del episodio 12161 son episode_steps:126
Total Steps: 768251 Episode Num: 12161 Reward: 63.00178399073102 avg_loss_c: 23.86109953834897 avg_loss_a: -63.209294758145774
Número de pasos del episodio 12162 son episode_steps:122
Total Steps: 768373 Episode Num: 12162 Reward: 69.92808818337183 avg_loss_c: 23.73214075995273 avg_loss_a: -63.80985735283523
Número de pasos del episodio 12163 son episode_steps:128
Total Steps: 768501 Episode Num: 12163 Reward: 85.60681267425632 avg_loss_c: 22.778413772583008 avg_loss_a: -64.55492049455643
Número de pasos del episodio 12164 son episode_steps:148
Total Steps: 768649 Episode Num: 12164 Reward: 97.62084035473154 avg_loss_c: 22.84363465695768 avg_loss_a: -64.3134765625
Número de pasos del episodio 12165 son episode_steps:37
Total Steps: 768686 Episode Num: 12165 Reward: -33.4673007307335 avg_loss_c: 23.280274520049225 avg_loss_a: -64.47839169888883
Número de pasos del episodio 12166 son episode_steps:208
Total Steps: 768894 Episode Num: 12166 Reward: 216.38023049283163 avg_loss_c: 23.038917092176582 avg_loss_a: -64.97451430100661
Número de pasos del episodio 12167 son episode_steps:84
Total Steps: 768978 Episode Num: 12167 Reward: 30.49263834697506 avg_loss_c: 22.582419508979434 avg_loss_a: -64.67644682384673
Número de pasos del episodio 12168 son episode_steps:96
Total Steps: 769074 Episode Num: 12168 Reward: 55.621384329577644 avg_loss_c: 23.060183823108673 avg_loss_a: -65.03092630704244
Número de pasos del episodio 12169 son episode_steps:59
Total Steps: 769133 Episode Num: 12169 Reward: -4.345955466753313 avg_loss_c: 22.57652694896116 avg_loss_a: -63.98050812543449
Número de pasos del episodio 12170 son episode_steps:34
Total Steps: 769167 Episode Num: 12170 Reward: -23.574447506136558 avg_loss_c: 22.354985265170825 avg_loss_a: -64.49088556626263
Número de pasos del episodio 12171 son episode_steps:51
Total Steps: 769218 Episode Num: 12171 Reward: 21.24601101759326 avg_loss_c: 23.098854551128312 avg_loss_a: -63.77335776534735
Número de pasos del episodio 12172 son episode_steps:60
Total Steps: 769278 Episode Num: 12172 Reward: -22.602429600517134 avg_loss_c: 23.15112450917562 avg_loss_a: -64.66264241536459
Número de pasos del episodio 12173 son episode_steps:38
Total Steps: 769316 Episode Num: 12173 Reward: -45.294391598451675 avg_loss_c: 24.887054870003148 avg_loss_a: -66.99082505075555
Número de pasos del episodio 12174 son episode_steps:102
Total Steps: 769418 Episode Num: 12174 Reward: 38.69441415061726 avg_loss_c: 23.382886316262038 avg_loss_a: -64.30074033550187
Número de pasos del episodio 12175 son episode_steps:38
Total Steps: 769456 Episode Num: 12175 Reward: -16.303723308877473 avg_loss_c: 24.469158272994193 avg_loss_a: -63.5980792798494
Número de pasos del episodio 12176 son episode_steps:25
Total Steps: 769481 Episode Num: 12176 Reward: -32.19479215904439 avg_loss_c: 25.110779418945313 avg_loss_a: -63.249237518310544
Número de pasos del episodio 12177 son episode_steps:62
Total Steps: 769543 Episode Num: 12177 Reward: -26.159408394603872 avg_loss_c: 24.558068183160596 avg_loss_a: -64.29125164401147
Número de pasos del episodio 12178 son episode_steps:97
Total Steps: 769640 Episode Num: 12178 Reward: 55.83608876942514 avg_loss_c: 22.953232942168246 avg_loss_a: -65.03395977216897
Número de pasos del episodio 12179 son episode_steps:116
Total Steps: 769756 Episode Num: 12179 Reward: 52.350335476661925 avg_loss_c: 24.637093815310248 avg_loss_a: -64.8833456368282
Número de pasos del episodio 12180 son episode_steps:111
Total Steps: 769867 Episode Num: 12180 Reward: 56.283695660323154 avg_loss_c: 23.255365612270595 avg_loss_a: -64.38075139501073
Número de pasos del episodio 12181 son episode_steps:89
Total Steps: 769956 Episode Num: 12181 Reward: 59.962761656257726 avg_loss_c: 23.22298287809565 avg_loss_a: -65.20452332228757
Número de pasos del episodio 12182 son episode_steps:114
Total Steps: 770070 Episode Num: 12182 Reward: 37.5959253978531 avg_loss_c: 24.725481209002044 avg_loss_a: -64.20970889978241
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 50.940854
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12183 son episode_steps:65
Total Steps: 770135 Episode Num: 12183 Reward: 33.21690453325151 avg_loss_c: 22.770704196049618 avg_loss_a: -64.26690192589393
Número de pasos del episodio 12184 son episode_steps:50
Total Steps: 770185 Episode Num: 12184 Reward: -34.89904135283578 avg_loss_c: 23.97839162826538 avg_loss_a: -64.76336059570312
Número de pasos del episodio 12185 son episode_steps:37
Total Steps: 770222 Episode Num: 12185 Reward: -28.393029959451468 avg_loss_c: 24.079663096247494 avg_loss_a: -64.16254198228991
Número de pasos del episodio 12186 son episode_steps:48
Total Steps: 770270 Episode Num: 12186 Reward: -7.80681168112905 avg_loss_c: 24.77908941109975 avg_loss_a: -63.16245190302531
Número de pasos del episodio 12187 son episode_steps:174
Total Steps: 770444 Episode Num: 12187 Reward: 57.28707348441035 avg_loss_c: 24.984492565023487 avg_loss_a: -64.5582661245061
Número de pasos del episodio 12188 son episode_steps:72
Total Steps: 770516 Episode Num: 12188 Reward: 2.2386607287243 avg_loss_c: 24.263754460546707 avg_loss_a: -64.23304589589436
Número de pasos del episodio 12189 son episode_steps:51
Total Steps: 770567 Episode Num: 12189 Reward: 17.989853800482678 avg_loss_c: 25.00904316995658 avg_loss_a: -64.06157609528186
Número de pasos del episodio 12190 son episode_steps:92
Total Steps: 770659 Episode Num: 12190 Reward: -20.565140931926297 avg_loss_c: 25.69493637914243 avg_loss_a: -64.5263380797013
Número de pasos del episodio 12191 son episode_steps:56
Total Steps: 770715 Episode Num: 12191 Reward: -27.15079159422798 avg_loss_c: 25.0161840234484 avg_loss_a: -64.9222868510655
Número de pasos del episodio 12192 son episode_steps:133
Total Steps: 770848 Episode Num: 12192 Reward: 77.56754285095009 avg_loss_c: 24.821334279569466 avg_loss_a: -63.266505764839344
Número de pasos del episodio 12193 son episode_steps:47
Total Steps: 770895 Episode Num: 12193 Reward: -22.70671902941668 avg_loss_c: 25.52361114988936 avg_loss_a: -64.59136248649435
Número de pasos del episodio 12194 son episode_steps:97
Total Steps: 770992 Episode Num: 12194 Reward: 54.49837224372587 avg_loss_c: 24.736148755574963 avg_loss_a: -63.06123265531874
Número de pasos del episodio 12195 son episode_steps:148
Total Steps: 771140 Episode Num: 12195 Reward: 97.03342962974627 avg_loss_c: 24.36826065424326 avg_loss_a: -62.15327974267908
Número de pasos del episodio 12196 son episode_steps:116
Total Steps: 771256 Episode Num: 12196 Reward: 37.311403063804754 avg_loss_c: 24.398559668968463 avg_loss_a: -63.58496639646333
Número de pasos del episodio 12197 son episode_steps:273
Total Steps: 771529 Episode Num: 12197 Reward: 200.2651562132978 avg_loss_c: 24.884171384594815 avg_loss_a: -64.09091950860216
Número de pasos del episodio 12198 son episode_steps:120
Total Steps: 771649 Episode Num: 12198 Reward: 71.6155311895117 avg_loss_c: 24.765941445032755 avg_loss_a: -63.88473415374756
Número de pasos del episodio 12199 son episode_steps:82
Total Steps: 771731 Episode Num: 12199 Reward: -9.896047155162229 avg_loss_c: 25.038356362319576 avg_loss_a: -63.435304595202936
Número de pasos del episodio 12200 son episode_steps:120
Total Steps: 771851 Episode Num: 12200 Reward: 105.4556409398564 avg_loss_c: 25.151554012298583 avg_loss_a: -64.16113986968995
Número de pasos del episodio 12201 son episode_steps:81
Total Steps: 771932 Episode Num: 12201 Reward: 41.2497918687074 avg_loss_c: 25.145955792179816 avg_loss_a: -64.54063547393422
Número de pasos del episodio 12202 son episode_steps:145
Total Steps: 772077 Episode Num: 12202 Reward: 119.38791341479178 avg_loss_c: 24.85140470307449 avg_loss_a: -63.70522984471815
Número de pasos del episodio 12203 son episode_steps:73
Total Steps: 772150 Episode Num: 12203 Reward: -3.762752565760574 avg_loss_c: 24.93305454515431 avg_loss_a: -63.65263533918825
Número de pasos del episodio 12204 son episode_steps:61
Total Steps: 772211 Episode Num: 12204 Reward: 6.267108276139375 avg_loss_c: 23.73572446479172 avg_loss_a: -64.808102467021
Número de pasos del episodio 12205 son episode_steps:42
Total Steps: 772253 Episode Num: 12205 Reward: -17.10572935188373 avg_loss_c: 24.598747071765718 avg_loss_a: -64.62030774071103
Número de pasos del episodio 12206 son episode_steps:71
Total Steps: 772324 Episode Num: 12206 Reward: -2.983836827540699 avg_loss_c: 25.136833540150818 avg_loss_a: -64.65289080982477
Número de pasos del episodio 12207 son episode_steps:74
Total Steps: 772398 Episode Num: 12207 Reward: -25.999163285285185 avg_loss_c: 25.24682514087574 avg_loss_a: -63.06611715780722
Número de pasos del episodio 12208 son episode_steps:59
Total Steps: 772457 Episode Num: 12208 Reward: -7.791251637221235 avg_loss_c: 26.255594221212096 avg_loss_a: -63.471540418721865
Número de pasos del episodio 12209 son episode_steps:156
Total Steps: 772613 Episode Num: 12209 Reward: 34.29010453718019 avg_loss_c: 25.67377937757052 avg_loss_a: -63.20125980866261
Número de pasos del episodio 12210 son episode_steps:118
Total Steps: 772731 Episode Num: 12210 Reward: 72.79545166868722 avg_loss_c: 24.569233231625315 avg_loss_a: -63.20587630191092
Número de pasos del episodio 12211 son episode_steps:139
Total Steps: 772870 Episode Num: 12211 Reward: 121.66579390383355 avg_loss_c: 23.941723953905722 avg_loss_a: -63.92181643479162
Número de pasos del episodio 12212 son episode_steps:44
Total Steps: 772914 Episode Num: 12212 Reward: -7.57895287485539 avg_loss_c: 24.181264183738016 avg_loss_a: -63.82069154219194
Número de pasos del episodio 12213 son episode_steps:37
Total Steps: 772951 Episode Num: 12213 Reward: -42.152416963727866 avg_loss_c: 25.32931900024414 avg_loss_a: -62.40474195738096
Número de pasos del episodio 12214 son episode_steps:94
Total Steps: 773045 Episode Num: 12214 Reward: -44.20986264059486 avg_loss_c: 24.903248969544755 avg_loss_a: -63.585756261297995
Número de pasos del episodio 12215 son episode_steps:54
Total Steps: 773099 Episode Num: 12215 Reward: 9.632842577063279 avg_loss_c: 24.774947572637487 avg_loss_a: -63.747457574915
Número de pasos del episodio 12216 son episode_steps:100
Total Steps: 773199 Episode Num: 12216 Reward: -71.73326411850753 avg_loss_c: 24.928588428497314 avg_loss_a: -62.84209342956543
Número de pasos del episodio 12217 son episode_steps:68
Total Steps: 773267 Episode Num: 12217 Reward: 32.570382010352446 avg_loss_c: 26.0156829216901 avg_loss_a: -63.086607203764075
Número de pasos del episodio 12218 son episode_steps:157
Total Steps: 773424 Episode Num: 12218 Reward: 71.47511234122948 avg_loss_c: 24.92056819891474 avg_loss_a: -63.6324215785713
Número de pasos del episodio 12219 son episode_steps:127
Total Steps: 773551 Episode Num: 12219 Reward: 98.85304631510037 avg_loss_c: 24.597367339246855 avg_loss_a: -63.76973472054549
Número de pasos del episodio 12220 son episode_steps:72
Total Steps: 773623 Episode Num: 12220 Reward: 35.92735330757715 avg_loss_c: 24.846872303220962 avg_loss_a: -62.99172878265381
Número de pasos del episodio 12221 son episode_steps:92
Total Steps: 773715 Episode Num: 12221 Reward: 43.89160258156994 avg_loss_c: 23.724187446677167 avg_loss_a: -63.91889489215353
Número de pasos del episodio 12222 son episode_steps:44
Total Steps: 773759 Episode Num: 12222 Reward: -1.558194956455727 avg_loss_c: 24.00095662203702 avg_loss_a: -63.24757870760831
Número de pasos del episodio 12223 son episode_steps:88
Total Steps: 773847 Episode Num: 12223 Reward: 55.952462363904836 avg_loss_c: 24.33286762237549 avg_loss_a: -63.70799801566384
Número de pasos del episodio 12224 son episode_steps:94
Total Steps: 773941 Episode Num: 12224 Reward: 33.2761884160495 avg_loss_c: 24.520117242285547 avg_loss_a: -63.73539912447016
Número de pasos del episodio 12225 son episode_steps:188
Total Steps: 774129 Episode Num: 12225 Reward: 94.76986610402582 avg_loss_c: 24.23542204309017 avg_loss_a: -63.628219645074076
Número de pasos del episodio 12226 son episode_steps:100
Total Steps: 774229 Episode Num: 12226 Reward: 20.465962035258006 avg_loss_c: 24.379688816070555 avg_loss_a: -63.15619110107422
Número de pasos del episodio 12227 son episode_steps:75
Total Steps: 774304 Episode Num: 12227 Reward: 63.73173204855786 avg_loss_c: 25.36940495808919 avg_loss_a: -62.90983093261719
Número de pasos del episodio 12228 son episode_steps:225
Total Steps: 774529 Episode Num: 12228 Reward: 185.65082767695867 avg_loss_c: 24.635122083028158 avg_loss_a: -64.13367750379774
Número de pasos del episodio 12229 son episode_steps:80
Total Steps: 774609 Episode Num: 12229 Reward: 12.51693406480223 avg_loss_c: 24.786502170562745 avg_loss_a: -63.9759635925293
Número de pasos del episodio 12230 son episode_steps:57
Total Steps: 774666 Episode Num: 12230 Reward: 26.57452904395507 avg_loss_c: 24.40750373037238 avg_loss_a: -63.100991232353344
Número de pasos del episodio 12231 son episode_steps:72
Total Steps: 774738 Episode Num: 12231 Reward: 31.095201894171986 avg_loss_c: 25.02190022998386 avg_loss_a: -63.69854895273844
Número de pasos del episodio 12232 son episode_steps:102
Total Steps: 774840 Episode Num: 12232 Reward: 86.70916872494992 avg_loss_c: 23.73157235687854 avg_loss_a: -63.63896134320427
Número de pasos del episodio 12233 son episode_steps:66
Total Steps: 774906 Episode Num: 12233 Reward: 40.65693658945779 avg_loss_c: 23.24816559300278 avg_loss_a: -63.79080096158114
Número de pasos del episodio 12234 son episode_steps:61
Total Steps: 774967 Episode Num: 12234 Reward: -47.9020725441371 avg_loss_c: 24.55431869381764 avg_loss_a: -64.23792717105053
Número de pasos del episodio 12235 son episode_steps:56
Total Steps: 775023 Episode Num: 12235 Reward: 11.394133925758137 avg_loss_c: 24.726689764431544 avg_loss_a: -62.6234621320452
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 121.653352
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12236 son episode_steps:67
Total Steps: 775090 Episode Num: 12236 Reward: 10.271075954518734 avg_loss_c: 24.251328112474127 avg_loss_a: -62.768076426947296
Número de pasos del episodio 12237 son episode_steps:117
Total Steps: 775207 Episode Num: 12237 Reward: -16.518950806409244 avg_loss_c: 24.822377571692833 avg_loss_a: -63.55384507138505
Número de pasos del episodio 12238 son episode_steps:111
Total Steps: 775318 Episode Num: 12238 Reward: 76.4949694837457 avg_loss_c: 25.2932470682505 avg_loss_a: -62.41337145556201
Número de pasos del episodio 12239 son episode_steps:67
Total Steps: 775385 Episode Num: 12239 Reward: 18.26898906025441 avg_loss_c: 26.002091621285054 avg_loss_a: -63.30731895788392
Número de pasos del episodio 12240 son episode_steps:168
Total Steps: 775553 Episode Num: 12240 Reward: 121.20191839657603 avg_loss_c: 24.00140344528925 avg_loss_a: -63.483399890718005
Número de pasos del episodio 12241 son episode_steps:46
Total Steps: 775599 Episode Num: 12241 Reward: 1.3697904999986452 avg_loss_c: 25.672937227332074 avg_loss_a: -62.58790737649669
Número de pasos del episodio 12242 son episode_steps:45
Total Steps: 775644 Episode Num: 12242 Reward: 4.506698313827783 avg_loss_c: 24.833632363213432 avg_loss_a: -63.53410407172309
Número de pasos del episodio 12243 son episode_steps:105
Total Steps: 775749 Episode Num: 12243 Reward: 3.825509634823243 avg_loss_c: 24.525258400326685 avg_loss_a: -63.615247453962056
Número de pasos del episodio 12244 son episode_steps:141
Total Steps: 775890 Episode Num: 12244 Reward: -71.7265809549332 avg_loss_c: 25.719625094258195 avg_loss_a: -62.37046283694869
Número de pasos del episodio 12245 son episode_steps:161
Total Steps: 776051 Episode Num: 12245 Reward: 70.61187525815812 avg_loss_c: 25.248480696115436 avg_loss_a: -63.02668468404261
Número de pasos del episodio 12246 son episode_steps:210
Total Steps: 776261 Episode Num: 12246 Reward: 127.55646990042015 avg_loss_c: 24.943615777151926 avg_loss_a: -63.911454082670666
Número de pasos del episodio 12247 son episode_steps:113
Total Steps: 776374 Episode Num: 12247 Reward: 37.52539869253437 avg_loss_c: 24.94901505191769 avg_loss_a: -64.15809979059
Número de pasos del episodio 12248 son episode_steps:163
Total Steps: 776537 Episode Num: 12248 Reward: 173.47356498871974 avg_loss_c: 24.86063799243763 avg_loss_a: -64.46816300468211
Número de pasos del episodio 12249 son episode_steps:50
Total Steps: 776587 Episode Num: 12249 Reward: -25.120226365398175 avg_loss_c: 24.101169147491454 avg_loss_a: -64.9260888671875
Número de pasos del episodio 12250 son episode_steps:38
Total Steps: 776625 Episode Num: 12250 Reward: -21.882203680904134 avg_loss_c: 26.329842567443848 avg_loss_a: -63.36635870682566
Número de pasos del episodio 12251 son episode_steps:103
Total Steps: 776728 Episode Num: 12251 Reward: 25.090910681103473 avg_loss_c: 26.065952375097183 avg_loss_a: -63.8900014266227
Número de pasos del episodio 12252 son episode_steps:56
Total Steps: 776784 Episode Num: 12252 Reward: -17.633275868753742 avg_loss_c: 25.410351072038925 avg_loss_a: -63.420346805027556
Número de pasos del episodio 12253 son episode_steps:264
Total Steps: 777048 Episode Num: 12253 Reward: 205.1965823201561 avg_loss_c: 24.983800158356175 avg_loss_a: -64.37979900475705
Número de pasos del episodio 12254 son episode_steps:127
Total Steps: 777175 Episode Num: 12254 Reward: 59.23408300974587 avg_loss_c: 24.831554217601386 avg_loss_a: -63.46097468578909
Número de pasos del episodio 12255 son episode_steps:49
Total Steps: 777224 Episode Num: 12255 Reward: 1.1873167886161633 avg_loss_c: 25.862056810028697 avg_loss_a: -63.14185831498126
Número de pasos del episodio 12256 son episode_steps:169
Total Steps: 777393 Episode Num: 12256 Reward: 179.76486788116156 avg_loss_c: 24.768761809761003 avg_loss_a: -65.07097846939719
Número de pasos del episodio 12257 son episode_steps:47
Total Steps: 777440 Episode Num: 12257 Reward: -19.801260448895107 avg_loss_c: 24.3899697648718 avg_loss_a: -63.32384961716672
Número de pasos del episodio 12258 son episode_steps:78
Total Steps: 777518 Episode Num: 12258 Reward: -24.326608587928785 avg_loss_c: 25.48202385046543 avg_loss_a: -65.29179362761668
Número de pasos del episodio 12259 son episode_steps:155
Total Steps: 777673 Episode Num: 12259 Reward: 111.34503800797894 avg_loss_c: 24.770717257838097 avg_loss_a: -65.08177042315083
Número de pasos del episodio 12260 son episode_steps:69
Total Steps: 777742 Episode Num: 12260 Reward: 40.31343251350539 avg_loss_c: 23.803682382555976 avg_loss_a: -65.43659740945567
Número de pasos del episodio 12261 son episode_steps:60
Total Steps: 777802 Episode Num: 12261 Reward: -45.15379188432844 avg_loss_c: 24.52404702504476 avg_loss_a: -65.70720799763997
Número de pasos del episodio 12262 son episode_steps:58
Total Steps: 777860 Episode Num: 12262 Reward: -11.974609094354566 avg_loss_c: 25.58010275610562 avg_loss_a: -64.59874475413355
Número de pasos del episodio 12263 son episode_steps:52
Total Steps: 777912 Episode Num: 12263 Reward: -2.079984033273489 avg_loss_c: 23.9947519669166 avg_loss_a: -63.91645035376916
Número de pasos del episodio 12264 son episode_steps:74
Total Steps: 777986 Episode Num: 12264 Reward: 30.405286085436497 avg_loss_c: 24.90300165640341 avg_loss_a: -64.15730357814479
Número de pasos del episodio 12265 son episode_steps:44
Total Steps: 778030 Episode Num: 12265 Reward: -12.607515351443167 avg_loss_c: 24.557668685913086 avg_loss_a: -63.393686121160336
Número de pasos del episodio 12266 son episode_steps:134
Total Steps: 778164 Episode Num: 12266 Reward: 107.42045403695201 avg_loss_c: 24.75291479879351 avg_loss_a: -64.83270713464537
Número de pasos del episodio 12267 son episode_steps:72
Total Steps: 778236 Episode Num: 12267 Reward: -29.867065971794446 avg_loss_c: 24.746630430221558 avg_loss_a: -63.31556701660156
Número de pasos del episodio 12268 son episode_steps:99
Total Steps: 778335 Episode Num: 12268 Reward: -10.19096861655363 avg_loss_c: 26.314262968121152 avg_loss_a: -64.55967974421954
Número de pasos del episodio 12269 son episode_steps:51
Total Steps: 778386 Episode Num: 12269 Reward: -4.236814753931171 avg_loss_c: 24.390368629904355 avg_loss_a: -63.646084355373006
Número de pasos del episodio 12270 son episode_steps:22
Total Steps: 778408 Episode Num: 12270 Reward: -39.311917692217584 avg_loss_c: 25.879127068953082 avg_loss_a: -66.62660460038619
Número de pasos del episodio 12271 son episode_steps:119
Total Steps: 778527 Episode Num: 12271 Reward: 72.15554531946279 avg_loss_c: 25.700404527808438 avg_loss_a: -63.80279553838137
Número de pasos del episodio 12272 son episode_steps:135
Total Steps: 778662 Episode Num: 12272 Reward: 116.8739939609911 avg_loss_c: 25.538164915861906 avg_loss_a: -64.25767372979058
Número de pasos del episodio 12273 son episode_steps:42
Total Steps: 778704 Episode Num: 12273 Reward: -4.635817978528994 avg_loss_c: 26.652159872509184 avg_loss_a: -61.76619357154483
Número de pasos del episodio 12274 son episode_steps:127
Total Steps: 778831 Episode Num: 12274 Reward: 1.914139966731466 avg_loss_c: 27.08432558014637 avg_loss_a: -63.56509345347487
Número de pasos del episodio 12275 son episode_steps:124
Total Steps: 778955 Episode Num: 12275 Reward: 37.51310991449559 avg_loss_c: 26.595428036105247 avg_loss_a: -63.26551345086867
Número de pasos del episodio 12276 son episode_steps:105
Total Steps: 779060 Episode Num: 12276 Reward: 31.67687915170045 avg_loss_c: 27.091753805251347 avg_loss_a: -62.79872334798177
Número de pasos del episodio 12277 son episode_steps:19
Total Steps: 779079 Episode Num: 12277 Reward: -49.23156166685544 avg_loss_c: 25.446523867155378 avg_loss_a: -63.1232207448859
Número de pasos del episodio 12278 son episode_steps:24
Total Steps: 779103 Episode Num: 12278 Reward: -13.061284903639091 avg_loss_c: 27.001089970270794 avg_loss_a: -64.16738033294678
Número de pasos del episodio 12279 son episode_steps:24
Total Steps: 779127 Episode Num: 12279 Reward: -21.87918302660958 avg_loss_c: 26.33512592315674 avg_loss_a: -62.948085149129234
Número de pasos del episodio 12280 son episode_steps:89
Total Steps: 779216 Episode Num: 12280 Reward: 55.759497249741536 avg_loss_c: 26.46634914098161 avg_loss_a: -63.022721365596475
Número de pasos del episodio 12281 son episode_steps:40
Total Steps: 779256 Episode Num: 12281 Reward: -18.815318910317004 avg_loss_c: 26.344321918487548 avg_loss_a: -63.91982307434082
Número de pasos del episodio 12282 son episode_steps:84
Total Steps: 779340 Episode Num: 12282 Reward: 11.03582072237622 avg_loss_c: 25.872104781014578 avg_loss_a: -62.82456688653855
Número de pasos del episodio 12283 son episode_steps:87
Total Steps: 779427 Episode Num: 12283 Reward: 48.62211329095115 avg_loss_c: 25.525037305108434 avg_loss_a: -63.16466653758082
Número de pasos del episodio 12284 son episode_steps:40
Total Steps: 779467 Episode Num: 12284 Reward: -0.7025989923491447 avg_loss_c: 25.805993270874023 avg_loss_a: -61.52634220123291
Número de pasos del episodio 12285 son episode_steps:135
Total Steps: 779602 Episode Num: 12285 Reward: 102.09130592059938 avg_loss_c: 26.562240339208532 avg_loss_a: -62.70972798665365
Número de pasos del episodio 12286 son episode_steps:60
Total Steps: 779662 Episode Num: 12286 Reward: -8.170235690329427 avg_loss_c: 26.258682664235433 avg_loss_a: -62.49210713704427
Número de pasos del episodio 12287 son episode_steps:77
Total Steps: 779739 Episode Num: 12287 Reward: 25.033632292589648 avg_loss_c: 25.69045321972339 avg_loss_a: -62.10461267248377
Número de pasos del episodio 12288 son episode_steps:20
Total Steps: 779759 Episode Num: 12288 Reward: -23.90798739316899 avg_loss_c: 26.634369373321533 avg_loss_a: -61.33468322753906
Número de pasos del episodio 12289 son episode_steps:67
Total Steps: 779826 Episode Num: 12289 Reward: -37.56335661263743 avg_loss_c: 25.983243259031383 avg_loss_a: -63.05787174737276
Número de pasos del episodio 12290 son episode_steps:71
Total Steps: 779897 Episode Num: 12290 Reward: -42.00824021802838 avg_loss_c: 27.624676959615357 avg_loss_a: -62.97403448400363
Número de pasos del episodio 12291 son episode_steps:60
Total Steps: 779957 Episode Num: 12291 Reward: 17.262267752587732 avg_loss_c: 27.470230865478516 avg_loss_a: -62.805843353271484
Número de pasos del episodio 12292 son episode_steps:158
Total Steps: 780115 Episode Num: 12292 Reward: 141.60209493509933 avg_loss_c: 26.58770746520803 avg_loss_a: -62.952519332306295
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 76.874943
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12293 son episode_steps:75
Total Steps: 780190 Episode Num: 12293 Reward: -2.5630842237304217 avg_loss_c: 26.20094741821289 avg_loss_a: -62.10527338663737
Número de pasos del episodio 12294 son episode_steps:61
Total Steps: 780251 Episode Num: 12294 Reward: 5.4878769996262236 avg_loss_c: 26.458985750792458 avg_loss_a: -63.402756988025104
Número de pasos del episodio 12295 son episode_steps:27
Total Steps: 780278 Episode Num: 12295 Reward: -20.75750882126648 avg_loss_c: 27.707829228153937 avg_loss_a: -64.52964712072301
Número de pasos del episodio 12296 son episode_steps:88
Total Steps: 780366 Episode Num: 12296 Reward: 17.81238201913709 avg_loss_c: 26.76068022034385 avg_loss_a: -62.383367104963824
Número de pasos del episodio 12297 son episode_steps:128
Total Steps: 780494 Episode Num: 12297 Reward: 86.91533248688759 avg_loss_c: 26.789289325475693 avg_loss_a: -63.42778968811035
Número de pasos del episodio 12298 son episode_steps:98
Total Steps: 780592 Episode Num: 12298 Reward: 4.699327370026447 avg_loss_c: 26.34701631507095 avg_loss_a: -63.8561633363062
Número de pasos del episodio 12299 son episode_steps:88
Total Steps: 780680 Episode Num: 12299 Reward: 34.52748196292261 avg_loss_c: 26.51313549822027 avg_loss_a: -62.90080321918834
Número de pasos del episodio 12300 son episode_steps:221
Total Steps: 780901 Episode Num: 12300 Reward: 171.83456364063417 avg_loss_c: 26.905643411351544 avg_loss_a: -63.219491932726555
Número de pasos del episodio 12301 son episode_steps:87
Total Steps: 780988 Episode Num: 12301 Reward: 60.614419998589874 avg_loss_c: 25.846099700050793 avg_loss_a: -63.05990477814071
Número de pasos del episodio 12302 son episode_steps:95
Total Steps: 781083 Episode Num: 12302 Reward: 4.8420132901493576 avg_loss_c: 27.325183386551707 avg_loss_a: -63.19126498573705
Número de pasos del episodio 12303 son episode_steps:72
Total Steps: 781155 Episode Num: 12303 Reward: 26.77371284743799 avg_loss_c: 25.715742031733196 avg_loss_a: -62.48076354132758
Número de pasos del episodio 12304 son episode_steps:162
Total Steps: 781317 Episode Num: 12304 Reward: 73.97364744522663 avg_loss_c: 27.403018056610485 avg_loss_a: -63.87927665239499
Número de pasos del episodio 12305 son episode_steps:40
Total Steps: 781357 Episode Num: 12305 Reward: -10.63252874007797 avg_loss_c: 26.22956986427307 avg_loss_a: -64.18785820007324
Número de pasos del episodio 12306 son episode_steps:41
Total Steps: 781398 Episode Num: 12306 Reward: -33.11500755485374 avg_loss_c: 25.49238302649521 avg_loss_a: -63.49062486974204
Número de pasos del episodio 12307 son episode_steps:57
Total Steps: 781455 Episode Num: 12307 Reward: 15.781489978508091 avg_loss_c: 27.744451991298742 avg_loss_a: -63.194418254651524
Número de pasos del episodio 12308 son episode_steps:95
Total Steps: 781550 Episode Num: 12308 Reward: 75.49911443740837 avg_loss_c: 27.12950573971397 avg_loss_a: -62.640615443179485
Número de pasos del episodio 12309 son episode_steps:165
Total Steps: 781715 Episode Num: 12309 Reward: 93.5571300311417 avg_loss_c: 25.5392389644276 avg_loss_a: -62.84514321991892
Número de pasos del episodio 12310 son episode_steps:150
Total Steps: 781865 Episode Num: 12310 Reward: 98.3203045896903 avg_loss_c: 26.656239687601726 avg_loss_a: -63.051262613932295
Número de pasos del episodio 12311 son episode_steps:103
Total Steps: 781968 Episode Num: 12311 Reward: 73.10072631266206 avg_loss_c: 26.009342175085568 avg_loss_a: -63.30658999693046
Número de pasos del episodio 12312 son episode_steps:199
Total Steps: 782167 Episode Num: 12312 Reward: 125.64422531088188 avg_loss_c: 25.471559845622462 avg_loss_a: -62.8764365498145
Número de pasos del episodio 12313 son episode_steps:135
Total Steps: 782302 Episode Num: 12313 Reward: 83.88909076819564 avg_loss_c: 26.10635819611726 avg_loss_a: -63.40440131293403
Número de pasos del episodio 12314 son episode_steps:57
Total Steps: 782359 Episode Num: 12314 Reward: 19.635093406794976 avg_loss_c: 26.62626932378401 avg_loss_a: -64.14676224557977
Número de pasos del episodio 12315 son episode_steps:95
Total Steps: 782454 Episode Num: 12315 Reward: 4.178180738166912 avg_loss_c: 26.23282605221397 avg_loss_a: -64.17697047183388
Número de pasos del episodio 12316 son episode_steps:90
Total Steps: 782544 Episode Num: 12316 Reward: -28.951203493091036 avg_loss_c: 25.25588455200195 avg_loss_a: -63.60649354722765
Número de pasos del episodio 12317 son episode_steps:156
Total Steps: 782700 Episode Num: 12317 Reward: 111.87002833262083 avg_loss_c: 26.582384891999073 avg_loss_a: -63.62540455353566
Número de pasos del episodio 12318 son episode_steps:53
Total Steps: 782753 Episode Num: 12318 Reward: 8.887799026550157 avg_loss_c: 25.431277149128466 avg_loss_a: -62.772588046091904
Número de pasos del episodio 12319 son episode_steps:79
Total Steps: 782832 Episode Num: 12319 Reward: 5.192661588400127 avg_loss_c: 25.27674518054045 avg_loss_a: -62.05595079252991
Número de pasos del episodio 12320 son episode_steps:71
Total Steps: 782903 Episode Num: 12320 Reward: -24.375251435981987 avg_loss_c: 26.75189028995138 avg_loss_a: -61.86897632437692
Número de pasos del episodio 12321 son episode_steps:87
Total Steps: 782990 Episode Num: 12321 Reward: 46.140312979605575 avg_loss_c: 26.22632074904168 avg_loss_a: -63.297045477505385
Número de pasos del episodio 12322 son episode_steps:43
Total Steps: 783033 Episode Num: 12322 Reward: -12.687932614423111 avg_loss_c: 27.053942037183184 avg_loss_a: -61.58652726994004
Número de pasos del episodio 12323 son episode_steps:56
Total Steps: 783089 Episode Num: 12323 Reward: -14.74589737590162 avg_loss_c: 26.209848131452286 avg_loss_a: -62.39486163003104
Número de pasos del episodio 12324 son episode_steps:182
Total Steps: 783271 Episode Num: 12324 Reward: 142.29439842506173 avg_loss_c: 26.406116349356516 avg_loss_a: -62.607718331473215
Número de pasos del episodio 12325 son episode_steps:184
Total Steps: 783455 Episode Num: 12325 Reward: 81.68237403694518 avg_loss_c: 26.2669749363609 avg_loss_a: -62.32172360627548
Número de pasos del episodio 12326 son episode_steps:105
Total Steps: 783560 Episode Num: 12326 Reward: -59.80385275297486 avg_loss_c: 25.65033467610677 avg_loss_a: -62.789520772298175
Número de pasos del episodio 12327 son episode_steps:103
Total Steps: 783663 Episode Num: 12327 Reward: 18.953861674723598 avg_loss_c: 26.82868503829808 avg_loss_a: -63.198122450448935
Número de pasos del episodio 12328 son episode_steps:180
Total Steps: 783843 Episode Num: 12328 Reward: 97.66148657071446 avg_loss_c: 26.569245433807374 avg_loss_a: -63.26935602823893
Número de pasos del episodio 12329 son episode_steps:199
Total Steps: 784042 Episode Num: 12329 Reward: 126.19673760992364 avg_loss_c: 26.02465373187808 avg_loss_a: -62.71953615351538
Número de pasos del episodio 12330 son episode_steps:118
Total Steps: 784160 Episode Num: 12330 Reward: 49.22504714794791 avg_loss_c: 25.276963080390026 avg_loss_a: -62.775385193905585
Número de pasos del episodio 12331 son episode_steps:187
Total Steps: 784347 Episode Num: 12331 Reward: 90.01586594762257 avg_loss_c: 26.103221719915215 avg_loss_a: -63.413043935031176
Número de pasos del episodio 12332 son episode_steps:42
Total Steps: 784389 Episode Num: 12332 Reward: -12.549252123447125 avg_loss_c: 25.938294728597004 avg_loss_a: -63.936864762079146
Número de pasos del episodio 12333 son episode_steps:87
Total Steps: 784476 Episode Num: 12333 Reward: 45.12797500666277 avg_loss_c: 26.956161411329248 avg_loss_a: -63.648456091168285
Número de pasos del episodio 12334 son episode_steps:263
Total Steps: 784739 Episode Num: 12334 Reward: 169.36571943911966 avg_loss_c: 25.426739627417504 avg_loss_a: -63.618013737319544
Número de pasos del episodio 12335 son episode_steps:96
Total Steps: 784835 Episode Num: 12335 Reward: 26.575804459925674 avg_loss_c: 25.51172544558843 avg_loss_a: -64.38567980130513
Número de pasos del episodio 12336 son episode_steps:220
Total Steps: 785055 Episode Num: 12336 Reward: 155.52983089788316 avg_loss_c: 25.702184694463558 avg_loss_a: -63.469720528342506
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 103.127105
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12337 son episode_steps:23
Total Steps: 785078 Episode Num: 12337 Reward: -20.72383770235753 avg_loss_c: 27.76231334520423 avg_loss_a: -63.735682446023695
Número de pasos del episodio 12338 son episode_steps:59
Total Steps: 785137 Episode Num: 12338 Reward: -0.08497085877562593 avg_loss_c: 27.006934085134734 avg_loss_a: -62.642735885361496
Número de pasos del episodio 12339 son episode_steps:58
Total Steps: 785195 Episode Num: 12339 Reward: 28.90769421468528 avg_loss_c: 26.592565536499023 avg_loss_a: -63.32921600341797
Número de pasos del episodio 12340 son episode_steps:71
Total Steps: 785266 Episode Num: 12340 Reward: 59.90948260683894 avg_loss_c: 24.797786309685506 avg_loss_a: -63.524106200312225
Número de pasos del episodio 12341 son episode_steps:68
Total Steps: 785334 Episode Num: 12341 Reward: 48.26240118055602 avg_loss_c: 25.316224645165835 avg_loss_a: -63.11047150106991
Número de pasos del episodio 12342 son episode_steps:19
Total Steps: 785353 Episode Num: 12342 Reward: -24.843063646088986 avg_loss_c: 25.759069844296103 avg_loss_a: -64.7844766315661
Número de pasos del episodio 12343 son episode_steps:184
Total Steps: 785537 Episode Num: 12343 Reward: 123.50198223673632 avg_loss_c: 24.62938036089358 avg_loss_a: -63.71838569641113
Número de pasos del episodio 12344 son episode_steps:70
Total Steps: 785607 Episode Num: 12344 Reward: -14.62496508618914 avg_loss_c: 25.649549729483468 avg_loss_a: -63.40354984828404
Número de pasos del episodio 12345 son episode_steps:101
Total Steps: 785708 Episode Num: 12345 Reward: 25.333458359855626 avg_loss_c: 25.87369966979074 avg_loss_a: -62.99392824833936
Número de pasos del episodio 12346 son episode_steps:51
Total Steps: 785759 Episode Num: 12346 Reward: -10.550242818475581 avg_loss_c: 25.587114595899394 avg_loss_a: -63.604960871677775
Número de pasos del episodio 12347 son episode_steps:112
Total Steps: 785871 Episode Num: 12347 Reward: 43.194974503666195 avg_loss_c: 25.586506417819432 avg_loss_a: -63.03411878858294
Número de pasos del episodio 12348 son episode_steps:23
Total Steps: 785894 Episode Num: 12348 Reward: -28.28701599387733 avg_loss_c: 24.753174491550613 avg_loss_a: -61.01240257594896
Número de pasos del episodio 12349 son episode_steps:163
Total Steps: 786057 Episode Num: 12349 Reward: 92.67696016752491 avg_loss_c: 25.387743130783363 avg_loss_a: -64.06978394209973
Número de pasos del episodio 12350 son episode_steps:127
Total Steps: 786184 Episode Num: 12350 Reward: 102.5283708330841 avg_loss_c: 25.9381853539174 avg_loss_a: -63.600589602012334
Número de pasos del episodio 12351 son episode_steps:41
Total Steps: 786225 Episode Num: 12351 Reward: -6.174353458631334 avg_loss_c: 25.723509439607945 avg_loss_a: -63.04317064983089
Número de pasos del episodio 12352 son episode_steps:82
Total Steps: 786307 Episode Num: 12352 Reward: -2.5713956680575762 avg_loss_c: 25.144708784615123 avg_loss_a: -64.00345025411467
Número de pasos del episodio 12353 son episode_steps:55
Total Steps: 786362 Episode Num: 12353 Reward: -69.80976225607968 avg_loss_c: 26.98583211031827 avg_loss_a: -63.19897516424005
Número de pasos del episodio 12354 son episode_steps:102
Total Steps: 786464 Episode Num: 12354 Reward: 50.842422100110646 avg_loss_c: 27.454414405074775 avg_loss_a: -63.03596526501226
Número de pasos del episodio 12355 son episode_steps:122
Total Steps: 786586 Episode Num: 12355 Reward: 37.27301785526323 avg_loss_c: 26.10757844956195 avg_loss_a: -63.58322756407691
Número de pasos del episodio 12356 son episode_steps:62
Total Steps: 786648 Episode Num: 12356 Reward: 17.26044923647717 avg_loss_c: 25.45304076902328 avg_loss_a: -62.69398978448683
Número de pasos del episodio 12357 son episode_steps:65
Total Steps: 786713 Episode Num: 12357 Reward: 30.874175091423464 avg_loss_c: 26.268918668306792 avg_loss_a: -62.77141060462365
Número de pasos del episodio 12358 son episode_steps:132
Total Steps: 786845 Episode Num: 12358 Reward: -27.477500495825325 avg_loss_c: 25.740266799926758 avg_loss_a: -63.197205341223516
Número de pasos del episodio 12359 son episode_steps:253
Total Steps: 787098 Episode Num: 12359 Reward: 180.73570566619782 avg_loss_c: 26.297140125229426 avg_loss_a: -63.0751284572918
Número de pasos del episodio 12360 son episode_steps:148
Total Steps: 787246 Episode Num: 12360 Reward: 109.21653119815078 avg_loss_c: 25.63139366459202 avg_loss_a: -62.534096795159414
Número de pasos del episodio 12361 son episode_steps:29
Total Steps: 787275 Episode Num: 12361 Reward: -23.710042467059097 avg_loss_c: 26.7181229426943 avg_loss_a: -63.02723904313712
Número de pasos del episodio 12362 son episode_steps:105
Total Steps: 787380 Episode Num: 12362 Reward: 23.81462522929062 avg_loss_c: 26.148543475923084 avg_loss_a: -62.91260521298363
Número de pasos del episodio 12363 son episode_steps:222
Total Steps: 787602 Episode Num: 12363 Reward: 107.04678114760222 avg_loss_c: 26.76207231401323 avg_loss_a: -63.00020369108733
Número de pasos del episodio 12364 son episode_steps:20
Total Steps: 787622 Episode Num: 12364 Reward: -34.81497120757901 avg_loss_c: 26.65227680206299 avg_loss_a: -61.15996627807617
Número de pasos del episodio 12365 son episode_steps:282
Total Steps: 787904 Episode Num: 12365 Reward: 230.87059902482565 avg_loss_c: 25.926009333725517 avg_loss_a: -62.88339384904145
Número de pasos del episodio 12366 son episode_steps:331
Total Steps: 788235 Episode Num: 12366 Reward: 157.02644502125366 avg_loss_c: 25.57371074411444 avg_loss_a: -63.69941909651742
Número de pasos del episodio 12367 son episode_steps:198
Total Steps: 788433 Episode Num: 12367 Reward: 101.35160538046073 avg_loss_c: 24.747737258371682 avg_loss_a: -63.2599404074929
Número de pasos del episodio 12368 son episode_steps:84
Total Steps: 788517 Episode Num: 12368 Reward: -18.955289412685975 avg_loss_c: 24.90807798930577 avg_loss_a: -63.26689992632185
Número de pasos del episodio 12369 son episode_steps:22
Total Steps: 788539 Episode Num: 12369 Reward: -22.243554509183 avg_loss_c: 23.611443346196953 avg_loss_a: -61.84210066361861
Número de pasos del episodio 12370 son episode_steps:149
Total Steps: 788688 Episode Num: 12370 Reward: -0.9542933582523112 avg_loss_c: 26.90777878473269 avg_loss_a: -63.43272973387033
Número de pasos del episodio 12371 son episode_steps:577
Total Steps: 789265 Episode Num: 12371 Reward: 430.39845094738183 avg_loss_c: 24.895560976950712 avg_loss_a: -63.581823973763136
Número de pasos del episodio 12372 son episode_steps:51
Total Steps: 789316 Episode Num: 12372 Reward: 8.20117139981689 avg_loss_c: 23.414616883969774 avg_loss_a: -63.03422052720014
Número de pasos del episodio 12373 son episode_steps:85
Total Steps: 789401 Episode Num: 12373 Reward: -9.537853573335052 avg_loss_c: 24.31986090716194 avg_loss_a: -64.40528286204619
Número de pasos del episodio 12374 son episode_steps:136
Total Steps: 789537 Episode Num: 12374 Reward: 87.64110704487076 avg_loss_c: 24.36924323614906 avg_loss_a: -64.08548831939697
Número de pasos del episodio 12375 son episode_steps:102
Total Steps: 789639 Episode Num: 12375 Reward: 72.61802176042553 avg_loss_c: 24.66788050707649 avg_loss_a: -64.23470972098556
Número de pasos del episodio 12376 son episode_steps:155
Total Steps: 789794 Episode Num: 12376 Reward: 121.05199869780681 avg_loss_c: 24.469718822356192 avg_loss_a: -63.74669772732642
Número de pasos del episodio 12377 son episode_steps:80
Total Steps: 789874 Episode Num: 12377 Reward: 33.10954508964118 avg_loss_c: 24.832056522369385 avg_loss_a: -62.99718723297119
Número de pasos del episodio 12378 son episode_steps:40
Total Steps: 789914 Episode Num: 12378 Reward: -73.76975818690984 avg_loss_c: 25.652016353607177 avg_loss_a: -64.87403259277343
Número de pasos del episodio 12379 son episode_steps:47
Total Steps: 789961 Episode Num: 12379 Reward: -31.64695478860174 avg_loss_c: 25.78546771597355 avg_loss_a: -64.78997754036112
Número de pasos del episodio 12380 son episode_steps:121
Total Steps: 790082 Episode Num: 12380 Reward: 78.48072524809776 avg_loss_c: 25.24919834609859 avg_loss_a: -64.35824972735949
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 76.133146
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12381 son episode_steps:153
Total Steps: 790235 Episode Num: 12381 Reward: 92.27416467116315 avg_loss_c: 25.070807637732013 avg_loss_a: -63.49278376460855
Número de pasos del episodio 12382 son episode_steps:54
Total Steps: 790289 Episode Num: 12382 Reward: 5.087385994402923 avg_loss_c: 25.59493421625208 avg_loss_a: -63.817158451786746
Número de pasos del episodio 12383 son episode_steps:177
Total Steps: 790466 Episode Num: 12383 Reward: 101.45765701980984 avg_loss_c: 25.47536189407952 avg_loss_a: -64.03126849158336
Número de pasos del episodio 12384 son episode_steps:64
Total Steps: 790530 Episode Num: 12384 Reward: 33.745434285617776 avg_loss_c: 25.06263166666031 avg_loss_a: -64.19860208034515
Número de pasos del episodio 12385 son episode_steps:59
Total Steps: 790589 Episode Num: 12385 Reward: -10.791396585612043 avg_loss_c: 24.91683070942507 avg_loss_a: -63.528524237164
Número de pasos del episodio 12386 son episode_steps:90
Total Steps: 790679 Episode Num: 12386 Reward: 38.284720511872834 avg_loss_c: 25.335296863979764 avg_loss_a: -62.988016510009764
Número de pasos del episodio 12387 son episode_steps:55
Total Steps: 790734 Episode Num: 12387 Reward: 24.71762397781682 avg_loss_c: 26.247617704218083 avg_loss_a: -64.63327858664773
Número de pasos del episodio 12388 son episode_steps:114
Total Steps: 790848 Episode Num: 12388 Reward: 34.519370911203964 avg_loss_c: 25.43616189454731 avg_loss_a: -63.45806483218544
Número de pasos del episodio 12389 son episode_steps:95
Total Steps: 790943 Episode Num: 12389 Reward: -0.4255702968226389 avg_loss_c: 26.593202490555612 avg_loss_a: -63.23731247751336
Número de pasos del episodio 12390 son episode_steps:59
Total Steps: 791002 Episode Num: 12390 Reward: -45.814015848468685 avg_loss_c: 25.766176159098997 avg_loss_a: -63.39046969656217
Número de pasos del episodio 12391 son episode_steps:93
Total Steps: 791095 Episode Num: 12391 Reward: 40.205599543347546 avg_loss_c: 26.845356049076205 avg_loss_a: -63.146503325431574
Número de pasos del episodio 12392 son episode_steps:311
Total Steps: 791406 Episode Num: 12392 Reward: 289.59205477502394 avg_loss_c: 24.922005840436437 avg_loss_a: -63.61446560924076
Número de pasos del episodio 12393 son episode_steps:76
Total Steps: 791482 Episode Num: 12393 Reward: 34.831598587119665 avg_loss_c: 23.995880528500205 avg_loss_a: -63.624793805574114
Número de pasos del episodio 12394 son episode_steps:52
Total Steps: 791534 Episode Num: 12394 Reward: 0.8741295985638327 avg_loss_c: 24.198181335742657 avg_loss_a: -62.12449645996094
Número de pasos del episodio 12395 son episode_steps:70
Total Steps: 791604 Episode Num: 12395 Reward: 19.625873383956264 avg_loss_c: 25.076050894601003 avg_loss_a: -63.20799200875418
Número de pasos del episodio 12396 son episode_steps:41
Total Steps: 791645 Episode Num: 12396 Reward: -23.019410774517215 avg_loss_c: 25.888668944196002 avg_loss_a: -62.24220359616163
Número de pasos del episodio 12397 son episode_steps:190
Total Steps: 791835 Episode Num: 12397 Reward: 128.6684501781269 avg_loss_c: 25.465181832564504 avg_loss_a: -63.333507377222965
Número de pasos del episodio 12398 son episode_steps:39
Total Steps: 791874 Episode Num: 12398 Reward: -26.07553789254053 avg_loss_c: 26.783617753248947 avg_loss_a: -65.89728653736604
Número de pasos del episodio 12399 son episode_steps:42
Total Steps: 791916 Episode Num: 12399 Reward: 4.055830628046841 avg_loss_c: 27.038004511878604 avg_loss_a: -62.19032687232608
Número de pasos del episodio 12400 son episode_steps:54
Total Steps: 791970 Episode Num: 12400 Reward: 15.79024649960677 avg_loss_c: 26.830783526102703 avg_loss_a: -63.67558613529912
Número de pasos del episodio 12401 son episode_steps:98
Total Steps: 792068 Episode Num: 12401 Reward: -23.144114852285227 avg_loss_c: 25.445902960641043 avg_loss_a: -63.30059884518993
Número de pasos del episodio 12402 son episode_steps:183
Total Steps: 792251 Episode Num: 12402 Reward: -21.025087913065768 avg_loss_c: 26.36881648517046 avg_loss_a: -62.87613778036149
Número de pasos del episodio 12403 son episode_steps:156
Total Steps: 792407 Episode Num: 12403 Reward: 116.76634228050992 avg_loss_c: 24.721297007340652 avg_loss_a: -63.205782230083756
Número de pasos del episodio 12404 son episode_steps:95
Total Steps: 792502 Episode Num: 12404 Reward: 55.02785147484018 avg_loss_c: 24.89841527436909 avg_loss_a: -63.14284808510228
Número de pasos del episodio 12405 son episode_steps:50
Total Steps: 792552 Episode Num: 12405 Reward: -3.81380996114945 avg_loss_c: 24.53363037109375 avg_loss_a: -62.44381729125976
Número de pasos del episodio 12406 son episode_steps:146
Total Steps: 792698 Episode Num: 12406 Reward: 41.614416111047895 avg_loss_c: 25.650486364756546 avg_loss_a: -63.49248279937326
Número de pasos del episodio 12407 son episode_steps:47
Total Steps: 792745 Episode Num: 12407 Reward: -3.792727369915556 avg_loss_c: 26.086794467682534 avg_loss_a: -63.157985849583405
Número de pasos del episodio 12408 son episode_steps:46
Total Steps: 792791 Episode Num: 12408 Reward: 19.666650410727385 avg_loss_c: 26.000126963076383 avg_loss_a: -62.87310392960258
Número de pasos del episodio 12409 son episode_steps:114
Total Steps: 792905 Episode Num: 12409 Reward: 84.38335440668384 avg_loss_c: 26.254898154944705 avg_loss_a: -63.00517098945484
Número de pasos del episodio 12410 son episode_steps:106
Total Steps: 793011 Episode Num: 12410 Reward: 84.79407282976516 avg_loss_c: 25.259461492862343 avg_loss_a: -64.19432780427753
Número de pasos del episodio 12411 son episode_steps:93
Total Steps: 793104 Episode Num: 12411 Reward: -19.183647498601857 avg_loss_c: 25.389393611620832 avg_loss_a: -62.842437580067624
Número de pasos del episodio 12412 son episode_steps:76
Total Steps: 793180 Episode Num: 12412 Reward: 56.8573896765571 avg_loss_c: 25.46123514677349 avg_loss_a: -63.68747420060007
Número de pasos del episodio 12413 son episode_steps:135
Total Steps: 793315 Episode Num: 12413 Reward: 76.72846880530032 avg_loss_c: 24.74458491007487 avg_loss_a: -63.59183129204644
Número de pasos del episodio 12414 son episode_steps:105
Total Steps: 793420 Episode Num: 12414 Reward: 73.87928427407442 avg_loss_c: 24.7080013638451 avg_loss_a: -63.37052699497768
Número de pasos del episodio 12415 son episode_steps:63
Total Steps: 793483 Episode Num: 12415 Reward: -2.827116663542741 avg_loss_c: 25.594499254983567 avg_loss_a: -62.015892028808594
Número de pasos del episodio 12416 son episode_steps:67
Total Steps: 793550 Episode Num: 12416 Reward: 9.059603272674423 avg_loss_c: 25.3858099410783 avg_loss_a: -63.28689654905405
Número de pasos del episodio 12417 son episode_steps:37
Total Steps: 793587 Episode Num: 12417 Reward: -57.51418963695459 avg_loss_c: 25.67988398268416 avg_loss_a: -63.56195253939242
Número de pasos del episodio 12418 son episode_steps:266
Total Steps: 793853 Episode Num: 12418 Reward: 221.47871020552424 avg_loss_c: 25.503651048904075 avg_loss_a: -63.59414294250029
Número de pasos del episodio 12419 son episode_steps:43
Total Steps: 793896 Episode Num: 12419 Reward: -15.80686099585083 avg_loss_c: 24.94814921534339 avg_loss_a: -63.634625545767854
Número de pasos del episodio 12420 son episode_steps:93
Total Steps: 793989 Episode Num: 12420 Reward: 14.398619712135893 avg_loss_c: 25.508934984924974 avg_loss_a: -62.413278313093286
Número de pasos del episodio 12421 son episode_steps:275
Total Steps: 794264 Episode Num: 12421 Reward: 193.46970694629678 avg_loss_c: 25.482574476762252 avg_loss_a: -64.3998515181108
Número de pasos del episodio 12422 son episode_steps:85
Total Steps: 794349 Episode Num: 12422 Reward: 12.139106691886948 avg_loss_c: 25.259824977201575 avg_loss_a: -62.91047372257008
Número de pasos del episodio 12423 son episode_steps:285
Total Steps: 794634 Episode Num: 12423 Reward: 257.0542997547493 avg_loss_c: 24.120849575912743 avg_loss_a: -64.36670094540244
Número de pasos del episodio 12424 son episode_steps:83
Total Steps: 794717 Episode Num: 12424 Reward: 47.522795489138105 avg_loss_c: 24.149602522332984 avg_loss_a: -64.66537732963103
Número de pasos del episodio 12425 son episode_steps:22
Total Steps: 794739 Episode Num: 12425 Reward: -27.99583751194304 avg_loss_c: 23.736604170365766 avg_loss_a: -61.58525432239879
Número de pasos del episodio 12426 son episode_steps:52
Total Steps: 794791 Episode Num: 12426 Reward: 10.7762874853149 avg_loss_c: 25.433326501112717 avg_loss_a: -65.18885289705716
Número de pasos del episodio 12427 son episode_steps:72
Total Steps: 794863 Episode Num: 12427 Reward: 11.327881552859854 avg_loss_c: 24.763296339246963 avg_loss_a: -64.65736410352919
Número de pasos del episodio 12428 son episode_steps:141
Total Steps: 795004 Episode Num: 12428 Reward: 79.61441075698495 avg_loss_c: 24.106337581120485 avg_loss_a: -63.8211758660932
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 157.595748
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12429 son episode_steps:58
Total Steps: 795062 Episode Num: 12429 Reward: 13.555294651385736 avg_loss_c: 24.216748796660326 avg_loss_a: -64.6813393954573
Número de pasos del episodio 12430 son episode_steps:179
Total Steps: 795241 Episode Num: 12430 Reward: 96.38831781864175 avg_loss_c: 24.472251972006685 avg_loss_a: -64.98284858831481
Número de pasos del episodio 12431 son episode_steps:158
Total Steps: 795399 Episode Num: 12431 Reward: 99.68713813030755 avg_loss_c: 24.22682978835287 avg_loss_a: -65.47103901150861
Número de pasos del episodio 12432 son episode_steps:312
Total Steps: 795711 Episode Num: 12432 Reward: 286.61881041165856 avg_loss_c: 23.729259478740204 avg_loss_a: -65.53941281636556
Número de pasos del episodio 12433 son episode_steps:62
Total Steps: 795773 Episode Num: 12433 Reward: -7.259692434058039 avg_loss_c: 23.80719049515263 avg_loss_a: -65.82291043189264
Número de pasos del episodio 12434 son episode_steps:152
Total Steps: 795925 Episode Num: 12434 Reward: 28.540807870423578 avg_loss_c: 24.362143428702105 avg_loss_a: -65.91162636405544
Número de pasos del episodio 12435 son episode_steps:97
Total Steps: 796022 Episode Num: 12435 Reward: 41.02880911834179 avg_loss_c: 24.246894777435617 avg_loss_a: -65.796552756398
Número de pasos del episodio 12436 son episode_steps:118
Total Steps: 796140 Episode Num: 12436 Reward: 34.60777272909001 avg_loss_c: 23.335283828993976 avg_loss_a: -66.1627663434562
Número de pasos del episodio 12437 son episode_steps:152
Total Steps: 796292 Episode Num: 12437 Reward: 117.9489265209019 avg_loss_c: 22.871366732998897 avg_loss_a: -66.4779230920892
Número de pasos del episodio 12438 son episode_steps:51
Total Steps: 796343 Episode Num: 12438 Reward: -76.51314339487529 avg_loss_c: 24.51420383827359 avg_loss_a: -66.92670410754634
Número de pasos del episodio 12439 son episode_steps:203
Total Steps: 796546 Episode Num: 12439 Reward: 165.77220294372233 avg_loss_c: 23.800132643413075 avg_loss_a: -66.86198049460725
Número de pasos del episodio 12440 son episode_steps:177
Total Steps: 796723 Episode Num: 12440 Reward: 94.74984025787046 avg_loss_c: 23.015466415275963 avg_loss_a: -66.86285240906106
Número de pasos del episodio 12441 son episode_steps:111
Total Steps: 796834 Episode Num: 12441 Reward: -30.565986702855863 avg_loss_c: 24.66192571966498 avg_loss_a: -67.48601263922615
Número de pasos del episodio 12442 son episode_steps:81
Total Steps: 796915 Episode Num: 12442 Reward: -111.74517919977087 avg_loss_c: 23.231533533261146 avg_loss_a: -67.28140192856023
Número de pasos del episodio 12443 son episode_steps:190
Total Steps: 797105 Episode Num: 12443 Reward: 125.67994001265964 avg_loss_c: 23.850152392136422 avg_loss_a: -66.96103150217156
Número de pasos del episodio 12444 son episode_steps:139
Total Steps: 797244 Episode Num: 12444 Reward: 85.01326830549849 avg_loss_c: 23.018779370424557 avg_loss_a: -66.7000808166943
Número de pasos del episodio 12445 son episode_steps:141
Total Steps: 797385 Episode Num: 12445 Reward: 42.144236065638964 avg_loss_c: 23.731748168350112 avg_loss_a: -68.25601845599235
Número de pasos del episodio 12446 son episode_steps:198
Total Steps: 797583 Episode Num: 12446 Reward: -54.481391724949646 avg_loss_c: 30.457391526963974 avg_loss_a: -67.1065841443611
Número de pasos del episodio 12447 son episode_steps:141
Total Steps: 797724 Episode Num: 12447 Reward: 104.08116175242597 avg_loss_c: 24.147828244148418 avg_loss_a: -67.5799234539059
Número de pasos del episodio 12448 son episode_steps:68
Total Steps: 797792 Episode Num: 12448 Reward: -10.669888983820387 avg_loss_c: 23.847217447617474 avg_loss_a: -67.43290194343118
Número de pasos del episodio 12449 son episode_steps:159
Total Steps: 797951 Episode Num: 12449 Reward: 76.90896303877214 avg_loss_c: 24.89364908326347 avg_loss_a: -67.6991446633009
Número de pasos del episodio 12450 son episode_steps:44
Total Steps: 797995 Episode Num: 12450 Reward: -45.675741120551244 avg_loss_c: 24.92894359068437 avg_loss_a: -67.75563725558195
Número de pasos del episodio 12451 son episode_steps:19
Total Steps: 798014 Episode Num: 12451 Reward: -26.239949379662793 avg_loss_c: 39.079610322651114 avg_loss_a: -67.54387022319592
Número de pasos del episodio 12452 son episode_steps:82
Total Steps: 798096 Episode Num: 12452 Reward: 46.75144238697548 avg_loss_c: 25.267526812669708 avg_loss_a: -67.9886786298054
Número de pasos del episodio 12453 son episode_steps:227
Total Steps: 798323 Episode Num: 12453 Reward: 135.78401415604947 avg_loss_c: 26.320342849529787 avg_loss_a: -68.02714261294462
Número de pasos del episodio 12454 son episode_steps:153
Total Steps: 798476 Episode Num: 12454 Reward: 79.4637097987788 avg_loss_c: 24.826745837342504 avg_loss_a: -68.64174472584443
Número de pasos del episodio 12455 son episode_steps:99
Total Steps: 798575 Episode Num: 12455 Reward: 23.210994436386528 avg_loss_c: 24.617486144557144 avg_loss_a: -67.22037829774798
Número de pasos del episodio 12456 son episode_steps:150
Total Steps: 798725 Episode Num: 12456 Reward: 97.67637980271122 avg_loss_c: 24.83698922475179 avg_loss_a: -68.96484191894531
Número de pasos del episodio 12457 son episode_steps:84
Total Steps: 798809 Episode Num: 12457 Reward: -10.739206154590033 avg_loss_c: 25.263422171274822 avg_loss_a: -66.44933055696033
Número de pasos del episodio 12458 son episode_steps:58
Total Steps: 798867 Episode Num: 12458 Reward: 28.314445825055678 avg_loss_c: 25.550429113979998 avg_loss_a: -68.59280027192214
Número de pasos del episodio 12459 son episode_steps:57
Total Steps: 798924 Episode Num: 12459 Reward: -25.969150419441853 avg_loss_c: 25.292154379058303 avg_loss_a: -69.42550953647546
Número de pasos del episodio 12460 son episode_steps:273
Total Steps: 799197 Episode Num: 12460 Reward: 197.44585502055074 avg_loss_c: 25.25476192292713 avg_loss_a: -69.06571217072316
Número de pasos del episodio 12461 son episode_steps:148
Total Steps: 799345 Episode Num: 12461 Reward: 66.28885352728774 avg_loss_c: 25.12145613979649 avg_loss_a: -69.41924430228569
Número de pasos del episodio 12462 son episode_steps:58
Total Steps: 799403 Episode Num: 12462 Reward: 4.757092891116439 avg_loss_c: 25.89006989577721 avg_loss_a: -68.56596492898875
Número de pasos del episodio 12463 son episode_steps:58
Total Steps: 799461 Episode Num: 12463 Reward: 7.852503403137424 avg_loss_c: 25.515666040880927 avg_loss_a: -68.76763113613787
Número de pasos del episodio 12464 son episode_steps:195
Total Steps: 799656 Episode Num: 12464 Reward: 110.98175052273868 avg_loss_c: 25.71511411911402 avg_loss_a: -69.48451338547926
Número de pasos del episodio 12465 son episode_steps:148
Total Steps: 799804 Episode Num: 12465 Reward: 87.82356763006356 avg_loss_c: 25.531527886519562 avg_loss_a: -70.1763384535506
Número de pasos del episodio 12466 son episode_steps:50
Total Steps: 799854 Episode Num: 12466 Reward: -20.736051893516326 avg_loss_c: 25.36959659576416 avg_loss_a: -70.4166326904297
Número de pasos del episodio 12467 son episode_steps:230
Total Steps: 800084 Episode Num: 12467 Reward: 163.70244733571104 avg_loss_c: 25.29964840930441 avg_loss_a: -69.90095092110012
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 159.168915
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12468 son episode_steps:61
Total Steps: 800145 Episode Num: 12468 Reward: -16.33048567212386 avg_loss_c: 24.816910696811362 avg_loss_a: -70.33674846711706
Número de pasos del episodio 12469 son episode_steps:165
Total Steps: 800310 Episode Num: 12469 Reward: -0.8509647293753906 avg_loss_c: 25.066988812070903 avg_loss_a: -69.74530644272313
Número de pasos del episodio 12470 son episode_steps:69
Total Steps: 800379 Episode Num: 12470 Reward: 17.31804572094458 avg_loss_c: 25.547539835390836 avg_loss_a: -69.6069931914841
Número de pasos del episodio 12471 son episode_steps:123
Total Steps: 800502 Episode Num: 12471 Reward: 62.113160677917435 avg_loss_c: 25.767184497864267 avg_loss_a: -69.95052560945837
Número de pasos del episodio 12472 son episode_steps:120
Total Steps: 800622 Episode Num: 12472 Reward: 56.66027371494653 avg_loss_c: 24.880315033594766 avg_loss_a: -69.76242103576661
Número de pasos del episodio 12473 son episode_steps:97
Total Steps: 800719 Episode Num: 12473 Reward: 17.30952404344257 avg_loss_c: 25.22588725925721 avg_loss_a: -70.62188885875584
Número de pasos del episodio 12474 son episode_steps:209
Total Steps: 800928 Episode Num: 12474 Reward: 46.15702980203269 avg_loss_c: 25.995417334816672 avg_loss_a: -69.67009935880962
Número de pasos del episodio 12475 son episode_steps:25
Total Steps: 800953 Episode Num: 12475 Reward: -15.916387682203013 avg_loss_c: 25.340442962646485 avg_loss_a: -68.04697723388672
Número de pasos del episodio 12476 son episode_steps:186
Total Steps: 801139 Episode Num: 12476 Reward: 65.60813250398716 avg_loss_c: 25.736646682985366 avg_loss_a: -69.3179323339975
Número de pasos del episodio 12477 son episode_steps:338
Total Steps: 801477 Episode Num: 12477 Reward: 240.49006711676918 avg_loss_c: 25.32332528131248 avg_loss_a: -70.21653061364529
Número de pasos del episodio 12478 son episode_steps:34
Total Steps: 801511 Episode Num: 12478 Reward: -6.168000866881448 avg_loss_c: 23.797223147223978 avg_loss_a: -70.46613311767578
Número de pasos del episodio 12479 son episode_steps:149
Total Steps: 801660 Episode Num: 12479 Reward: 30.230024694124772 avg_loss_c: 26.185536467789003 avg_loss_a: -70.38234470034605
Número de pasos del episodio 12480 son episode_steps:105
Total Steps: 801765 Episode Num: 12480 Reward: 56.135222766186146 avg_loss_c: 24.86128481910342 avg_loss_a: -70.49360409691221
Número de pasos del episodio 12481 son episode_steps:134
Total Steps: 801899 Episode Num: 12481 Reward: 73.4571061701698 avg_loss_c: 25.273151276716547 avg_loss_a: -69.70488084252202
Número de pasos del episodio 12482 son episode_steps:56
Total Steps: 801955 Episode Num: 12482 Reward: -41.17453870160122 avg_loss_c: 25.16055962017604 avg_loss_a: -69.27989946092877
Número de pasos del episodio 12483 son episode_steps:65
Total Steps: 802020 Episode Num: 12483 Reward: -4.550635587848058 avg_loss_c: 26.055194473266603 avg_loss_a: -70.50513469989482
Número de pasos del episodio 12484 son episode_steps:32
Total Steps: 802052 Episode Num: 12484 Reward: -28.199708344022774 avg_loss_c: 24.52512663602829 avg_loss_a: -70.02721834182739
Número de pasos del episodio 12485 son episode_steps:102
Total Steps: 802154 Episode Num: 12485 Reward: 53.29395891995194 avg_loss_c: 25.657649900399 avg_loss_a: -69.68335058174881
Número de pasos del episodio 12486 son episode_steps:80
Total Steps: 802234 Episode Num: 12486 Reward: 32.295977833441704 avg_loss_c: 25.50887143611908 avg_loss_a: -69.96298704147338
Número de pasos del episodio 12487 son episode_steps:96
Total Steps: 802330 Episode Num: 12487 Reward: 55.16296048830448 avg_loss_c: 25.66415818532308 avg_loss_a: -69.96169662475586
Número de pasos del episodio 12488 son episode_steps:79
Total Steps: 802409 Episode Num: 12488 Reward: 20.527153722652297 avg_loss_c: 24.061697899540768 avg_loss_a: -70.23775424232966
Número de pasos del episodio 12489 son episode_steps:71
Total Steps: 802480 Episode Num: 12489 Reward: 24.60119864536757 avg_loss_c: 24.72607267406625 avg_loss_a: -69.871054635921
Número de pasos del episodio 12490 son episode_steps:79
Total Steps: 802559 Episode Num: 12490 Reward: 48.111837137051936 avg_loss_c: 25.2284026568449 avg_loss_a: -71.12817489044576
Número de pasos del episodio 12491 son episode_steps:258
Total Steps: 802817 Episode Num: 12491 Reward: 175.2254024300193 avg_loss_c: 24.977621071098387 avg_loss_a: -70.60348558056262
Número de pasos del episodio 12492 son episode_steps:234
Total Steps: 803051 Episode Num: 12492 Reward: 78.45332062550845 avg_loss_c: 24.964045540899292 avg_loss_a: -70.59668536063953
Número de pasos del episodio 12493 son episode_steps:131
Total Steps: 803182 Episode Num: 12493 Reward: 40.80461278379089 avg_loss_c: 24.994212230653254 avg_loss_a: -71.1849127616591
Número de pasos del episodio 12494 son episode_steps:64
Total Steps: 803246 Episode Num: 12494 Reward: 23.461812097051393 avg_loss_c: 24.965648740530014 avg_loss_a: -70.17354941368103
Número de pasos del episodio 12495 son episode_steps:72
Total Steps: 803318 Episode Num: 12495 Reward: -12.719861285542533 avg_loss_c: 24.770869493484497 avg_loss_a: -69.75854343838162
Número de pasos del episodio 12496 son episode_steps:36
Total Steps: 803354 Episode Num: 12496 Reward: -40.18325878287653 avg_loss_c: 24.888191170162624 avg_loss_a: -69.3148816426595
Número de pasos del episodio 12497 son episode_steps:96
Total Steps: 803450 Episode Num: 12497 Reward: 38.72305368095175 avg_loss_c: 24.75249109665553 avg_loss_a: -70.17540081342061
Número de pasos del episodio 12498 son episode_steps:49
Total Steps: 803499 Episode Num: 12498 Reward: -45.89326347993049 avg_loss_c: 26.463288560205577 avg_loss_a: -70.80803197743941
Número de pasos del episodio 12499 son episode_steps:68
Total Steps: 803567 Episode Num: 12499 Reward: 12.467307182117366 avg_loss_c: 25.75021735359641 avg_loss_a: -69.87545518314137
Número de pasos del episodio 12500 son episode_steps:227
Total Steps: 803794 Episode Num: 12500 Reward: 131.2748873192235 avg_loss_c: 25.276399007452742 avg_loss_a: -69.9630754445618
Número de pasos del episodio 12501 son episode_steps:39
Total Steps: 803833 Episode Num: 12501 Reward: -25.61888550711124 avg_loss_c: 24.683154521844326 avg_loss_a: -69.88420281043419
Número de pasos del episodio 12502 son episode_steps:58
Total Steps: 803891 Episode Num: 12502 Reward: -66.79155555696751 avg_loss_c: 24.851815355235132 avg_loss_a: -70.66854082304856
Número de pasos del episodio 12503 son episode_steps:39
Total Steps: 803930 Episode Num: 12503 Reward: 12.346530426960465 avg_loss_c: 25.35686590732672 avg_loss_a: -70.1779057429387
Número de pasos del episodio 12504 son episode_steps:72
Total Steps: 804002 Episode Num: 12504 Reward: -4.85114460398113 avg_loss_c: 26.001586781607735 avg_loss_a: -70.86206510331895
Número de pasos del episodio 12505 son episode_steps:223
Total Steps: 804225 Episode Num: 12505 Reward: 133.4098859362057 avg_loss_c: 24.99908432725299 avg_loss_a: -69.923069119988
Número de pasos del episodio 12506 son episode_steps:55
Total Steps: 804280 Episode Num: 12506 Reward: -2.657412316388756 avg_loss_c: 25.376362176374954 avg_loss_a: -69.99094890247692
Número de pasos del episodio 12507 son episode_steps:54
Total Steps: 804334 Episode Num: 12507 Reward: -21.437556821285806 avg_loss_c: 25.31106009306731 avg_loss_a: -68.99614856861255
Número de pasos del episodio 12508 son episode_steps:66
Total Steps: 804400 Episode Num: 12508 Reward: -8.94630667917451 avg_loss_c: 26.010287487145625 avg_loss_a: -69.90595349398527
Número de pasos del episodio 12509 son episode_steps:55
Total Steps: 804455 Episode Num: 12509 Reward: -14.576965873499365 avg_loss_c: 25.426574967124246 avg_loss_a: -67.1981499411843
Número de pasos del episodio 12510 son episode_steps:44
Total Steps: 804499 Episode Num: 12510 Reward: -26.4601347004961 avg_loss_c: 26.648249452764336 avg_loss_a: -70.47851076993075
Número de pasos del episodio 12511 son episode_steps:51
Total Steps: 804550 Episode Num: 12511 Reward: -17.880704348039615 avg_loss_c: 24.803939295750038 avg_loss_a: -69.73327576880361
Número de pasos del episodio 12512 son episode_steps:84
Total Steps: 804634 Episode Num: 12512 Reward: -7.366291764082054 avg_loss_c: 26.4352350348518 avg_loss_a: -67.58998325892857
Número de pasos del episodio 12513 son episode_steps:72
Total Steps: 804706 Episode Num: 12513 Reward: 12.736888686756469 avg_loss_c: 26.08914049466451 avg_loss_a: -68.08956146240234
Número de pasos del episodio 12514 son episode_steps:34
Total Steps: 804740 Episode Num: 12514 Reward: -52.663363247645705 avg_loss_c: 25.652442315045526 avg_loss_a: -70.03347419289982
Número de pasos del episodio 12515 son episode_steps:43
Total Steps: 804783 Episode Num: 12515 Reward: -45.249334750819024 avg_loss_c: 26.607995365941246 avg_loss_a: -68.8957343877748
Número de pasos del episodio 12516 son episode_steps:78
Total Steps: 804861 Episode Num: 12516 Reward: 11.146586200348452 avg_loss_c: 26.83923146663568 avg_loss_a: -67.9045305496607
Número de pasos del episodio 12517 son episode_steps:61
Total Steps: 804922 Episode Num: 12517 Reward: 17.78838773087738 avg_loss_c: 26.430277558623768 avg_loss_a: -68.5605043505059
Número de pasos del episodio 12518 son episode_steps:31
Total Steps: 804953 Episode Num: 12518 Reward: -56.49386435243132 avg_loss_c: 26.930496154292936 avg_loss_a: -68.19461059570312
Número de pasos del episodio 12519 son episode_steps:82
Total Steps: 805035 Episode Num: 12519 Reward: -20.033462435311353 avg_loss_c: 27.045387616971645 avg_loss_a: -67.46100337330888
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 121.142412
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12520 son episode_steps:223
Total Steps: 805258 Episode Num: 12520 Reward: 168.4825902401317 avg_loss_c: 26.521724914756057 avg_loss_a: -68.40304517532144
Número de pasos del episodio 12521 son episode_steps:132
Total Steps: 805390 Episode Num: 12521 Reward: 35.9079515902005 avg_loss_c: 25.57540682590369 avg_loss_a: -68.86954954898718
Número de pasos del episodio 12522 son episode_steps:26
Total Steps: 805416 Episode Num: 12522 Reward: -33.56711318765531 avg_loss_c: 28.623470893272987 avg_loss_a: -67.85357548640324
Número de pasos del episodio 12523 son episode_steps:34
Total Steps: 805450 Episode Num: 12523 Reward: -25.90244791734841 avg_loss_c: 26.832852531881894 avg_loss_a: -68.29296830121208
Número de pasos del episodio 12524 son episode_steps:40
Total Steps: 805490 Episode Num: 12524 Reward: -4.734861862171944 avg_loss_c: 26.12668294906616 avg_loss_a: -67.44988269805908
Número de pasos del episodio 12525 son episode_steps:171
Total Steps: 805661 Episode Num: 12525 Reward: 45.11791979505761 avg_loss_c: 27.79161156548394 avg_loss_a: -68.72470141851414
Número de pasos del episodio 12526 son episode_steps:33
Total Steps: 805694 Episode Num: 12526 Reward: -12.930336179721373 avg_loss_c: 28.063376397797555 avg_loss_a: -67.55644526626125
Número de pasos del episodio 12527 son episode_steps:74
Total Steps: 805768 Episode Num: 12527 Reward: -57.70573467032596 avg_loss_c: 27.943670401702057 avg_loss_a: -68.40787846333272
Número de pasos del episodio 12528 son episode_steps:78
Total Steps: 805846 Episode Num: 12528 Reward: -33.9593682246994 avg_loss_c: 28.416032375433506 avg_loss_a: -68.14729651426657
Número de pasos del episodio 12529 son episode_steps:166
Total Steps: 806012 Episode Num: 12529 Reward: 110.01747400652367 avg_loss_c: 27.746913266469196 avg_loss_a: -67.68596970891377
Número de pasos del episodio 12530 son episode_steps:252
Total Steps: 806264 Episode Num: 12530 Reward: 178.20580427637987 avg_loss_c: 27.35487377075922 avg_loss_a: -68.07661510649181
Número de pasos del episodio 12531 son episode_steps:63
Total Steps: 806327 Episode Num: 12531 Reward: -8.112784351749145 avg_loss_c: 26.83126655457512 avg_loss_a: -67.18795425172836
Número de pasos del episodio 12532 son episode_steps:193
Total Steps: 806520 Episode Num: 12532 Reward: 121.93647928085014 avg_loss_c: 26.394632201120643 avg_loss_a: -67.92826432144086
Número de pasos del episodio 12533 son episode_steps:40
Total Steps: 806560 Episode Num: 12533 Reward: -28.991746070648887 avg_loss_c: 26.527299308776854 avg_loss_a: -69.19501113891602
Número de pasos del episodio 12534 son episode_steps:58
Total Steps: 806618 Episode Num: 12534 Reward: 30.157688020909518 avg_loss_c: 26.461415915653625 avg_loss_a: -67.41057494591023
Número de pasos del episodio 12535 son episode_steps:92
Total Steps: 806710 Episode Num: 12535 Reward: 56.65219948482472 avg_loss_c: 27.096899239913277 avg_loss_a: -68.71380872311799
Número de pasos del episodio 12536 son episode_steps:174
Total Steps: 806884 Episode Num: 12536 Reward: 71.17347986786291 avg_loss_c: 26.847485893074122 avg_loss_a: -67.8322587287289
Número de pasos del episodio 12537 son episode_steps:120
Total Steps: 807004 Episode Num: 12537 Reward: 85.27455201639562 avg_loss_c: 26.522777350743613 avg_loss_a: -67.60970204671224
Número de pasos del episodio 12538 son episode_steps:134
Total Steps: 807138 Episode Num: 12538 Reward: 43.140350728663634 avg_loss_c: 25.66152181198348 avg_loss_a: -67.74074725250699
Número de pasos del episodio 12539 son episode_steps:148
Total Steps: 807286 Episode Num: 12539 Reward: 93.43466903834637 avg_loss_c: 26.32392472189826 avg_loss_a: -68.66079830478978
Número de pasos del episodio 12540 son episode_steps:28
Total Steps: 807314 Episode Num: 12540 Reward: -15.070128368896125 avg_loss_c: 24.1920713697161 avg_loss_a: -68.23696844918388
Número de pasos del episodio 12541 son episode_steps:312
Total Steps: 807626 Episode Num: 12541 Reward: 249.40785667607224 avg_loss_c: 25.725344071021446 avg_loss_a: -68.63494506249062
Número de pasos del episodio 12542 son episode_steps:571
Total Steps: 808197 Episode Num: 12542 Reward: 446.19791140193183 avg_loss_c: 25.590334686840478 avg_loss_a: -68.33130473389099
Número de pasos del episodio 12543 son episode_steps:159
Total Steps: 808356 Episode Num: 12543 Reward: 75.589187333964 avg_loss_c: 24.603498854727114 avg_loss_a: -68.31463181597631
Número de pasos del episodio 12544 son episode_steps:56
Total Steps: 808412 Episode Num: 12544 Reward: -38.762594542100814 avg_loss_c: 25.529874631336757 avg_loss_a: -67.53314072745187
Número de pasos del episodio 12545 son episode_steps:99
Total Steps: 808511 Episode Num: 12545 Reward: 32.8853708203216 avg_loss_c: 24.513407350790622 avg_loss_a: -68.2968336933791
Número de pasos del episodio 12546 son episode_steps:128
Total Steps: 808639 Episode Num: 12546 Reward: -66.06546844006428 avg_loss_c: 25.626255750656128 avg_loss_a: -69.31066316366196
Número de pasos del episodio 12547 son episode_steps:487
Total Steps: 809126 Episode Num: 12547 Reward: 441.33373440783106 avg_loss_c: 25.69582096898825 avg_loss_a: -67.94985824052313
Número de pasos del episodio 12548 son episode_steps:47
Total Steps: 809173 Episode Num: 12548 Reward: 2.897710558994114 avg_loss_c: 24.368966285218583 avg_loss_a: -66.78335782314869
Número de pasos del episodio 12549 son episode_steps:141
Total Steps: 809314 Episode Num: 12549 Reward: 52.95479873323963 avg_loss_c: 25.50829669600683 avg_loss_a: -68.42311864541777
Número de pasos del episodio 12550 son episode_steps:62
Total Steps: 809376 Episode Num: 12550 Reward: -4.910519553915431 avg_loss_c: 25.093371299005323 avg_loss_a: -66.8586189516129
Número de pasos del episodio 12551 son episode_steps:91
Total Steps: 809467 Episode Num: 12551 Reward: 13.536436390341429 avg_loss_c: 25.772086929488967 avg_loss_a: -68.45842918982872
Número de pasos del episodio 12552 son episode_steps:45
Total Steps: 809512 Episode Num: 12552 Reward: -29.513720999712834 avg_loss_c: 24.527166726854112 avg_loss_a: -68.77902526855469
Número de pasos del episodio 12553 son episode_steps:216
Total Steps: 809728 Episode Num: 12553 Reward: 102.87968133330061 avg_loss_c: 25.48298794251901 avg_loss_a: -69.10292159186469
Número de pasos del episodio 12554 son episode_steps:181
Total Steps: 809909 Episode Num: 12554 Reward: 106.09308147774937 avg_loss_c: 25.838747867563153 avg_loss_a: -69.00960443823377
Número de pasos del episodio 12555 son episode_steps:53
Total Steps: 809962 Episode Num: 12555 Reward: -44.99159693101328 avg_loss_c: 24.006158648796802 avg_loss_a: -69.21580663717018
Número de pasos del episodio 12556 son episode_steps:122
Total Steps: 810084 Episode Num: 12556 Reward: 21.6154824468237 avg_loss_c: 25.383373979662284 avg_loss_a: -68.27655529585041
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 183.337769
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12557 son episode_steps:167
Total Steps: 810251 Episode Num: 12557 Reward: 98.32892827029156 avg_loss_c: 24.292277964289315 avg_loss_a: -69.05139192135748
Número de pasos del episodio 12558 son episode_steps:38
Total Steps: 810289 Episode Num: 12558 Reward: -28.418089134680848 avg_loss_c: 24.54503651669151 avg_loss_a: -69.50294374164783
Número de pasos del episodio 12559 son episode_steps:194
Total Steps: 810483 Episode Num: 12559 Reward: 79.96581137780362 avg_loss_c: 25.282849700180524 avg_loss_a: -69.7914354383331
Número de pasos del episodio 12560 son episode_steps:74
Total Steps: 810557 Episode Num: 12560 Reward: -36.49039930517168 avg_loss_c: 25.865056759602314 avg_loss_a: -68.98314316208298
Número de pasos del episodio 12561 son episode_steps:57
Total Steps: 810614 Episode Num: 12561 Reward: -34.29584927644993 avg_loss_c: 26.40893668459173 avg_loss_a: -68.82664315742359
Número de pasos del episodio 12562 son episode_steps:67
Total Steps: 810681 Episode Num: 12562 Reward: -21.729090494768457 avg_loss_c: 26.548509910925112 avg_loss_a: -68.90379857305271
Número de pasos del episodio 12563 son episode_steps:92
Total Steps: 810773 Episode Num: 12563 Reward: 28.586427314668267 avg_loss_c: 25.503147374028746 avg_loss_a: -69.20964979088825
Número de pasos del episodio 12564 son episode_steps:423
Total Steps: 811196 Episode Num: 12564 Reward: 177.3779627059102 avg_loss_c: 25.201567002785684 avg_loss_a: -69.57057390145376
Número de pasos del episodio 12565 son episode_steps:149
Total Steps: 811345 Episode Num: 12565 Reward: 74.44169110153479 avg_loss_c: 24.421228831246395 avg_loss_a: -69.14515798683935
Número de pasos del episodio 12566 son episode_steps:66
Total Steps: 811411 Episode Num: 12566 Reward: -38.721324263163595 avg_loss_c: 25.038516969391793 avg_loss_a: -68.94126325665098
Número de pasos del episodio 12567 son episode_steps:78
Total Steps: 811489 Episode Num: 12567 Reward: -7.431704549708888 avg_loss_c: 25.979797827891815 avg_loss_a: -70.40934274135492
Número de pasos del episodio 12568 son episode_steps:186
Total Steps: 811675 Episode Num: 12568 Reward: 127.06145876642299 avg_loss_c: 25.11391738153273 avg_loss_a: -69.74657444287372
Número de pasos del episodio 12569 son episode_steps:74
Total Steps: 811749 Episode Num: 12569 Reward: -18.529167108289496 avg_loss_c: 25.20222913896715 avg_loss_a: -69.37695291880014
Número de pasos del episodio 12570 son episode_steps:18
Total Steps: 811767 Episode Num: 12570 Reward: -40.858299376974756 avg_loss_c: 22.386224640740288 avg_loss_a: -70.4614749484592
Número de pasos del episodio 12571 son episode_steps:57
Total Steps: 811824 Episode Num: 12571 Reward: 17.1972431894488 avg_loss_c: 25.408708036991587 avg_loss_a: -69.25964944404468
Número de pasos del episodio 12572 son episode_steps:61
Total Steps: 811885 Episode Num: 12572 Reward: 1.2857916938098453 avg_loss_c: 25.95140357095687 avg_loss_a: -69.14605312660092
Número de pasos del episodio 12573 son episode_steps:262
Total Steps: 812147 Episode Num: 12573 Reward: 164.2841687107265 avg_loss_c: 24.844640578932434 avg_loss_a: -69.06190333475594
Número de pasos del episodio 12574 son episode_steps:64
Total Steps: 812211 Episode Num: 12574 Reward: 9.814471429126662 avg_loss_c: 23.95316708087921 avg_loss_a: -69.18429493904114
Número de pasos del episodio 12575 son episode_steps:53
Total Steps: 812264 Episode Num: 12575 Reward: -5.2794806194846435 avg_loss_c: 23.996578936306936 avg_loss_a: -69.83358304005749
Número de pasos del episodio 12576 son episode_steps:81
Total Steps: 812345 Episode Num: 12576 Reward: 7.049776889621168 avg_loss_c: 25.084720540929723 avg_loss_a: -69.00917298116802
Número de pasos del episodio 12577 son episode_steps:111
Total Steps: 812456 Episode Num: 12577 Reward: 47.18410734830389 avg_loss_c: 25.458440694723045 avg_loss_a: -69.08043760007565
Número de pasos del episodio 12578 son episode_steps:86
Total Steps: 812542 Episode Num: 12578 Reward: 8.293744409681937 avg_loss_c: 25.74926182281139 avg_loss_a: -69.11291228893191
Número de pasos del episodio 12579 son episode_steps:177
Total Steps: 812719 Episode Num: 12579 Reward: 108.80063860617283 avg_loss_c: 24.25406189826922 avg_loss_a: -69.98518181924766
Número de pasos del episodio 12580 son episode_steps:90
Total Steps: 812809 Episode Num: 12580 Reward: 33.96581487339532 avg_loss_c: 24.376298565334743 avg_loss_a: -69.0893658955892
Número de pasos del episodio 12581 son episode_steps:70
Total Steps: 812879 Episode Num: 12581 Reward: -0.448121397291668 avg_loss_c: 25.397922270638603 avg_loss_a: -69.25939592633928
Número de pasos del episodio 12582 son episode_steps:212
Total Steps: 813091 Episode Num: 12582 Reward: 113.80853370748852 avg_loss_c: 24.590947947412168 avg_loss_a: -69.39949737404878
Número de pasos del episodio 12583 son episode_steps:96
Total Steps: 813187 Episode Num: 12583 Reward: 13.807997179591503 avg_loss_c: 25.61274199684461 avg_loss_a: -69.18506932258606
Número de pasos del episodio 12584 son episode_steps:126
Total Steps: 813313 Episode Num: 12584 Reward: -53.8462464143351 avg_loss_c: 25.796943452623154 avg_loss_a: -70.0386483328683
Número de pasos del episodio 12585 son episode_steps:151
Total Steps: 813464 Episode Num: 12585 Reward: 58.20769590580828 avg_loss_c: 26.202219628340362 avg_loss_a: -69.93111601570584
Número de pasos del episodio 12586 son episode_steps:130
Total Steps: 813594 Episode Num: 12586 Reward: -0.7560371703283417 avg_loss_c: 25.45134093944843 avg_loss_a: -69.77463026780349
Número de pasos del episodio 12587 son episode_steps:37
Total Steps: 813631 Episode Num: 12587 Reward: -15.793041642893662 avg_loss_c: 26.936113873043574 avg_loss_a: -70.36192796037004
Número de pasos del episodio 12588 son episode_steps:77
Total Steps: 813708 Episode Num: 12588 Reward: -4.049490277259614 avg_loss_c: 27.27070696942218 avg_loss_a: -68.8003537066571
Número de pasos del episodio 12589 son episode_steps:110
Total Steps: 813818 Episode Num: 12589 Reward: -43.40390239579559 avg_loss_c: 25.466303634643555 avg_loss_a: -69.7215250188654
Número de pasos del episodio 12590 son episode_steps:93
Total Steps: 813911 Episode Num: 12590 Reward: 3.2461856582407087 avg_loss_c: 26.504367284877326 avg_loss_a: -69.17753330353767
Número de pasos del episodio 12591 son episode_steps:89
Total Steps: 814000 Episode Num: 12591 Reward: 20.842981597980764 avg_loss_c: 25.7040659443716 avg_loss_a: -69.18849490733629
Número de pasos del episodio 12592 son episode_steps:67
Total Steps: 814067 Episode Num: 12592 Reward: 9.391553288490401 avg_loss_c: 27.27714757776972 avg_loss_a: -67.6002494470397
Número de pasos del episodio 12593 son episode_steps:99
Total Steps: 814166 Episode Num: 12593 Reward: 14.649304604954963 avg_loss_c: 26.806864112314553 avg_loss_a: -69.46020765978881
Número de pasos del episodio 12594 son episode_steps:69
Total Steps: 814235 Episode Num: 12594 Reward: -18.66850678490439 avg_loss_c: 26.221667745838996 avg_loss_a: -69.08762282219486
Número de pasos del episodio 12595 son episode_steps:285
Total Steps: 814520 Episode Num: 12595 Reward: 207.98632216813195 avg_loss_c: 26.128034705446478 avg_loss_a: -68.93836659213953
Número de pasos del episodio 12596 son episode_steps:50
Total Steps: 814570 Episode Num: 12596 Reward: -38.60695612762496 avg_loss_c: 26.167929039001464 avg_loss_a: -69.38419036865234
Número de pasos del episodio 12597 son episode_steps:145
Total Steps: 814715 Episode Num: 12597 Reward: -26.6557289424411 avg_loss_c: 25.87974036644245 avg_loss_a: -68.41507442079741
Número de pasos del episodio 12598 son episode_steps:181
Total Steps: 814896 Episode Num: 12598 Reward: 109.49601409626723 avg_loss_c: 26.63560640219167 avg_loss_a: -68.73945255174162
Número de pasos del episodio 12599 son episode_steps:48
Total Steps: 814944 Episode Num: 12599 Reward: -26.98519995635857 avg_loss_c: 25.72728153069814 avg_loss_a: -69.18219550450642
Número de pasos del episodio 12600 son episode_steps:205
Total Steps: 815149 Episode Num: 12600 Reward: 40.329351611461995 avg_loss_c: 27.07116697357922 avg_loss_a: -69.6905783304354
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 46.098402
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12601 son episode_steps:102
Total Steps: 815251 Episode Num: 12601 Reward: -1.2989504552425295 avg_loss_c: 26.41201301649505 avg_loss_a: -70.45846879248525
Número de pasos del episodio 12602 son episode_steps:46
Total Steps: 815297 Episode Num: 12602 Reward: -15.760606385085385 avg_loss_c: 26.26007262520168 avg_loss_a: -67.70143492325492
Número de pasos del episodio 12603 son episode_steps:39
Total Steps: 815336 Episode Num: 12603 Reward: -19.60723698171886 avg_loss_c: 26.50058007851625 avg_loss_a: -69.64219724214993
Número de pasos del episodio 12604 son episode_steps:39
Total Steps: 815375 Episode Num: 12604 Reward: -21.341541375409925 avg_loss_c: 27.77368041796562 avg_loss_a: -68.40316567054161
Número de pasos del episodio 12605 son episode_steps:40
Total Steps: 815415 Episode Num: 12605 Reward: -33.27536024304333 avg_loss_c: 28.737556982040406 avg_loss_a: -68.6053430557251
Número de pasos del episodio 12606 son episode_steps:95
Total Steps: 815510 Episode Num: 12606 Reward: 15.211996737592193 avg_loss_c: 26.001690613596065 avg_loss_a: -69.24739877801193
Número de pasos del episodio 12607 son episode_steps:96
Total Steps: 815606 Episode Num: 12607 Reward: 9.224527333060191 avg_loss_c: 27.3362877368927 avg_loss_a: -68.16925652821858
Número de pasos del episodio 12608 son episode_steps:144
Total Steps: 815750 Episode Num: 12608 Reward: 51.507098396412765 avg_loss_c: 26.90054515997569 avg_loss_a: -67.92643377516005
Número de pasos del episodio 12609 son episode_steps:92
Total Steps: 815842 Episode Num: 12609 Reward: 35.72200758938015 avg_loss_c: 27.45716267046721 avg_loss_a: -68.50456204621688
Número de pasos del episodio 12610 son episode_steps:169
Total Steps: 816011 Episode Num: 12610 Reward: 66.1925724458818 avg_loss_c: 26.627846035026234 avg_loss_a: -68.67448362090884
Número de pasos del episodio 12611 son episode_steps:124
Total Steps: 816135 Episode Num: 12611 Reward: 52.76777390263695 avg_loss_c: 27.380862989733295 avg_loss_a: -68.55322899356965
Número de pasos del episodio 12612 son episode_steps:317
Total Steps: 816452 Episode Num: 12612 Reward: 207.65126588532613 avg_loss_c: 26.065346546353602 avg_loss_a: -68.93087024869227
Número de pasos del episodio 12613 son episode_steps:95
Total Steps: 816547 Episode Num: 12613 Reward: -48.24683842795913 avg_loss_c: 26.76152236336156 avg_loss_a: -68.6160340961657
Número de pasos del episodio 12614 son episode_steps:41
Total Steps: 816588 Episode Num: 12614 Reward: -5.449826528348678 avg_loss_c: 25.95872102132658 avg_loss_a: -66.93251000381098
Número de pasos del episodio 12615 son episode_steps:112
Total Steps: 816700 Episode Num: 12615 Reward: 68.4738297704233 avg_loss_c: 26.258912461144583 avg_loss_a: -68.4048342023577
Número de pasos del episodio 12616 son episode_steps:155
Total Steps: 816855 Episode Num: 12616 Reward: 94.72776969446397 avg_loss_c: 26.255080216930757 avg_loss_a: -68.50774265412362
Número de pasos del episodio 12617 son episode_steps:18
Total Steps: 816873 Episode Num: 12617 Reward: -32.441970600717276 avg_loss_c: 26.389596780141193 avg_loss_a: -67.5772196451823
Número de pasos del episodio 12618 son episode_steps:106
Total Steps: 816979 Episode Num: 12618 Reward: 58.389801660545565 avg_loss_c: 26.560794902297687 avg_loss_a: -69.24958844454784
Número de pasos del episodio 12619 son episode_steps:141
Total Steps: 817120 Episode Num: 12619 Reward: 93.27187395266759 avg_loss_c: 26.09173786893804 avg_loss_a: -69.02070682606798
Número de pasos del episodio 12620 son episode_steps:196
Total Steps: 817316 Episode Num: 12620 Reward: 124.87563049764205 avg_loss_c: 25.787236515356568 avg_loss_a: -69.16496440342495
Número de pasos del episodio 12621 son episode_steps:131
Total Steps: 817447 Episode Num: 12621 Reward: 60.38983074843736 avg_loss_c: 26.195611706216827 avg_loss_a: -68.47738041768547
Número de pasos del episodio 12622 son episode_steps:104
Total Steps: 817551 Episode Num: 12622 Reward: 25.38369833835151 avg_loss_c: 26.325214862823486 avg_loss_a: -69.36169851743259
Número de pasos del episodio 12623 son episode_steps:72
Total Steps: 817623 Episode Num: 12623 Reward: -65.10493034911363 avg_loss_c: 26.215557204352486 avg_loss_a: -69.22613101535373
Número de pasos del episodio 12624 son episode_steps:99
Total Steps: 817722 Episode Num: 12624 Reward: -32.72907914436378 avg_loss_c: 28.37671399357343 avg_loss_a: -68.22124404136581
Número de pasos del episodio 12625 son episode_steps:41
Total Steps: 817763 Episode Num: 12625 Reward: -5.630048768648994 avg_loss_c: 25.347196811582982 avg_loss_a: -68.37782920279155
Número de pasos del episodio 12626 son episode_steps:101
Total Steps: 817864 Episode Num: 12626 Reward: 29.013695980040836 avg_loss_c: 26.58832313990829 avg_loss_a: -68.41427891797359
Número de pasos del episodio 12627 son episode_steps:52
Total Steps: 817916 Episode Num: 12627 Reward: 9.322351270762287 avg_loss_c: 26.59632367354173 avg_loss_a: -69.14934510451097
Número de pasos del episodio 12628 son episode_steps:71
Total Steps: 817987 Episode Num: 12628 Reward: -2.077495461326424 avg_loss_c: 25.89674146410445 avg_loss_a: -68.64423961370764
Número de pasos del episodio 12629 son episode_steps:176
Total Steps: 818163 Episode Num: 12629 Reward: 107.75213322353528 avg_loss_c: 26.46486590125344 avg_loss_a: -68.74351132999767
Número de pasos del episodio 12630 son episode_steps:65
Total Steps: 818228 Episode Num: 12630 Reward: -20.285200158931506 avg_loss_c: 25.665308233407828 avg_loss_a: -68.58512772780199
Número de pasos del episodio 12631 son episode_steps:112
Total Steps: 818340 Episode Num: 12631 Reward: -93.53554501272728 avg_loss_c: 26.562742693083628 avg_loss_a: -68.62916803359985
Número de pasos del episodio 12632 son episode_steps:189
Total Steps: 818529 Episode Num: 12632 Reward: 104.80151251617536 avg_loss_c: 26.59028187504521 avg_loss_a: -68.40776025681268
Número de pasos del episodio 12633 son episode_steps:88
Total Steps: 818617 Episode Num: 12633 Reward: 72.41497746434203 avg_loss_c: 25.81171633980491 avg_loss_a: -68.36094986308704
Número de pasos del episodio 12634 son episode_steps:72
Total Steps: 818689 Episode Num: 12634 Reward: 13.495902799523847 avg_loss_c: 26.504587690035503 avg_loss_a: -68.30081166161432
Número de pasos del episodio 12635 son episode_steps:147
Total Steps: 818836 Episode Num: 12635 Reward: 51.49518583805488 avg_loss_c: 26.640237224345306 avg_loss_a: -68.76541609991165
Número de pasos del episodio 12636 son episode_steps:132
Total Steps: 818968 Episode Num: 12636 Reward: 87.46950739513915 avg_loss_c: 25.5307547973864 avg_loss_a: -68.26864808978456
Número de pasos del episodio 12637 son episode_steps:56
Total Steps: 819024 Episode Num: 12637 Reward: 6.397263642345617 avg_loss_c: 26.219830955777848 avg_loss_a: -69.36799049377441
Número de pasos del episodio 12638 son episode_steps:56
Total Steps: 819080 Episode Num: 12638 Reward: -14.55118272987375 avg_loss_c: 26.24549470629011 avg_loss_a: -68.15973690577916
Número de pasos del episodio 12639 son episode_steps:61
Total Steps: 819141 Episode Num: 12639 Reward: -3.8397980752533383 avg_loss_c: 25.718140742817862 avg_loss_a: -67.4742983208328
Número de pasos del episodio 12640 son episode_steps:68
Total Steps: 819209 Episode Num: 12640 Reward: -5.948635543101036 avg_loss_c: 26.11890130884507 avg_loss_a: -67.1658919839298
Número de pasos del episodio 12641 son episode_steps:137
Total Steps: 819346 Episode Num: 12641 Reward: 48.58746870540856 avg_loss_c: 25.833348782393184 avg_loss_a: -67.59874165667235
Número de pasos del episodio 12642 son episode_steps:135
Total Steps: 819481 Episode Num: 12642 Reward: 54.27583264661371 avg_loss_c: 26.37724767614294 avg_loss_a: -67.71523652253327
Número de pasos del episodio 12643 son episode_steps:53
Total Steps: 819534 Episode Num: 12643 Reward: -39.43869464382554 avg_loss_c: 24.874578997773945 avg_loss_a: -67.86485038613374
Número de pasos del episodio 12644 son episode_steps:63
Total Steps: 819597 Episode Num: 12644 Reward: -20.49503404788961 avg_loss_c: 26.95308546036009 avg_loss_a: -67.32570999387711
Número de pasos del episodio 12645 son episode_steps:83
Total Steps: 819680 Episode Num: 12645 Reward: -50.324548069383724 avg_loss_c: 25.462908710341857 avg_loss_a: -67.4699884437653
Número de pasos del episodio 12646 son episode_steps:230
Total Steps: 819910 Episode Num: 12646 Reward: 96.86863396179515 avg_loss_c: 26.37554648855458 avg_loss_a: -66.95148335332456
Número de pasos del episodio 12647 son episode_steps:167
Total Steps: 820077 Episode Num: 12647 Reward: 80.07915834486009 avg_loss_c: 26.53214510043938 avg_loss_a: -67.81727156953184
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 143.315238
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12648 son episode_steps:36
Total Steps: 820113 Episode Num: 12648 Reward: -36.21198155198971 avg_loss_c: 26.425460391574436 avg_loss_a: -68.51655620998807
Número de pasos del episodio 12649 son episode_steps:132
Total Steps: 820245 Episode Num: 12649 Reward: -13.614146430678662 avg_loss_c: 26.135625766985346 avg_loss_a: -66.69845141786517
Número de pasos del episodio 12650 son episode_steps:41
Total Steps: 820286 Episode Num: 12650 Reward: -50.283438886491055 avg_loss_c: 26.741556214123236 avg_loss_a: -67.47695792593608
Número de pasos del episodio 12651 son episode_steps:86
Total Steps: 820372 Episode Num: 12651 Reward: -27.154819338591984 avg_loss_c: 27.929040354351663 avg_loss_a: -67.53117574647416
Número de pasos del episodio 12652 son episode_steps:63
Total Steps: 820435 Episode Num: 12652 Reward: -4.8100673922938295 avg_loss_c: 25.899714061192103 avg_loss_a: -67.02970553201342
Número de pasos del episodio 12653 son episode_steps:173
Total Steps: 820608 Episode Num: 12653 Reward: 96.09192402049068 avg_loss_c: 27.3486958211557 avg_loss_a: -66.86674305469315
Número de pasos del episodio 12654 son episode_steps:86
Total Steps: 820694 Episode Num: 12654 Reward: -24.98193680327856 avg_loss_c: 27.0443106362986 avg_loss_a: -67.39989648863326
Número de pasos del episodio 12655 son episode_steps:101
Total Steps: 820795 Episode Num: 12655 Reward: 23.987796080134963 avg_loss_c: 27.370603976863446 avg_loss_a: -67.58451027445274
Número de pasos del episodio 12656 son episode_steps:47
Total Steps: 820842 Episode Num: 12656 Reward: -36.469788227147106 avg_loss_c: 27.327561439351832 avg_loss_a: -66.61310090409948
Número de pasos del episodio 12657 son episode_steps:212
Total Steps: 821054 Episode Num: 12657 Reward: 166.9074985591901 avg_loss_c: 27.378160881546307 avg_loss_a: -67.20091290743846
Número de pasos del episodio 12658 son episode_steps:38
Total Steps: 821092 Episode Num: 12658 Reward: -35.05861434076851 avg_loss_c: 26.858231042560778 avg_loss_a: -65.74130289178146
Número de pasos del episodio 12659 son episode_steps:169
Total Steps: 821261 Episode Num: 12659 Reward: 78.41310640655291 avg_loss_c: 27.835160424723426 avg_loss_a: -67.3992840016382
Número de pasos del episodio 12660 son episode_steps:143
Total Steps: 821404 Episode Num: 12660 Reward: 105.58670224385853 avg_loss_c: 27.311622219485837 avg_loss_a: -66.91745256543993
Número de pasos del episodio 12661 son episode_steps:74
Total Steps: 821478 Episode Num: 12661 Reward: 42.6458292108956 avg_loss_c: 28.148800076665104 avg_loss_a: -68.45354987479546
Número de pasos del episodio 12662 son episode_steps:111
Total Steps: 821589 Episode Num: 12662 Reward: 9.01263789862514 avg_loss_c: 27.22104414518889 avg_loss_a: -67.63246546564875
Número de pasos del episodio 12663 son episode_steps:56
Total Steps: 821645 Episode Num: 12663 Reward: 17.1476478372693 avg_loss_c: 26.46127019609724 avg_loss_a: -66.99099717821393
Número de pasos del episodio 12664 son episode_steps:85
Total Steps: 821730 Episode Num: 12664 Reward: -56.67661632840187 avg_loss_c: 28.691373241648954 avg_loss_a: -67.34510417265051
Número de pasos del episodio 12665 son episode_steps:68
Total Steps: 821798 Episode Num: 12665 Reward: 33.58441501992745 avg_loss_c: 27.717193855958826 avg_loss_a: -66.95782021915211
Número de pasos del episodio 12666 son episode_steps:87
Total Steps: 821885 Episode Num: 12666 Reward: 6.1601742564812785 avg_loss_c: 27.232076864132935 avg_loss_a: -67.39692972994399
Número de pasos del episodio 12667 son episode_steps:174
Total Steps: 822059 Episode Num: 12667 Reward: 80.1633106036269 avg_loss_c: 27.46814489364624 avg_loss_a: -66.60079859591079
Número de pasos del episodio 12668 son episode_steps:84
Total Steps: 822143 Episode Num: 12668 Reward: -19.572399096768656 avg_loss_c: 27.75037919907343 avg_loss_a: -67.15943790617443
Número de pasos del episodio 12669 son episode_steps:69
Total Steps: 822212 Episode Num: 12669 Reward: -44.21475363078005 avg_loss_c: 27.865887296372566 avg_loss_a: -67.41914323447408
Número de pasos del episodio 12670 son episode_steps:93
Total Steps: 822305 Episode Num: 12670 Reward: 25.493726874814126 avg_loss_c: 27.676845058318108 avg_loss_a: -67.3805640435988
Número de pasos del episodio 12671 son episode_steps:43
Total Steps: 822348 Episode Num: 12671 Reward: -30.452605060826222 avg_loss_c: 28.436698070792264 avg_loss_a: -66.47644326853198
Número de pasos del episodio 12672 son episode_steps:35
Total Steps: 822383 Episode Num: 12672 Reward: -48.5095983547339 avg_loss_c: 26.693364988054547 avg_loss_a: -65.7327392578125
Número de pasos del episodio 12673 son episode_steps:180
Total Steps: 822563 Episode Num: 12673 Reward: 22.475755323575722 avg_loss_c: 27.71099679734972 avg_loss_a: -66.99228837754991
Número de pasos del episodio 12674 son episode_steps:57
Total Steps: 822620 Episode Num: 12674 Reward: -56.41503656733029 avg_loss_c: 27.64575931482148 avg_loss_a: -66.2233851918003
Número de pasos del episodio 12675 son episode_steps:190
Total Steps: 822810 Episode Num: 12675 Reward: 74.83764033256944 avg_loss_c: 27.13961585195441 avg_loss_a: -66.64154883936831
Número de pasos del episodio 12676 son episode_steps:83
Total Steps: 822893 Episode Num: 12676 Reward: -0.7566827047591866 avg_loss_c: 27.55524821453784 avg_loss_a: -66.22010380388743
Número de pasos del episodio 12677 son episode_steps:45
Total Steps: 822938 Episode Num: 12677 Reward: -5.329543548865294 avg_loss_c: 28.467667939927843 avg_loss_a: -66.1031364440918
Número de pasos del episodio 12678 son episode_steps:58
Total Steps: 822996 Episode Num: 12678 Reward: -27.06225673682254 avg_loss_c: 28.637132513112036 avg_loss_a: -66.08772922384328
Número de pasos del episodio 12679 son episode_steps:88
Total Steps: 823084 Episode Num: 12679 Reward: 37.82207531232738 avg_loss_c: 26.937141266736116 avg_loss_a: -66.14924838326193
Número de pasos del episodio 12680 son episode_steps:53
Total Steps: 823137 Episode Num: 12680 Reward: -79.46867193284035 avg_loss_c: 26.955963134765625 avg_loss_a: -66.32027032240381
Número de pasos del episodio 12681 son episode_steps:57
Total Steps: 823194 Episode Num: 12681 Reward: -20.631719556617593 avg_loss_c: 27.502921388860333 avg_loss_a: -67.24495871025219
Número de pasos del episodio 12682 son episode_steps:193
Total Steps: 823387 Episode Num: 12682 Reward: 55.33314521823232 avg_loss_c: 28.013952531962815 avg_loss_a: -66.52405223945262
Número de pasos del episodio 12683 son episode_steps:45
Total Steps: 823432 Episode Num: 12683 Reward: -13.11429174131937 avg_loss_c: 26.337615712483725 avg_loss_a: -66.44332360161675
Número de pasos del episodio 12684 son episode_steps:64
Total Steps: 823496 Episode Num: 12684 Reward: -36.39279541459968 avg_loss_c: 27.82056361436844 avg_loss_a: -65.93157982826233
Número de pasos del episodio 12685 son episode_steps:172
Total Steps: 823668 Episode Num: 12685 Reward: 59.213188338449974 avg_loss_c: 28.505513457364813 avg_loss_a: -66.36689656279808
Número de pasos del episodio 12686 son episode_steps:51
Total Steps: 823719 Episode Num: 12686 Reward: -41.93060308367806 avg_loss_c: 29.112863166659487 avg_loss_a: -66.36496465346393
Número de pasos del episodio 12687 son episode_steps:106
Total Steps: 823825 Episode Num: 12687 Reward: 5.2683562790609395 avg_loss_c: 27.91922751012838 avg_loss_a: -65.98075197327812
Número de pasos del episodio 12688 son episode_steps:141
Total Steps: 823966 Episode Num: 12688 Reward: -10.998863683448516 avg_loss_c: 29.081152895663646 avg_loss_a: -66.5231218811468
Número de pasos del episodio 12689 son episode_steps:57
Total Steps: 824023 Episode Num: 12689 Reward: -41.62886580108674 avg_loss_c: 30.62609445003041 avg_loss_a: -65.38902777956243
Número de pasos del episodio 12690 son episode_steps:80
Total Steps: 824103 Episode Num: 12690 Reward: -20.38831613535527 avg_loss_c: 28.013652777671815 avg_loss_a: -64.89848699569703
Número de pasos del episodio 12691 son episode_steps:101
Total Steps: 824204 Episode Num: 12691 Reward: -31.003341334585272 avg_loss_c: 27.72783564577008 avg_loss_a: -65.42301215747796
Número de pasos del episodio 12692 son episode_steps:117
Total Steps: 824321 Episode Num: 12692 Reward: 31.40268105454152 avg_loss_c: 28.469183375692776 avg_loss_a: -65.54083545391376
Número de pasos del episodio 12693 son episode_steps:74
Total Steps: 824395 Episode Num: 12693 Reward: 4.2761661758579725 avg_loss_c: 28.53184462882377 avg_loss_a: -64.26811754381335
Número de pasos del episodio 12694 son episode_steps:60
Total Steps: 824455 Episode Num: 12694 Reward: -10.222863914448519 avg_loss_c: 28.57167174021403 avg_loss_a: -65.96769943237305
Número de pasos del episodio 12695 son episode_steps:34
Total Steps: 824489 Episode Num: 12695 Reward: 4.74362899365587 avg_loss_c: 29.53176700367647 avg_loss_a: -65.36168805290671
Número de pasos del episodio 12696 son episode_steps:68
Total Steps: 824557 Episode Num: 12696 Reward: 23.737421779863 avg_loss_c: 28.680912242216223 avg_loss_a: -66.46244991526885
Número de pasos del episodio 12697 son episode_steps:104
Total Steps: 824661 Episode Num: 12697 Reward: -55.72696027288637 avg_loss_c: 29.220119292919453 avg_loss_a: -65.93059752537654
Número de pasos del episodio 12698 son episode_steps:87
Total Steps: 824748 Episode Num: 12698 Reward: -24.20463297833668 avg_loss_c: 29.53701161790168 avg_loss_a: -65.91282995815935
Número de pasos del episodio 12699 son episode_steps:52
Total Steps: 824800 Episode Num: 12699 Reward: -35.12046437004255 avg_loss_c: 28.95621395111084 avg_loss_a: -66.5405943943904
Número de pasos del episodio 12700 son episode_steps:86
Total Steps: 824886 Episode Num: 12700 Reward: 17.936679727373033 avg_loss_c: 29.04231574923493 avg_loss_a: -66.64216782325921
Número de pasos del episodio 12701 son episode_steps:75
Total Steps: 824961 Episode Num: 12701 Reward: -41.674683754417146 avg_loss_c: 30.07704495747884 avg_loss_a: -65.31825205485026
Número de pasos del episodio 12702 son episode_steps:131
Total Steps: 825092 Episode Num: 12702 Reward: 17.899106000312457 avg_loss_c: 29.541108400767087 avg_loss_a: -66.1176878950978
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 75.787112
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12703 son episode_steps:195
Total Steps: 825287 Episode Num: 12703 Reward: 106.94895074263592 avg_loss_c: 29.140539971376075 avg_loss_a: -65.50933251014122
Número de pasos del episodio 12704 son episode_steps:72
Total Steps: 825359 Episode Num: 12704 Reward: -44.55780528850871 avg_loss_c: 29.221395121680366 avg_loss_a: -65.28946018218994
Número de pasos del episodio 12705 son episode_steps:191
Total Steps: 825550 Episode Num: 12705 Reward: 92.76928124558445 avg_loss_c: 28.742660222877383 avg_loss_a: -66.03102671039042
Número de pasos del episodio 12706 son episode_steps:43
Total Steps: 825593 Episode Num: 12706 Reward: 7.470406470404162 avg_loss_c: 28.489789962768555 avg_loss_a: -65.89546948809956
Número de pasos del episodio 12707 son episode_steps:71
Total Steps: 825664 Episode Num: 12707 Reward: 45.99204853560757 avg_loss_c: 29.317211715268417 avg_loss_a: -66.37655757850325
Número de pasos del episodio 12708 son episode_steps:127
Total Steps: 825791 Episode Num: 12708 Reward: 5.753008515907229 avg_loss_c: 28.650490302739183 avg_loss_a: -66.66752879826103
Número de pasos del episodio 12709 son episode_steps:84
Total Steps: 825875 Episode Num: 12709 Reward: 28.7476397051678 avg_loss_c: 30.077903089069185 avg_loss_a: -66.07688222612653
Número de pasos del episodio 12710 son episode_steps:93
Total Steps: 825968 Episode Num: 12710 Reward: -8.574416823414863 avg_loss_c: 29.230993209346646 avg_loss_a: -64.80129418321835
Número de pasos del episodio 12711 son episode_steps:28
Total Steps: 825996 Episode Num: 12711 Reward: -26.91187730911767 avg_loss_c: 26.853646687098912 avg_loss_a: -66.25902257646833
Número de pasos del episodio 12712 son episode_steps:69
Total Steps: 826065 Episode Num: 12712 Reward: -13.783700714802322 avg_loss_c: 29.11501840232075 avg_loss_a: -65.4583482604096
Número de pasos del episodio 12713 son episode_steps:70
Total Steps: 826135 Episode Num: 12713 Reward: 9.274905956382613 avg_loss_c: 29.104088810511996 avg_loss_a: -65.72459498814175
Número de pasos del episodio 12714 son episode_steps:80
Total Steps: 826215 Episode Num: 12714 Reward: 1.1112752570420934 avg_loss_c: 30.323912477493288 avg_loss_a: -65.38153171539307
Número de pasos del episodio 12715 son episode_steps:82
Total Steps: 826297 Episode Num: 12715 Reward: -20.371416162652906 avg_loss_c: 29.437160119777772 avg_loss_a: -67.17471443734517
Número de pasos del episodio 12716 son episode_steps:87
Total Steps: 826384 Episode Num: 12716 Reward: 38.82499817878382 avg_loss_c: 30.81777789674956 avg_loss_a: -65.68975374068337
Número de pasos del episodio 12717 son episode_steps:85
Total Steps: 826469 Episode Num: 12717 Reward: 35.12455822052097 avg_loss_c: 30.995119610954735 avg_loss_a: -65.8968822703642
Número de pasos del episodio 12718 son episode_steps:60
Total Steps: 826529 Episode Num: 12718 Reward: 1.3979901354300885 avg_loss_c: 29.574665768941244 avg_loss_a: -65.8599131266276
Número de pasos del episodio 12719 son episode_steps:76
Total Steps: 826605 Episode Num: 12719 Reward: 23.189315493139645 avg_loss_c: 30.450652574238024 avg_loss_a: -64.71438769290322
Número de pasos del episodio 12720 son episode_steps:16
Total Steps: 826621 Episode Num: 12720 Reward: -51.52338353684283 avg_loss_c: 30.08039426803589 avg_loss_a: -67.16294765472412
Número de pasos del episodio 12721 son episode_steps:89
Total Steps: 826710 Episode Num: 12721 Reward: 2.1803436429357683 avg_loss_c: 30.808155124107103 avg_loss_a: -66.06208501237163
Número de pasos del episodio 12722 son episode_steps:111
Total Steps: 826821 Episode Num: 12722 Reward: 68.60015594003184 avg_loss_c: 30.224546810528178 avg_loss_a: -66.10259432406039
Número de pasos del episodio 12723 son episode_steps:93
Total Steps: 826914 Episode Num: 12723 Reward: 6.643333404207943 avg_loss_c: 30.043740816013788 avg_loss_a: -66.11678429060085
Número de pasos del episodio 12724 son episode_steps:47
Total Steps: 826961 Episode Num: 12724 Reward: -16.55096765982652 avg_loss_c: 30.443866121008043 avg_loss_a: -65.5805252562178
Número de pasos del episodio 12725 son episode_steps:94
Total Steps: 827055 Episode Num: 12725 Reward: 72.62271219750758 avg_loss_c: 31.666151898972533 avg_loss_a: -64.49062323062978
Número de pasos del episodio 12726 son episode_steps:46
Total Steps: 827101 Episode Num: 12726 Reward: -40.48919826540157 avg_loss_c: 30.402348020802375 avg_loss_a: -65.62303344063137
Número de pasos del episodio 12727 son episode_steps:98
Total Steps: 827199 Episode Num: 12727 Reward: 12.916846486729511 avg_loss_c: 31.805543432430344 avg_loss_a: -65.60104658165757
Número de pasos del episodio 12728 son episode_steps:83
Total Steps: 827282 Episode Num: 12728 Reward: 25.076744184339987 avg_loss_c: 30.82042563105204 avg_loss_a: -65.0899015679417
Número de pasos del episodio 12729 son episode_steps:138
Total Steps: 827420 Episode Num: 12729 Reward: 74.21071435305971 avg_loss_c: 30.876772617948227 avg_loss_a: -66.01566336811453
Número de pasos del episodio 12730 son episode_steps:128
Total Steps: 827548 Episode Num: 12730 Reward: 51.554484683857595 avg_loss_c: 31.341829240322113 avg_loss_a: -64.0523322224617
Número de pasos del episodio 12731 son episode_steps:65
Total Steps: 827613 Episode Num: 12731 Reward: 13.45738535650913 avg_loss_c: 30.494553991464468 avg_loss_a: -64.00073946439304
Número de pasos del episodio 12732 son episode_steps:62
Total Steps: 827675 Episode Num: 12732 Reward: 0.7827580479798062 avg_loss_c: 30.615058099069902 avg_loss_a: -65.0381098101216
Número de pasos del episodio 12733 son episode_steps:88
Total Steps: 827763 Episode Num: 12733 Reward: 0.9348035122909675 avg_loss_c: 31.999773719094016 avg_loss_a: -63.99134705283425
Número de pasos del episodio 12734 son episode_steps:54
Total Steps: 827817 Episode Num: 12734 Reward: -3.9726248411704423 avg_loss_c: 31.541639822500724 avg_loss_a: -63.09156742802373
Número de pasos del episodio 12735 son episode_steps:101
Total Steps: 827918 Episode Num: 12735 Reward: -2.1290530130102563 avg_loss_c: 30.984527455698146 avg_loss_a: -63.43232855466333
Número de pasos del episodio 12736 son episode_steps:136
Total Steps: 828054 Episode Num: 12736 Reward: 38.938000495216535 avg_loss_c: 32.15303395776188 avg_loss_a: -64.16588396184585
Número de pasos del episodio 12737 son episode_steps:62
Total Steps: 828116 Episode Num: 12737 Reward: 20.573352514863913 avg_loss_c: 32.46318755611296 avg_loss_a: -62.29225478633757
Número de pasos del episodio 12738 son episode_steps:56
Total Steps: 828172 Episode Num: 12738 Reward: -17.165906558544314 avg_loss_c: 33.02865672111511 avg_loss_a: -63.42007228306362
Número de pasos del episodio 12739 son episode_steps:51
Total Steps: 828223 Episode Num: 12739 Reward: -35.000797345156236 avg_loss_c: 31.8109556833903 avg_loss_a: -63.90225623635685
Número de pasos del episodio 12740 son episode_steps:137
Total Steps: 828360 Episode Num: 12740 Reward: 72.39224996059309 avg_loss_c: 32.179568882406194 avg_loss_a: -63.74967438635165
Número de pasos del episodio 12741 son episode_steps:50
Total Steps: 828410 Episode Num: 12741 Reward: 5.075580508997525 avg_loss_c: 32.10058227539062 avg_loss_a: -63.750439147949216
Número de pasos del episodio 12742 son episode_steps:102
Total Steps: 828512 Episode Num: 12742 Reward: 59.4290854271698 avg_loss_c: 31.43127504984538 avg_loss_a: -62.8209997438917
Número de pasos del episodio 12743 son episode_steps:63
Total Steps: 828575 Episode Num: 12743 Reward: -59.307684823007335 avg_loss_c: 32.11296953473772 avg_loss_a: -62.6522707257952
Número de pasos del episodio 12744 son episode_steps:120
Total Steps: 828695 Episode Num: 12744 Reward: 31.07996246390534 avg_loss_c: 32.64133661588033 avg_loss_a: -63.75431442260742
Número de pasos del episodio 12745 son episode_steps:243
Total Steps: 828938 Episode Num: 12745 Reward: 127.70494940045128 avg_loss_c: 32.516917515193484 avg_loss_a: -62.66035750275286
Número de pasos del episodio 12746 son episode_steps:274
Total Steps: 829212 Episode Num: 12746 Reward: 186.37649576911164 avg_loss_c: 31.807154175138823 avg_loss_a: -62.336230591265824
Número de pasos del episodio 12747 son episode_steps:63
Total Steps: 829275 Episode Num: 12747 Reward: -24.566256686727833 avg_loss_c: 31.473721579899863 avg_loss_a: -63.95363398960659
Número de pasos del episodio 12748 son episode_steps:64
Total Steps: 829339 Episode Num: 12748 Reward: 11.644308200512832 avg_loss_c: 32.041060984134674 avg_loss_a: -62.62134802341461
Número de pasos del episodio 12749 son episode_steps:149
Total Steps: 829488 Episode Num: 12749 Reward: -32.318971883597975 avg_loss_c: 32.258872012964034 avg_loss_a: -62.10358114050539
Número de pasos del episodio 12750 son episode_steps:101
Total Steps: 829589 Episode Num: 12750 Reward: -6.909349789295312 avg_loss_c: 33.46740433721259 avg_loss_a: -61.028766972003595
Número de pasos del episodio 12751 son episode_steps:22
Total Steps: 829611 Episode Num: 12751 Reward: -41.564599638741306 avg_loss_c: 31.778234221718527 avg_loss_a: -61.65508894486861
Número de pasos del episodio 12752 son episode_steps:196
Total Steps: 829807 Episode Num: 12752 Reward: 23.675004164620795 avg_loss_c: 32.35648306048646 avg_loss_a: -62.3716387846032
Número de pasos del episodio 12753 son episode_steps:192
Total Steps: 829999 Episode Num: 12753 Reward: 99.4213566146594 avg_loss_c: 31.87377052505811 avg_loss_a: -62.40314678351084
Número de pasos del episodio 12754 son episode_steps:221
Total Steps: 830220 Episode Num: 12754 Reward: 115.70179832401215 avg_loss_c: 32.13579618876876 avg_loss_a: -62.38743056215312
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 95.128994
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12755 son episode_steps:142
Total Steps: 830362 Episode Num: 12755 Reward: 71.52488763788323 avg_loss_c: 31.534047556595063 avg_loss_a: -62.74876317843585
Número de pasos del episodio 12756 son episode_steps:163
Total Steps: 830525 Episode Num: 12756 Reward: 75.36702159903122 avg_loss_c: 31.34086198163179 avg_loss_a: -61.934108663921705
Número de pasos del episodio 12757 son episode_steps:52
Total Steps: 830577 Episode Num: 12757 Reward: -29.582447567613656 avg_loss_c: 32.11895517202524 avg_loss_a: -62.17450083219088
Número de pasos del episodio 12758 son episode_steps:72
Total Steps: 830649 Episode Num: 12758 Reward: -10.483855238215426 avg_loss_c: 31.445987224578857 avg_loss_a: -62.35622448391385
Número de pasos del episodio 12759 son episode_steps:148
Total Steps: 830797 Episode Num: 12759 Reward: -26.47705344616008 avg_loss_c: 32.260340175113164 avg_loss_a: -62.36222803270495
Número de pasos del episodio 12760 son episode_steps:112
Total Steps: 830909 Episode Num: 12760 Reward: 71.75904844053953 avg_loss_c: 32.224177496773855 avg_loss_a: -62.033064705984934
Número de pasos del episodio 12761 son episode_steps:154
Total Steps: 831063 Episode Num: 12761 Reward: 96.12399227569932 avg_loss_c: 31.799806916868533 avg_loss_a: -61.92247207443435
Número de pasos del episodio 12762 son episode_steps:66
Total Steps: 831129 Episode Num: 12762 Reward: -10.618072346202386 avg_loss_c: 30.53282239220359 avg_loss_a: -62.422408826423414
Número de pasos del episodio 12763 son episode_steps:232
Total Steps: 831361 Episode Num: 12763 Reward: 205.89128460366823 avg_loss_c: 31.331972656578852 avg_loss_a: -62.3039649766067
Número de pasos del episodio 12764 son episode_steps:126
Total Steps: 831487 Episode Num: 12764 Reward: 74.42996031665002 avg_loss_c: 30.98408932156033 avg_loss_a: -62.86230977376302
Número de pasos del episodio 12765 son episode_steps:183
Total Steps: 831670 Episode Num: 12765 Reward: 95.42286722889824 avg_loss_c: 30.733424035577826 avg_loss_a: -63.240668083149224
Número de pasos del episodio 12766 son episode_steps:30
Total Steps: 831700 Episode Num: 12766 Reward: -29.38093267402853 avg_loss_c: 31.08890463511149 avg_loss_a: -63.25532633463542
Número de pasos del episodio 12767 son episode_steps:133
Total Steps: 831833 Episode Num: 12767 Reward: 34.2956451919736 avg_loss_c: 30.1393014864814 avg_loss_a: -63.34727931201906
Número de pasos del episodio 12768 son episode_steps:50
Total Steps: 831883 Episode Num: 12768 Reward: -25.368014594085885 avg_loss_c: 30.008193321228028 avg_loss_a: -63.08612091064453
Número de pasos del episodio 12769 son episode_steps:207
Total Steps: 832090 Episode Num: 12769 Reward: 84.37800529859373 avg_loss_c: 30.412426593798948 avg_loss_a: -63.49558294913619
Número de pasos del episodio 12770 son episode_steps:79
Total Steps: 832169 Episode Num: 12770 Reward: 5.147928071085888 avg_loss_c: 30.738448082646237 avg_loss_a: -64.69551158856741
Número de pasos del episodio 12771 son episode_steps:103
Total Steps: 832272 Episode Num: 12771 Reward: 45.48404163608784 avg_loss_c: 30.3075434119956 avg_loss_a: -64.27068951060471
Número de pasos del episodio 12772 son episode_steps:132
Total Steps: 832404 Episode Num: 12772 Reward: 45.79747289703906 avg_loss_c: 30.92528960199067 avg_loss_a: -64.89139660921964
Número de pasos del episodio 12773 son episode_steps:79
Total Steps: 832483 Episode Num: 12773 Reward: 0.32805925992833185 avg_loss_c: 30.605084407178662 avg_loss_a: -63.84755832334108
Número de pasos del episodio 12774 son episode_steps:48
Total Steps: 832531 Episode Num: 12774 Reward: -33.51597946048707 avg_loss_c: 31.907659729321797 avg_loss_a: -65.05835819244385
Número de pasos del episodio 12775 son episode_steps:250
Total Steps: 832781 Episode Num: 12775 Reward: 146.69238690340924 avg_loss_c: 30.13236474609375 avg_loss_a: -64.5748793334961
Número de pasos del episodio 12776 son episode_steps:153
Total Steps: 832934 Episode Num: 12776 Reward: 102.43554769555928 avg_loss_c: 30.159261105107326 avg_loss_a: -64.79139377868253
Número de pasos del episodio 12777 son episode_steps:116
Total Steps: 833050 Episode Num: 12777 Reward: 52.703797902382895 avg_loss_c: 30.405517479469037 avg_loss_a: -65.02322913860452
Número de pasos del episodio 12778 son episode_steps:58
Total Steps: 833108 Episode Num: 12778 Reward: -6.479640747528797 avg_loss_c: 30.16984778437121 avg_loss_a: -64.52074471835432
Número de pasos del episodio 12779 son episode_steps:155
Total Steps: 833263 Episode Num: 12779 Reward: 72.4866013471769 avg_loss_c: 30.398528880457725 avg_loss_a: -64.86506830030872
Número de pasos del episodio 12780 son episode_steps:197
Total Steps: 833460 Episode Num: 12780 Reward: 139.75509184199913 avg_loss_c: 29.667558912093263 avg_loss_a: -65.86712375389138
Número de pasos del episodio 12781 son episode_steps:55
Total Steps: 833515 Episode Num: 12781 Reward: -14.011827604331508 avg_loss_c: 30.439962421764026 avg_loss_a: -65.52259022105824
Número de pasos del episodio 12782 son episode_steps:29
Total Steps: 833544 Episode Num: 12782 Reward: -30.787384128384968 avg_loss_c: 30.89724823524212 avg_loss_a: -65.18047385380186
Número de pasos del episodio 12783 son episode_steps:140
Total Steps: 833684 Episode Num: 12783 Reward: 28.83853531378576 avg_loss_c: 30.368348257882253 avg_loss_a: -65.55544569832938
Número de pasos del episodio 12784 son episode_steps:223
Total Steps: 833907 Episode Num: 12784 Reward: 105.71182208221079 avg_loss_c: 31.339805406305288 avg_loss_a: -65.34926175857339
Número de pasos del episodio 12785 son episode_steps:52
Total Steps: 833959 Episode Num: 12785 Reward: -2.2719710474875683 avg_loss_c: 31.001138393695538 avg_loss_a: -66.47233918996957
Número de pasos del episodio 12786 son episode_steps:57
Total Steps: 834016 Episode Num: 12786 Reward: -55.784335816389216 avg_loss_c: 30.917181450023985 avg_loss_a: -63.94598033971954
Número de pasos del episodio 12787 son episode_steps:68
Total Steps: 834084 Episode Num: 12787 Reward: -17.148594589432253 avg_loss_c: 32.787177702959845 avg_loss_a: -65.20966877656825
Número de pasos del episodio 12788 son episode_steps:175
Total Steps: 834259 Episode Num: 12788 Reward: 91.19150668166925 avg_loss_c: 32.69941315787179 avg_loss_a: -65.52934906005859
Número de pasos del episodio 12789 son episode_steps:70
Total Steps: 834329 Episode Num: 12789 Reward: 40.53562797043663 avg_loss_c: 31.688919830322266 avg_loss_a: -65.57430398123604
Número de pasos del episodio 12790 son episode_steps:55
Total Steps: 834384 Episode Num: 12790 Reward: -20.49049158251646 avg_loss_c: 31.324206161499024 avg_loss_a: -64.46741915616123
Número de pasos del episodio 12791 son episode_steps:171
Total Steps: 834555 Episode Num: 12791 Reward: 58.27867911331149 avg_loss_c: 31.771180526554932 avg_loss_a: -65.47357619436164
Número de pasos del episodio 12792 son episode_steps:47
Total Steps: 834602 Episode Num: 12792 Reward: 8.477060073101896 avg_loss_c: 30.99970655238375 avg_loss_a: -66.1455698216215
Número de pasos del episodio 12793 son episode_steps:88
Total Steps: 834690 Episode Num: 12793 Reward: -13.652557821296975 avg_loss_c: 30.225057320161298 avg_loss_a: -64.0712816065008
Número de pasos del episodio 12794 son episode_steps:162
Total Steps: 834852 Episode Num: 12794 Reward: 101.63959127714983 avg_loss_c: 31.75135114457872 avg_loss_a: -65.05499926908517
Número de pasos del episodio 12795 son episode_steps:51
Total Steps: 834903 Episode Num: 12795 Reward: 30.209950847934866 avg_loss_c: 31.771022310443954 avg_loss_a: -64.77338947969325
Número de pasos del episodio 12796 son episode_steps:58
Total Steps: 834961 Episode Num: 12796 Reward: -24.006617686732092 avg_loss_c: 30.556598038508973 avg_loss_a: -63.064647016854124
Número de pasos del episodio 12797 son episode_steps:200
Total Steps: 835161 Episode Num: 12797 Reward: 138.84875715491216 avg_loss_c: 32.25913039207458 avg_loss_a: -66.71695453643798
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 41.796620
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12798 son episode_steps:121
Total Steps: 835282 Episode Num: 12798 Reward: 2.295807222094213 avg_loss_c: 31.210622519500983 avg_loss_a: -65.66135841558787
Número de pasos del episodio 12799 son episode_steps:46
Total Steps: 835328 Episode Num: 12799 Reward: 22.358885762123165 avg_loss_c: 30.472940942515496 avg_loss_a: -65.5945283640986
Número de pasos del episodio 12800 son episode_steps:95
Total Steps: 835423 Episode Num: 12800 Reward: 13.884246123168124 avg_loss_c: 31.178642955579257 avg_loss_a: -66.95356678209806
Número de pasos del episodio 12801 son episode_steps:82
Total Steps: 835505 Episode Num: 12801 Reward: -93.87261711017912 avg_loss_c: 31.90280905002501 avg_loss_a: -66.7368136150081
Número de pasos del episodio 12802 son episode_steps:103
Total Steps: 835608 Episode Num: 12802 Reward: 42.742211208797194 avg_loss_c: 31.72296562935542 avg_loss_a: -66.07873475898816
Número de pasos del episodio 12803 son episode_steps:77
Total Steps: 835685 Episode Num: 12803 Reward: 14.86061274969704 avg_loss_c: 32.07817808374182 avg_loss_a: -65.5655912919478
Número de pasos del episodio 12804 son episode_steps:55
Total Steps: 835740 Episode Num: 12804 Reward: -49.89059754093212 avg_loss_c: 31.888892052390357 avg_loss_a: -65.34842113148082
Número de pasos del episodio 12805 son episode_steps:47
Total Steps: 835787 Episode Num: 12805 Reward: -66.2770029132585 avg_loss_c: 33.7907091505984 avg_loss_a: -66.02603977284532
Número de pasos del episodio 12806 son episode_steps:43
Total Steps: 835830 Episode Num: 12806 Reward: -11.565184096883593 avg_loss_c: 32.18454046027605 avg_loss_a: -66.6623544027639
Número de pasos del episodio 12807 son episode_steps:150
Total Steps: 835980 Episode Num: 12807 Reward: 46.21545105534827 avg_loss_c: 32.49730107625326 avg_loss_a: -66.09663330078125
Número de pasos del episodio 12808 son episode_steps:69
Total Steps: 836049 Episode Num: 12808 Reward: -8.23317307537639 avg_loss_c: 32.11433938620747 avg_loss_a: -65.77085014011548
Número de pasos del episodio 12809 son episode_steps:105
Total Steps: 836154 Episode Num: 12809 Reward: 47.88339374909671 avg_loss_c: 32.70660923549107 avg_loss_a: -65.78206147693453
Número de pasos del episodio 12810 son episode_steps:158
Total Steps: 836312 Episode Num: 12810 Reward: 62.39557503429815 avg_loss_c: 32.089797635621665 avg_loss_a: -66.38880118840858
Número de pasos del episodio 12811 son episode_steps:102
Total Steps: 836414 Episode Num: 12811 Reward: 39.334925012044685 avg_loss_c: 32.07949959998037 avg_loss_a: -65.12836882647346
Número de pasos del episodio 12812 son episode_steps:149
Total Steps: 836563 Episode Num: 12812 Reward: 7.611051511636005 avg_loss_c: 32.52958227324006 avg_loss_a: -66.4546791947128
Número de pasos del episodio 12813 son episode_steps:54
Total Steps: 836617 Episode Num: 12813 Reward: -8.705640067283893 avg_loss_c: 31.320342346473975 avg_loss_a: -65.21792263454861
Número de pasos del episodio 12814 son episode_steps:322
Total Steps: 836939 Episode Num: 12814 Reward: 154.909951592485 avg_loss_c: 30.994264513809487 avg_loss_a: -66.68320555124224
Número de pasos del episodio 12815 son episode_steps:69
Total Steps: 837008 Episode Num: 12815 Reward: -9.867382484798588 avg_loss_c: 31.205847228782766 avg_loss_a: -66.15497655453889
Número de pasos del episodio 12816 son episode_steps:39
Total Steps: 837047 Episode Num: 12816 Reward: 4.6703785536609015 avg_loss_c: 31.058125569270207 avg_loss_a: -65.84353442069812
Número de pasos del episodio 12817 son episode_steps:56
Total Steps: 837103 Episode Num: 12817 Reward: 5.907316961221801 avg_loss_c: 31.61328090940203 avg_loss_a: -65.80581964765277
Número de pasos del episodio 12818 son episode_steps:68
Total Steps: 837171 Episode Num: 12818 Reward: 3.4008631675267456 avg_loss_c: 31.817423147313736 avg_loss_a: -65.03891361460967
Número de pasos del episodio 12819 son episode_steps:123
Total Steps: 837294 Episode Num: 12819 Reward: 43.411519806817445 avg_loss_c: 31.67879948189588 avg_loss_a: -65.32827445549694
Número de pasos del episodio 12820 son episode_steps:90
Total Steps: 837384 Episode Num: 12820 Reward: 12.348907350027496 avg_loss_c: 31.42745566897922 avg_loss_a: -65.91946826510959
Número de pasos del episodio 12821 son episode_steps:71
Total Steps: 837455 Episode Num: 12821 Reward: -50.96969951222726 avg_loss_c: 30.66246733866947 avg_loss_a: -65.73227740005709
Número de pasos del episodio 12822 son episode_steps:69
Total Steps: 837524 Episode Num: 12822 Reward: -2.4147806844843296 avg_loss_c: 29.623295189677805 avg_loss_a: -65.72934429887412
Número de pasos del episodio 12823 son episode_steps:39
Total Steps: 837563 Episode Num: 12823 Reward: -11.092728887781856 avg_loss_c: 31.216822208502354 avg_loss_a: -65.82484690348308
Número de pasos del episodio 12824 son episode_steps:64
Total Steps: 837627 Episode Num: 12824 Reward: 11.568721462263774 avg_loss_c: 32.18606889247894 avg_loss_a: -66.27939641475677
Número de pasos del episodio 12825 son episode_steps:122
Total Steps: 837749 Episode Num: 12825 Reward: 25.29699966973294 avg_loss_c: 32.45998057381051 avg_loss_a: -64.19336913061923
Número de pasos del episodio 12826 son episode_steps:245
Total Steps: 837994 Episode Num: 12826 Reward: 100.46750584824375 avg_loss_c: 32.01900723515725 avg_loss_a: -65.81961539132254
Número de pasos del episodio 12827 son episode_steps:97
Total Steps: 838091 Episode Num: 12827 Reward: 56.461942571284006 avg_loss_c: 30.07974760311166 avg_loss_a: -66.98121658797116
Número de pasos del episodio 12828 son episode_steps:80
Total Steps: 838171 Episode Num: 12828 Reward: -11.190290077794508 avg_loss_c: 32.98168807029724 avg_loss_a: -65.31384248733521
Número de pasos del episodio 12829 son episode_steps:90
Total Steps: 838261 Episode Num: 12829 Reward: -46.91854033302811 avg_loss_c: 31.823338656955293 avg_loss_a: -65.01849127875434
Número de pasos del episodio 12830 son episode_steps:77
Total Steps: 838338 Episode Num: 12830 Reward: 20.75089002549586 avg_loss_c: 30.945524265239765 avg_loss_a: -66.20824580997616
Número de pasos del episodio 12831 son episode_steps:56
Total Steps: 838394 Episode Num: 12831 Reward: -1.6983271332015883 avg_loss_c: 32.08390058789934 avg_loss_a: -66.45856693812779
Número de pasos del episodio 12832 son episode_steps:91
Total Steps: 838485 Episode Num: 12832 Reward: 23.237993002286853 avg_loss_c: 32.049402027339724 avg_loss_a: -65.38205073429988
Número de pasos del episodio 12833 son episode_steps:55
Total Steps: 838540 Episode Num: 12833 Reward: -22.815311327202977 avg_loss_c: 30.996345901489256 avg_loss_a: -64.29418848211115
Número de pasos del episodio 12834 son episode_steps:177
Total Steps: 838717 Episode Num: 12834 Reward: 36.977570073539745 avg_loss_c: 31.234038983361195 avg_loss_a: -65.94449524960275
Número de pasos del episodio 12835 son episode_steps:63
Total Steps: 838780 Episode Num: 12835 Reward: 1.1136753643571824 avg_loss_c: 30.673323858351935 avg_loss_a: -65.79722013927642
Número de pasos del episodio 12836 son episode_steps:37
Total Steps: 838817 Episode Num: 12836 Reward: 0.09928466363072053 avg_loss_c: 31.263172046558278 avg_loss_a: -66.47049032675254
Número de pasos del episodio 12837 son episode_steps:222
Total Steps: 839039 Episode Num: 12837 Reward: 138.97363389873183 avg_loss_c: 30.947775273709684 avg_loss_a: -66.27990007830095
Número de pasos del episodio 12838 son episode_steps:56
Total Steps: 839095 Episode Num: 12838 Reward: -21.515024658595966 avg_loss_c: 31.125590562820435 avg_loss_a: -66.1823286328997
Número de pasos del episodio 12839 son episode_steps:62
Total Steps: 839157 Episode Num: 12839 Reward: -13.028853772329875 avg_loss_c: 31.243396236050515 avg_loss_a: -65.54223694339875
Número de pasos del episodio 12840 son episode_steps:58
Total Steps: 839215 Episode Num: 12840 Reward: -10.55857622294649 avg_loss_c: 31.322089918728533 avg_loss_a: -66.30021891100654
Número de pasos del episodio 12841 son episode_steps:41
Total Steps: 839256 Episode Num: 12841 Reward: -1.9176802415900598 avg_loss_c: 33.13180881593286 avg_loss_a: -63.970636879525536
Número de pasos del episodio 12842 son episode_steps:45
Total Steps: 839301 Episode Num: 12842 Reward: 4.069184931864228 avg_loss_c: 32.19012264675564 avg_loss_a: -66.50806562635634
Número de pasos del episodio 12843 son episode_steps:67
Total Steps: 839368 Episode Num: 12843 Reward: 20.543126112244614 avg_loss_c: 30.96458033661344 avg_loss_a: -64.59518455391499
Número de pasos del episodio 12844 son episode_steps:40
Total Steps: 839408 Episode Num: 12844 Reward: -11.727693682212895 avg_loss_c: 29.80831160545349 avg_loss_a: -64.6613000869751
Número de pasos del episodio 12845 son episode_steps:70
Total Steps: 839478 Episode Num: 12845 Reward: -66.50431135960645 avg_loss_c: 32.523905290876115 avg_loss_a: -66.04042946951729
Número de pasos del episodio 12846 son episode_steps:48
Total Steps: 839526 Episode Num: 12846 Reward: -20.803168651036632 avg_loss_c: 31.229767004648846 avg_loss_a: -66.67676067352295
Número de pasos del episodio 12847 son episode_steps:58
Total Steps: 839584 Episode Num: 12847 Reward: 35.59907486564574 avg_loss_c: 31.162437471850165 avg_loss_a: -66.24382229509025
Número de pasos del episodio 12848 son episode_steps:60
Total Steps: 839644 Episode Num: 12848 Reward: -32.285397432203666 avg_loss_c: 30.770488866170247 avg_loss_a: -66.18646354675293
Número de pasos del episodio 12849 son episode_steps:69
Total Steps: 839713 Episode Num: 12849 Reward: 25.586957044741375 avg_loss_c: 31.263255271358766 avg_loss_a: -65.55354834293973
Número de pasos del episodio 12850 son episode_steps:99
Total Steps: 839812 Episode Num: 12850 Reward: -6.023162040522459 avg_loss_c: 32.50343719636551 avg_loss_a: -65.89846532031743
Número de pasos del episodio 12851 son episode_steps:48
Total Steps: 839860 Episode Num: 12851 Reward: 4.519417998751599 avg_loss_c: 31.385233561197918 avg_loss_a: -66.1274840037028
Número de pasos del episodio 12852 son episode_steps:37
Total Steps: 839897 Episode Num: 12852 Reward: -18.639176194660607 avg_loss_c: 31.02839980254302 avg_loss_a: -65.9109257878484
Número de pasos del episodio 12853 son episode_steps:84
Total Steps: 839981 Episode Num: 12853 Reward: 42.74904030989924 avg_loss_c: 31.242119948069256 avg_loss_a: -64.68537757510231
Número de pasos del episodio 12854 son episode_steps:68
Total Steps: 840049 Episode Num: 12854 Reward: -44.623904467114684 avg_loss_c: 32.51738349129172 avg_loss_a: -64.68549189848058
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 23.251803
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12855 son episode_steps:63
Total Steps: 840112 Episode Num: 12855 Reward: -5.62905711005548 avg_loss_c: 31.37010471404545 avg_loss_a: -66.99546160016742
Número de pasos del episodio 12856 son episode_steps:47
Total Steps: 840159 Episode Num: 12856 Reward: -7.32468516747193 avg_loss_c: 31.0807513784855 avg_loss_a: -65.31559501810277
Número de pasos del episodio 12857 son episode_steps:40
Total Steps: 840199 Episode Num: 12857 Reward: -4.992470200864899 avg_loss_c: 31.521235466003418 avg_loss_a: -64.29282436370849
Número de pasos del episodio 12858 son episode_steps:266
Total Steps: 840465 Episode Num: 12858 Reward: 119.79582575314518 avg_loss_c: 31.734415369822567 avg_loss_a: -65.78016028726907
Número de pasos del episodio 12859 son episode_steps:47
Total Steps: 840512 Episode Num: 12859 Reward: -3.216588625567897 avg_loss_c: 31.66650557010732 avg_loss_a: -65.52508398827086
Número de pasos del episodio 12860 son episode_steps:103
Total Steps: 840615 Episode Num: 12860 Reward: 68.05873994956308 avg_loss_c: 30.6989917384768 avg_loss_a: -65.68369274694943
Número de pasos del episodio 12861 son episode_steps:40
Total Steps: 840655 Episode Num: 12861 Reward: -8.110917470364992 avg_loss_c: 29.98710060119629 avg_loss_a: -64.61165733337403
Número de pasos del episodio 12862 son episode_steps:94
Total Steps: 840749 Episode Num: 12862 Reward: 27.33902470127638 avg_loss_c: 30.818414992474494 avg_loss_a: -65.19792053547312
Número de pasos del episodio 12863 son episode_steps:68
Total Steps: 840817 Episode Num: 12863 Reward: 7.596359991259343 avg_loss_c: 30.935975215014288 avg_loss_a: -65.07639795191147
Número de pasos del episodio 12864 son episode_steps:42
Total Steps: 840859 Episode Num: 12864 Reward: -20.358108947844666 avg_loss_c: 32.25505874270485 avg_loss_a: -65.4688577197847
Número de pasos del episodio 12865 son episode_steps:55
Total Steps: 840914 Episode Num: 12865 Reward: 15.44999409002958 avg_loss_c: 31.38891216624867 avg_loss_a: -65.23716118552468
Número de pasos del episodio 12866 son episode_steps:30
Total Steps: 840944 Episode Num: 12866 Reward: -13.287301826058743 avg_loss_c: 29.455799229939778 avg_loss_a: -66.05896453857422
Número de pasos del episodio 12867 son episode_steps:47
Total Steps: 840991 Episode Num: 12867 Reward: -32.405341376294636 avg_loss_c: 32.4368370543135 avg_loss_a: -64.43262644016997
Número de pasos del episodio 12868 son episode_steps:111
Total Steps: 841102 Episode Num: 12868 Reward: 38.575821996407065 avg_loss_c: 32.918748133891334 avg_loss_a: -65.21502417487068
Número de pasos del episodio 12869 son episode_steps:66
Total Steps: 841168 Episode Num: 12869 Reward: 10.9706117357918 avg_loss_c: 31.014345400261156 avg_loss_a: -65.13190494884144
Número de pasos del episodio 12870 son episode_steps:48
Total Steps: 841216 Episode Num: 12870 Reward: 10.660441552488038 avg_loss_c: 32.8504741191864 avg_loss_a: -65.16018962860107
Número de pasos del episodio 12871 son episode_steps:97
Total Steps: 841313 Episode Num: 12871 Reward: 60.800827211798705 avg_loss_c: 32.403010319188695 avg_loss_a: -63.2577892972022
Número de pasos del episodio 12872 son episode_steps:19
Total Steps: 841332 Episode Num: 12872 Reward: -37.90071792425867 avg_loss_c: 30.771793867412367 avg_loss_a: -64.93718478554173
Número de pasos del episodio 12873 son episode_steps:62
Total Steps: 841394 Episode Num: 12873 Reward: 11.370915491587418 avg_loss_c: 32.0990440307125 avg_loss_a: -63.91465045559791
Número de pasos del episodio 12874 son episode_steps:91
Total Steps: 841485 Episode Num: 12874 Reward: -4.446644768938997 avg_loss_c: 32.94419716216706 avg_loss_a: -64.23070945320549
Número de pasos del episodio 12875 son episode_steps:69
Total Steps: 841554 Episode Num: 12875 Reward: -9.942911828688151 avg_loss_c: 33.25311608245407 avg_loss_a: -63.36849710215693
Número de pasos del episodio 12876 son episode_steps:45
Total Steps: 841599 Episode Num: 12876 Reward: -8.406783825065062 avg_loss_c: 32.35029542711046 avg_loss_a: -64.65991634792752
Número de pasos del episodio 12877 son episode_steps:57
Total Steps: 841656 Episode Num: 12877 Reward: 10.711221206513745 avg_loss_c: 32.34861675061678 avg_loss_a: -62.68696607623184
Número de pasos del episodio 12878 son episode_steps:79
Total Steps: 841735 Episode Num: 12878 Reward: 25.295527419730988 avg_loss_c: 33.051202049738244 avg_loss_a: -63.329444498955446
Número de pasos del episodio 12879 son episode_steps:210
Total Steps: 841945 Episode Num: 12879 Reward: 106.24070641413628 avg_loss_c: 31.430763862246557 avg_loss_a: -63.88877229236421
Número de pasos del episodio 12880 son episode_steps:47
Total Steps: 841992 Episode Num: 12880 Reward: -18.01143256880158 avg_loss_c: 31.10077127497247 avg_loss_a: -63.875785097162776
Número de pasos del episodio 12881 son episode_steps:86
Total Steps: 842078 Episode Num: 12881 Reward: 22.106115558532228 avg_loss_c: 31.843252869539484 avg_loss_a: -63.067433556845025
Número de pasos del episodio 12882 son episode_steps:39
Total Steps: 842117 Episode Num: 12882 Reward: -74.25285234834107 avg_loss_c: 30.538223022069687 avg_loss_a: -63.719947814941406
Número de pasos del episodio 12883 son episode_steps:111
Total Steps: 842228 Episode Num: 12883 Reward: 54.439933009612666 avg_loss_c: 31.77162221960119 avg_loss_a: -63.582031524933136
Número de pasos del episodio 12884 son episode_steps:210
Total Steps: 842438 Episode Num: 12884 Reward: 78.48243564301333 avg_loss_c: 32.431163887750536 avg_loss_a: -64.47593456449962
Número de pasos del episodio 12885 son episode_steps:151
Total Steps: 842589 Episode Num: 12885 Reward: 56.269116662773115 avg_loss_c: 32.2147385047761 avg_loss_a: -64.4544792680551
Número de pasos del episodio 12886 son episode_steps:34
Total Steps: 842623 Episode Num: 12886 Reward: -23.669072848216594 avg_loss_c: 30.66204906912411 avg_loss_a: -63.71025422040154
Número de pasos del episodio 12887 son episode_steps:68
Total Steps: 842691 Episode Num: 12887 Reward: 2.457660979083731 avg_loss_c: 31.087423717274387 avg_loss_a: -64.23674213185029
Número de pasos del episodio 12888 son episode_steps:50
Total Steps: 842741 Episode Num: 12888 Reward: -0.9014144581220964 avg_loss_c: 31.981806640625 avg_loss_a: -65.26061981201173
Número de pasos del episodio 12889 son episode_steps:80
Total Steps: 842821 Episode Num: 12889 Reward: 33.78315443852469 avg_loss_c: 32.59022219181061 avg_loss_a: -64.12787504196167
Número de pasos del episodio 12890 son episode_steps:64
Total Steps: 842885 Episode Num: 12890 Reward: 14.674548279018987 avg_loss_c: 32.147282123565674 avg_loss_a: -63.59697711467743
Número de pasos del episodio 12891 son episode_steps:68
Total Steps: 842953 Episode Num: 12891 Reward: -15.55450479152909 avg_loss_c: 32.217840026406684 avg_loss_a: -64.67758728476132
Número de pasos del episodio 12892 son episode_steps:273
Total Steps: 843226 Episode Num: 12892 Reward: 159.4929334120348 avg_loss_c: 32.222085065457414 avg_loss_a: -64.86756849463606
Número de pasos del episodio 12893 son episode_steps:92
Total Steps: 843318 Episode Num: 12893 Reward: 20.769861740442394 avg_loss_c: 31.90628420788309 avg_loss_a: -64.9527121004851
Número de pasos del episodio 12894 son episode_steps:53
Total Steps: 843371 Episode Num: 12894 Reward: -92.40283213810538 avg_loss_c: 32.06838305491321 avg_loss_a: -64.69872715788067
Número de pasos del episodio 12895 son episode_steps:93
Total Steps: 843464 Episode Num: 12895 Reward: 8.055917350066753 avg_loss_c: 30.870493632490916 avg_loss_a: -64.77413661505587
Número de pasos del episodio 12896 son episode_steps:78
Total Steps: 843542 Episode Num: 12896 Reward: 3.215143928479125 avg_loss_c: 31.410764816479805 avg_loss_a: -64.68661459898337
Número de pasos del episodio 12897 son episode_steps:132
Total Steps: 843674 Episode Num: 12897 Reward: 80.19800534383435 avg_loss_c: 31.549728798143793 avg_loss_a: -64.63317304669005
Número de pasos del episodio 12898 son episode_steps:78
Total Steps: 843752 Episode Num: 12898 Reward: -23.186961751632854 avg_loss_c: 31.849898362771057 avg_loss_a: -66.04995170006386
Número de pasos del episodio 12899 son episode_steps:138
Total Steps: 843890 Episode Num: 12899 Reward: -8.226951053753409 avg_loss_c: 31.80107503697492 avg_loss_a: -64.55450489210045
Número de pasos del episodio 12900 son episode_steps:243
Total Steps: 844133 Episode Num: 12900 Reward: 116.43157129833855 avg_loss_c: 32.165395603258425 avg_loss_a: -65.07880241488233
Número de pasos del episodio 12901 son episode_steps:118
Total Steps: 844251 Episode Num: 12901 Reward: 24.193195908381274 avg_loss_c: 31.99262599621789 avg_loss_a: -66.24571829327083
Número de pasos del episodio 12902 son episode_steps:214
Total Steps: 844465 Episode Num: 12902 Reward: 74.20584820475136 avg_loss_c: 31.21104882142254 avg_loss_a: -65.81686355020398
Número de pasos del episodio 12903 son episode_steps:145
Total Steps: 844610 Episode Num: 12903 Reward: 82.37614307015518 avg_loss_c: 31.792898349104256 avg_loss_a: -64.9036538485823
Número de pasos del episodio 12904 son episode_steps:89
Total Steps: 844699 Episode Num: 12904 Reward: -7.886786987726864 avg_loss_c: 31.65433320034756 avg_loss_a: -65.40064599540796
Número de pasos del episodio 12905 son episode_steps:60
Total Steps: 844759 Episode Num: 12905 Reward: -51.011104645854665 avg_loss_c: 34.185421530405684 avg_loss_a: -63.94602266947428
Número de pasos del episodio 12906 son episode_steps:166
Total Steps: 844925 Episode Num: 12906 Reward: 26.114130251379123 avg_loss_c: 32.818046202142554 avg_loss_a: -65.40821962471468
Número de pasos del episodio 12907 son episode_steps:74
Total Steps: 844999 Episode Num: 12907 Reward: -36.2737490207502 avg_loss_c: 34.122730306676914 avg_loss_a: -66.24058697674725
Número de pasos del episodio 12908 son episode_steps:79
Total Steps: 845078 Episode Num: 12908 Reward: -54.79865202986744 avg_loss_c: 32.61125682879098 avg_loss_a: -66.9436689932135
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 48.624344
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12909 son episode_steps:76
Total Steps: 845154 Episode Num: 12909 Reward: -10.542002015329377 avg_loss_c: 33.94783444153635 avg_loss_a: -65.89136424817536
Número de pasos del episodio 12910 son episode_steps:143
Total Steps: 845297 Episode Num: 12910 Reward: 26.851122271505965 avg_loss_c: 33.312400284347 avg_loss_a: -65.68131672252308
Número de pasos del episodio 12911 son episode_steps:83
Total Steps: 845380 Episode Num: 12911 Reward: -47.21313092629068 avg_loss_c: 32.17755995601057 avg_loss_a: -65.78251978862717
Número de pasos del episodio 12912 son episode_steps:72
Total Steps: 845452 Episode Num: 12912 Reward: -30.78128659970091 avg_loss_c: 33.5252104335361 avg_loss_a: -65.09471819135878
Número de pasos del episodio 12913 son episode_steps:103
Total Steps: 845555 Episode Num: 12913 Reward: 40.22074960822684 avg_loss_c: 34.26833874970964 avg_loss_a: -65.5017283171126
Número de pasos del episodio 12914 son episode_steps:280
Total Steps: 845835 Episode Num: 12914 Reward: 127.14963527593187 avg_loss_c: 33.06742515563965 avg_loss_a: -65.89900940486363
Número de pasos del episodio 12915 son episode_steps:112
Total Steps: 845947 Episode Num: 12915 Reward: -48.31788207407145 avg_loss_c: 33.966956870896475 avg_loss_a: -65.09483357838222
Número de pasos del episodio 12916 son episode_steps:45
Total Steps: 845992 Episode Num: 12916 Reward: -57.446287493797676 avg_loss_c: 32.9166508992513 avg_loss_a: -66.80636461046007
Número de pasos del episodio 12917 son episode_steps:59
Total Steps: 846051 Episode Num: 12917 Reward: -38.82334766510583 avg_loss_c: 32.59405404430325 avg_loss_a: -64.04558828321554
Número de pasos del episodio 12918 son episode_steps:54
Total Steps: 846105 Episode Num: 12918 Reward: -34.268715295231466 avg_loss_c: 33.18366746549253 avg_loss_a: -66.26178600169995
Número de pasos del episodio 12919 son episode_steps:49
Total Steps: 846154 Episode Num: 12919 Reward: -63.58470833900133 avg_loss_c: 34.041328702654155 avg_loss_a: -64.80123730095066
Número de pasos del episodio 12920 son episode_steps:42
Total Steps: 846196 Episode Num: 12920 Reward: 2.4206719589571826 avg_loss_c: 32.78891141074045 avg_loss_a: -63.38738069080171
Número de pasos del episodio 12921 son episode_steps:38
Total Steps: 846234 Episode Num: 12921 Reward: -38.0961933965796 avg_loss_c: 33.37357234954834 avg_loss_a: -66.09642892134816
Número de pasos del episodio 12922 son episode_steps:36
Total Steps: 846270 Episode Num: 12922 Reward: -14.900581029042154 avg_loss_c: 33.658172925313316 avg_loss_a: -65.1798135969374
Número de pasos del episodio 12923 son episode_steps:75
Total Steps: 846345 Episode Num: 12923 Reward: 19.104093500867442 avg_loss_c: 33.0915443166097 avg_loss_a: -65.08838729858398
Número de pasos del episodio 12924 son episode_steps:45
Total Steps: 846390 Episode Num: 12924 Reward: 16.65150065908967 avg_loss_c: 34.443691889444985 avg_loss_a: -64.62682766384549
Número de pasos del episodio 12925 son episode_steps:65
Total Steps: 846455 Episode Num: 12925 Reward: -21.844764615074546 avg_loss_c: 32.32016842181866 avg_loss_a: -65.08697938185472
Número de pasos del episodio 12926 son episode_steps:61
Total Steps: 846516 Episode Num: 12926 Reward: -12.031878935401771 avg_loss_c: 34.24287730357686 avg_loss_a: -64.91014624423669
Número de pasos del episodio 12927 son episode_steps:77
Total Steps: 846593 Episode Num: 12927 Reward: -75.90337821458387 avg_loss_c: 33.16364350256982 avg_loss_a: -64.82555419129211
Número de pasos del episodio 12928 son episode_steps:107
Total Steps: 846700 Episode Num: 12928 Reward: 11.874018838991855 avg_loss_c: 33.15342323802342 avg_loss_a: -64.31277579904717
Número de pasos del episodio 12929 son episode_steps:106
Total Steps: 846806 Episode Num: 12929 Reward: 10.102605356282588 avg_loss_c: 34.44485691358458 avg_loss_a: -64.91127899457824
Número de pasos del episodio 12930 son episode_steps:105
Total Steps: 846911 Episode Num: 12930 Reward: 14.93014238522405 avg_loss_c: 34.19810656592959 avg_loss_a: -63.98121083577474
Número de pasos del episodio 12931 son episode_steps:103
Total Steps: 847014 Episode Num: 12931 Reward: 20.964888436156556 avg_loss_c: 33.14464104291305 avg_loss_a: -65.02176762553094
Número de pasos del episodio 12932 son episode_steps:87
Total Steps: 847101 Episode Num: 12932 Reward: -0.32457128056971873 avg_loss_c: 33.45302645365397 avg_loss_a: -64.9670875812399
Número de pasos del episodio 12933 son episode_steps:45
Total Steps: 847146 Episode Num: 12933 Reward: -30.902719560033383 avg_loss_c: 33.91138191223145 avg_loss_a: -65.00177349514432
Número de pasos del episodio 12934 son episode_steps:96
Total Steps: 847242 Episode Num: 12934 Reward: -16.547233084231504 avg_loss_c: 34.20033174753189 avg_loss_a: -65.9380452632904
Número de pasos del episodio 12935 son episode_steps:162
Total Steps: 847404 Episode Num: 12935 Reward: 77.51598139257545 avg_loss_c: 33.221409679930886 avg_loss_a: -65.38969986527054
Número de pasos del episodio 12936 son episode_steps:226
Total Steps: 847630 Episode Num: 12936 Reward: 105.06460470517858 avg_loss_c: 32.65734364501143 avg_loss_a: -65.39058371349773
Número de pasos del episodio 12937 son episode_steps:153
Total Steps: 847783 Episode Num: 12937 Reward: 70.50924420335532 avg_loss_c: 33.23770872128555 avg_loss_a: -65.31969875759549
Número de pasos del episodio 12938 son episode_steps:53
Total Steps: 847836 Episode Num: 12938 Reward: 14.99633864908904 avg_loss_c: 32.31597216624134 avg_loss_a: -64.82702291236734
Número de pasos del episodio 12939 son episode_steps:118
Total Steps: 847954 Episode Num: 12939 Reward: -5.625095738894716 avg_loss_c: 32.99496505220058 avg_loss_a: -65.18565013044972
Número de pasos del episodio 12940 son episode_steps:113
Total Steps: 848067 Episode Num: 12940 Reward: -16.272417372466588 avg_loss_c: 32.43049256991496 avg_loss_a: -65.01957800536029
Número de pasos del episodio 12941 son episode_steps:137
Total Steps: 848204 Episode Num: 12941 Reward: 68.23905622755217 avg_loss_c: 34.44243328066638 avg_loss_a: -66.08961620470033
Número de pasos del episodio 12942 son episode_steps:51
Total Steps: 848255 Episode Num: 12942 Reward: 8.473625128586727 avg_loss_c: 33.89983655892166 avg_loss_a: -65.55552194632736
Número de pasos del episodio 12943 son episode_steps:150
Total Steps: 848405 Episode Num: 12943 Reward: 57.059856711382196 avg_loss_c: 32.41019601186117 avg_loss_a: -66.15178024291993
Número de pasos del episodio 12944 son episode_steps:173
Total Steps: 848578 Episode Num: 12944 Reward: 126.43885776565723 avg_loss_c: 31.92872762955682 avg_loss_a: -65.52120455703295
Número de pasos del episodio 12945 son episode_steps:48
Total Steps: 848626 Episode Num: 12945 Reward: -23.92263436440669 avg_loss_c: 32.33528037865957 avg_loss_a: -65.82593711217244
Número de pasos del episodio 12946 son episode_steps:81
Total Steps: 848707 Episode Num: 12946 Reward: 4.362806235363349 avg_loss_c: 30.702729001457307 avg_loss_a: -66.9533770525897
Número de pasos del episodio 12947 son episode_steps:54
Total Steps: 848761 Episode Num: 12947 Reward: 10.87790614317645 avg_loss_c: 31.932948359736688 avg_loss_a: -65.85682508680556
Número de pasos del episodio 12948 son episode_steps:114
Total Steps: 848875 Episode Num: 12948 Reward: 0.5097834261410825 avg_loss_c: 32.40480267374139 avg_loss_a: -66.1859370449133
Número de pasos del episodio 12949 son episode_steps:46
Total Steps: 848921 Episode Num: 12949 Reward: -48.98087983944403 avg_loss_c: 32.59240863634192 avg_loss_a: -65.50926009468411
Número de pasos del episodio 12950 son episode_steps:24
Total Steps: 848945 Episode Num: 12950 Reward: -57.09475553115185 avg_loss_c: 32.033335288365684 avg_loss_a: -66.10165309906006
Número de pasos del episodio 12951 son episode_steps:44
Total Steps: 848989 Episode Num: 12951 Reward: -1.8275154182416893 avg_loss_c: 33.25670498067682 avg_loss_a: -65.14401678605513
Número de pasos del episodio 12952 son episode_steps:31
Total Steps: 849020 Episode Num: 12952 Reward: -8.870769254633885 avg_loss_c: 32.150415174422726 avg_loss_a: -66.0599111741589
Número de pasos del episodio 12953 son episode_steps:104
Total Steps: 849124 Episode Num: 12953 Reward: -15.080780007295811 avg_loss_c: 33.377491785929756 avg_loss_a: -65.38257173391489
Número de pasos del episodio 12954 son episode_steps:159
Total Steps: 849283 Episode Num: 12954 Reward: 31.484858388692672 avg_loss_c: 34.20810544715737 avg_loss_a: -64.66415573216085
Número de pasos del episodio 12955 son episode_steps:233
Total Steps: 849516 Episode Num: 12955 Reward: 161.8691610202716 avg_loss_c: 33.14146894037468 avg_loss_a: -66.26127333088495
Número de pasos del episodio 12956 son episode_steps:94
Total Steps: 849610 Episode Num: 12956 Reward: 14.645914717299327 avg_loss_c: 32.55858153485237 avg_loss_a: -66.5558101572889
Número de pasos del episodio 12957 son episode_steps:112
Total Steps: 849722 Episode Num: 12957 Reward: -0.044106387727002705 avg_loss_c: 33.684703316007344 avg_loss_a: -65.82171045030866
Número de pasos del episodio 12958 son episode_steps:48
Total Steps: 849770 Episode Num: 12958 Reward: -19.043564995637468 avg_loss_c: 33.2202764749527 avg_loss_a: -65.72737073898315
Número de pasos del episodio 12959 son episode_steps:115
Total Steps: 849885 Episode Num: 12959 Reward: -8.032313574237705 avg_loss_c: 33.09605157271675 avg_loss_a: -65.20538409689199
Número de pasos del episodio 12960 son episode_steps:161
Total Steps: 850046 Episode Num: 12960 Reward: 60.95237892349487 avg_loss_c: 34.21772145336459 avg_loss_a: -65.18349579994722
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 117.477221
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12961 son episode_steps:410
Total Steps: 850456 Episode Num: 12961 Reward: 308.560260184412 avg_loss_c: 32.21673331376983 avg_loss_a: -66.46581305527106
Número de pasos del episodio 12962 son episode_steps:372
Total Steps: 850828 Episode Num: 12962 Reward: 297.446389728489 avg_loss_c: 31.66260906957811 avg_loss_a: -67.36263260790096
Número de pasos del episodio 12963 son episode_steps:40
Total Steps: 850868 Episode Num: 12963 Reward: -31.8630405102862 avg_loss_c: 32.05334324836731 avg_loss_a: -66.83607845306396
Número de pasos del episodio 12964 son episode_steps:110
Total Steps: 850978 Episode Num: 12964 Reward: 38.794981493032694 avg_loss_c: 33.25077027407559 avg_loss_a: -67.19187781594016
Número de pasos del episodio 12965 son episode_steps:170
Total Steps: 851148 Episode Num: 12965 Reward: 107.63758453270952 avg_loss_c: 31.509510904199935 avg_loss_a: -67.29276921889361
Número de pasos del episodio 12966 son episode_steps:112
Total Steps: 851260 Episode Num: 12966 Reward: -23.21743096080922 avg_loss_c: 31.912362422261918 avg_loss_a: -66.82376514162335
Número de pasos del episodio 12967 son episode_steps:109
Total Steps: 851369 Episode Num: 12967 Reward: 19.730055850094345 avg_loss_c: 31.954589248797216 avg_loss_a: -65.6106235609142
Número de pasos del episodio 12968 son episode_steps:462
Total Steps: 851831 Episode Num: 12968 Reward: 373.11598816129066 avg_loss_c: 32.40297350532565 avg_loss_a: -67.17917535624979
Número de pasos del episodio 12969 son episode_steps:46
Total Steps: 851877 Episode Num: 12969 Reward: -16.061667392822898 avg_loss_c: 32.79728321407152 avg_loss_a: -67.54638837731403
Número de pasos del episodio 12970 son episode_steps:121
Total Steps: 851998 Episode Num: 12970 Reward: -74.71674859322364 avg_loss_c: 33.033197749744765 avg_loss_a: -67.24913655430818
Número de pasos del episodio 12971 son episode_steps:507
Total Steps: 852505 Episode Num: 12971 Reward: 329.158242087138 avg_loss_c: 32.00665890770786 avg_loss_a: -68.14748797896345
Número de pasos del episodio 12972 son episode_steps:60
Total Steps: 852565 Episode Num: 12972 Reward: -28.121300264305674 avg_loss_c: 33.43886814117432 avg_loss_a: -68.16308390299479
Número de pasos del episodio 12973 son episode_steps:45
Total Steps: 852610 Episode Num: 12973 Reward: 5.209198955975151 avg_loss_c: 31.370894156561956 avg_loss_a: -68.2109608968099
Número de pasos del episodio 12974 son episode_steps:40
Total Steps: 852650 Episode Num: 12974 Reward: -12.766036916693498 avg_loss_c: 31.550546169281006 avg_loss_a: -69.43116302490235
Número de pasos del episodio 12975 son episode_steps:75
Total Steps: 852725 Episode Num: 12975 Reward: -44.54241798767811 avg_loss_c: 33.35143984476725 avg_loss_a: -66.6116172281901
Número de pasos del episodio 12976 son episode_steps:96
Total Steps: 852821 Episode Num: 12976 Reward: -69.85194706171112 avg_loss_c: 32.62938392162323 avg_loss_a: -66.62536374727885
Número de pasos del episodio 12977 son episode_steps:205
Total Steps: 853026 Episode Num: 12977 Reward: 147.8163916574652 avg_loss_c: 32.6001113054229 avg_loss_a: -67.57665260128859
Número de pasos del episodio 12978 son episode_steps:70
Total Steps: 853096 Episode Num: 12978 Reward: -41.18852939366811 avg_loss_c: 33.89883128574916 avg_loss_a: -67.59030009678432
Número de pasos del episodio 12979 son episode_steps:54
Total Steps: 853150 Episode Num: 12979 Reward: -13.425019612405869 avg_loss_c: 32.56705164026331 avg_loss_a: -66.21056026882596
Número de pasos del episodio 12980 son episode_steps:37
Total Steps: 853187 Episode Num: 12980 Reward: -10.898637488047441 avg_loss_c: 33.133654568646406 avg_loss_a: -68.71917477169552
Número de pasos del episodio 12981 son episode_steps:116
Total Steps: 853303 Episode Num: 12981 Reward: 46.101817983873836 avg_loss_c: 33.27676338985049 avg_loss_a: -67.0610298945986
Número de pasos del episodio 12982 son episode_steps:62
Total Steps: 853365 Episode Num: 12982 Reward: 27.390046997414597 avg_loss_c: 33.41710930485879 avg_loss_a: -66.43831363801033
Número de pasos del episodio 12983 son episode_steps:55
Total Steps: 853420 Episode Num: 12983 Reward: 6.696126924076587 avg_loss_c: 32.83143577575684 avg_loss_a: -68.25032750909979
Número de pasos del episodio 12984 son episode_steps:84
Total Steps: 853504 Episode Num: 12984 Reward: 23.198349476117905 avg_loss_c: 31.971005144573393 avg_loss_a: -67.4092036655971
Número de pasos del episodio 12985 son episode_steps:101
Total Steps: 853605 Episode Num: 12985 Reward: 49.354063993550994 avg_loss_c: 33.07013541873139 avg_loss_a: -66.92391061310721
Número de pasos del episodio 12986 son episode_steps:363
Total Steps: 853968 Episode Num: 12986 Reward: 357.0878568384007 avg_loss_c: 31.608065775931703 avg_loss_a: -67.10125406648831
Número de pasos del episodio 12987 son episode_steps:172
Total Steps: 854140 Episode Num: 12987 Reward: 69.55676405150817 avg_loss_c: 31.5972836738409 avg_loss_a: -67.85980965370355
Número de pasos del episodio 12988 son episode_steps:73
Total Steps: 854213 Episode Num: 12988 Reward: 16.5122910214241 avg_loss_c: 31.753594307050314 avg_loss_a: -69.60248806052012
Número de pasos del episodio 12989 son episode_steps:42
Total Steps: 854255 Episode Num: 12989 Reward: -20.54988182607921 avg_loss_c: 30.752779642740887 avg_loss_a: -68.43327967325847
Número de pasos del episodio 12990 son episode_steps:118
Total Steps: 854373 Episode Num: 12990 Reward: 32.05541873429303 avg_loss_c: 32.439448017185015 avg_loss_a: -67.3415664414228
Número de pasos del episodio 12991 son episode_steps:37
Total Steps: 854410 Episode Num: 12991 Reward: -7.470509546550664 avg_loss_c: 32.5205030699034 avg_loss_a: -68.4960364264411
Número de pasos del episodio 12992 son episode_steps:264
Total Steps: 854674 Episode Num: 12992 Reward: 213.34270249435173 avg_loss_c: 31.454901745825104 avg_loss_a: -68.216390060656
Número de pasos del episodio 12993 son episode_steps:78
Total Steps: 854752 Episode Num: 12993 Reward: 20.57669459619408 avg_loss_c: 30.283893707471016 avg_loss_a: -69.6399659376878
Número de pasos del episodio 12994 son episode_steps:165
Total Steps: 854917 Episode Num: 12994 Reward: 118.95899086977603 avg_loss_c: 31.383942193695994 avg_loss_a: -68.16531376694188
Número de pasos del episodio 12995 son episode_steps:217
Total Steps: 855134 Episode Num: 12995 Reward: 179.72322922659322 avg_loss_c: 31.1782165474606 avg_loss_a: -68.33370068106234
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 80.372649
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 12996 son episode_steps:50
Total Steps: 855184 Episode Num: 12996 Reward: -22.45008961385627 avg_loss_c: 30.82447742462158 avg_loss_a: -67.36538925170899
Número de pasos del episodio 12997 son episode_steps:55
Total Steps: 855239 Episode Num: 12997 Reward: 23.882207814266703 avg_loss_c: 32.35709010037509 avg_loss_a: -68.31821122602983
Número de pasos del episodio 12998 son episode_steps:535
Total Steps: 855774 Episode Num: 12998 Reward: 357.17709604238473 avg_loss_c: 31.377582147188274 avg_loss_a: -69.74240383255147
Número de pasos del episodio 12999 son episode_steps:66
Total Steps: 855840 Episode Num: 12999 Reward: -27.00582888664856 avg_loss_c: 30.9585048791134 avg_loss_a: -69.48239343816584
Número de pasos del episodio 13000 son episode_steps:29
Total Steps: 855869 Episode Num: 13000 Reward: -20.871837676945912 avg_loss_c: 32.418905126637426 avg_loss_a: -70.5257955090753
Número de pasos del episodio 13001 son episode_steps:157
Total Steps: 856026 Episode Num: 13001 Reward: 87.03389350907503 avg_loss_c: 31.394078698127892 avg_loss_a: -69.07965471790095
Número de pasos del episodio 13002 son episode_steps:93
Total Steps: 856119 Episode Num: 13002 Reward: -5.723405302680738 avg_loss_c: 32.170833751719485 avg_loss_a: -69.69004206503591
Número de pasos del episodio 13003 son episode_steps:42
Total Steps: 856161 Episode Num: 13003 Reward: -2.7492453198087534 avg_loss_c: 30.99850300380162 avg_loss_a: -70.48929813929966
Número de pasos del episodio 13004 son episode_steps:44
Total Steps: 856205 Episode Num: 13004 Reward: -36.53690857883952 avg_loss_c: 32.18313039432872 avg_loss_a: -68.99384377219461
Número de pasos del episodio 13005 son episode_steps:58
Total Steps: 856263 Episode Num: 13005 Reward: 17.27487524073115 avg_loss_c: 31.74588104774212 avg_loss_a: -69.34719730245656
Número de pasos del episodio 13006 son episode_steps:205
Total Steps: 856468 Episode Num: 13006 Reward: 150.67776875361847 avg_loss_c: 32.18115994523211 avg_loss_a: -70.04996732386147
Número de pasos del episodio 13007 son episode_steps:102
Total Steps: 856570 Episode Num: 13007 Reward: 39.294862088171186 avg_loss_c: 31.107407738180722 avg_loss_a: -70.42782906924977
Número de pasos del episodio 13008 son episode_steps:159
Total Steps: 856729 Episode Num: 13008 Reward: 124.25920423149395 avg_loss_c: 31.873697868683053 avg_loss_a: -69.20295720130393
Número de pasos del episodio 13009 son episode_steps:93
Total Steps: 856822 Episode Num: 13009 Reward: 39.83919321490829 avg_loss_c: 31.347434197702714 avg_loss_a: -69.9314211773616
Número de pasos del episodio 13010 son episode_steps:72
Total Steps: 856894 Episode Num: 13010 Reward: -4.765065601100954 avg_loss_c: 32.51677833663093 avg_loss_a: -70.47175333234999
Número de pasos del episodio 13011 son episode_steps:144
Total Steps: 857038 Episode Num: 13011 Reward: -4.735516631208007 avg_loss_c: 32.94239775339762 avg_loss_a: -69.84985409842596
Número de pasos del episodio 13012 son episode_steps:60
Total Steps: 857098 Episode Num: 13012 Reward: -6.703961527117638 avg_loss_c: 31.469773546854654 avg_loss_a: -69.48623555501302
Número de pasos del episodio 13013 son episode_steps:89
Total Steps: 857187 Episode Num: 13013 Reward: 27.20049556745145 avg_loss_c: 32.94232400615564 avg_loss_a: -69.95535998397999
Número de pasos del episodio 13014 son episode_steps:89
Total Steps: 857276 Episode Num: 13014 Reward: -12.139511509304459 avg_loss_c: 31.6422870507401 avg_loss_a: -69.85035294093443
Número de pasos del episodio 13015 son episode_steps:95
Total Steps: 857371 Episode Num: 13015 Reward: -50.634979625984364 avg_loss_c: 31.157577052869296 avg_loss_a: -69.78995995772512
Número de pasos del episodio 13016 son episode_steps:90
Total Steps: 857461 Episode Num: 13016 Reward: 13.502020142262097 avg_loss_c: 32.07353604634603 avg_loss_a: -69.41433927747939
Número de pasos del episodio 13017 son episode_steps:99
Total Steps: 857560 Episode Num: 13017 Reward: 41.16870566848306 avg_loss_c: 33.09360837454748 avg_loss_a: -69.8148053872465
Número de pasos del episodio 13018 son episode_steps:56
Total Steps: 857616 Episode Num: 13018 Reward: 26.25309818572194 avg_loss_c: 32.79844389642988 avg_loss_a: -70.39042854309082
Número de pasos del episodio 13019 son episode_steps:72
Total Steps: 857688 Episode Num: 13019 Reward: 15.39419718771718 avg_loss_c: 32.86327465375265 avg_loss_a: -70.13840230305989
Número de pasos del episodio 13020 son episode_steps:86
Total Steps: 857774 Episode Num: 13020 Reward: 69.36782519688975 avg_loss_c: 32.43981864840485 avg_loss_a: -70.03177864606991
Número de pasos del episodio 13021 son episode_steps:42
Total Steps: 857816 Episode Num: 13021 Reward: 15.086078031126076 avg_loss_c: 30.65985938480922 avg_loss_a: -69.25939923241025
Número de pasos del episodio 13022 son episode_steps:27
Total Steps: 857843 Episode Num: 13022 Reward: -25.412814600868646 avg_loss_c: 32.142399328726306 avg_loss_a: -69.09665256076389
Número de pasos del episodio 13023 son episode_steps:74
Total Steps: 857917 Episode Num: 13023 Reward: 15.125287220496194 avg_loss_c: 32.29207515716553 avg_loss_a: -69.65457751299884
Número de pasos del episodio 13024 son episode_steps:56
Total Steps: 857973 Episode Num: 13024 Reward: 17.63175954408713 avg_loss_c: 30.822505610329763 avg_loss_a: -69.365341595241
Número de pasos del episodio 13025 son episode_steps:207
Total Steps: 858180 Episode Num: 13025 Reward: 33.90840185254219 avg_loss_c: 31.98980895332668 avg_loss_a: -69.53183053426696
Número de pasos del episodio 13026 son episode_steps:52
Total Steps: 858232 Episode Num: 13026 Reward: -1.344142820093556 avg_loss_c: 32.036220220419075 avg_loss_a: -69.9350940997784
Número de pasos del episodio 13027 son episode_steps:107
Total Steps: 858339 Episode Num: 13027 Reward: 55.41538094650523 avg_loss_c: 31.014024449286058 avg_loss_a: -69.65336038464697
Número de pasos del episodio 13028 son episode_steps:57
Total Steps: 858396 Episode Num: 13028 Reward: -24.83427783233456 avg_loss_c: 31.83858339410079 avg_loss_a: -69.49559395773369
Número de pasos del episodio 13029 son episode_steps:116
Total Steps: 858512 Episode Num: 13029 Reward: 17.13087259944878 avg_loss_c: 31.437200940888502 avg_loss_a: -69.85015218011264
Número de pasos del episodio 13030 son episode_steps:120
Total Steps: 858632 Episode Num: 13030 Reward: 48.086480478218036 avg_loss_c: 31.686440070470173 avg_loss_a: -69.40949846903483
Número de pasos del episodio 13031 son episode_steps:149
Total Steps: 858781 Episode Num: 13031 Reward: 28.838396955872447 avg_loss_c: 31.21877103203895 avg_loss_a: -69.75489643276138
Número de pasos del episodio 13032 son episode_steps:49
Total Steps: 858830 Episode Num: 13032 Reward: -50.71823658514531 avg_loss_c: 31.385912369708624 avg_loss_a: -70.26241395911391
Número de pasos del episodio 13033 son episode_steps:53
Total Steps: 858883 Episode Num: 13033 Reward: -20.663591590178697 avg_loss_c: 31.503267935986788 avg_loss_a: -70.74619696275244
Número de pasos del episodio 13034 son episode_steps:111
Total Steps: 858994 Episode Num: 13034 Reward: 37.10561887346532 avg_loss_c: 31.61549360258085 avg_loss_a: -70.08635807896519
Número de pasos del episodio 13035 son episode_steps:197
Total Steps: 859191 Episode Num: 13035 Reward: 86.62781492001797 avg_loss_c: 31.941483638008233 avg_loss_a: -70.75613205808068
Número de pasos del episodio 13036 son episode_steps:80
Total Steps: 859271 Episode Num: 13036 Reward: -23.673537852624733 avg_loss_c: 31.599850821495057 avg_loss_a: -71.08976030349731
Número de pasos del episodio 13037 son episode_steps:94
Total Steps: 859365 Episode Num: 13037 Reward: -111.3348857718785 avg_loss_c: 32.079430377229734 avg_loss_a: -70.5918800678659
Número de pasos del episodio 13038 son episode_steps:110
Total Steps: 859475 Episode Num: 13038 Reward: 41.45771230273632 avg_loss_c: 32.86108122738925 avg_loss_a: -69.11139484752309
Número de pasos del episodio 13039 son episode_steps:92
Total Steps: 859567 Episode Num: 13039 Reward: 16.093218027973627 avg_loss_c: 30.80522110151208 avg_loss_a: -69.09265543066937
Número de pasos del episodio 13040 son episode_steps:77
Total Steps: 859644 Episode Num: 13040 Reward: -9.477651462114725 avg_loss_c: 33.178135314545074 avg_loss_a: -70.4963735605215
Número de pasos del episodio 13041 son episode_steps:67
Total Steps: 859711 Episode Num: 13041 Reward: 7.114185012507246 avg_loss_c: 31.865203800486096 avg_loss_a: -71.03228645894065
Número de pasos del episodio 13042 son episode_steps:159
Total Steps: 859870 Episode Num: 13042 Reward: 96.85782164222243 avg_loss_c: 31.851716959251547 avg_loss_a: -70.14592023165721
Número de pasos del episodio 13043 son episode_steps:33
Total Steps: 859903 Episode Num: 13043 Reward: -54.067596864236876 avg_loss_c: 31.895099061908144 avg_loss_a: -70.4460273511482
Número de pasos del episodio 13044 son episode_steps:90
Total Steps: 859993 Episode Num: 13044 Reward: 24.60277675753086 avg_loss_c: 32.14945835537381 avg_loss_a: -70.54411070081923
Número de pasos del episodio 13045 son episode_steps:112
Total Steps: 860105 Episode Num: 13045 Reward: -42.47822504497767 avg_loss_c: 33.194719314575195 avg_loss_a: -71.58010292053223
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 60.134072
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13046 son episode_steps:67
Total Steps: 860172 Episode Num: 13046 Reward: -55.06563883922974 avg_loss_c: 32.0739900389714 avg_loss_a: -71.09443698712249
Número de pasos del episodio 13047 son episode_steps:157
Total Steps: 860329 Episode Num: 13047 Reward: 51.806073135592484 avg_loss_c: 32.595779309606854 avg_loss_a: -71.60738367943247
Número de pasos del episodio 13048 son episode_steps:116
Total Steps: 860445 Episode Num: 13048 Reward: 22.134228631611542 avg_loss_c: 33.16981595138024 avg_loss_a: -69.87650963355755
Número de pasos del episodio 13049 son episode_steps:117
Total Steps: 860562 Episode Num: 13049 Reward: 29.924123562709287 avg_loss_c: 32.70834502195701 avg_loss_a: -70.7007317176232
Número de pasos del episodio 13050 son episode_steps:48
Total Steps: 860610 Episode Num: 13050 Reward: -8.088271089149146 avg_loss_c: 32.25309646129608 avg_loss_a: -71.47860495249431
Número de pasos del episodio 13051 son episode_steps:107
Total Steps: 860717 Episode Num: 13051 Reward: -17.353275209312358 avg_loss_c: 33.08526135382251 avg_loss_a: -71.1325751331365
Número de pasos del episodio 13052 son episode_steps:74
Total Steps: 860791 Episode Num: 13052 Reward: -14.664545005834956 avg_loss_c: 31.47125873050174 avg_loss_a: -71.07440494846654
Número de pasos del episodio 13053 son episode_steps:56
Total Steps: 860847 Episode Num: 13053 Reward: -18.939816979574744 avg_loss_c: 32.48184977258955 avg_loss_a: -70.0916782106672
Número de pasos del episodio 13054 son episode_steps:53
Total Steps: 860900 Episode Num: 13054 Reward: -18.508344477195912 avg_loss_c: 32.97775739993689 avg_loss_a: -72.01185190452719
Número de pasos del episodio 13055 son episode_steps:208
Total Steps: 861108 Episode Num: 13055 Reward: 76.51833974895125 avg_loss_c: 32.963061992938705 avg_loss_a: -70.62203183540932
Número de pasos del episodio 13056 son episode_steps:25
Total Steps: 861133 Episode Num: 13056 Reward: -42.81168196714191 avg_loss_c: 32.89059387207031 avg_loss_a: -69.84794036865235
Número de pasos del episodio 13057 son episode_steps:38
Total Steps: 861171 Episode Num: 13057 Reward: -66.17464352583033 avg_loss_c: 34.9498983684339 avg_loss_a: -68.30095552143298
Número de pasos del episodio 13058 son episode_steps:150
Total Steps: 861321 Episode Num: 13058 Reward: 78.47628803249616 avg_loss_c: 33.34340436299642 avg_loss_a: -70.84683247884115
Número de pasos del episodio 13059 son episode_steps:50
Total Steps: 861371 Episode Num: 13059 Reward: 13.376375911431026 avg_loss_c: 32.219319877624514 avg_loss_a: -70.51682006835938
Número de pasos del episodio 13060 son episode_steps:166
Total Steps: 861537 Episode Num: 13060 Reward: 89.62765156007889 avg_loss_c: 32.918637539966994 avg_loss_a: -71.31994615118188
Número de pasos del episodio 13061 son episode_steps:94
Total Steps: 861631 Episode Num: 13061 Reward: 3.0522678210719123 avg_loss_c: 33.63470191143929 avg_loss_a: -70.11458311689661
Número de pasos del episodio 13062 son episode_steps:69
Total Steps: 861700 Episode Num: 13062 Reward: 27.216369720764934 avg_loss_c: 33.35601145979287 avg_loss_a: -71.52790191208106
Número de pasos del episodio 13063 son episode_steps:112
Total Steps: 861812 Episode Num: 13063 Reward: -9.668338112927227 avg_loss_c: 32.790322048323496 avg_loss_a: -69.18044982637677
Número de pasos del episodio 13064 son episode_steps:81
Total Steps: 861893 Episode Num: 13064 Reward: -54.120226549242254 avg_loss_c: 34.20970641242133 avg_loss_a: -70.21774706428434
Número de pasos del episodio 13065 son episode_steps:79
Total Steps: 861972 Episode Num: 13065 Reward: -24.358897056003528 avg_loss_c: 34.001691069784044 avg_loss_a: -69.97018287755266
Número de pasos del episodio 13066 son episode_steps:126
Total Steps: 862098 Episode Num: 13066 Reward: 41.5714151374666 avg_loss_c: 32.57575245509072 avg_loss_a: -70.15081084720673
Número de pasos del episodio 13067 son episode_steps:47
Total Steps: 862145 Episode Num: 13067 Reward: -51.35281630075024 avg_loss_c: 32.37192734251631 avg_loss_a: -69.48359144494889
Número de pasos del episodio 13068 son episode_steps:109
Total Steps: 862254 Episode Num: 13068 Reward: -10.155590665103563 avg_loss_c: 33.9020470085494 avg_loss_a: -70.15447228107978
Número de pasos del episodio 13069 son episode_steps:60
Total Steps: 862314 Episode Num: 13069 Reward: -16.225187026254584 avg_loss_c: 35.805286184946695 avg_loss_a: -69.8620012919108
Número de pasos del episodio 13070 son episode_steps:128
Total Steps: 862442 Episode Num: 13070 Reward: -27.64363343143951 avg_loss_c: 33.94147910177708 avg_loss_a: -70.61376416683197
Número de pasos del episodio 13071 son episode_steps:60
Total Steps: 862502 Episode Num: 13071 Reward: -44.343306283538524 avg_loss_c: 33.58588202794393 avg_loss_a: -70.36710408528646
Número de pasos del episodio 13072 son episode_steps:201
Total Steps: 862703 Episode Num: 13072 Reward: 137.95342971111327 avg_loss_c: 34.30295089228236 avg_loss_a: -69.94159155698559
Número de pasos del episodio 13073 son episode_steps:60
Total Steps: 862763 Episode Num: 13073 Reward: -42.608171895189585 avg_loss_c: 33.80421781539917 avg_loss_a: -71.15205243428548
Número de pasos del episodio 13074 son episode_steps:37
Total Steps: 862800 Episode Num: 13074 Reward: -17.07202103807248 avg_loss_c: 34.29689458898596 avg_loss_a: -70.03372357342694
Número de pasos del episodio 13075 son episode_steps:28
Total Steps: 862828 Episode Num: 13075 Reward: -34.507328305421495 avg_loss_c: 33.53338861465454 avg_loss_a: -71.28109414236886
Número de pasos del episodio 13076 son episode_steps:58
Total Steps: 862886 Episode Num: 13076 Reward: -0.4428178996010512 avg_loss_c: 34.76874252845501 avg_loss_a: -70.87652561582368
Número de pasos del episodio 13077 son episode_steps:129
Total Steps: 863015 Episode Num: 13077 Reward: 52.89276428546056 avg_loss_c: 34.24606573119644 avg_loss_a: -69.57270440389944
Número de pasos del episodio 13078 son episode_steps:129
Total Steps: 863144 Episode Num: 13078 Reward: 40.60246137130764 avg_loss_c: 34.16085123461346 avg_loss_a: -69.74477617130724
Número de pasos del episodio 13079 son episode_steps:85
Total Steps: 863229 Episode Num: 13079 Reward: -7.817464386073267 avg_loss_c: 34.29077231463264 avg_loss_a: -68.48661732393153
Número de pasos del episodio 13080 son episode_steps:148
Total Steps: 863377 Episode Num: 13080 Reward: 50.32067391142693 avg_loss_c: 34.93389503375904 avg_loss_a: -69.10227069339237
Número de pasos del episodio 13081 son episode_steps:114
Total Steps: 863491 Episode Num: 13081 Reward: 34.58069986969813 avg_loss_c: 35.32434491943895 avg_loss_a: -69.41372352733947
Número de pasos del episodio 13082 son episode_steps:315
Total Steps: 863806 Episode Num: 13082 Reward: 154.02213138455107 avg_loss_c: 35.303849435231044 avg_loss_a: -69.189234003945
Número de pasos del episodio 13083 son episode_steps:55
Total Steps: 863861 Episode Num: 13083 Reward: -43.10537079821444 avg_loss_c: 35.03845117742365 avg_loss_a: -70.11686970103871
Número de pasos del episodio 13084 son episode_steps:188
Total Steps: 864049 Episode Num: 13084 Reward: 101.4600227904661 avg_loss_c: 34.64816631154811 avg_loss_a: -69.7608796789291
Número de pasos del episodio 13085 son episode_steps:52
Total Steps: 864101 Episode Num: 13085 Reward: -4.326053834387743 avg_loss_c: 35.2403584260207 avg_loss_a: -69.14554273165189
Número de pasos del episodio 13086 son episode_steps:22
Total Steps: 864123 Episode Num: 13086 Reward: -39.27829194120987 avg_loss_c: 33.63335791501132 avg_loss_a: -69.67170784690164
Número de pasos del episodio 13087 son episode_steps:51
Total Steps: 864174 Episode Num: 13087 Reward: 19.183658986430434 avg_loss_c: 35.99551537457634 avg_loss_a: -69.19173730588427
Número de pasos del episodio 13088 son episode_steps:71
Total Steps: 864245 Episode Num: 13088 Reward: 8.725728368957867 avg_loss_c: 36.7434024810791 avg_loss_a: -68.16147581288513
Número de pasos del episodio 13089 son episode_steps:134
Total Steps: 864379 Episode Num: 13089 Reward: 114.56008169887694 avg_loss_c: 35.3468556332944 avg_loss_a: -69.17426408226811
Número de pasos del episodio 13090 son episode_steps:115
Total Steps: 864494 Episode Num: 13090 Reward: 18.701942023258894 avg_loss_c: 34.80007057189941 avg_loss_a: -69.72668543276579
Número de pasos del episodio 13091 son episode_steps:71
Total Steps: 864565 Episode Num: 13091 Reward: 5.5775779844888325 avg_loss_c: 33.86424755042707 avg_loss_a: -69.80617071877063
Número de pasos del episodio 13092 son episode_steps:40
Total Steps: 864605 Episode Num: 13092 Reward: -5.287112422821968 avg_loss_c: 34.017302465438846 avg_loss_a: -71.96527347564697
Número de pasos del episodio 13093 son episode_steps:43
Total Steps: 864648 Episode Num: 13093 Reward: 6.631648520927836 avg_loss_c: 35.56780105413392 avg_loss_a: -69.51960559223973
Número de pasos del episodio 13094 son episode_steps:33
Total Steps: 864681 Episode Num: 13094 Reward: -6.557629051574038 avg_loss_c: 35.76333178895892 avg_loss_a: -68.25619368119673
Número de pasos del episodio 13095 son episode_steps:137
Total Steps: 864818 Episode Num: 13095 Reward: 43.10939227545838 avg_loss_c: 36.5133995975021 avg_loss_a: -69.17849024194871
Número de pasos del episodio 13096 son episode_steps:185
Total Steps: 865003 Episode Num: 13096 Reward: 26.064807079136084 avg_loss_c: 34.56885176993705 avg_loss_a: -69.8366593232026
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 109.759172
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13097 son episode_steps:33
Total Steps: 865036 Episode Num: 13097 Reward: -13.71216564252517 avg_loss_c: 34.03903649070046 avg_loss_a: -68.95469549930456
Número de pasos del episodio 13098 son episode_steps:165
Total Steps: 865201 Episode Num: 13098 Reward: 60.535871758288785 avg_loss_c: 35.037943383419154 avg_loss_a: -69.73086423006924
Número de pasos del episodio 13099 son episode_steps:227
Total Steps: 865428 Episode Num: 13099 Reward: 123.88649209160388 avg_loss_c: 35.0523724408927 avg_loss_a: -70.02241395118479
Número de pasos del episodio 13100 son episode_steps:152
Total Steps: 865580 Episode Num: 13100 Reward: 69.90809025074364 avg_loss_c: 34.680136931569955 avg_loss_a: -69.77626885865864
Número de pasos del episodio 13101 son episode_steps:25
Total Steps: 865605 Episode Num: 13101 Reward: -21.987805501985235 avg_loss_c: 34.20611083984375 avg_loss_a: -69.88544067382813
Número de pasos del episodio 13102 son episode_steps:33
Total Steps: 865638 Episode Num: 13102 Reward: -32.64763069127199 avg_loss_c: 34.25702811732437 avg_loss_a: -68.88341915246212
Número de pasos del episodio 13103 son episode_steps:48
Total Steps: 865686 Episode Num: 13103 Reward: -23.193900194656795 avg_loss_c: 34.619479298591614 avg_loss_a: -68.8762412071228
Número de pasos del episodio 13104 son episode_steps:27
Total Steps: 865713 Episode Num: 13104 Reward: -15.724951414328446 avg_loss_c: 34.31253793504503 avg_loss_a: -68.71409098307292
Número de pasos del episodio 13105 son episode_steps:46
Total Steps: 865759 Episode Num: 13105 Reward: -24.236186136477652 avg_loss_c: 36.90949643176535 avg_loss_a: -70.24782844211744
Número de pasos del episodio 13106 son episode_steps:84
Total Steps: 865843 Episode Num: 13106 Reward: -72.91464978370286 avg_loss_c: 34.825925963265554 avg_loss_a: -70.05671982538132
Número de pasos del episodio 13107 son episode_steps:90
Total Steps: 865933 Episode Num: 13107 Reward: 7.10588003402706 avg_loss_c: 35.54073011610243 avg_loss_a: -69.58738547431098
Número de pasos del episodio 13108 son episode_steps:94
Total Steps: 866027 Episode Num: 13108 Reward: 27.373960883044347 avg_loss_c: 38.951814428288884 avg_loss_a: -70.38060606286881
Número de pasos del episodio 13109 son episode_steps:57
Total Steps: 866084 Episode Num: 13109 Reward: 15.324180022523242 avg_loss_c: 36.41684635898523 avg_loss_a: -70.36808790240372
Número de pasos del episodio 13110 son episode_steps:270
Total Steps: 866354 Episode Num: 13110 Reward: 198.4731072899274 avg_loss_c: 36.00851167749475 avg_loss_a: -70.80266212180808
Número de pasos del episodio 13111 son episode_steps:32
Total Steps: 866386 Episode Num: 13111 Reward: -35.074945150962336 avg_loss_c: 33.83287692070007 avg_loss_a: -70.83746838569641
Número de pasos del episodio 13112 son episode_steps:156
Total Steps: 866542 Episode Num: 13112 Reward: 75.67474120614176 avg_loss_c: 36.061469567127716 avg_loss_a: -71.09675299815642
Número de pasos del episodio 13113 son episode_steps:65
Total Steps: 866607 Episode Num: 13113 Reward: -19.95955904915571 avg_loss_c: 36.97222131582407 avg_loss_a: -72.1699481670673
Número de pasos del episodio 13114 son episode_steps:105
Total Steps: 866712 Episode Num: 13114 Reward: 15.85658913763015 avg_loss_c: 34.69878563653855 avg_loss_a: -71.78951953706287
Número de pasos del episodio 13115 son episode_steps:53
Total Steps: 866765 Episode Num: 13115 Reward: 9.508819098067335 avg_loss_c: 34.748176826621 avg_loss_a: -72.16468379182636
Número de pasos del episodio 13116 son episode_steps:50
Total Steps: 866815 Episode Num: 13116 Reward: 5.906043867389607 avg_loss_c: 37.00592113494873 avg_loss_a: -72.57415802001952
Número de pasos del episodio 13117 son episode_steps:125
Total Steps: 866940 Episode Num: 13117 Reward: 45.573058807701074 avg_loss_c: 36.292597961425784 avg_loss_a: -71.21038842773437
Número de pasos del episodio 13118 son episode_steps:209
Total Steps: 867149 Episode Num: 13118 Reward: 79.25911691427237 avg_loss_c: 35.253959254214635 avg_loss_a: -71.80967851118608
Número de pasos del episodio 13119 son episode_steps:43
Total Steps: 867192 Episode Num: 13119 Reward: -16.731594992320506 avg_loss_c: 33.35733906058378 avg_loss_a: -72.6228396393532
Número de pasos del episodio 13120 son episode_steps:48
Total Steps: 867240 Episode Num: 13120 Reward: 8.74330259150982 avg_loss_c: 35.82540468374888 avg_loss_a: -73.90552934010823
Número de pasos del episodio 13121 son episode_steps:58
Total Steps: 867298 Episode Num: 13121 Reward: -2.0116828419763477 avg_loss_c: 34.534412219606594 avg_loss_a: -71.57789743357691
Número de pasos del episodio 13122 son episode_steps:187
Total Steps: 867485 Episode Num: 13122 Reward: 103.8797429311271 avg_loss_c: 34.452996483461106 avg_loss_a: -72.16572589160286
Número de pasos del episodio 13123 son episode_steps:51
Total Steps: 867536 Episode Num: 13123 Reward: -24.733165017994633 avg_loss_c: 35.2435048421224 avg_loss_a: -73.33931851854511
Número de pasos del episodio 13124 son episode_steps:33
Total Steps: 867569 Episode Num: 13124 Reward: 4.293557668262153 avg_loss_c: 35.1876839724454 avg_loss_a: -69.89513212261778
Número de pasos del episodio 13125 son episode_steps:197
Total Steps: 867766 Episode Num: 13125 Reward: 144.1162591779691 avg_loss_c: 35.20710040833139 avg_loss_a: -70.61666506075012
Número de pasos del episodio 13126 son episode_steps:61
Total Steps: 867827 Episode Num: 13126 Reward: -3.8433124974455977 avg_loss_c: 34.386788727807215 avg_loss_a: -71.60646832575563
Número de pasos del episodio 13127 son episode_steps:46
Total Steps: 867873 Episode Num: 13127 Reward: 7.359833740329037 avg_loss_c: 34.8308045760445 avg_loss_a: -71.55813814246136
Número de pasos del episodio 13128 son episode_steps:177
Total Steps: 868050 Episode Num: 13128 Reward: 35.11311845960526 avg_loss_c: 34.669942791179075 avg_loss_a: -72.77986554506808
Número de pasos del episodio 13129 son episode_steps:53
Total Steps: 868103 Episode Num: 13129 Reward: -74.8717988165912 avg_loss_c: 36.094445570459904 avg_loss_a: -71.61888856707878
Número de pasos del episodio 13130 son episode_steps:57
Total Steps: 868160 Episode Num: 13130 Reward: -24.53884116187507 avg_loss_c: 34.50764739722536 avg_loss_a: -71.14468865645559
Número de pasos del episodio 13131 son episode_steps:31
Total Steps: 868191 Episode Num: 13131 Reward: -15.662061526882752 avg_loss_c: 35.74841400884813 avg_loss_a: -71.34618451518398
Número de pasos del episodio 13132 son episode_steps:38
Total Steps: 868229 Episode Num: 13132 Reward: -16.726944386144893 avg_loss_c: 37.56573762391743 avg_loss_a: -72.01416176243832
Número de pasos del episodio 13133 son episode_steps:156
Total Steps: 868385 Episode Num: 13133 Reward: 101.7921851535375 avg_loss_c: 36.20555392289773 avg_loss_a: -71.15159137432391
Número de pasos del episodio 13134 son episode_steps:53
Total Steps: 868438 Episode Num: 13134 Reward: 0.4922776734206973 avg_loss_c: 34.79575106782733 avg_loss_a: -71.64062672741008
Número de pasos del episodio 13135 son episode_steps:53
Total Steps: 868491 Episode Num: 13135 Reward: -21.93942514412554 avg_loss_c: 35.94340345994482 avg_loss_a: -70.5002853105653
Número de pasos del episodio 13136 son episode_steps:171
Total Steps: 868662 Episode Num: 13136 Reward: 57.107409211002825 avg_loss_c: 34.92463001451994 avg_loss_a: -71.9234821698819
Número de pasos del episodio 13137 son episode_steps:49
Total Steps: 868711 Episode Num: 13137 Reward: 0.3853038312550847 avg_loss_c: 35.95222706697425 avg_loss_a: -71.18683593127193
Número de pasos del episodio 13138 son episode_steps:61
Total Steps: 868772 Episode Num: 13138 Reward: 0.46541011282377287 avg_loss_c: 35.27852396105157 avg_loss_a: -72.28911928270684
Número de pasos del episodio 13139 son episode_steps:73
Total Steps: 868845 Episode Num: 13139 Reward: -70.18831188454288 avg_loss_c: 35.08435215362131 avg_loss_a: -71.96460378986515
Número de pasos del episodio 13140 son episode_steps:153
Total Steps: 868998 Episode Num: 13140 Reward: 98.44769154496963 avg_loss_c: 35.22236569722494 avg_loss_a: -72.43784170213088
Número de pasos del episodio 13141 son episode_steps:35
Total Steps: 869033 Episode Num: 13141 Reward: -29.144878288208837 avg_loss_c: 36.47391597202846 avg_loss_a: -71.1956322806222
Número de pasos del episodio 13142 son episode_steps:136
Total Steps: 869169 Episode Num: 13142 Reward: 56.81049791974535 avg_loss_c: 36.48298406600952 avg_loss_a: -72.02684682958267
Número de pasos del episodio 13143 son episode_steps:124
Total Steps: 869293 Episode Num: 13143 Reward: 19.055485225632204 avg_loss_c: 36.00228791083059 avg_loss_a: -72.42435775264617
Número de pasos del episodio 13144 son episode_steps:48
Total Steps: 869341 Episode Num: 13144 Reward: 5.476709786813608 avg_loss_c: 37.21760594844818 avg_loss_a: -70.87146886189778
Número de pasos del episodio 13145 son episode_steps:60
Total Steps: 869401 Episode Num: 13145 Reward: -5.451487755070566 avg_loss_c: 36.46440035502116 avg_loss_a: -71.40510584513346
Número de pasos del episodio 13146 son episode_steps:151
Total Steps: 869552 Episode Num: 13146 Reward: 124.46549854926586 avg_loss_c: 35.98947237027402 avg_loss_a: -72.76075835575331
Número de pasos del episodio 13147 son episode_steps:127
Total Steps: 869679 Episode Num: 13147 Reward: 57.23891962794281 avg_loss_c: 35.60724961288332 avg_loss_a: -71.74559020996094
Número de pasos del episodio 13148 son episode_steps:56
Total Steps: 869735 Episode Num: 13148 Reward: 1.3808700895737038 avg_loss_c: 35.56416004044669 avg_loss_a: -72.90449360438755
Número de pasos del episodio 13149 son episode_steps:372
Total Steps: 870107 Episode Num: 13149 Reward: 242.48248214429537 avg_loss_c: 35.287378880285445 avg_loss_a: -73.1191156038674
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 127.974704
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13150 son episode_steps:89
Total Steps: 870196 Episode Num: 13150 Reward: 7.417926011378818 avg_loss_c: 35.43433898754334 avg_loss_a: -72.46001039997915
Número de pasos del episodio 13151 son episode_steps:53
Total Steps: 870249 Episode Num: 13151 Reward: -28.159725654782175 avg_loss_c: 37.157929726366724 avg_loss_a: -71.93216223086951
Número de pasos del episodio 13152 son episode_steps:130
Total Steps: 870379 Episode Num: 13152 Reward: 65.91325897210767 avg_loss_c: 35.403781392024115 avg_loss_a: -73.41377316988431
Número de pasos del episodio 13153 son episode_steps:143
Total Steps: 870522 Episode Num: 13153 Reward: 56.177976008666455 avg_loss_c: 35.27171767174781 avg_loss_a: -72.87557802000246
Número de pasos del episodio 13154 son episode_steps:238
Total Steps: 870760 Episode Num: 13154 Reward: 189.0132591606809 avg_loss_c: 35.12818640220065 avg_loss_a: -73.64322303323185
Número de pasos del episodio 13155 son episode_steps:206
Total Steps: 870966 Episode Num: 13155 Reward: 119.01487147392729 avg_loss_c: 34.20343619411432 avg_loss_a: -73.59300635624858
Número de pasos del episodio 13156 son episode_steps:100
Total Steps: 871066 Episode Num: 13156 Reward: 15.962321137396938 avg_loss_c: 34.64149513244629 avg_loss_a: -72.93095436096192
Número de pasos del episodio 13157 son episode_steps:91
Total Steps: 871157 Episode Num: 13157 Reward: -6.6199562504459895 avg_loss_c: 35.939768864558296 avg_loss_a: -74.01031955257876
Número de pasos del episodio 13158 son episode_steps:62
Total Steps: 871219 Episode Num: 13158 Reward: -1.3417102032986679 avg_loss_c: 36.22450637817383 avg_loss_a: -72.8638413952243
Número de pasos del episodio 13159 son episode_steps:279
Total Steps: 871498 Episode Num: 13159 Reward: 126.36714910699563 avg_loss_c: 35.79173682838358 avg_loss_a: -73.6249272336242
Número de pasos del episodio 13160 son episode_steps:61
Total Steps: 871559 Episode Num: 13160 Reward: -41.22069464928275 avg_loss_c: 35.80566102950299 avg_loss_a: -74.08838028204245
Número de pasos del episodio 13161 son episode_steps:107
Total Steps: 871666 Episode Num: 13161 Reward: 19.223876802766647 avg_loss_c: 37.77105140686035 avg_loss_a: -73.88066985228352
Número de pasos del episodio 13162 son episode_steps:254
Total Steps: 871920 Episode Num: 13162 Reward: 179.26824823642943 avg_loss_c: 36.61283821196068 avg_loss_a: -74.31388575636495
Número de pasos del episodio 13163 son episode_steps:133
Total Steps: 872053 Episode Num: 13163 Reward: 20.15159190028196 avg_loss_c: 36.897763359815556 avg_loss_a: -74.6518025792631
Número de pasos del episodio 13164 son episode_steps:63
Total Steps: 872116 Episode Num: 13164 Reward: -23.363640590680713 avg_loss_c: 35.04485675266811 avg_loss_a: -75.37968142070467
Número de pasos del episodio 13165 son episode_steps:39
Total Steps: 872155 Episode Num: 13165 Reward: -28.059846816810857 avg_loss_c: 35.60691897074381 avg_loss_a: -75.41523644863031
Número de pasos del episodio 13166 son episode_steps:35
Total Steps: 872190 Episode Num: 13166 Reward: -28.965285031455775 avg_loss_c: 38.646326719011576 avg_loss_a: -74.89367762974331
Número de pasos del episodio 13167 son episode_steps:111
Total Steps: 872301 Episode Num: 13167 Reward: -43.71092089947186 avg_loss_c: 37.8558254757443 avg_loss_a: -73.23155947848483
Número de pasos del episodio 13168 son episode_steps:73
Total Steps: 872374 Episode Num: 13168 Reward: 5.180388611100868 avg_loss_c: 36.21250813627896 avg_loss_a: -73.73571118916551
Número de pasos del episodio 13169 son episode_steps:63
Total Steps: 872437 Episode Num: 13169 Reward: -58.82067956297726 avg_loss_c: 38.45784123738607 avg_loss_a: -73.43615541003999
Número de pasos del episodio 13170 son episode_steps:254
Total Steps: 872691 Episode Num: 13170 Reward: 174.4444746250309 avg_loss_c: 37.11723251042404 avg_loss_a: -73.66719767052358
Número de pasos del episodio 13171 son episode_steps:138
Total Steps: 872829 Episode Num: 13171 Reward: 70.56258842496682 avg_loss_c: 34.736339444699496 avg_loss_a: -74.53203593820766
Número de pasos del episodio 13172 son episode_steps:47
Total Steps: 872876 Episode Num: 13172 Reward: 4.534756274098703 avg_loss_c: 35.74353347940648 avg_loss_a: -74.8272201862741
Número de pasos del episodio 13173 son episode_steps:137
Total Steps: 873013 Episode Num: 13173 Reward: 26.02672427367882 avg_loss_c: 36.539263954997935 avg_loss_a: -74.57754639117387
Número de pasos del episodio 13174 son episode_steps:168
Total Steps: 873181 Episode Num: 13174 Reward: 94.02632081851422 avg_loss_c: 35.98966261318752 avg_loss_a: -74.98901712326776
Número de pasos del episodio 13175 son episode_steps:200
Total Steps: 873381 Episode Num: 13175 Reward: 164.6338951810021 avg_loss_c: 35.7654310131073 avg_loss_a: -75.1681159210205
Número de pasos del episodio 13176 son episode_steps:216
Total Steps: 873597 Episode Num: 13176 Reward: 87.89165656036559 avg_loss_c: 37.06988665792677 avg_loss_a: -75.47638363308377
Número de pasos del episodio 13177 son episode_steps:54
Total Steps: 873651 Episode Num: 13177 Reward: -20.860039570798993 avg_loss_c: 36.545684319955335 avg_loss_a: -75.25954380741825
Número de pasos del episodio 13178 son episode_steps:31
Total Steps: 873682 Episode Num: 13178 Reward: -10.016260382710303 avg_loss_c: 36.25177248062626 avg_loss_a: -75.37249829692226
Número de pasos del episodio 13179 son episode_steps:43
Total Steps: 873725 Episode Num: 13179 Reward: 0.49486904631578055 avg_loss_c: 34.74906535481298 avg_loss_a: -74.79977984761082
Número de pasos del episodio 13180 son episode_steps:47
Total Steps: 873772 Episode Num: 13180 Reward: -3.3564977261364635 avg_loss_c: 35.50198676738333 avg_loss_a: -73.93288859915226
Número de pasos del episodio 13181 son episode_steps:211
Total Steps: 873983 Episode Num: 13181 Reward: 70.78165145267232 avg_loss_c: 36.23677458017358 avg_loss_a: -75.01395043829606
Número de pasos del episodio 13182 son episode_steps:65
Total Steps: 874048 Episode Num: 13182 Reward: -43.520225102000694 avg_loss_c: 36.39135574927697 avg_loss_a: -73.21058232234074
Número de pasos del episodio 13183 son episode_steps:71
Total Steps: 874119 Episode Num: 13183 Reward: -3.4477071469313088 avg_loss_c: 36.33604006700113 avg_loss_a: -75.98685337120378
Número de pasos del episodio 13184 son episode_steps:86
Total Steps: 874205 Episode Num: 13184 Reward: 8.65528031745455 avg_loss_c: 36.206169838129085 avg_loss_a: -75.44429938737736
Número de pasos del episodio 13185 son episode_steps:199
Total Steps: 874404 Episode Num: 13185 Reward: 47.349529944463626 avg_loss_c: 36.888534066665116 avg_loss_a: -75.60734408584672
Número de pasos del episodio 13186 son episode_steps:119
Total Steps: 874523 Episode Num: 13186 Reward: 0.6227083969564249 avg_loss_c: 36.25832615379526 avg_loss_a: -75.3058602469308
Número de pasos del episodio 13187 son episode_steps:131
Total Steps: 874654 Episode Num: 13187 Reward: 69.73681840943394 avg_loss_c: 36.213859674584775 avg_loss_a: -75.95872060761197
Número de pasos del episodio 13188 son episode_steps:65
Total Steps: 874719 Episode Num: 13188 Reward: 2.3101605031409966 avg_loss_c: 37.016454256497894 avg_loss_a: -75.15352325439453
Número de pasos del episodio 13189 son episode_steps:342
Total Steps: 875061 Episode Num: 13189 Reward: 169.34348586539838 avg_loss_c: 36.01754383734095 avg_loss_a: -75.26077863905165
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 79.118401
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13190 son episode_steps:163
Total Steps: 875224 Episode Num: 13190 Reward: -17.277551303037747 avg_loss_c: 37.619770787244924 avg_loss_a: -76.08302625410396
Número de pasos del episodio 13191 son episode_steps:140
Total Steps: 875364 Episode Num: 13191 Reward: 51.0103320097648 avg_loss_c: 36.71440974644252 avg_loss_a: -75.37810876028878
Número de pasos del episodio 13192 son episode_steps:70
Total Steps: 875434 Episode Num: 13192 Reward: -11.308517956310691 avg_loss_c: 37.035533496311736 avg_loss_a: -75.22467215401785
Número de pasos del episodio 13193 son episode_steps:30
Total Steps: 875464 Episode Num: 13193 Reward: -31.077749679235914 avg_loss_c: 39.45183741251628 avg_loss_a: -75.13554331461589
Número de pasos del episodio 13194 son episode_steps:125
Total Steps: 875589 Episode Num: 13194 Reward: -28.81427143730433 avg_loss_c: 36.78301586914063 avg_loss_a: -75.40236401367187
Número de pasos del episodio 13195 son episode_steps:102
Total Steps: 875691 Episode Num: 13195 Reward: 22.817159294731105 avg_loss_c: 37.558672717973295 avg_loss_a: -74.31390635172527
Número de pasos del episodio 13196 son episode_steps:75
Total Steps: 875766 Episode Num: 13196 Reward: -11.616850322085636 avg_loss_c: 38.97184211730957 avg_loss_a: -74.41369018554687
Número de pasos del episodio 13197 son episode_steps:77
Total Steps: 875843 Episode Num: 13197 Reward: -88.50370696726407 avg_loss_c: 37.893522609363906 avg_loss_a: -76.04677730411679
Número de pasos del episodio 13198 son episode_steps:116
Total Steps: 875959 Episode Num: 13198 Reward: 11.422520791979656 avg_loss_c: 37.96218273557466 avg_loss_a: -74.58343571630017
Número de pasos del episodio 13199 son episode_steps:40
Total Steps: 875999 Episode Num: 13199 Reward: -34.5099199252668 avg_loss_c: 37.731723880767824 avg_loss_a: -74.84159851074219
Número de pasos del episodio 13200 son episode_steps:42
Total Steps: 876041 Episode Num: 13200 Reward: -9.10332786720776 avg_loss_c: 36.97856567019508 avg_loss_a: -74.25264122372582
Número de pasos del episodio 13201 son episode_steps:19
Total Steps: 876060 Episode Num: 13201 Reward: -29.62478361400091 avg_loss_c: 39.40442085266113 avg_loss_a: -73.03935522782176
Número de pasos del episodio 13202 son episode_steps:42
Total Steps: 876102 Episode Num: 13202 Reward: -68.31091353271667 avg_loss_c: 37.36230232602074 avg_loss_a: -76.37396058582124
Número de pasos del episodio 13203 son episode_steps:246
Total Steps: 876348 Episode Num: 13203 Reward: 113.46094232984974 avg_loss_c: 38.42494328816732 avg_loss_a: -74.38876938238377
Número de pasos del episodio 13204 son episode_steps:34
Total Steps: 876382 Episode Num: 13204 Reward: -63.20035478674801 avg_loss_c: 40.945230540107275 avg_loss_a: -72.99469936595244
Número de pasos del episodio 13205 son episode_steps:47
Total Steps: 876429 Episode Num: 13205 Reward: -35.27996502844666 avg_loss_c: 38.520414595908306 avg_loss_a: -74.91483047160696
Número de pasos del episodio 13206 son episode_steps:58
Total Steps: 876487 Episode Num: 13206 Reward: -23.645336971787593 avg_loss_c: 37.4338405214507 avg_loss_a: -74.41562284272293
Número de pasos del episodio 13207 son episode_steps:217
Total Steps: 876704 Episode Num: 13207 Reward: 87.29305223890748 avg_loss_c: 38.84475625385337 avg_loss_a: -74.22461282053301
Número de pasos del episodio 13208 son episode_steps:219
Total Steps: 876923 Episode Num: 13208 Reward: 103.9613347511145 avg_loss_c: 37.61131518289923 avg_loss_a: -74.30267755517133
Número de pasos del episodio 13209 son episode_steps:60
Total Steps: 876983 Episode Num: 13209 Reward: 2.8876875692761406 avg_loss_c: 37.53996197382609 avg_loss_a: -75.19731063842774
Número de pasos del episodio 13210 son episode_steps:35
Total Steps: 877018 Episode Num: 13210 Reward: -24.500670371764002 avg_loss_c: 38.52420338221959 avg_loss_a: -73.28917214529855
Número de pasos del episodio 13211 son episode_steps:132
Total Steps: 877150 Episode Num: 13211 Reward: 51.34166255254538 avg_loss_c: 38.58547722209584 avg_loss_a: -73.924222425981
Número de pasos del episodio 13212 son episode_steps:51
Total Steps: 877201 Episode Num: 13212 Reward: -21.035870489581562 avg_loss_c: 38.9163049436083 avg_loss_a: -73.65598730947457
Número de pasos del episodio 13213 son episode_steps:88
Total Steps: 877289 Episode Num: 13213 Reward: -90.12098352324386 avg_loss_c: 38.53354295817289 avg_loss_a: -74.05819650129838
Número de pasos del episodio 13214 son episode_steps:87
Total Steps: 877376 Episode Num: 13214 Reward: -62.71253430317278 avg_loss_c: 40.14102521435968 avg_loss_a: -73.31502410187119
Número de pasos del episodio 13215 son episode_steps:171
Total Steps: 877547 Episode Num: 13215 Reward: 37.17074369149611 avg_loss_c: 39.13386027018229 avg_loss_a: -74.1855653461657
Número de pasos del episodio 13216 son episode_steps:70
Total Steps: 877617 Episode Num: 13216 Reward: -94.208982339494 avg_loss_c: 39.08432750701904 avg_loss_a: -72.53486764090401
Número de pasos del episodio 13217 son episode_steps:34
Total Steps: 877651 Episode Num: 13217 Reward: -22.487881226010273 avg_loss_c: 39.56973423677332 avg_loss_a: -74.90514598173253
Número de pasos del episodio 13218 son episode_steps:92
Total Steps: 877743 Episode Num: 13218 Reward: -2.4825141027667996 avg_loss_c: 40.59242053653883 avg_loss_a: -74.5928082673446
Número de pasos del episodio 13219 son episode_steps:50
Total Steps: 877793 Episode Num: 13219 Reward: -22.82285396589227 avg_loss_c: 37.166812095642086 avg_loss_a: -73.58542877197266
Número de pasos del episodio 13220 son episode_steps:33
Total Steps: 877826 Episode Num: 13220 Reward: -55.42336960168192 avg_loss_c: 42.07941425207889 avg_loss_a: -72.5373640349417
Número de pasos del episodio 13221 son episode_steps:68
Total Steps: 877894 Episode Num: 13221 Reward: -6.837132299581844 avg_loss_c: 40.221675395965576 avg_loss_a: -74.17794014425839
Número de pasos del episodio 13222 son episode_steps:114
Total Steps: 878008 Episode Num: 13222 Reward: 30.772784500584844 avg_loss_c: 38.82123209300794 avg_loss_a: -74.81755895781936
Número de pasos del episodio 13223 son episode_steps:118
Total Steps: 878126 Episode Num: 13223 Reward: -36.731923263364386 avg_loss_c: 40.570174233388094 avg_loss_a: -74.41570773367154
Número de pasos del episodio 13224 son episode_steps:53
Total Steps: 878179 Episode Num: 13224 Reward: -37.53785575177204 avg_loss_c: 38.092926529218566 avg_loss_a: -74.13970587388525
Número de pasos del episodio 13225 son episode_steps:330
Total Steps: 878509 Episode Num: 13225 Reward: 213.43456019000257 avg_loss_c: 39.86074261520848 avg_loss_a: -74.31238657633463
Número de pasos del episodio 13226 son episode_steps:175
Total Steps: 878684 Episode Num: 13226 Reward: 76.7227165080233 avg_loss_c: 39.58464260646275 avg_loss_a: -74.60382873535156
Número de pasos del episodio 13227 son episode_steps:59
Total Steps: 878743 Episode Num: 13227 Reward: -55.87273645250333 avg_loss_c: 39.32371886301849 avg_loss_a: -75.34182635808395
Número de pasos del episodio 13228 son episode_steps:256
Total Steps: 878999 Episode Num: 13228 Reward: 167.47699418578165 avg_loss_c: 39.23835343122482 avg_loss_a: -75.63704007863998
Número de pasos del episodio 13229 son episode_steps:400
Total Steps: 879399 Episode Num: 13229 Reward: 209.9459605996128 avg_loss_c: 39.035562586784366 avg_loss_a: -75.5674419784546
Número de pasos del episodio 13230 son episode_steps:169
Total Steps: 879568 Episode Num: 13230 Reward: 105.31534609826765 avg_loss_c: 39.4851222292206 avg_loss_a: -77.08489308554745
Número de pasos del episodio 13231 son episode_steps:157
Total Steps: 879725 Episode Num: 13231 Reward: 83.1934245326645 avg_loss_c: 37.85682413380617 avg_loss_a: -76.72381577218414
Número de pasos del episodio 13232 son episode_steps:107
Total Steps: 879832 Episode Num: 13232 Reward: 45.37865175565069 avg_loss_c: 37.5437333828935 avg_loss_a: -76.57433575781707
Número de pasos del episodio 13233 son episode_steps:56
Total Steps: 879888 Episode Num: 13233 Reward: -12.105683368978589 avg_loss_c: 39.397404534476145 avg_loss_a: -76.32162693568638
Número de pasos del episodio 13234 son episode_steps:46
Total Steps: 879934 Episode Num: 13234 Reward: -23.868051562337122 avg_loss_c: 39.866713026295535 avg_loss_a: -76.28021638289742
Número de pasos del episodio 13235 son episode_steps:86
Total Steps: 880020 Episode Num: 13235 Reward: -71.73859605940926 avg_loss_c: 37.689057727192726 avg_loss_a: -75.02762284389762
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 70.908410
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13236 son episode_steps:154
Total Steps: 880174 Episode Num: 13236 Reward: 58.77122162422863 avg_loss_c: 39.330806484470116 avg_loss_a: -76.65651836642971
Número de pasos del episodio 13237 son episode_steps:124
Total Steps: 880298 Episode Num: 13237 Reward: -5.384304187704586 avg_loss_c: 39.669532175986994 avg_loss_a: -76.13658794280022
Número de pasos del episodio 13238 son episode_steps:194
Total Steps: 880492 Episode Num: 13238 Reward: 79.69067474116979 avg_loss_c: 37.96771842917216 avg_loss_a: -76.26652605509021
Número de pasos del episodio 13239 son episode_steps:146
Total Steps: 880638 Episode Num: 13239 Reward: 33.254678355806064 avg_loss_c: 39.25774603020655 avg_loss_a: -76.6115856431935
Número de pasos del episodio 13240 son episode_steps:329
Total Steps: 880967 Episode Num: 13240 Reward: 213.26695959236764 avg_loss_c: 38.05663281588569 avg_loss_a: -77.41332576485028
Número de pasos del episodio 13241 son episode_steps:127
Total Steps: 881094 Episode Num: 13241 Reward: 59.0281312242302 avg_loss_c: 38.41806374196931 avg_loss_a: -77.05052713709553
Número de pasos del episodio 13242 son episode_steps:258
Total Steps: 881352 Episode Num: 13242 Reward: 104.52095153883432 avg_loss_c: 37.759743683097895 avg_loss_a: -77.36087160332258
Número de pasos del episodio 13243 son episode_steps:254
Total Steps: 881606 Episode Num: 13243 Reward: 172.0060149775892 avg_loss_c: 37.31617512289933 avg_loss_a: -78.27782362089383
Número de pasos del episodio 13244 son episode_steps:120
Total Steps: 881726 Episode Num: 13244 Reward: -41.50144866098093 avg_loss_c: 37.109105332692465 avg_loss_a: -77.90439860026042
Número de pasos del episodio 13245 son episode_steps:173
Total Steps: 881899 Episode Num: 13245 Reward: 48.140518572013484 avg_loss_c: 36.87681321601647 avg_loss_a: -78.93677586902773
Número de pasos del episodio 13246 son episode_steps:43
Total Steps: 881942 Episode Num: 13246 Reward: -39.787832996566756 avg_loss_c: 35.904429635336236 avg_loss_a: -78.51503469777661
Número de pasos del episodio 13247 son episode_steps:55
Total Steps: 881997 Episode Num: 13247 Reward: -12.295850048105006 avg_loss_c: 36.848859613591976 avg_loss_a: -78.82563948197799
Número de pasos del episodio 13248 son episode_steps:53
Total Steps: 882050 Episode Num: 13248 Reward: -20.703290179026716 avg_loss_c: 36.724814504947304 avg_loss_a: -77.65839314010908
Número de pasos del episodio 13249 son episode_steps:53
Total Steps: 882103 Episode Num: 13249 Reward: -16.11119924135974 avg_loss_c: 36.559660929553914 avg_loss_a: -79.51847277947192
Número de pasos del episodio 13250 son episode_steps:91
Total Steps: 882194 Episode Num: 13250 Reward: -67.05680218707698 avg_loss_c: 38.545306132389946 avg_loss_a: -77.97536938007062
Número de pasos del episodio 13251 son episode_steps:25
Total Steps: 882219 Episode Num: 13251 Reward: -34.12323362774377 avg_loss_c: 38.336012573242186 avg_loss_a: -78.59970642089844
Número de pasos del episodio 13252 son episode_steps:40
Total Steps: 882259 Episode Num: 13252 Reward: -8.940192784643592 avg_loss_c: 35.292466163635254 avg_loss_a: -77.7806884765625
Número de pasos del episodio 13253 son episode_steps:145
Total Steps: 882404 Episode Num: 13253 Reward: 22.724631465833454 avg_loss_c: 37.89262445384058 avg_loss_a: -78.59812485267376
Número de pasos del episodio 13254 son episode_steps:61
Total Steps: 882465 Episode Num: 13254 Reward: -37.057658019170965 avg_loss_c: 37.061879830282244 avg_loss_a: -78.67596185402792
Número de pasos del episodio 13255 son episode_steps:86
Total Steps: 882551 Episode Num: 13255 Reward: 16.541167215509056 avg_loss_c: 38.26218327810598 avg_loss_a: -79.317539126374
Número de pasos del episodio 13256 son episode_steps:135
Total Steps: 882686 Episode Num: 13256 Reward: 55.10343238404356 avg_loss_c: 37.10673791390878 avg_loss_a: -77.45472395155164
Número de pasos del episodio 13257 son episode_steps:146
Total Steps: 882832 Episode Num: 13257 Reward: 56.55362627351102 avg_loss_c: 38.73998073682393 avg_loss_a: -79.31338333756956
Número de pasos del episodio 13258 son episode_steps:73
Total Steps: 882905 Episode Num: 13258 Reward: -43.12814615553324 avg_loss_c: 37.75457408330212 avg_loss_a: -80.23480809877996
Número de pasos del episodio 13259 son episode_steps:49
Total Steps: 882954 Episode Num: 13259 Reward: -39.804999589500994 avg_loss_c: 39.04905272503289 avg_loss_a: -78.5421756043726
Número de pasos del episodio 13260 son episode_steps:61
Total Steps: 883015 Episode Num: 13260 Reward: 3.012280479273352 avg_loss_c: 36.849523638115556 avg_loss_a: -78.63611665319223
Número de pasos del episodio 13261 son episode_steps:71
Total Steps: 883086 Episode Num: 13261 Reward: 3.0027963991745663 avg_loss_c: 36.23537592820718 avg_loss_a: -79.1837860967072
Número de pasos del episodio 13262 son episode_steps:110
Total Steps: 883196 Episode Num: 13262 Reward: 33.337578692196175 avg_loss_c: 38.42649680050937 avg_loss_a: -79.46108856201172
Número de pasos del episodio 13263 son episode_steps:58
Total Steps: 883254 Episode Num: 13263 Reward: -6.657874452529947 avg_loss_c: 37.903828357828075 avg_loss_a: -78.19334911477976
Número de pasos del episodio 13264 son episode_steps:61
Total Steps: 883315 Episode Num: 13264 Reward: -41.98934563797728 avg_loss_c: 37.122483550525104 avg_loss_a: -79.00257911056768
Número de pasos del episodio 13265 son episode_steps:20
Total Steps: 883335 Episode Num: 13265 Reward: -30.91786144959712 avg_loss_c: 38.45098791122437 avg_loss_a: -77.74296493530274
Número de pasos del episodio 13266 son episode_steps:39
Total Steps: 883374 Episode Num: 13266 Reward: -26.42808950546485 avg_loss_c: 37.38383586590107 avg_loss_a: -79.99901248247195
Número de pasos del episodio 13267 son episode_steps:154
Total Steps: 883528 Episode Num: 13267 Reward: 59.40725044432118 avg_loss_c: 37.769952724506325 avg_loss_a: -78.65628517448128
Número de pasos del episodio 13268 son episode_steps:161
Total Steps: 883689 Episode Num: 13268 Reward: 95.03046853625966 avg_loss_c: 37.543619452055935 avg_loss_a: -79.39532409099318
Número de pasos del episodio 13269 son episode_steps:193
Total Steps: 883882 Episode Num: 13269 Reward: 84.82061714027631 avg_loss_c: 37.159100023576016 avg_loss_a: -78.72124018693835
Número de pasos del episodio 13270 son episode_steps:75
Total Steps: 883957 Episode Num: 13270 Reward: -24.442659246574806 avg_loss_c: 37.27358050028483 avg_loss_a: -79.47288248697917
Número de pasos del episodio 13271 son episode_steps:62
Total Steps: 884019 Episode Num: 13271 Reward: 13.987177890560273 avg_loss_c: 36.86412263685657 avg_loss_a: -79.40061261576992
Número de pasos del episodio 13272 son episode_steps:67
Total Steps: 884086 Episode Num: 13272 Reward: -30.788463396252048 avg_loss_c: 37.88379301953672 avg_loss_a: -78.60388479659807
Número de pasos del episodio 13273 son episode_steps:36
Total Steps: 884122 Episode Num: 13273 Reward: -14.328354046506831 avg_loss_c: 36.93475951088799 avg_loss_a: -79.11953650580512
Número de pasos del episodio 13274 son episode_steps:22
Total Steps: 884144 Episode Num: 13274 Reward: -46.72613829327722 avg_loss_c: 35.09824336658824 avg_loss_a: -79.6323734630238
Número de pasos del episodio 13275 son episode_steps:44
Total Steps: 884188 Episode Num: 13275 Reward: -22.51989726721267 avg_loss_c: 38.01704506440596 avg_loss_a: -80.64609596946023
Número de pasos del episodio 13276 son episode_steps:48
Total Steps: 884236 Episode Num: 13276 Reward: -19.74191988697244 avg_loss_c: 37.82056681315104 avg_loss_a: -78.53833452860515
Número de pasos del episodio 13277 son episode_steps:70
Total Steps: 884306 Episode Num: 13277 Reward: -30.11817098801976 avg_loss_c: 38.704041263035364 avg_loss_a: -79.20085165841239
Número de pasos del episodio 13278 son episode_steps:105
Total Steps: 884411 Episode Num: 13278 Reward: -6.053421683111739 avg_loss_c: 38.95979220072429 avg_loss_a: -78.15059443882534
Número de pasos del episodio 13279 son episode_steps:72
Total Steps: 884483 Episode Num: 13279 Reward: 6.455652173364346 avg_loss_c: 38.52117135789659 avg_loss_a: -78.37300067477756
Número de pasos del episodio 13280 son episode_steps:60
Total Steps: 884543 Episode Num: 13280 Reward: -25.935236041992848 avg_loss_c: 38.40278949737549 avg_loss_a: -78.89926350911459
Número de pasos del episodio 13281 son episode_steps:56
Total Steps: 884599 Episode Num: 13281 Reward: -21.31885398540036 avg_loss_c: 37.08003418786185 avg_loss_a: -78.97001266479492
Número de pasos del episodio 13282 son episode_steps:64
Total Steps: 884663 Episode Num: 13282 Reward: -10.128472245001262 avg_loss_c: 39.787931233644485 avg_loss_a: -79.63412833213806
Número de pasos del episodio 13283 son episode_steps:163
Total Steps: 884826 Episode Num: 13283 Reward: 76.91474370835742 avg_loss_c: 38.73548622365378 avg_loss_a: -79.17743987100987
Número de pasos del episodio 13284 son episode_steps:34
Total Steps: 884860 Episode Num: 13284 Reward: -2.1471695589146966 avg_loss_c: 39.525423274320715 avg_loss_a: -76.1364844827091
Número de pasos del episodio 13285 son episode_steps:82
Total Steps: 884942 Episode Num: 13285 Reward: -20.842746525531236 avg_loss_c: 39.90303120962003 avg_loss_a: -78.95880629376667
Número de pasos del episodio 13286 son episode_steps:144
Total Steps: 885086 Episode Num: 13286 Reward: 82.61997318453349 avg_loss_c: 38.33087396621704 avg_loss_a: -78.67274475097656
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 69.944909
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13287 son episode_steps:80
Total Steps: 885166 Episode Num: 13287 Reward: 8.539855451045348 avg_loss_c: 36.846703839302066 avg_loss_a: -78.25316791534424
Número de pasos del episodio 13288 son episode_steps:223
Total Steps: 885389 Episode Num: 13288 Reward: 94.710140567821 avg_loss_c: 37.97026092802997 avg_loss_a: -77.61863239784412
Número de pasos del episodio 13289 son episode_steps:103
Total Steps: 885492 Episode Num: 13289 Reward: -25.891505731980637 avg_loss_c: 39.446591738358286 avg_loss_a: -77.68014911540503
Número de pasos del episodio 13290 son episode_steps:70
Total Steps: 885562 Episode Num: 13290 Reward: 14.650439114354313 avg_loss_c: 38.167989594595774 avg_loss_a: -78.5530264718192
Número de pasos del episodio 13291 son episode_steps:75
Total Steps: 885637 Episode Num: 13291 Reward: 14.651005953553119 avg_loss_c: 38.704036992390954 avg_loss_a: -78.70025105794271
Número de pasos del episodio 13292 son episode_steps:55
Total Steps: 885692 Episode Num: 13292 Reward: -49.4978266679376 avg_loss_c: 39.69285007823597 avg_loss_a: -77.22199748646129
Número de pasos del episodio 13293 son episode_steps:158
Total Steps: 885850 Episode Num: 13293 Reward: 52.76775568194474 avg_loss_c: 38.154281857647476 avg_loss_a: -79.39325057403951
Número de pasos del episodio 13294 son episode_steps:92
Total Steps: 885942 Episode Num: 13294 Reward: 31.313072763411235 avg_loss_c: 38.28634894412497 avg_loss_a: -78.24125936756964
Número de pasos del episodio 13295 son episode_steps:65
Total Steps: 886007 Episode Num: 13295 Reward: -29.552400657806125 avg_loss_c: 38.46928526071402 avg_loss_a: -79.5339106633113
Número de pasos del episodio 13296 son episode_steps:46
Total Steps: 886053 Episode Num: 13296 Reward: 1.3231896498582891 avg_loss_c: 38.56045424419901 avg_loss_a: -78.87145962922469
Número de pasos del episodio 13297 son episode_steps:98
Total Steps: 886151 Episode Num: 13297 Reward: -0.9864782561112846 avg_loss_c: 39.085594780591066 avg_loss_a: -78.62352192158602
Número de pasos del episodio 13298 son episode_steps:111
Total Steps: 886262 Episode Num: 13298 Reward: -35.29607708516216 avg_loss_c: 38.78823544957616 avg_loss_a: -78.83231257533168
Número de pasos del episodio 13299 son episode_steps:188
Total Steps: 886450 Episode Num: 13299 Reward: 30.656525671793336 avg_loss_c: 37.81383181632833 avg_loss_a: -78.31312934388505
Número de pasos del episodio 13300 son episode_steps:39
Total Steps: 886489 Episode Num: 13300 Reward: -0.615384942191801 avg_loss_c: 35.9612110333565 avg_loss_a: -78.26022769243289
Número de pasos del episodio 13301 son episode_steps:220
Total Steps: 886709 Episode Num: 13301 Reward: 87.3676758590805 avg_loss_c: 39.26702117919922 avg_loss_a: -78.2078468322754
Número de pasos del episodio 13302 son episode_steps:51
Total Steps: 886760 Episode Num: 13302 Reward: -17.38368259275877 avg_loss_c: 38.35528347538967 avg_loss_a: -77.96375065223843
Número de pasos del episodio 13303 son episode_steps:82
Total Steps: 886842 Episode Num: 13303 Reward: -11.6659361072235 avg_loss_c: 39.695464064435264 avg_loss_a: -78.48705570872237
Número de pasos del episodio 13304 son episode_steps:86
Total Steps: 886928 Episode Num: 13304 Reward: 31.460523750455273 avg_loss_c: 39.30983490167662 avg_loss_a: -77.30967951929847
Número de pasos del episodio 13305 son episode_steps:205
Total Steps: 887133 Episode Num: 13305 Reward: -40.05537639756213 avg_loss_c: 38.36827836385587 avg_loss_a: -77.93083179753002
Número de pasos del episodio 13306 son episode_steps:59
Total Steps: 887192 Episode Num: 13306 Reward: -8.190128227356311 avg_loss_c: 37.736505799374335 avg_loss_a: -77.89541535458322
Número de pasos del episodio 13307 son episode_steps:81
Total Steps: 887273 Episode Num: 13307 Reward: 28.957069807091038 avg_loss_c: 39.923767395961434 avg_loss_a: -76.77757649362823
Número de pasos del episodio 13308 son episode_steps:42
Total Steps: 887315 Episode Num: 13308 Reward: -16.533014670784688 avg_loss_c: 36.552905536833265 avg_loss_a: -77.36517769949776
Número de pasos del episodio 13309 son episode_steps:44
Total Steps: 887359 Episode Num: 13309 Reward: -15.778316868586632 avg_loss_c: 40.12520842118697 avg_loss_a: -78.03656213933772
Número de pasos del episodio 13310 son episode_steps:103
Total Steps: 887462 Episode Num: 13310 Reward: 11.147091021896905 avg_loss_c: 40.167243679750314 avg_loss_a: -76.8479294267673
Número de pasos del episodio 13311 son episode_steps:210
Total Steps: 887672 Episode Num: 13311 Reward: 139.94864624820582 avg_loss_c: 38.41299122401646 avg_loss_a: -77.01981244768415
Número de pasos del episodio 13312 son episode_steps:106
Total Steps: 887778 Episode Num: 13312 Reward: 70.27192908447523 avg_loss_c: 37.96373271942139 avg_loss_a: -77.47971185648217
Número de pasos del episodio 13313 son episode_steps:80
Total Steps: 887858 Episode Num: 13313 Reward: 10.845670460090073 avg_loss_c: 38.1326562166214 avg_loss_a: -77.43782081604004
Número de pasos del episodio 13314 son episode_steps:73
Total Steps: 887931 Episode Num: 13314 Reward: -15.590177302854892 avg_loss_c: 37.424422956492805 avg_loss_a: -77.88603837522741
Número de pasos del episodio 13315 son episode_steps:28
Total Steps: 887959 Episode Num: 13315 Reward: -52.594261050681006 avg_loss_c: 36.99372012274606 avg_loss_a: -79.86129597255162
Número de pasos del episodio 13316 son episode_steps:75
Total Steps: 888034 Episode Num: 13316 Reward: 15.651198596847497 avg_loss_c: 40.394840520222985 avg_loss_a: -77.3133408610026
Número de pasos del episodio 13317 son episode_steps:47
Total Steps: 888081 Episode Num: 13317 Reward: 8.26521105254889 avg_loss_c: 38.21851823685017 avg_loss_a: -76.75770114330535
Número de pasos del episodio 13318 son episode_steps:235
Total Steps: 888316 Episode Num: 13318 Reward: 163.35581304931088 avg_loss_c: 39.16228680712111 avg_loss_a: -78.15195156665558
Número de pasos del episodio 13319 son episode_steps:162
Total Steps: 888478 Episode Num: 13319 Reward: 39.67448982646896 avg_loss_c: 38.2000911736194 avg_loss_a: -77.81845375343606
Número de pasos del episodio 13320 son episode_steps:36
Total Steps: 888514 Episode Num: 13320 Reward: -19.921924423914785 avg_loss_c: 41.610592683156334 avg_loss_a: -76.45164065890842
Número de pasos del episodio 13321 son episode_steps:45
Total Steps: 888559 Episode Num: 13321 Reward: -16.83223021469553 avg_loss_c: 37.348558849758575 avg_loss_a: -78.89785800509982
Número de pasos del episodio 13322 son episode_steps:55
Total Steps: 888614 Episode Num: 13322 Reward: -23.497321705853604 avg_loss_c: 38.194977430863815 avg_loss_a: -76.8791177923029
Número de pasos del episodio 13323 son episode_steps:41
Total Steps: 888655 Episode Num: 13323 Reward: 3.6404288376736607 avg_loss_c: 39.71649816559582 avg_loss_a: -76.79008614144674
Número de pasos del episodio 13324 son episode_steps:26
Total Steps: 888681 Episode Num: 13324 Reward: -35.77837990605423 avg_loss_c: 37.66049561133752 avg_loss_a: -75.87296295166016
Número de pasos del episodio 13325 son episode_steps:171
Total Steps: 888852 Episode Num: 13325 Reward: 51.91018020898927 avg_loss_c: 38.69252175894397 avg_loss_a: -77.44244741696363
Número de pasos del episodio 13326 son episode_steps:78
Total Steps: 888930 Episode Num: 13326 Reward: -7.582230941930293 avg_loss_c: 38.40840234511938 avg_loss_a: -78.60933607052534
Número de pasos del episodio 13327 son episode_steps:44
Total Steps: 888974 Episode Num: 13327 Reward: -15.008779039211525 avg_loss_c: 38.24946711280129 avg_loss_a: -76.58434434370561
Número de pasos del episodio 13328 son episode_steps:59
Total Steps: 889033 Episode Num: 13328 Reward: -32.75579960360171 avg_loss_c: 37.694383233280504 avg_loss_a: -78.03269350730767
Número de pasos del episodio 13329 son episode_steps:174
Total Steps: 889207 Episode Num: 13329 Reward: 111.57945422262706 avg_loss_c: 38.994770926990725 avg_loss_a: -77.4349708118658
Número de pasos del episodio 13330 son episode_steps:60
Total Steps: 889267 Episode Num: 13330 Reward: 13.327446449134444 avg_loss_c: 37.587008539835615 avg_loss_a: -76.06937917073567
Número de pasos del episodio 13331 son episode_steps:107
Total Steps: 889374 Episode Num: 13331 Reward: 58.64920041743507 avg_loss_c: 37.7975457093426 avg_loss_a: -78.17444147127812
Número de pasos del episodio 13332 son episode_steps:57
Total Steps: 889431 Episode Num: 13332 Reward: 17.117142641730254 avg_loss_c: 36.13808802554482 avg_loss_a: -76.75659447385554
Número de pasos del episodio 13333 son episode_steps:26
Total Steps: 889457 Episode Num: 13333 Reward: -17.606719453071083 avg_loss_c: 39.55339189676138 avg_loss_a: -77.56665743314304
Número de pasos del episodio 13334 son episode_steps:66
Total Steps: 889523 Episode Num: 13334 Reward: -27.382450259929037 avg_loss_c: 38.8915511044589 avg_loss_a: -76.55401842521898
Número de pasos del episodio 13335 son episode_steps:151
Total Steps: 889674 Episode Num: 13335 Reward: 12.40137423176592 avg_loss_c: 39.41332395187277 avg_loss_a: -76.57124358928756
Número de pasos del episodio 13336 son episode_steps:354
Total Steps: 890028 Episode Num: 13336 Reward: 235.15154538659385 avg_loss_c: 37.75805519664355 avg_loss_a: -76.52904269116073
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 69.866727
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13337 son episode_steps:55
Total Steps: 890083 Episode Num: 13337 Reward: -21.389144571386932 avg_loss_c: 35.58731477910822 avg_loss_a: -76.23580488725142
Número de pasos del episodio 13338 son episode_steps:87
Total Steps: 890170 Episode Num: 13338 Reward: -16.746408236547353 avg_loss_c: 37.994275564434886 avg_loss_a: -77.06973029827249
Número de pasos del episodio 13339 son episode_steps:42
Total Steps: 890212 Episode Num: 13339 Reward: -31.917896848565785 avg_loss_c: 37.62622288295201 avg_loss_a: -75.97583552769252
Número de pasos del episodio 13340 son episode_steps:51
Total Steps: 890263 Episode Num: 13340 Reward: -46.12963562131932 avg_loss_c: 38.4624464745615 avg_loss_a: -76.50173351811428
Número de pasos del episodio 13341 son episode_steps:94
Total Steps: 890357 Episode Num: 13341 Reward: 22.76973922183412 avg_loss_c: 38.377473100702815 avg_loss_a: -76.4436941755579
Número de pasos del episodio 13342 son episode_steps:69
Total Steps: 890426 Episode Num: 13342 Reward: -36.697411566811844 avg_loss_c: 36.83735739666483 avg_loss_a: -76.42840509829314
Número de pasos del episodio 13343 son episode_steps:43
Total Steps: 890469 Episode Num: 13343 Reward: -27.75738879782444 avg_loss_c: 36.63162417744481 avg_loss_a: -77.55650702188181
Número de pasos del episodio 13344 son episode_steps:128
Total Steps: 890597 Episode Num: 13344 Reward: 45.68582775524441 avg_loss_c: 39.912565380334854 avg_loss_a: -76.42903351783752
Número de pasos del episodio 13345 son episode_steps:31
Total Steps: 890628 Episode Num: 13345 Reward: -37.073733040190874 avg_loss_c: 40.94595619939989 avg_loss_a: -75.21339293449155
Número de pasos del episodio 13346 son episode_steps:56
Total Steps: 890684 Episode Num: 13346 Reward: -46.451411610692304 avg_loss_c: 38.9133985042572 avg_loss_a: -75.86190264565604
Número de pasos del episodio 13347 son episode_steps:85
Total Steps: 890769 Episode Num: 13347 Reward: -9.105148938272912 avg_loss_c: 39.14507432825425 avg_loss_a: -75.75414024801815
Número de pasos del episodio 13348 son episode_steps:147
Total Steps: 890916 Episode Num: 13348 Reward: 30.380767948866264 avg_loss_c: 39.916675982832096 avg_loss_a: -75.50037576065583
Número de pasos del episodio 13349 son episode_steps:98
Total Steps: 891014 Episode Num: 13349 Reward: -43.90543876403133 avg_loss_c: 38.65596424803442 avg_loss_a: -75.06128863899075
Número de pasos del episodio 13350 son episode_steps:144
Total Steps: 891158 Episode Num: 13350 Reward: -10.012398566463993 avg_loss_c: 39.800479094187416 avg_loss_a: -76.21537060207791
Número de pasos del episodio 13351 son episode_steps:58
Total Steps: 891216 Episode Num: 13351 Reward: -15.495168717104548 avg_loss_c: 38.20563668218152 avg_loss_a: -75.53587341308594
Número de pasos del episodio 13352 son episode_steps:62
Total Steps: 891278 Episode Num: 13352 Reward: -48.963652979983095 avg_loss_c: 39.14156052374071 avg_loss_a: -74.4935548843876
Número de pasos del episodio 13353 son episode_steps:89
Total Steps: 891367 Episode Num: 13353 Reward: 27.49189907973034 avg_loss_c: 40.28706473446964 avg_loss_a: -74.99175305312939
Número de pasos del episodio 13354 son episode_steps:183
Total Steps: 891550 Episode Num: 13354 Reward: 84.30229643958253 avg_loss_c: 39.387880137709324 avg_loss_a: -74.14483959427297
Número de pasos del episodio 13355 son episode_steps:81
Total Steps: 891631 Episode Num: 13355 Reward: 12.224903294972822 avg_loss_c: 37.41034973992242 avg_loss_a: -75.4942800262828
Número de pasos del episodio 13356 son episode_steps:166
Total Steps: 891797 Episode Num: 13356 Reward: 96.90202045650975 avg_loss_c: 36.59033444416092 avg_loss_a: -74.61685134703855
Número de pasos del episodio 13357 son episode_steps:228
Total Steps: 892025 Episode Num: 13357 Reward: 90.01480594122324 avg_loss_c: 37.43827588934647 avg_loss_a: -75.11632962812457
Número de pasos del episodio 13358 son episode_steps:181
Total Steps: 892206 Episode Num: 13358 Reward: 12.585886414306628 avg_loss_c: 37.73853469553573 avg_loss_a: -75.60045762878755
Número de pasos del episodio 13359 son episode_steps:51
Total Steps: 892257 Episode Num: 13359 Reward: -50.22491200679477 avg_loss_c: 36.61696377922507 avg_loss_a: -75.62158143286611
Número de pasos del episodio 13360 son episode_steps:90
Total Steps: 892347 Episode Num: 13360 Reward: -2.8442483867433848 avg_loss_c: 37.526854557461206 avg_loss_a: -74.60453643798829
Número de pasos del episodio 13361 son episode_steps:123
Total Steps: 892470 Episode Num: 13361 Reward: -56.25297631328513 avg_loss_c: 38.236938972783285 avg_loss_a: -75.75404940969575
Número de pasos del episodio 13362 son episode_steps:31
Total Steps: 892501 Episode Num: 13362 Reward: -39.913492408023984 avg_loss_c: 37.93112379504788 avg_loss_a: -72.77169356807586
Número de pasos del episodio 13363 son episode_steps:161
Total Steps: 892662 Episode Num: 13363 Reward: 78.10071414057789 avg_loss_c: 37.77297619410923 avg_loss_a: -74.96375971255095
Número de pasos del episodio 13364 son episode_steps:50
Total Steps: 892712 Episode Num: 13364 Reward: -36.326846077292366 avg_loss_c: 39.829024925231934 avg_loss_a: -72.41674102783203
Número de pasos del episodio 13365 son episode_steps:67
Total Steps: 892779 Episode Num: 13365 Reward: -49.53999934762038 avg_loss_c: 38.45933319205668 avg_loss_a: -75.49053135202892
Número de pasos del episodio 13366 son episode_steps:128
Total Steps: 892907 Episode Num: 13366 Reward: 12.709543054901388 avg_loss_c: 38.03496214747429 avg_loss_a: -74.68690645694733
Número de pasos del episodio 13367 son episode_steps:97
Total Steps: 893004 Episode Num: 13367 Reward: 6.190728379892957 avg_loss_c: 39.66525567438185 avg_loss_a: -74.02685004165492
Número de pasos del episodio 13368 son episode_steps:33
Total Steps: 893037 Episode Num: 13368 Reward: -29.399318782462956 avg_loss_c: 38.90081659952799 avg_loss_a: -75.24905094955906
Número de pasos del episodio 13369 son episode_steps:75
Total Steps: 893112 Episode Num: 13369 Reward: -3.0808416913921874 avg_loss_c: 39.50868578592936 avg_loss_a: -73.94804392496745
Número de pasos del episodio 13370 son episode_steps:153
Total Steps: 893265 Episode Num: 13370 Reward: 2.671446426197682 avg_loss_c: 38.922876607358845 avg_loss_a: -74.72361969791986
Número de pasos del episodio 13371 son episode_steps:37
Total Steps: 893302 Episode Num: 13371 Reward: -19.970740287229432 avg_loss_c: 38.80065598358979 avg_loss_a: -73.92184633822055
Número de pasos del episodio 13372 son episode_steps:79
Total Steps: 893381 Episode Num: 13372 Reward: -6.268332397582466 avg_loss_c: 40.44381974618646 avg_loss_a: -74.18058100833169
Número de pasos del episodio 13373 son episode_steps:120
Total Steps: 893501 Episode Num: 13373 Reward: 43.612332087424825 avg_loss_c: 39.68258441289266 avg_loss_a: -73.90123163859049
Número de pasos del episodio 13374 son episode_steps:61
Total Steps: 893562 Episode Num: 13374 Reward: -48.360383122337126 avg_loss_c: 39.64164161682129 avg_loss_a: -72.41967435742988
Número de pasos del episodio 13375 son episode_steps:94
Total Steps: 893656 Episode Num: 13375 Reward: 37.76584237080153 avg_loss_c: 38.81406834784975 avg_loss_a: -74.12511914841672
Número de pasos del episodio 13376 son episode_steps:171
Total Steps: 893827 Episode Num: 13376 Reward: 53.82768008703804 avg_loss_c: 40.31697712725366 avg_loss_a: -74.49309526410019
Número de pasos del episodio 13377 son episode_steps:48
Total Steps: 893875 Episode Num: 13377 Reward: -57.09905493065859 avg_loss_c: 40.451725363731384 avg_loss_a: -74.70218467712402
Número de pasos del episodio 13378 son episode_steps:41
Total Steps: 893916 Episode Num: 13378 Reward: -57.34341039318704 avg_loss_c: 38.785312326943 avg_loss_a: -73.6219339138124
Número de pasos del episodio 13379 son episode_steps:48
Total Steps: 893964 Episode Num: 13379 Reward: -16.677088201077712 avg_loss_c: 37.76738854249319 avg_loss_a: -74.5749158859253
Número de pasos del episodio 13380 son episode_steps:54
Total Steps: 894018 Episode Num: 13380 Reward: 0.5814683034796406 avg_loss_c: 39.7667728000217 avg_loss_a: -72.72365344012225
Número de pasos del episodio 13381 son episode_steps:178
Total Steps: 894196 Episode Num: 13381 Reward: 51.04219505660854 avg_loss_c: 39.66430315810643 avg_loss_a: -73.51488091972436
Número de pasos del episodio 13382 son episode_steps:36
Total Steps: 894232 Episode Num: 13382 Reward: -27.584362940476048 avg_loss_c: 38.15375651253594 avg_loss_a: -74.347898695204
Número de pasos del episodio 13383 son episode_steps:165
Total Steps: 894397 Episode Num: 13383 Reward: 47.77028243054197 avg_loss_c: 39.273016553936586 avg_loss_a: -73.99111809008049
Número de pasos del episodio 13384 son episode_steps:131
Total Steps: 894528 Episode Num: 13384 Reward: 43.11186559567922 avg_loss_c: 38.22224088479545 avg_loss_a: -73.59467234138314
Número de pasos del episodio 13385 son episode_steps:63
Total Steps: 894591 Episode Num: 13385 Reward: -4.952161041581903 avg_loss_c: 38.42890745495993 avg_loss_a: -74.19372195289249
Número de pasos del episodio 13386 son episode_steps:33
Total Steps: 894624 Episode Num: 13386 Reward: -39.83861061385391 avg_loss_c: 37.28587977091471 avg_loss_a: -74.05030753395774
Número de pasos del episodio 13387 son episode_steps:217
Total Steps: 894841 Episode Num: 13387 Reward: 29.50035574695239 avg_loss_c: 39.59510205528154 avg_loss_a: -73.72172314340618
Número de pasos del episodio 13388 son episode_steps:111
Total Steps: 894952 Episode Num: 13388 Reward: 79.79626770998303 avg_loss_c: 39.12895104691789 avg_loss_a: -72.9684609765405
Número de pasos del episodio 13389 son episode_steps:149
Total Steps: 895101 Episode Num: 13389 Reward: 21.46894457848383 avg_loss_c: 38.565217510965844 avg_loss_a: -73.1858227108949
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 46.303662
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13390 son episode_steps:75
Total Steps: 895176 Episode Num: 13390 Reward: -6.825012154963531 avg_loss_c: 38.26164978027344 avg_loss_a: -72.51228922526042
Número de pasos del episodio 13391 son episode_steps:158
Total Steps: 895334 Episode Num: 13391 Reward: 15.09437191321456 avg_loss_c: 39.45125472394726 avg_loss_a: -72.94923840293401
Número de pasos del episodio 13392 son episode_steps:50
Total Steps: 895384 Episode Num: 13392 Reward: -51.701370280338026 avg_loss_c: 38.523885612487796 avg_loss_a: -72.50665054321288
Número de pasos del episodio 13393 son episode_steps:48
Total Steps: 895432 Episode Num: 13393 Reward: -9.01670127649995 avg_loss_c: 38.377198815345764 avg_loss_a: -72.78083483378093
Número de pasos del episodio 13394 son episode_steps:136
Total Steps: 895568 Episode Num: 13394 Reward: 43.10216498017405 avg_loss_c: 39.243081639794745 avg_loss_a: -73.40114206426284
Número de pasos del episodio 13395 son episode_steps:142
Total Steps: 895710 Episode Num: 13395 Reward: 53.59058078325513 avg_loss_c: 39.515379395283446 avg_loss_a: -72.76899622527647
Número de pasos del episodio 13396 son episode_steps:116
Total Steps: 895826 Episode Num: 13396 Reward: 19.531955365511603 avg_loss_c: 38.49435702685652 avg_loss_a: -72.80408780328159
Número de pasos del episodio 13397 son episode_steps:324
Total Steps: 896150 Episode Num: 13397 Reward: 135.91999490617894 avg_loss_c: 38.835723765102436 avg_loss_a: -72.91304042015547
Número de pasos del episodio 13398 son episode_steps:44
Total Steps: 896194 Episode Num: 13398 Reward: 10.455995310402894 avg_loss_c: 37.887687553058974 avg_loss_a: -73.28010628440164
Número de pasos del episodio 13399 son episode_steps:136
Total Steps: 896330 Episode Num: 13399 Reward: 30.688709619266795 avg_loss_c: 37.67784033102148 avg_loss_a: -74.10578177956974
Número de pasos del episodio 13400 son episode_steps:323
Total Steps: 896653 Episode Num: 13400 Reward: 225.20152456016817 avg_loss_c: 37.409341558214315 avg_loss_a: -74.17889250764168
Número de pasos del episodio 13401 son episode_steps:69
Total Steps: 896722 Episode Num: 13401 Reward: -59.82838856165512 avg_loss_c: 37.919172895127446 avg_loss_a: -73.77586862315302
Número de pasos del episodio 13402 son episode_steps:204
Total Steps: 896926 Episode Num: 13402 Reward: 32.69640567307392 avg_loss_c: 38.8102382959104 avg_loss_a: -74.25040547987994
Número de pasos del episodio 13403 son episode_steps:378
Total Steps: 897304 Episode Num: 13403 Reward: 191.25597002781072 avg_loss_c: 37.43605906875045 avg_loss_a: -75.01791446423404
Número de pasos del episodio 13404 son episode_steps:63
Total Steps: 897367 Episode Num: 13404 Reward: -16.394427100731498 avg_loss_c: 36.7424243442596 avg_loss_a: -74.75845397464813
Número de pasos del episodio 13405 son episode_steps:48
Total Steps: 897415 Episode Num: 13405 Reward: -32.481806005086426 avg_loss_c: 37.45426340897878 avg_loss_a: -75.22104295094807
Número de pasos del episodio 13406 son episode_steps:98
Total Steps: 897513 Episode Num: 13406 Reward: -8.229245443595609 avg_loss_c: 37.477138052181324 avg_loss_a: -73.92057457748724
Número de pasos del episodio 13407 son episode_steps:24
Total Steps: 897537 Episode Num: 13407 Reward: -28.014844242942914 avg_loss_c: 41.096251010894775 avg_loss_a: -76.6613941192627
Número de pasos del episodio 13408 son episode_steps:58
Total Steps: 897595 Episode Num: 13408 Reward: -8.074108984629095 avg_loss_c: 37.575685238016064 avg_loss_a: -75.17158113676926
Número de pasos del episodio 13409 son episode_steps:117
Total Steps: 897712 Episode Num: 13409 Reward: 46.73875696449695 avg_loss_c: 38.38228297437358 avg_loss_a: -74.46504335321931
Número de pasos del episodio 13410 son episode_steps:25
Total Steps: 897737 Episode Num: 13410 Reward: -36.376726375746486 avg_loss_c: 38.944975509643555 avg_loss_a: -73.44142272949219
Número de pasos del episodio 13411 son episode_steps:59
Total Steps: 897796 Episode Num: 13411 Reward: -55.18383209005336 avg_loss_c: 37.183107149803035 avg_loss_a: -74.26280432232356
Número de pasos del episodio 13412 son episode_steps:138
Total Steps: 897934 Episode Num: 13412 Reward: 91.823627216549 avg_loss_c: 38.311355839604914 avg_loss_a: -74.75272844839787
Número de pasos del episodio 13413 son episode_steps:293
Total Steps: 898227 Episode Num: 13413 Reward: 196.70052352903812 avg_loss_c: 37.172898022388026 avg_loss_a: -75.25185818721003
Número de pasos del episodio 13414 son episode_steps:58
Total Steps: 898285 Episode Num: 13414 Reward: 13.240625970424796 avg_loss_c: 37.065065285255166 avg_loss_a: -74.95344674998316
Número de pasos del episodio 13415 son episode_steps:182
Total Steps: 898467 Episode Num: 13415 Reward: 108.18096712341624 avg_loss_c: 37.591449936667644 avg_loss_a: -76.48376062414148
Número de pasos del episodio 13416 son episode_steps:190
Total Steps: 898657 Episode Num: 13416 Reward: -17.651391683935707 avg_loss_c: 37.25484391262657 avg_loss_a: -75.47075548673931
Número de pasos del episodio 13417 son episode_steps:74
Total Steps: 898731 Episode Num: 13417 Reward: -88.62331548345688 avg_loss_c: 37.41568307618837 avg_loss_a: -77.2693337105416
Número de pasos del episodio 13418 son episode_steps:40
Total Steps: 898771 Episode Num: 13418 Reward: -14.10225126309235 avg_loss_c: 37.95658831596374 avg_loss_a: -74.5740909576416
Número de pasos del episodio 13419 son episode_steps:41
Total Steps: 898812 Episode Num: 13419 Reward: -43.39407812696733 avg_loss_c: 38.96457830289515 avg_loss_a: -76.54846991562262
Número de pasos del episodio 13420 son episode_steps:84
Total Steps: 898896 Episode Num: 13420 Reward: 51.52867357596936 avg_loss_c: 39.205902917044504 avg_loss_a: -75.7130370367141
Número de pasos del episodio 13421 son episode_steps:144
Total Steps: 899040 Episode Num: 13421 Reward: 22.94021641120694 avg_loss_c: 40.15648816691505 avg_loss_a: -75.73637623257108
Número de pasos del episodio 13422 son episode_steps:47
Total Steps: 899087 Episode Num: 13422 Reward: -21.302357208058673 avg_loss_c: 36.63014233365972 avg_loss_a: -74.54773679692694
Número de pasos del episodio 13423 son episode_steps:223
Total Steps: 899310 Episode Num: 13423 Reward: 59.645373301174445 avg_loss_c: 39.644994504783185 avg_loss_a: -74.32579030263584
Número de pasos del episodio 13424 son episode_steps:49
Total Steps: 899359 Episode Num: 13424 Reward: -33.320456424315346 avg_loss_c: 36.43950598580496 avg_loss_a: -73.83049322634326
Número de pasos del episodio 13425 son episode_steps:31
Total Steps: 899390 Episode Num: 13425 Reward: -10.880510716247421 avg_loss_c: 37.741985628681796 avg_loss_a: -78.27751922607422
Número de pasos del episodio 13426 son episode_steps:30
Total Steps: 899420 Episode Num: 13426 Reward: -11.686330937617614 avg_loss_c: 38.02847906748454 avg_loss_a: -76.83780873616537
Número de pasos del episodio 13427 son episode_steps:104
Total Steps: 899524 Episode Num: 13427 Reward: 20.422323724414863 avg_loss_c: 40.774365608508774 avg_loss_a: -75.363129395705
Número de pasos del episodio 13428 son episode_steps:122
Total Steps: 899646 Episode Num: 13428 Reward: 14.00155536688527 avg_loss_c: 40.24145615687136 avg_loss_a: -75.22414986031954
Número de pasos del episodio 13429 son episode_steps:43
Total Steps: 899689 Episode Num: 13429 Reward: -8.614269017480389 avg_loss_c: 38.68382560375125 avg_loss_a: -76.01278881693996
Número de pasos del episodio 13430 son episode_steps:67
Total Steps: 899756 Episode Num: 13430 Reward: -35.26819403744159 avg_loss_c: 40.7744629418672 avg_loss_a: -75.1898221827265
Número de pasos del episodio 13431 son episode_steps:212
Total Steps: 899968 Episode Num: 13431 Reward: 130.18487033878412 avg_loss_c: 39.95015183034933 avg_loss_a: -75.86182763441553
Número de pasos del episodio 13432 son episode_steps:123
Total Steps: 900091 Episode Num: 13432 Reward: 47.03607710421078 avg_loss_c: 39.23408343927647 avg_loss_a: -75.84203499894801
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 112.883859
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13433 son episode_steps:213
Total Steps: 900304 Episode Num: 13433 Reward: 53.25204453706158 avg_loss_c: 38.94547893183892 avg_loss_a: -76.10799977477167
Número de pasos del episodio 13434 son episode_steps:125
Total Steps: 900429 Episode Num: 13434 Reward: 46.28502324181798 avg_loss_c: 38.77112017822266 avg_loss_a: -76.50675665283202
Número de pasos del episodio 13435 son episode_steps:181
Total Steps: 900610 Episode Num: 13435 Reward: 136.9391006723589 avg_loss_c: 38.03542144522483 avg_loss_a: -75.49647214267794
Número de pasos del episodio 13436 son episode_steps:314
Total Steps: 900924 Episode Num: 13436 Reward: 132.5021737932173 avg_loss_c: 37.73631062477258 avg_loss_a: -75.50073164435709
Número de pasos del episodio 13437 son episode_steps:119
Total Steps: 901043 Episode Num: 13437 Reward: 44.88103398795883 avg_loss_c: 36.59999453119871 avg_loss_a: -75.02609278574711
Número de pasos del episodio 13438 son episode_steps:92
Total Steps: 901135 Episode Num: 13438 Reward: -3.540831732346187 avg_loss_c: 36.82476406512053 avg_loss_a: -76.05691544905953
Número de pasos del episodio 13439 son episode_steps:82
Total Steps: 901217 Episode Num: 13439 Reward: -73.84546208402267 avg_loss_c: 36.55188867522449 avg_loss_a: -75.19116908747975
Número de pasos del episodio 13440 son episode_steps:136
Total Steps: 901353 Episode Num: 13440 Reward: 92.07836541849578 avg_loss_c: 36.66786738003002 avg_loss_a: -74.61779796375947
Número de pasos del episodio 13441 son episode_steps:73
Total Steps: 901426 Episode Num: 13441 Reward: 12.751709588359525 avg_loss_c: 36.002720662992296 avg_loss_a: -75.72029751294279
Número de pasos del episodio 13442 son episode_steps:24
Total Steps: 901450 Episode Num: 13442 Reward: -37.95235313513723 avg_loss_c: 34.831953366597496 avg_loss_a: -75.04848289489746
Número de pasos del episodio 13443 son episode_steps:128
Total Steps: 901578 Episode Num: 13443 Reward: -50.47299331994602 avg_loss_c: 39.30094675719738 avg_loss_a: -74.21286308765411
Número de pasos del episodio 13444 son episode_steps:89
Total Steps: 901667 Episode Num: 13444 Reward: -16.045047871275198 avg_loss_c: 38.51955968878242 avg_loss_a: -74.52647279889396
Número de pasos del episodio 13445 son episode_steps:114
Total Steps: 901781 Episode Num: 13445 Reward: -92.14006729554372 avg_loss_c: 38.23580221544232 avg_loss_a: -75.53571794744124
Número de pasos del episodio 13446 son episode_steps:129
Total Steps: 901910 Episode Num: 13446 Reward: 32.42395463225457 avg_loss_c: 39.56185259560282 avg_loss_a: -75.35609087093856
Número de pasos del episodio 13447 son episode_steps:69
Total Steps: 901979 Episode Num: 13447 Reward: -22.79043695177341 avg_loss_c: 38.102340753527656 avg_loss_a: -72.88245093304178
Número de pasos del episodio 13448 son episode_steps:144
Total Steps: 902123 Episode Num: 13448 Reward: 2.7328336465252976 avg_loss_c: 39.60578205850389 avg_loss_a: -74.06770896911621
Número de pasos del episodio 13449 son episode_steps:125
Total Steps: 902248 Episode Num: 13449 Reward: 45.787736300352854 avg_loss_c: 38.746998901367185 avg_loss_a: -75.11499285888672
Número de pasos del episodio 13450 son episode_steps:82
Total Steps: 902330 Episode Num: 13450 Reward: 48.72887479888873 avg_loss_c: 37.07365538434284 avg_loss_a: -74.53725042575743
Número de pasos del episodio 13451 son episode_steps:73
Total Steps: 902403 Episode Num: 13451 Reward: -8.275866720935696 avg_loss_c: 38.74698152934035 avg_loss_a: -75.75430590485874
Número de pasos del episodio 13452 son episode_steps:62
Total Steps: 902465 Episode Num: 13452 Reward: 16.439457231024182 avg_loss_c: 38.87533353990124 avg_loss_a: -76.3095439787834
Número de pasos del episodio 13453 son episode_steps:125
Total Steps: 902590 Episode Num: 13453 Reward: 70.340628899207 avg_loss_c: 38.75198377990723 avg_loss_a: -75.57239141845703
Número de pasos del episodio 13454 son episode_steps:54
Total Steps: 902644 Episode Num: 13454 Reward: 0.9436111994771728 avg_loss_c: 37.88623113985415 avg_loss_a: -76.72826102927878
Número de pasos del episodio 13455 son episode_steps:195
Total Steps: 902839 Episode Num: 13455 Reward: 116.19156814356406 avg_loss_c: 38.65390984950921 avg_loss_a: -75.02894095396384
Número de pasos del episodio 13456 son episode_steps:36
Total Steps: 902875 Episode Num: 13456 Reward: -8.72740659672234 avg_loss_c: 38.06878572040134 avg_loss_a: -75.84817843967014
Número de pasos del episodio 13457 son episode_steps:151
Total Steps: 903026 Episode Num: 13457 Reward: 10.305599803209187 avg_loss_c: 38.9876985865713 avg_loss_a: -75.41624854889926
Número de pasos del episodio 13458 son episode_steps:215
Total Steps: 903241 Episode Num: 13458 Reward: -1.7846036351458414 avg_loss_c: 39.01474135642828 avg_loss_a: -75.71882370349972
Número de pasos del episodio 13459 son episode_steps:22
Total Steps: 903263 Episode Num: 13459 Reward: -26.27204316453933 avg_loss_c: 38.807106885043055 avg_loss_a: -76.36269517378373
Número de pasos del episodio 13460 son episode_steps:109
Total Steps: 903372 Episode Num: 13460 Reward: 34.84578982610992 avg_loss_c: 39.145810800954834 avg_loss_a: -75.54768266590364
Número de pasos del episodio 13461 son episode_steps:181
Total Steps: 903553 Episode Num: 13461 Reward: 74.73411341929028 avg_loss_c: 38.01125448448223 avg_loss_a: -76.27216381262679
Número de pasos del episodio 13462 son episode_steps:109
Total Steps: 903662 Episode Num: 13462 Reward: -25.735578513235794 avg_loss_c: 38.5457062852492 avg_loss_a: -76.1071424571746
Número de pasos del episodio 13463 son episode_steps:161
Total Steps: 903823 Episode Num: 13463 Reward: 34.558899197348815 avg_loss_c: 38.43468268021293 avg_loss_a: -75.98653246008831
Número de pasos del episodio 13464 son episode_steps:112
Total Steps: 903935 Episode Num: 13464 Reward: -17.119684065395887 avg_loss_c: 38.68847862311772 avg_loss_a: -75.57447569710868
Número de pasos del episodio 13465 son episode_steps:112
Total Steps: 904047 Episode Num: 13465 Reward: 60.5845205905288 avg_loss_c: 38.93725609779358 avg_loss_a: -75.29822662898472
Número de pasos del episodio 13466 son episode_steps:88
Total Steps: 904135 Episode Num: 13466 Reward: -35.81430587336166 avg_loss_c: 39.56558043306524 avg_loss_a: -76.22518678144975
Número de pasos del episodio 13467 son episode_steps:188
Total Steps: 904323 Episode Num: 13467 Reward: 141.5056023223411 avg_loss_c: 38.59479248777349 avg_loss_a: -75.58044360546356
Número de pasos del episodio 13468 son episode_steps:104
Total Steps: 904427 Episode Num: 13468 Reward: -44.750583294808976 avg_loss_c: 38.9819821027609 avg_loss_a: -75.06626451932468
Número de pasos del episodio 13469 son episode_steps:191
Total Steps: 904618 Episode Num: 13469 Reward: 142.62143139928776 avg_loss_c: 38.44932604085712 avg_loss_a: -75.70666032561456
Número de pasos del episodio 13470 son episode_steps:172
Total Steps: 904790 Episode Num: 13470 Reward: 114.60527216845054 avg_loss_c: 36.348784646322564 avg_loss_a: -75.97364177260287
Número de pasos del episodio 13471 son episode_steps:35
Total Steps: 904825 Episode Num: 13471 Reward: -45.59852806425114 avg_loss_c: 37.390097045898436 avg_loss_a: -75.76370391845703
Número de pasos del episodio 13472 son episode_steps:129
Total Steps: 904954 Episode Num: 13472 Reward: 55.76816629904647 avg_loss_c: 37.08936438449594 avg_loss_a: -76.08347149043121
Número de pasos del episodio 13473 son episode_steps:233
Total Steps: 905187 Episode Num: 13473 Reward: 168.765231826614 avg_loss_c: 37.179792944453816 avg_loss_a: -76.72406490473277
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 64.854386
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13474 son episode_steps:174
Total Steps: 905361 Episode Num: 13474 Reward: 80.22751598498824 avg_loss_c: 36.139776931411916 avg_loss_a: -75.722873161579
Número de pasos del episodio 13475 son episode_steps:80
Total Steps: 905441 Episode Num: 13475 Reward: -48.949363330022116 avg_loss_c: 36.5992954492569 avg_loss_a: -76.19208431243896
Número de pasos del episodio 13476 son episode_steps:72
Total Steps: 905513 Episode Num: 13476 Reward: 38.15714755590982 avg_loss_c: 35.695639557308624 avg_loss_a: -75.89987161424425
Número de pasos del episodio 13477 son episode_steps:133
Total Steps: 905646 Episode Num: 13477 Reward: 97.96502116522981 avg_loss_c: 36.409938640164256 avg_loss_a: -76.59623741207267
Número de pasos del episodio 13478 son episode_steps:64
Total Steps: 905710 Episode Num: 13478 Reward: -37.97537935124472 avg_loss_c: 37.678620874881744 avg_loss_a: -75.80819034576416
Número de pasos del episodio 13479 son episode_steps:129
Total Steps: 905839 Episode Num: 13479 Reward: 34.950452872339 avg_loss_c: 36.33091048307197 avg_loss_a: -76.18102607431338
Número de pasos del episodio 13480 son episode_steps:46
Total Steps: 905885 Episode Num: 13480 Reward: -52.932788703028066 avg_loss_c: 35.62214461616848 avg_loss_a: -76.39104992410411
Número de pasos del episodio 13481 son episode_steps:160
Total Steps: 906045 Episode Num: 13481 Reward: 66.47016165996097 avg_loss_c: 36.649268460273746 avg_loss_a: -76.17887907028198
Número de pasos del episodio 13482 son episode_steps:173
Total Steps: 906218 Episode Num: 13482 Reward: -1.2234293055734877 avg_loss_c: 36.34024907812218 avg_loss_a: -76.18367396889394
Número de pasos del episodio 13483 son episode_steps:114
Total Steps: 906332 Episode Num: 13483 Reward: -9.70073697914152 avg_loss_c: 35.66616766076339 avg_loss_a: -76.31579201681572
Número de pasos del episodio 13484 son episode_steps:218
Total Steps: 906550 Episode Num: 13484 Reward: 181.84033568319697 avg_loss_c: 36.28868106527066 avg_loss_a: -77.10079795067463
Número de pasos del episodio 13485 son episode_steps:56
Total Steps: 906606 Episode Num: 13485 Reward: -42.2576154320647 avg_loss_c: 36.937370913369314 avg_loss_a: -75.94062914167132
Número de pasos del episodio 13486 son episode_steps:142
Total Steps: 906748 Episode Num: 13486 Reward: 95.54669796885851 avg_loss_c: 35.570788746148764 avg_loss_a: -77.0866743275817
Número de pasos del episodio 13487 son episode_steps:56
Total Steps: 906804 Episode Num: 13487 Reward: -28.278895335015577 avg_loss_c: 34.985877411706106 avg_loss_a: -75.85051155090332
Número de pasos del episodio 13488 son episode_steps:75
Total Steps: 906879 Episode Num: 13488 Reward: 5.681143949133445 avg_loss_c: 37.59842213948568 avg_loss_a: -76.30814422607422
Número de pasos del episodio 13489 son episode_steps:44
Total Steps: 906923 Episode Num: 13489 Reward: -41.84584782129128 avg_loss_c: 36.56513595581055 avg_loss_a: -76.67319453846325
Número de pasos del episodio 13490 son episode_steps:139
Total Steps: 907062 Episode Num: 13490 Reward: 68.94807674763939 avg_loss_c: 36.379554185935916 avg_loss_a: -75.81570193064299
Número de pasos del episodio 13491 son episode_steps:118
Total Steps: 907180 Episode Num: 13491 Reward: -0.36154447208649465 avg_loss_c: 37.04860837580794 avg_loss_a: -77.46197936494471
Número de pasos del episodio 13492 son episode_steps:127
Total Steps: 907307 Episode Num: 13492 Reward: 81.44654615451742 avg_loss_c: 37.43358801293561 avg_loss_a: -77.12749319001446
Número de pasos del episodio 13493 son episode_steps:72
Total Steps: 907379 Episode Num: 13493 Reward: 46.174395379791 avg_loss_c: 35.92585518625047 avg_loss_a: -77.65457725524902
Número de pasos del episodio 13494 son episode_steps:140
Total Steps: 907519 Episode Num: 13494 Reward: 71.00251705765139 avg_loss_c: 36.22893104553223 avg_loss_a: -77.79528950282506
Número de pasos del episodio 13495 son episode_steps:203
Total Steps: 907722 Episode Num: 13495 Reward: 121.06365392564983 avg_loss_c: 34.88081034768391 avg_loss_a: -77.21295102124144
Número de pasos del episodio 13496 son episode_steps:95
Total Steps: 907817 Episode Num: 13496 Reward: 9.290653936581624 avg_loss_c: 33.93793493572034 avg_loss_a: -77.15685280247739
Número de pasos del episodio 13497 son episode_steps:139
Total Steps: 907956 Episode Num: 13497 Reward: 82.36366542096654 avg_loss_c: 33.363973891992366 avg_loss_a: -77.62410911724722
Número de pasos del episodio 13498 son episode_steps:157
Total Steps: 908113 Episode Num: 13498 Reward: 137.51093098268893 avg_loss_c: 34.38632411106377 avg_loss_a: -76.9768045510456
Número de pasos del episodio 13499 son episode_steps:54
Total Steps: 908167 Episode Num: 13499 Reward: 0.6522673680968598 avg_loss_c: 33.6790973522045 avg_loss_a: -77.55219466597946
Número de pasos del episodio 13500 son episode_steps:142
Total Steps: 908309 Episode Num: 13500 Reward: 90.69546687153746 avg_loss_c: 33.92790756762867 avg_loss_a: -77.65104772003603
Número de pasos del episodio 13501 son episode_steps:137
Total Steps: 908446 Episode Num: 13501 Reward: -13.881506211574797 avg_loss_c: 34.58662333801715 avg_loss_a: -77.74321512932325
Número de pasos del episodio 13502 son episode_steps:65
Total Steps: 908511 Episode Num: 13502 Reward: -38.68842924950577 avg_loss_c: 34.88670812753531 avg_loss_a: -77.98821528508113
Número de pasos del episodio 13503 son episode_steps:152
Total Steps: 908663 Episode Num: 13503 Reward: 62.81238409508813 avg_loss_c: 33.7003000535463 avg_loss_a: -78.17850745351691
Número de pasos del episodio 13504 son episode_steps:239
Total Steps: 908902 Episode Num: 13504 Reward: 127.94623766684032 avg_loss_c: 33.62150910509181 avg_loss_a: -77.69493010453101
Número de pasos del episodio 13505 son episode_steps:62
Total Steps: 908964 Episode Num: 13505 Reward: 28.2696831161769 avg_loss_c: 34.09133864987281 avg_loss_a: -76.18856565413937
Número de pasos del episodio 13506 son episode_steps:64
Total Steps: 909028 Episode Num: 13506 Reward: 10.760712292291142 avg_loss_c: 32.65463000535965 avg_loss_a: -77.3632583618164
Número de pasos del episodio 13507 son episode_steps:157
Total Steps: 909185 Episode Num: 13507 Reward: 90.4582907460291 avg_loss_c: 33.37059513019149 avg_loss_a: -78.24676644878024
Número de pasos del episodio 13508 son episode_steps:96
Total Steps: 909281 Episode Num: 13508 Reward: 37.267310885196665 avg_loss_c: 33.36368147532145 avg_loss_a: -77.69090684254964
Número de pasos del episodio 13509 son episode_steps:84
Total Steps: 909365 Episode Num: 13509 Reward: 9.907280131246106 avg_loss_c: 33.07575586863926 avg_loss_a: -77.10178829374767
Número de pasos del episodio 13510 son episode_steps:86
Total Steps: 909451 Episode Num: 13510 Reward: 20.079813252936322 avg_loss_c: 32.1960773911587 avg_loss_a: -77.96633644991142
Número de pasos del episodio 13511 son episode_steps:110
Total Steps: 909561 Episode Num: 13511 Reward: 53.61914236867261 avg_loss_c: 33.02596383528276 avg_loss_a: -78.35075947154652
Número de pasos del episodio 13512 son episode_steps:106
Total Steps: 909667 Episode Num: 13512 Reward: -22.64073632036651 avg_loss_c: 32.37301077932682 avg_loss_a: -77.95294650095813
Número de pasos del episodio 13513 son episode_steps:152
Total Steps: 909819 Episode Num: 13513 Reward: 101.91963601253289 avg_loss_c: 34.07383956407246 avg_loss_a: -77.48217211271587
Número de pasos del episodio 13514 son episode_steps:129
Total Steps: 909948 Episode Num: 13514 Reward: 30.351544288021753 avg_loss_c: 33.81110901056334 avg_loss_a: -77.76925416695055
Número de pasos del episodio 13515 son episode_steps:31
Total Steps: 909979 Episode Num: 13515 Reward: -38.6937824232114 avg_loss_c: 33.3952818224507 avg_loss_a: -77.93063625212639
Número de pasos del episodio 13516 son episode_steps:122
Total Steps: 910101 Episode Num: 13516 Reward: 29.229473860388783 avg_loss_c: 33.583359124230554 avg_loss_a: -77.92691790471312
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 169.730206
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13517 son episode_steps:47
Total Steps: 910148 Episode Num: 13517 Reward: -54.8283002870533 avg_loss_c: 36.04863783653746 avg_loss_a: -78.84766956085855
Número de pasos del episodio 13518 son episode_steps:39
Total Steps: 910187 Episode Num: 13518 Reward: -2.436354129215767 avg_loss_c: 32.97785582909217 avg_loss_a: -78.03443517440405
Número de pasos del episodio 13519 son episode_steps:74
Total Steps: 910261 Episode Num: 13519 Reward: 10.91085012357197 avg_loss_c: 33.948391914367676 avg_loss_a: -78.51987787195154
Número de pasos del episodio 13520 son episode_steps:89
Total Steps: 910350 Episode Num: 13520 Reward: 49.48197395723275 avg_loss_c: 34.7699842988775 avg_loss_a: -78.38198235329617
Número de pasos del episodio 13521 son episode_steps:27
Total Steps: 910377 Episode Num: 13521 Reward: -51.05572625255785 avg_loss_c: 32.955434022126376 avg_loss_a: -77.78169307002315
Número de pasos del episodio 13522 son episode_steps:183
Total Steps: 910560 Episode Num: 13522 Reward: 101.89157695172126 avg_loss_c: 33.16657448857208 avg_loss_a: -77.41534769860773
Número de pasos del episodio 13523 son episode_steps:74
Total Steps: 910634 Episode Num: 13523 Reward: -89.04788340326087 avg_loss_c: 34.68579885121938 avg_loss_a: -77.36132276380384
Número de pasos del episodio 13524 son episode_steps:49
Total Steps: 910683 Episode Num: 13524 Reward: -9.910241805423219 avg_loss_c: 32.40038836732202 avg_loss_a: -77.62990227524115
Número de pasos del episodio 13525 son episode_steps:138
Total Steps: 910821 Episode Num: 13525 Reward: -69.03109331819576 avg_loss_c: 34.57320263074792 avg_loss_a: -77.3412718841995
Número de pasos del episodio 13526 son episode_steps:179
Total Steps: 911000 Episode Num: 13526 Reward: 48.27576814905947 avg_loss_c: 33.517063215458194 avg_loss_a: -78.26125135368476
Número de pasos del episodio 13527 son episode_steps:132
Total Steps: 911132 Episode Num: 13527 Reward: 55.145483744432234 avg_loss_c: 33.98647038141886 avg_loss_a: -79.29036955399947
Número de pasos del episodio 13528 son episode_steps:68
Total Steps: 911200 Episode Num: 13528 Reward: 21.152452628620942 avg_loss_c: 32.1879508635577 avg_loss_a: -77.61879169239717
Número de pasos del episodio 13529 son episode_steps:33
Total Steps: 911233 Episode Num: 13529 Reward: -4.958066116752473 avg_loss_c: 33.15809550429835 avg_loss_a: -77.91674203583689
Número de pasos del episodio 13530 son episode_steps:113
Total Steps: 911346 Episode Num: 13530 Reward: 45.5295009346513 avg_loss_c: 34.16701988625316 avg_loss_a: -78.08553901604847
Número de pasos del episodio 13531 son episode_steps:141
Total Steps: 911487 Episode Num: 13531 Reward: 56.572935964237786 avg_loss_c: 33.576954253176424 avg_loss_a: -77.81867683356535
Número de pasos del episodio 13532 son episode_steps:118
Total Steps: 911605 Episode Num: 13532 Reward: 71.34472672696354 avg_loss_c: 33.66023791038384 avg_loss_a: -78.67480843754139
Número de pasos del episodio 13533 son episode_steps:162
Total Steps: 911767 Episode Num: 13533 Reward: 102.12246505902382 avg_loss_c: 31.55866512251489 avg_loss_a: -78.40859128222053
Número de pasos del episodio 13534 son episode_steps:140
Total Steps: 911907 Episode Num: 13534 Reward: 71.99564987578651 avg_loss_c: 31.910896750858853 avg_loss_a: -78.40978022984096
Número de pasos del episodio 13535 son episode_steps:270
Total Steps: 912177 Episode Num: 13535 Reward: 94.597632264473 avg_loss_c: 32.267822074890134 avg_loss_a: -77.9107272112811
Número de pasos del episodio 13536 son episode_steps:53
Total Steps: 912230 Episode Num: 13536 Reward: -32.63596661419986 avg_loss_c: 32.08197500120919 avg_loss_a: -78.3038484105524
Número de pasos del episodio 13537 son episode_steps:182
Total Steps: 912412 Episode Num: 13537 Reward: 111.4940637988757 avg_loss_c: 32.402044684022336 avg_loss_a: -77.58341393103966
Número de pasos del episodio 13538 son episode_steps:110
Total Steps: 912522 Episode Num: 13538 Reward: 57.27688883783765 avg_loss_c: 31.794494507529517 avg_loss_a: -78.43523878617721
Número de pasos del episodio 13539 son episode_steps:53
Total Steps: 912575 Episode Num: 13539 Reward: -5.475397208985212 avg_loss_c: 32.40967099171765 avg_loss_a: -78.87957274239018
Número de pasos del episodio 13540 son episode_steps:39
Total Steps: 912614 Episode Num: 13540 Reward: -35.89304285753236 avg_loss_c: 33.1373778123122 avg_loss_a: -78.04974834735577
Número de pasos del episodio 13541 son episode_steps:94
Total Steps: 912708 Episode Num: 13541 Reward: 14.22287089815678 avg_loss_c: 32.041691739508444 avg_loss_a: -78.0738702327647
Número de pasos del episodio 13542 son episode_steps:54
Total Steps: 912762 Episode Num: 13542 Reward: -47.64556082251341 avg_loss_c: 33.56986148269088 avg_loss_a: -77.7618495799877
Número de pasos del episodio 13543 son episode_steps:34
Total Steps: 912796 Episode Num: 13543 Reward: -6.028125580562199 avg_loss_c: 32.53094695596134 avg_loss_a: -79.64077983183019
Número de pasos del episodio 13544 son episode_steps:73
Total Steps: 912869 Episode Num: 13544 Reward: 41.76929601996719 avg_loss_c: 34.44385447567456 avg_loss_a: -77.01696934112131
Número de pasos del episodio 13545 son episode_steps:25
Total Steps: 912894 Episode Num: 13545 Reward: -31.85756895614769 avg_loss_c: 35.30805809020996 avg_loss_a: -78.30044830322265
Número de pasos del episodio 13546 son episode_steps:154
Total Steps: 913048 Episode Num: 13546 Reward: 90.92126934509753 avg_loss_c: 32.102213537538205 avg_loss_a: -78.68961383770039
Número de pasos del episodio 13547 son episode_steps:58
Total Steps: 913106 Episode Num: 13547 Reward: -41.38304415110184 avg_loss_c: 34.172620049838365 avg_loss_a: -78.68783174712082
Número de pasos del episodio 13548 son episode_steps:125
Total Steps: 913231 Episode Num: 13548 Reward: 54.22505081386261 avg_loss_c: 32.56182572937012 avg_loss_a: -78.53543737792968
Número de pasos del episodio 13549 son episode_steps:62
Total Steps: 913293 Episode Num: 13549 Reward: -44.11969969473489 avg_loss_c: 32.58840348643641 avg_loss_a: -79.47321147303427
Número de pasos del episodio 13550 son episode_steps:107
Total Steps: 913400 Episode Num: 13550 Reward: 27.123879096194997 avg_loss_c: 32.750796594352366 avg_loss_a: -78.51698745299723
Número de pasos del episodio 13551 son episode_steps:95
Total Steps: 913495 Episode Num: 13551 Reward: 23.064165661391595 avg_loss_c: 32.593079697458364 avg_loss_a: -77.51205532676295
Número de pasos del episodio 13552 son episode_steps:222
Total Steps: 913717 Episode Num: 13552 Reward: 155.42017956197043 avg_loss_c: 32.390825134139874 avg_loss_a: -78.48689221906233
Número de pasos del episodio 13553 son episode_steps:91
Total Steps: 913808 Episode Num: 13553 Reward: 38.98586633006573 avg_loss_c: 32.860040496993854 avg_loss_a: -79.00409346360426
Número de pasos del episodio 13554 son episode_steps:62
Total Steps: 913870 Episode Num: 13554 Reward: 15.559434713169946 avg_loss_c: 32.14898374003749 avg_loss_a: -78.4429439421623
Número de pasos del episodio 13555 son episode_steps:130
Total Steps: 914000 Episode Num: 13555 Reward: 72.73153583144422 avg_loss_c: 32.02040418478159 avg_loss_a: -78.1319337111253
Número de pasos del episodio 13556 son episode_steps:134
Total Steps: 914134 Episode Num: 13556 Reward: 61.73743566882789 avg_loss_c: 32.84268541478399 avg_loss_a: -77.53654058655697
Número de pasos del episodio 13557 son episode_steps:104
Total Steps: 914238 Episode Num: 13557 Reward: -3.724738851827665 avg_loss_c: 32.4196522969466 avg_loss_a: -78.18061799269456
Número de pasos del episodio 13558 son episode_steps:95
Total Steps: 914333 Episode Num: 13558 Reward: 53.89169379122574 avg_loss_c: 31.4422226152922 avg_loss_a: -78.90145930240028
Número de pasos del episodio 13559 son episode_steps:98
Total Steps: 914431 Episode Num: 13559 Reward: 7.843303598527566 avg_loss_c: 32.76617445264544 avg_loss_a: -77.50170976288464
Número de pasos del episodio 13560 son episode_steps:163
Total Steps: 914594 Episode Num: 13560 Reward: 106.32525430405491 avg_loss_c: 33.30162982121567 avg_loss_a: -78.17722999245112
Número de pasos del episodio 13561 son episode_steps:83
Total Steps: 914677 Episode Num: 13561 Reward: -1.4486876215338689 avg_loss_c: 31.80553064001612 avg_loss_a: -78.668529280697
Número de pasos del episodio 13562 son episode_steps:72
Total Steps: 914749 Episode Num: 13562 Reward: 17.754943622850885 avg_loss_c: 30.996924850675796 avg_loss_a: -79.1171743604872
Número de pasos del episodio 13563 son episode_steps:37
Total Steps: 914786 Episode Num: 13563 Reward: -50.70677193591 avg_loss_c: 33.18058673755543 avg_loss_a: -78.40795692237648
Número de pasos del episodio 13564 son episode_steps:25
Total Steps: 914811 Episode Num: 13564 Reward: -38.40187365427736 avg_loss_c: 31.84151580810547 avg_loss_a: -79.4474819946289
Número de pasos del episodio 13565 son episode_steps:88
Total Steps: 914899 Episode Num: 13565 Reward: -13.675740718616067 avg_loss_c: 32.83787233179266 avg_loss_a: -77.40592540394177
Número de pasos del episodio 13566 son episode_steps:158
Total Steps: 915057 Episode Num: 13566 Reward: 109.70596286943254 avg_loss_c: 32.92735331571555 avg_loss_a: -78.08010893230197
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 67.556802
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13567 son episode_steps:90
Total Steps: 915147 Episode Num: 13567 Reward: -15.438677850465293 avg_loss_c: 32.132635815938315 avg_loss_a: -78.13192121717665
Número de pasos del episodio 13568 son episode_steps:149
Total Steps: 915296 Episode Num: 13568 Reward: 108.5385125125335 avg_loss_c: 33.43622481582949 avg_loss_a: -78.77245428098128
Número de pasos del episodio 13569 son episode_steps:209
Total Steps: 915505 Episode Num: 13569 Reward: 166.43374920989393 avg_loss_c: 32.42558443717409 avg_loss_a: -79.22342316841966
Número de pasos del episodio 13570 son episode_steps:76
Total Steps: 915581 Episode Num: 13570 Reward: 36.14822036162243 avg_loss_c: 32.03744890815333 avg_loss_a: -79.26494277151008
Número de pasos del episodio 13571 son episode_steps:94
Total Steps: 915675 Episode Num: 13571 Reward: 20.69335840576849 avg_loss_c: 31.952872093687667 avg_loss_a: -77.57956435832571
Número de pasos del episodio 13572 son episode_steps:46
Total Steps: 915721 Episode Num: 13572 Reward: -7.997443975552856 avg_loss_c: 32.14913036512292 avg_loss_a: -78.20977982230808
Número de pasos del episodio 13573 son episode_steps:36
Total Steps: 915757 Episode Num: 13573 Reward: -13.096977204936039 avg_loss_c: 31.53155755996704 avg_loss_a: -77.91349199083116
Número de pasos del episodio 13574 son episode_steps:117
Total Steps: 915874 Episode Num: 13574 Reward: 5.826611480141225 avg_loss_c: 32.810676591009155 avg_loss_a: -77.74774515526926
Número de pasos del episodio 13575 son episode_steps:258
Total Steps: 916132 Episode Num: 13575 Reward: 157.2686916302365 avg_loss_c: 32.802926181822784 avg_loss_a: -78.39771406779917
Número de pasos del episodio 13576 son episode_steps:134
Total Steps: 916266 Episode Num: 13576 Reward: -58.98708490653142 avg_loss_c: 33.066420668986304 avg_loss_a: -78.62358389327775
Número de pasos del episodio 13577 son episode_steps:58
Total Steps: 916324 Episode Num: 13577 Reward: 17.615736385998822 avg_loss_c: 31.6332667449425 avg_loss_a: -77.38763717125202
Número de pasos del episodio 13578 son episode_steps:152
Total Steps: 916476 Episode Num: 13578 Reward: 69.93811495363931 avg_loss_c: 32.77699086540624 avg_loss_a: -77.95737617894223
Número de pasos del episodio 13579 son episode_steps:20
Total Steps: 916496 Episode Num: 13579 Reward: -59.90791287005846 avg_loss_c: 33.03785829544067 avg_loss_a: -78.59485321044922
Número de pasos del episodio 13580 son episode_steps:50
Total Steps: 916546 Episode Num: 13580 Reward: -30.644148844680117 avg_loss_c: 32.94348140716553 avg_loss_a: -77.53467010498046
Número de pasos del episodio 13581 son episode_steps:26
Total Steps: 916572 Episode Num: 13581 Reward: -15.522460550407716 avg_loss_c: 33.78620521838848 avg_loss_a: -75.32722003643329
Número de pasos del episodio 13582 son episode_steps:49
Total Steps: 916621 Episode Num: 13582 Reward: -44.583501730106825 avg_loss_c: 34.709532212237924 avg_loss_a: -76.52660681276905
Número de pasos del episodio 13583 son episode_steps:97
Total Steps: 916718 Episode Num: 13583 Reward: -3.67963458825343 avg_loss_c: 33.437627025486265 avg_loss_a: -76.41325063803761
Número de pasos del episodio 13584 son episode_steps:47
Total Steps: 916765 Episode Num: 13584 Reward: 4.188468723370441 avg_loss_c: 31.873131934632646 avg_loss_a: -76.5686861403445
Número de pasos del episodio 13585 son episode_steps:251
Total Steps: 917016 Episode Num: 13585 Reward: 132.77902238473806 avg_loss_c: 34.60943159734111 avg_loss_a: -77.00514443082163
Número de pasos del episodio 13586 son episode_steps:283
Total Steps: 917299 Episode Num: 13586 Reward: 234.98897255505435 avg_loss_c: 32.55824045241932 avg_loss_a: -77.5688337454105
Número de pasos del episodio 13587 son episode_steps:213
Total Steps: 917512 Episode Num: 13587 Reward: 141.6804400696747 avg_loss_c: 33.103682468754585 avg_loss_a: -77.09961646711322
Número de pasos del episodio 13588 son episode_steps:268
Total Steps: 917780 Episode Num: 13588 Reward: 119.33191060792282 avg_loss_c: 32.045760503455774 avg_loss_a: -77.78209469923333
Número de pasos del episodio 13589 son episode_steps:79
Total Steps: 917859 Episode Num: 13589 Reward: 35.46201005436839 avg_loss_c: 32.64482546456252 avg_loss_a: -78.64345666426647
Número de pasos del episodio 13590 son episode_steps:120
Total Steps: 917979 Episode Num: 13590 Reward: 84.3555062244502 avg_loss_c: 32.48528291384379 avg_loss_a: -78.24667587280274
Número de pasos del episodio 13591 son episode_steps:168
Total Steps: 918147 Episode Num: 13591 Reward: 82.02385981823284 avg_loss_c: 31.161478553499496 avg_loss_a: -77.27512586684455
Número de pasos del episodio 13592 son episode_steps:60
Total Steps: 918207 Episode Num: 13592 Reward: -8.16639153591996 avg_loss_c: 31.79559055964152 avg_loss_a: -75.16556065877279
Número de pasos del episodio 13593 son episode_steps:49
Total Steps: 918256 Episode Num: 13593 Reward: 1.2252852348784402 avg_loss_c: 32.53256618733309 avg_loss_a: -77.23357126664142
Número de pasos del episodio 13594 son episode_steps:205
Total Steps: 918461 Episode Num: 13594 Reward: 126.39955585469816 avg_loss_c: 31.836425409084413 avg_loss_a: -76.41822867044588
Número de pasos del episodio 13595 son episode_steps:82
Total Steps: 918543 Episode Num: 13595 Reward: 4.224102343923866 avg_loss_c: 31.88301433004984 avg_loss_a: -76.96408639303068
Número de pasos del episodio 13596 son episode_steps:62
Total Steps: 918605 Episode Num: 13596 Reward: -12.172223826044327 avg_loss_c: 30.491106340962073 avg_loss_a: -76.36962521460748
Número de pasos del episodio 13597 son episode_steps:79
Total Steps: 918684 Episode Num: 13597 Reward: -67.0038588197601 avg_loss_c: 31.49205644824837 avg_loss_a: -77.2534105325047
Número de pasos del episodio 13598 son episode_steps:115
Total Steps: 918799 Episode Num: 13598 Reward: 69.77658993423655 avg_loss_c: 30.43636358509893 avg_loss_a: -77.55208315641984
Número de pasos del episodio 13599 son episode_steps:38
Total Steps: 918837 Episode Num: 13599 Reward: -41.627065144727766 avg_loss_c: 32.15705324474134 avg_loss_a: -76.06721416272615
Número de pasos del episodio 13600 son episode_steps:84
Total Steps: 918921 Episode Num: 13600 Reward: 5.887551295747892 avg_loss_c: 30.82162500563122 avg_loss_a: -76.7955057053339
Número de pasos del episodio 13601 son episode_steps:136
Total Steps: 919057 Episode Num: 13601 Reward: 71.8441231234616 avg_loss_c: 31.520137702717502 avg_loss_a: -76.72501990374397
Número de pasos del episodio 13602 son episode_steps:96
Total Steps: 919153 Episode Num: 13602 Reward: 50.86184058892907 avg_loss_c: 31.20046430826187 avg_loss_a: -77.9188601175944
Número de pasos del episodio 13603 son episode_steps:44
Total Steps: 919197 Episode Num: 13603 Reward: -27.907433768821054 avg_loss_c: 33.0272291356867 avg_loss_a: -76.52110047773881
Número de pasos del episodio 13604 son episode_steps:32
Total Steps: 919229 Episode Num: 13604 Reward: -52.23035425097587 avg_loss_c: 30.096328020095825 avg_loss_a: -75.98101472854614
Número de pasos del episodio 13605 son episode_steps:47
Total Steps: 919276 Episode Num: 13605 Reward: -70.83793085082581 avg_loss_c: 31.300899221542032 avg_loss_a: -76.94662085999833
Número de pasos del episodio 13606 son episode_steps:283
Total Steps: 919559 Episode Num: 13606 Reward: 147.32065929493027 avg_loss_c: 31.489381298159543 avg_loss_a: -77.41526945403945
Número de pasos del episodio 13607 son episode_steps:99
Total Steps: 919658 Episode Num: 13607 Reward: -42.24949810234917 avg_loss_c: 32.01903928891577 avg_loss_a: -77.69233903981218
Número de pasos del episodio 13608 son episode_steps:74
Total Steps: 919732 Episode Num: 13608 Reward: -16.24280710631627 avg_loss_c: 32.02319673589758 avg_loss_a: -77.64275813747096
Número de pasos del episodio 13609 son episode_steps:45
Total Steps: 919777 Episode Num: 13609 Reward: -45.226282424595446 avg_loss_c: 30.327148395114474 avg_loss_a: -76.43328569200304
Número de pasos del episodio 13610 son episode_steps:154
Total Steps: 919931 Episode Num: 13610 Reward: 138.11638748789355 avg_loss_c: 31.287164601412687 avg_loss_a: -76.61689401601816
Número de pasos del episodio 13611 son episode_steps:105
Total Steps: 920036 Episode Num: 13611 Reward: -0.8049693455249338 avg_loss_c: 31.58608738127209 avg_loss_a: -76.74261460077194
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 107.466453
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13612 son episode_steps:56
Total Steps: 920092 Episode Num: 13612 Reward: -49.788101851329955 avg_loss_c: 31.84339121409825 avg_loss_a: -76.30118261064801
Número de pasos del episodio 13613 son episode_steps:67
Total Steps: 920159 Episode Num: 13613 Reward: -71.73281298594331 avg_loss_c: 31.42789191630349 avg_loss_a: -76.22689420785477
Número de pasos del episodio 13614 son episode_steps:39
Total Steps: 920198 Episode Num: 13614 Reward: -37.45761222785907 avg_loss_c: 32.91950352986654 avg_loss_a: -76.95704611753806
Número de pasos del episodio 13615 son episode_steps:63
Total Steps: 920261 Episode Num: 13615 Reward: -38.647737294413304 avg_loss_c: 35.842294571891664 avg_loss_a: -77.92117067367312
Número de pasos del episodio 13616 son episode_steps:31
Total Steps: 920292 Episode Num: 13616 Reward: -24.19279154440454 avg_loss_c: 33.25127386277722 avg_loss_a: -78.22108557916457
Número de pasos del episodio 13617 son episode_steps:38
Total Steps: 920330 Episode Num: 13617 Reward: -41.945642826987545 avg_loss_c: 34.102991806833366 avg_loss_a: -76.90839225367496
Número de pasos del episodio 13618 son episode_steps:50
Total Steps: 920380 Episode Num: 13618 Reward: -42.451720710598295 avg_loss_c: 32.54073802947998 avg_loss_a: -75.43075256347656
Número de pasos del episodio 13619 son episode_steps:165
Total Steps: 920545 Episode Num: 13619 Reward: 88.04908344718812 avg_loss_c: 34.43001526341294 avg_loss_a: -75.13885567405008
Número de pasos del episodio 13620 son episode_steps:36
Total Steps: 920581 Episode Num: 13620 Reward: -5.333754907468215 avg_loss_c: 30.305276340908474 avg_loss_a: -75.56065538194444
Número de pasos del episodio 13621 son episode_steps:95
Total Steps: 920676 Episode Num: 13621 Reward: 23.163041658844413 avg_loss_c: 30.87177728351794 avg_loss_a: -76.35842911569696
Número de pasos del episodio 13622 son episode_steps:35
Total Steps: 920711 Episode Num: 13622 Reward: -28.696706873768164 avg_loss_c: 33.934490258353094 avg_loss_a: -76.54735979352678
Número de pasos del episodio 13623 son episode_steps:136
Total Steps: 920847 Episode Num: 13623 Reward: 44.22128935473219 avg_loss_c: 32.44489206987269 avg_loss_a: -74.93876625509823
Número de pasos del episodio 13624 son episode_steps:36
Total Steps: 920883 Episode Num: 13624 Reward: -67.07130373768055 avg_loss_c: 35.219419638315834 avg_loss_a: -75.30962583753798
Número de pasos del episodio 13625 son episode_steps:84
Total Steps: 920967 Episode Num: 13625 Reward: -15.008903936375912 avg_loss_c: 33.31785286040533 avg_loss_a: -74.97200811476935
Número de pasos del episodio 13626 son episode_steps:75
Total Steps: 921042 Episode Num: 13626 Reward: 28.458100348128095 avg_loss_c: 32.069268213907876 avg_loss_a: -76.27376983642579
Número de pasos del episodio 13627 son episode_steps:97
Total Steps: 921139 Episode Num: 13627 Reward: -32.59547737438838 avg_loss_c: 32.51131297632591 avg_loss_a: -75.55455827221428
Número de pasos del episodio 13628 son episode_steps:109
Total Steps: 921248 Episode Num: 13628 Reward: 43.760122489984866 avg_loss_c: 33.28331921078743 avg_loss_a: -75.06572093438665
Número de pasos del episodio 13629 son episode_steps:114
Total Steps: 921362 Episode Num: 13629 Reward: 31.982900861121085 avg_loss_c: 32.51125431060791 avg_loss_a: -75.81174495763946
Número de pasos del episodio 13630 son episode_steps:105
Total Steps: 921467 Episode Num: 13630 Reward: -49.037353691332 avg_loss_c: 33.877383622669036 avg_loss_a: -74.97211274646577
Número de pasos del episodio 13631 son episode_steps:55
Total Steps: 921522 Episode Num: 13631 Reward: -29.68229120620925 avg_loss_c: 33.65384202436967 avg_loss_a: -74.8403812755238
Número de pasos del episodio 13632 son episode_steps:67
Total Steps: 921589 Episode Num: 13632 Reward: -17.468932047303127 avg_loss_c: 37.44493561360373 avg_loss_a: -74.31490667542415
Número de pasos del episodio 13633 son episode_steps:115
Total Steps: 921704 Episode Num: 13633 Reward: 88.46818234169433 avg_loss_c: 32.8760731904403 avg_loss_a: -76.07959680971892
Número de pasos del episodio 13634 son episode_steps:66
Total Steps: 921770 Episode Num: 13634 Reward: 14.69029518724982 avg_loss_c: 33.55351933566007 avg_loss_a: -76.02554991751006
Número de pasos del episodio 13635 son episode_steps:74
Total Steps: 921844 Episode Num: 13635 Reward: -20.852550130047725 avg_loss_c: 33.184380892160775 avg_loss_a: -75.40199465365023
Número de pasos del episodio 13636 son episode_steps:74
Total Steps: 921918 Episode Num: 13636 Reward: -0.7500829976002295 avg_loss_c: 35.059645962070775 avg_loss_a: -74.80753996565535
Número de pasos del episodio 13637 son episode_steps:142
Total Steps: 922060 Episode Num: 13637 Reward: 100.45298191984948 avg_loss_c: 33.11654227888081 avg_loss_a: -75.8654545528788
Número de pasos del episodio 13638 son episode_steps:78
Total Steps: 922138 Episode Num: 13638 Reward: -12.318571756363559 avg_loss_c: 34.62470382299178 avg_loss_a: -75.42603615002754
Número de pasos del episodio 13639 son episode_steps:53
Total Steps: 922191 Episode Num: 13639 Reward: -10.496333337114212 avg_loss_c: 30.370445107514005 avg_loss_a: -76.88054383475826
Número de pasos del episodio 13640 son episode_steps:57
Total Steps: 922248 Episode Num: 13640 Reward: 11.940389071386733 avg_loss_c: 32.202277668735434 avg_loss_a: -76.95097832930715
Número de pasos del episodio 13641 son episode_steps:96
Total Steps: 922344 Episode Num: 13641 Reward: -52.34610701938386 avg_loss_c: 33.648589531580605 avg_loss_a: -75.21264314651489
Número de pasos del episodio 13642 son episode_steps:31
Total Steps: 922375 Episode Num: 13642 Reward: -29.454638109582618 avg_loss_c: 31.859020233154297 avg_loss_a: -76.34910755772745
Número de pasos del episodio 13643 son episode_steps:76
Total Steps: 922451 Episode Num: 13643 Reward: 12.922691948374354 avg_loss_c: 33.75752283397474 avg_loss_a: -75.15877482765599
Número de pasos del episodio 13644 son episode_steps:57
Total Steps: 922508 Episode Num: 13644 Reward: 24.8716596532936 avg_loss_c: 32.705748307077506 avg_loss_a: -73.74364257277104
Número de pasos del episodio 13645 son episode_steps:246
Total Steps: 922754 Episode Num: 13645 Reward: 169.45812949677813 avg_loss_c: 33.63327625708851 avg_loss_a: -74.44537034073497
Número de pasos del episodio 13646 son episode_steps:55
Total Steps: 922809 Episode Num: 13646 Reward: -9.81558666985271 avg_loss_c: 32.67711757313121 avg_loss_a: -73.86417846679687
Número de pasos del episodio 13647 son episode_steps:183
Total Steps: 922992 Episode Num: 13647 Reward: 128.66728190403296 avg_loss_c: 32.18800256030807 avg_loss_a: -74.91420708327998
Número de pasos del episodio 13648 son episode_steps:37
Total Steps: 923029 Episode Num: 13648 Reward: -9.340275233678117 avg_loss_c: 32.14986053672997 avg_loss_a: -74.8155039194468
Número de pasos del episodio 13649 son episode_steps:156
Total Steps: 923185 Episode Num: 13649 Reward: 128.54009857793983 avg_loss_c: 31.33734568571433 avg_loss_a: -75.35556098742363
Número de pasos del episodio 13650 son episode_steps:163
Total Steps: 923348 Episode Num: 13650 Reward: 48.934298015110414 avg_loss_c: 32.46799853974325 avg_loss_a: -75.89334939593918
Número de pasos del episodio 13651 son episode_steps:42
Total Steps: 923390 Episode Num: 13651 Reward: -7.190233587986352 avg_loss_c: 32.821690150669646 avg_loss_a: -74.80860610235305
Número de pasos del episodio 13652 son episode_steps:87
Total Steps: 923477 Episode Num: 13652 Reward: 34.134105144120184 avg_loss_c: 31.074097183929094 avg_loss_a: -74.75914089159033
Número de pasos del episodio 13653 son episode_steps:42
Total Steps: 923519 Episode Num: 13653 Reward: -7.6510773703377515 avg_loss_c: 32.298211052304225 avg_loss_a: -72.90590377081008
Número de pasos del episodio 13654 son episode_steps:46
Total Steps: 923565 Episode Num: 13654 Reward: 1.6279827702244374 avg_loss_c: 32.17778230750042 avg_loss_a: -74.9286578634511
Número de pasos del episodio 13655 son episode_steps:28
Total Steps: 923593 Episode Num: 13655 Reward: -16.126295788844562 avg_loss_c: 33.90221561704363 avg_loss_a: -76.75008446829659
Número de pasos del episodio 13656 son episode_steps:51
Total Steps: 923644 Episode Num: 13656 Reward: -6.461543035434584 avg_loss_c: 32.91781126284132 avg_loss_a: -75.81359564089307
Número de pasos del episodio 13657 son episode_steps:77
Total Steps: 923721 Episode Num: 13657 Reward: 26.937910756041642 avg_loss_c: 32.20100566319057 avg_loss_a: -75.14084704510577
Número de pasos del episodio 13658 son episode_steps:103
Total Steps: 923824 Episode Num: 13658 Reward: 45.43609037700071 avg_loss_c: 31.174718764221783 avg_loss_a: -76.18452453613281
Número de pasos del episodio 13659 son episode_steps:51
Total Steps: 923875 Episode Num: 13659 Reward: 7.276470839902957 avg_loss_c: 31.445405249502144 avg_loss_a: -74.40025748458564
Número de pasos del episodio 13660 son episode_steps:81
Total Steps: 923956 Episode Num: 13660 Reward: 1.076723001674917 avg_loss_c: 32.66430256690508 avg_loss_a: -75.22401164490499
Número de pasos del episodio 13661 son episode_steps:39
Total Steps: 923995 Episode Num: 13661 Reward: -13.326826868296964 avg_loss_c: 31.993570034320538 avg_loss_a: -73.96569335154997
Número de pasos del episodio 13662 son episode_steps:113
Total Steps: 924108 Episode Num: 13662 Reward: 61.415038322273446 avg_loss_c: 33.80281639099121 avg_loss_a: -74.61263707253785
Número de pasos del episodio 13663 son episode_steps:33
Total Steps: 924141 Episode Num: 13663 Reward: -6.1399034900393685 avg_loss_c: 34.54402623032079 avg_loss_a: -75.5699569239761
Número de pasos del episodio 13664 son episode_steps:139
Total Steps: 924280 Episode Num: 13664 Reward: 60.666162685779824 avg_loss_c: 33.43440880535318 avg_loss_a: -74.71079160841249
Número de pasos del episodio 13665 son episode_steps:36
Total Steps: 924316 Episode Num: 13665 Reward: -28.202882738644398 avg_loss_c: 32.82435343000624 avg_loss_a: -74.10922241210938
Número de pasos del episodio 13666 son episode_steps:32
Total Steps: 924348 Episode Num: 13666 Reward: -6.238754411321433 avg_loss_c: 33.90561830997467 avg_loss_a: -73.60492706298828
Número de pasos del episodio 13667 son episode_steps:97
Total Steps: 924445 Episode Num: 13667 Reward: 58.65106978578007 avg_loss_c: 32.96021675817745 avg_loss_a: -75.18438295973945
Número de pasos del episodio 13668 son episode_steps:27
Total Steps: 924472 Episode Num: 13668 Reward: -33.48433300892126 avg_loss_c: 33.763354266131365 avg_loss_a: -74.19361905698423
Número de pasos del episodio 13669 son episode_steps:39
Total Steps: 924511 Episode Num: 13669 Reward: 1.5220626045380836 avg_loss_c: 35.09456918178461 avg_loss_a: -74.23002624511719
Número de pasos del episodio 13670 son episode_steps:44
Total Steps: 924555 Episode Num: 13670 Reward: -34.984107026054446 avg_loss_c: 32.8671122897755 avg_loss_a: -73.29271680658513
Número de pasos del episodio 13671 son episode_steps:68
Total Steps: 924623 Episode Num: 13671 Reward: 19.99707593621216 avg_loss_c: 33.909017590915454 avg_loss_a: -75.00615894093232
Número de pasos del episodio 13672 son episode_steps:99
Total Steps: 924722 Episode Num: 13672 Reward: 77.38553960139852 avg_loss_c: 34.09376899642174 avg_loss_a: -74.70637342664931
Número de pasos del episodio 13673 son episode_steps:38
Total Steps: 924760 Episode Num: 13673 Reward: -2.4847380742548104 avg_loss_c: 34.09114872781854 avg_loss_a: -73.78676444605777
Número de pasos del episodio 13674 son episode_steps:133
Total Steps: 924893 Episode Num: 13674 Reward: 45.358790065872505 avg_loss_c: 33.54023113107323 avg_loss_a: -74.21979115421611
Número de pasos del episodio 13675 son episode_steps:132
Total Steps: 925025 Episode Num: 13675 Reward: 83.43120351858914 avg_loss_c: 33.72180035620025 avg_loss_a: -74.31896579626834
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 81.627884
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13676 son episode_steps:132
Total Steps: 925157 Episode Num: 13676 Reward: 85.8503946136004 avg_loss_c: 32.93780547922308 avg_loss_a: -73.60497318614613
Número de pasos del episodio 13677 son episode_steps:103
Total Steps: 925260 Episode Num: 13677 Reward: 27.778006055102015 avg_loss_c: 33.18365919242785 avg_loss_a: -73.57079167041964
Número de pasos del episodio 13678 son episode_steps:145
Total Steps: 925405 Episode Num: 13678 Reward: 105.46135818573583 avg_loss_c: 35.10265641048037 avg_loss_a: -73.21224370496026
Número de pasos del episodio 13679 son episode_steps:56
Total Steps: 925461 Episode Num: 13679 Reward: 19.405598825434375 avg_loss_c: 33.50418210029602 avg_loss_a: -73.14969607761928
Número de pasos del episodio 13680 son episode_steps:56
Total Steps: 925517 Episode Num: 13680 Reward: 18.65046120756642 avg_loss_c: 33.52810665539333 avg_loss_a: -74.37559155055455
Número de pasos del episodio 13681 son episode_steps:62
Total Steps: 925579 Episode Num: 13681 Reward: 8.331392628595669 avg_loss_c: 32.59117418719876 avg_loss_a: -73.55020264656314
Número de pasos del episodio 13682 son episode_steps:30
Total Steps: 925609 Episode Num: 13682 Reward: -15.035423558405846 avg_loss_c: 32.284953625996906 avg_loss_a: -73.17292785644531
Número de pasos del episodio 13683 son episode_steps:51
Total Steps: 925660 Episode Num: 13683 Reward: -29.422190802322078 avg_loss_c: 35.22507390788957 avg_loss_a: -73.50623127058441
Número de pasos del episodio 13684 son episode_steps:209
Total Steps: 925869 Episode Num: 13684 Reward: 163.99767337107642 avg_loss_c: 33.91234757455342 avg_loss_a: -73.32713624507046
Número de pasos del episodio 13685 son episode_steps:71
Total Steps: 925940 Episode Num: 13685 Reward: 6.012247813494115 avg_loss_c: 32.59914927415445 avg_loss_a: -73.96012770961708
Número de pasos del episodio 13686 son episode_steps:122
Total Steps: 926062 Episode Num: 13686 Reward: 47.341556685888676 avg_loss_c: 33.56063908436259 avg_loss_a: -73.15354162747742
Número de pasos del episodio 13687 son episode_steps:50
Total Steps: 926112 Episode Num: 13687 Reward: -13.382190651638009 avg_loss_c: 32.98837844848633 avg_loss_a: -73.215380859375
Número de pasos del episodio 13688 son episode_steps:38
Total Steps: 926150 Episode Num: 13688 Reward: -59.539584545546155 avg_loss_c: 34.64190021314119 avg_loss_a: -72.87345605147512
Número de pasos del episodio 13689 son episode_steps:47
Total Steps: 926197 Episode Num: 13689 Reward: -26.647350918249675 avg_loss_c: 33.65790127693339 avg_loss_a: -74.24968540922124
Número de pasos del episodio 13690 son episode_steps:75
Total Steps: 926272 Episode Num: 13690 Reward: 9.823356662243294 avg_loss_c: 33.49986770629883 avg_loss_a: -72.8050752766927
Número de pasos del episodio 13691 son episode_steps:167
Total Steps: 926439 Episode Num: 13691 Reward: 54.81298589981554 avg_loss_c: 34.55769389261029 avg_loss_a: -72.74957823610592
Número de pasos del episodio 13692 son episode_steps:53
Total Steps: 926492 Episode Num: 13692 Reward: -3.7224312007507194 avg_loss_c: 33.6249108584422 avg_loss_a: -74.38561435915389
Número de pasos del episodio 13693 son episode_steps:55
Total Steps: 926547 Episode Num: 13693 Reward: -41.08075263720951 avg_loss_c: 34.9592680497603 avg_loss_a: -73.19255301735618
Número de pasos del episodio 13694 son episode_steps:96
Total Steps: 926643 Episode Num: 13694 Reward: 41.87344847239569 avg_loss_c: 33.859596172968544 avg_loss_a: -74.03750077883403
Número de pasos del episodio 13695 son episode_steps:159
Total Steps: 926802 Episode Num: 13695 Reward: 83.79046288452912 avg_loss_c: 34.33253816088791 avg_loss_a: -73.49497952251315
Número de pasos del episodio 13696 son episode_steps:53
Total Steps: 926855 Episode Num: 13696 Reward: 9.114129991196247 avg_loss_c: 33.67852826388377 avg_loss_a: -72.64462021161926
Número de pasos del episodio 13697 son episode_steps:164
Total Steps: 927019 Episode Num: 13697 Reward: 131.6760436438789 avg_loss_c: 33.87019909881964 avg_loss_a: -72.27183104724419
Número de pasos del episodio 13698 son episode_steps:86
Total Steps: 927105 Episode Num: 13698 Reward: -6.406723507668558 avg_loss_c: 33.677420261294344 avg_loss_a: -71.28810545455578
Número de pasos del episodio 13699 son episode_steps:41
Total Steps: 927146 Episode Num: 13699 Reward: -11.879266247091167 avg_loss_c: 32.332070327386624 avg_loss_a: -73.52431655511623
Número de pasos del episodio 13700 son episode_steps:18
Total Steps: 927164 Episode Num: 13700 Reward: -35.32333627789141 avg_loss_c: 33.379431830512154 avg_loss_a: -71.68521457248264
Número de pasos del episodio 13701 son episode_steps:54
Total Steps: 927218 Episode Num: 13701 Reward: -7.847545208434173 avg_loss_c: 34.40232700771756 avg_loss_a: -72.87945471869574
Número de pasos del episodio 13702 son episode_steps:37
Total Steps: 927255 Episode Num: 13702 Reward: -74.32778730514892 avg_loss_c: 36.135207511283255 avg_loss_a: -72.83085879764042
Número de pasos del episodio 13703 son episode_steps:63
Total Steps: 927318 Episode Num: 13703 Reward: 4.92804933192083 avg_loss_c: 36.18498584202358 avg_loss_a: -71.9431882585798
Número de pasos del episodio 13704 son episode_steps:44
Total Steps: 927362 Episode Num: 13704 Reward: -9.646465830656892 avg_loss_c: 36.2855018268932 avg_loss_a: -73.0701886957342
Número de pasos del episodio 13705 son episode_steps:126
Total Steps: 927488 Episode Num: 13705 Reward: 65.92985891757932 avg_loss_c: 37.407065330989774 avg_loss_a: -72.79521978469123
Número de pasos del episodio 13706 son episode_steps:146
Total Steps: 927634 Episode Num: 13706 Reward: 87.93960187652927 avg_loss_c: 35.22056579589844 avg_loss_a: -71.74237959352259
Número de pasos del episodio 13707 son episode_steps:103
Total Steps: 927737 Episode Num: 13707 Reward: 76.59608689603958 avg_loss_c: 34.93184104475003 avg_loss_a: -73.0812249785488
Número de pasos del episodio 13708 son episode_steps:295
Total Steps: 928032 Episode Num: 13708 Reward: 58.530102746727216 avg_loss_c: 36.012503911681094 avg_loss_a: -71.25738952119471
Número de pasos del episodio 13709 son episode_steps:127
Total Steps: 928159 Episode Num: 13709 Reward: 123.10502041471909 avg_loss_c: 33.363710027980055 avg_loss_a: -72.09537992702694
Número de pasos del episodio 13710 son episode_steps:133
Total Steps: 928292 Episode Num: 13710 Reward: 77.45937696661613 avg_loss_c: 34.410944214440825 avg_loss_a: -71.8811975923696
Número de pasos del episodio 13711 son episode_steps:58
Total Steps: 928350 Episode Num: 13711 Reward: 12.206776212333677 avg_loss_c: 34.650921920250205 avg_loss_a: -71.3231262996279
Número de pasos del episodio 13712 son episode_steps:110
Total Steps: 928460 Episode Num: 13712 Reward: 73.76624010709011 avg_loss_c: 34.325503713434394 avg_loss_a: -72.42470065030184
Número de pasos del episodio 13713 son episode_steps:70
Total Steps: 928530 Episode Num: 13713 Reward: 41.743885452185005 avg_loss_c: 32.836268751961846 avg_loss_a: -72.45402199881417
Número de pasos del episodio 13714 son episode_steps:121
Total Steps: 928651 Episode Num: 13714 Reward: 46.49557888445876 avg_loss_c: 33.65094824861889 avg_loss_a: -72.1950852575381
Número de pasos del episodio 13715 son episode_steps:65
Total Steps: 928716 Episode Num: 13715 Reward: 40.500522647878924 avg_loss_c: 33.453794538057764 avg_loss_a: -72.16915247990535
Número de pasos del episodio 13716 son episode_steps:165
Total Steps: 928881 Episode Num: 13716 Reward: 177.95546531962347 avg_loss_c: 33.15285527778394 avg_loss_a: -71.85109211314808
Número de pasos del episodio 13717 son episode_steps:148
Total Steps: 929029 Episode Num: 13717 Reward: 104.89830486297588 avg_loss_c: 32.48902663669071 avg_loss_a: -72.22199873022132
Número de pasos del episodio 13718 son episode_steps:173
Total Steps: 929202 Episode Num: 13718 Reward: 153.94512390769606 avg_loss_c: 33.390898114684 avg_loss_a: -72.54924227323146
Número de pasos del episodio 13719 son episode_steps:168
Total Steps: 929370 Episode Num: 13719 Reward: 61.23870407049567 avg_loss_c: 34.38968979744684 avg_loss_a: -72.18282358986991
Número de pasos del episodio 13720 son episode_steps:70
Total Steps: 929440 Episode Num: 13720 Reward: 2.6876408733481503 avg_loss_c: 32.92762895311628 avg_loss_a: -71.19090423583984
Número de pasos del episodio 13721 son episode_steps:69
Total Steps: 929509 Episode Num: 13721 Reward: -10.775318297069294 avg_loss_c: 34.43271730948186 avg_loss_a: -72.2182541999264
Número de pasos del episodio 13722 son episode_steps:131
Total Steps: 929640 Episode Num: 13722 Reward: 13.518359997571372 avg_loss_c: 33.66986999802917 avg_loss_a: -72.2942583506344
Número de pasos del episodio 13723 son episode_steps:137
Total Steps: 929777 Episode Num: 13723 Reward: 109.0005093284432 avg_loss_c: 33.768195688289445 avg_loss_a: -72.1014319649578
Número de pasos del episodio 13724 son episode_steps:33
Total Steps: 929810 Episode Num: 13724 Reward: -34.37201559196838 avg_loss_c: 33.47756351124156 avg_loss_a: -71.97196636777936
Número de pasos del episodio 13725 son episode_steps:30
Total Steps: 929840 Episode Num: 13725 Reward: -11.98669877173807 avg_loss_c: 33.14576059977214 avg_loss_a: -72.12985178629557
Número de pasos del episodio 13726 son episode_steps:64
Total Steps: 929904 Episode Num: 13726 Reward: 26.153955374296782 avg_loss_c: 32.35238340497017 avg_loss_a: -72.63480341434479
Número de pasos del episodio 13727 son episode_steps:179
Total Steps: 930083 Episode Num: 13727 Reward: 129.20121706612127 avg_loss_c: 33.41196793284496 avg_loss_a: -71.60608809487114
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 78.575946
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13728 son episode_steps:35
Total Steps: 930118 Episode Num: 13728 Reward: -38.711845969534814 avg_loss_c: 33.65126119341169 avg_loss_a: -71.14312962123326
Número de pasos del episodio 13729 son episode_steps:110
Total Steps: 930228 Episode Num: 13729 Reward: 84.48234269612365 avg_loss_c: 34.449691876498136 avg_loss_a: -71.42123211947354
Número de pasos del episodio 13730 son episode_steps:56
Total Steps: 930284 Episode Num: 13730 Reward: 4.81440519003449 avg_loss_c: 33.01034688949585 avg_loss_a: -71.1668951851981
Número de pasos del episodio 13731 son episode_steps:83
Total Steps: 930367 Episode Num: 13731 Reward: -50.39224100671271 avg_loss_c: 34.33151955202401 avg_loss_a: -72.62615222241504
Número de pasos del episodio 13732 son episode_steps:34
Total Steps: 930401 Episode Num: 13732 Reward: 0.3468438295231415 avg_loss_c: 33.04946355258717 avg_loss_a: -72.36241778205422
Número de pasos del episodio 13733 son episode_steps:30
Total Steps: 930431 Episode Num: 13733 Reward: -8.687132619633147 avg_loss_c: 33.43188921610514 avg_loss_a: -71.65621185302734
Número de pasos del episodio 13734 son episode_steps:73
Total Steps: 930504 Episode Num: 13734 Reward: 4.200750106755893 avg_loss_c: 33.707302145761986 avg_loss_a: -71.79704681814533
Número de pasos del episodio 13735 son episode_steps:79
Total Steps: 930583 Episode Num: 13735 Reward: 40.336191856798905 avg_loss_c: 33.23496767840808 avg_loss_a: -71.81843518607224
Número de pasos del episodio 13736 son episode_steps:53
Total Steps: 930636 Episode Num: 13736 Reward: -25.210296296297237 avg_loss_c: 34.4495437909972 avg_loss_a: -72.19058846527676
Número de pasos del episodio 13737 son episode_steps:70
Total Steps: 930706 Episode Num: 13737 Reward: 9.723475552338554 avg_loss_c: 34.26584107535226 avg_loss_a: -71.01505268641881
Número de pasos del episodio 13738 son episode_steps:174
Total Steps: 930880 Episode Num: 13738 Reward: 134.12119676957448 avg_loss_c: 34.39432697734613 avg_loss_a: -72.22235817744814
Número de pasos del episodio 13739 son episode_steps:56
Total Steps: 930936 Episode Num: 13739 Reward: 11.273304346121922 avg_loss_c: 33.80127229009356 avg_loss_a: -71.45088114057269
Número de pasos del episodio 13740 son episode_steps:38
Total Steps: 930974 Episode Num: 13740 Reward: 4.233717883249491 avg_loss_c: 33.28198312458239 avg_loss_a: -71.58291385048314
Número de pasos del episodio 13741 son episode_steps:29
Total Steps: 931003 Episode Num: 13741 Reward: -12.450720206184084 avg_loss_c: 34.38140592903927 avg_loss_a: -72.58278524464575
Número de pasos del episodio 13742 son episode_steps:73
Total Steps: 931076 Episode Num: 13742 Reward: 18.3805252133697 avg_loss_c: 34.250617693548335 avg_loss_a: -72.32336624354532
Número de pasos del episodio 13743 son episode_steps:46
Total Steps: 931122 Episode Num: 13743 Reward: -38.20414380377616 avg_loss_c: 33.39935767132303 avg_loss_a: -73.04180941374406
Número de pasos del episodio 13744 son episode_steps:111
Total Steps: 931233 Episode Num: 13744 Reward: 38.59302525958327 avg_loss_c: 33.99312634511037 avg_loss_a: -72.12787257014094
Número de pasos del episodio 13745 son episode_steps:30
Total Steps: 931263 Episode Num: 13745 Reward: -16.617921003944048 avg_loss_c: 33.321761767069496 avg_loss_a: -73.4121098836263
Número de pasos del episodio 13746 son episode_steps:148
Total Steps: 931411 Episode Num: 13746 Reward: 18.762018015403456 avg_loss_c: 33.6206801130965 avg_loss_a: -72.42252581828349
Número de pasos del episodio 13747 son episode_steps:40
Total Steps: 931451 Episode Num: 13747 Reward: -4.406326101183093 avg_loss_c: 33.42304620742798 avg_loss_a: -72.21855926513672
Número de pasos del episodio 13748 son episode_steps:113
Total Steps: 931564 Episode Num: 13748 Reward: 26.858803160589098 avg_loss_c: 35.24426515967445 avg_loss_a: -71.2952760679532
Número de pasos del episodio 13749 son episode_steps:101
Total Steps: 931665 Episode Num: 13749 Reward: 29.617599160363504 avg_loss_c: 34.28680689972226 avg_loss_a: -72.25553002687964
Número de pasos del episodio 13750 son episode_steps:78
Total Steps: 931743 Episode Num: 13750 Reward: 12.394626920767134 avg_loss_c: 34.452263612013596 avg_loss_a: -71.70229398287259
Número de pasos del episodio 13751 son episode_steps:62
Total Steps: 931805 Episode Num: 13751 Reward: -3.410804324346575 avg_loss_c: 34.076491263604936 avg_loss_a: -71.69852152178365
Número de pasos del episodio 13752 son episode_steps:154
Total Steps: 931959 Episode Num: 13752 Reward: 92.02042515277529 avg_loss_c: 34.296840122767854 avg_loss_a: -71.48523365367542
Número de pasos del episodio 13753 son episode_steps:129
Total Steps: 932088 Episode Num: 13753 Reward: 55.77881242427442 avg_loss_c: 32.43453707436259 avg_loss_a: -71.35560400911079
Número de pasos del episodio 13754 son episode_steps:67
Total Steps: 932155 Episode Num: 13754 Reward: 17.64858739386368 avg_loss_c: 32.82810737837607 avg_loss_a: -71.3179219943374
Número de pasos del episodio 13755 son episode_steps:64
Total Steps: 932219 Episode Num: 13755 Reward: 44.71314664168565 avg_loss_c: 34.7919881939888 avg_loss_a: -72.12317776679993
Número de pasos del episodio 13756 son episode_steps:63
Total Steps: 932282 Episode Num: 13756 Reward: -0.4365517545160511 avg_loss_c: 35.39883359273275 avg_loss_a: -72.74405803377667
Número de pasos del episodio 13757 son episode_steps:91
Total Steps: 932373 Episode Num: 13757 Reward: 31.722439576809393 avg_loss_c: 34.47839904617477 avg_loss_a: -70.71146091000064
Número de pasos del episodio 13758 son episode_steps:170
Total Steps: 932543 Episode Num: 13758 Reward: 111.0354618579127 avg_loss_c: 35.07645099864286 avg_loss_a: -71.26355245253619
Número de pasos del episodio 13759 son episode_steps:113
Total Steps: 932656 Episode Num: 13759 Reward: -3.0410089083558836 avg_loss_c: 34.42502958584676 avg_loss_a: -71.36548310676507
Número de pasos del episodio 13760 son episode_steps:51
Total Steps: 932707 Episode Num: 13760 Reward: -5.599155670817542 avg_loss_c: 35.00918754876829 avg_loss_a: -70.71280759923599
Número de pasos del episodio 13761 son episode_steps:122
Total Steps: 932829 Episode Num: 13761 Reward: 103.82693129672265 avg_loss_c: 35.13490522103231 avg_loss_a: -70.78884068473441
Número de pasos del episodio 13762 son episode_steps:43
Total Steps: 932872 Episode Num: 13762 Reward: -2.206822483895855 avg_loss_c: 36.440990891567495 avg_loss_a: -71.23078191003134
Número de pasos del episodio 13763 son episode_steps:47
Total Steps: 932919 Episode Num: 13763 Reward: -5.86613879993248 avg_loss_c: 33.99438728170192 avg_loss_a: -71.19021119462683
Número de pasos del episodio 13764 son episode_steps:45
Total Steps: 932964 Episode Num: 13764 Reward: -7.98689589375614 avg_loss_c: 35.35885238647461 avg_loss_a: -70.5797141181098
Número de pasos del episodio 13765 son episode_steps:207
Total Steps: 933171 Episode Num: 13765 Reward: 148.04016429691634 avg_loss_c: 34.256166946484846 avg_loss_a: -71.52911295867773
Número de pasos del episodio 13766 son episode_steps:172
Total Steps: 933343 Episode Num: 13766 Reward: 158.24783369136654 avg_loss_c: 34.616391581158304 avg_loss_a: -72.19832198564396
Número de pasos del episodio 13767 son episode_steps:43
Total Steps: 933386 Episode Num: 13767 Reward: 0.11301617812525677 avg_loss_c: 33.382358595382335 avg_loss_a: -71.70204410996548
Número de pasos del episodio 13768 son episode_steps:71
Total Steps: 933457 Episode Num: 13768 Reward: -38.40946359431088 avg_loss_c: 35.48651974637743 avg_loss_a: -72.14407724729726
Número de pasos del episodio 13769 son episode_steps:150
Total Steps: 933607 Episode Num: 13769 Reward: 109.75170886023457 avg_loss_c: 35.932453600565594 avg_loss_a: -70.94078058878581
Número de pasos del episodio 13770 son episode_steps:163
Total Steps: 933770 Episode Num: 13770 Reward: 131.44576023497072 avg_loss_c: 35.47181308488904 avg_loss_a: -71.4176223380434
Número de pasos del episodio 13771 son episode_steps:59
Total Steps: 933829 Episode Num: 13771 Reward: 20.809677991187844 avg_loss_c: 35.2537713778221 avg_loss_a: -71.54013436527576
Número de pasos del episodio 13772 son episode_steps:186
Total Steps: 934015 Episode Num: 13772 Reward: 61.43089233539516 avg_loss_c: 35.21056937145931 avg_loss_a: -71.08039150443129
Número de pasos del episodio 13773 son episode_steps:40
Total Steps: 934055 Episode Num: 13773 Reward: -7.2222566341565475 avg_loss_c: 34.36835398674011 avg_loss_a: -71.07386741638183
Número de pasos del episodio 13774 son episode_steps:33
Total Steps: 934088 Episode Num: 13774 Reward: -22.752833638104168 avg_loss_c: 38.11354128519694 avg_loss_a: -72.7694443211411
Número de pasos del episodio 13775 son episode_steps:131
Total Steps: 934219 Episode Num: 13775 Reward: 76.0184178322543 avg_loss_c: 36.05131155115957 avg_loss_a: -71.26668571879846
Número de pasos del episodio 13776 son episode_steps:86
Total Steps: 934305 Episode Num: 13776 Reward: 36.616583669448616 avg_loss_c: 36.28382806999739 avg_loss_a: -71.3858088116313
Número de pasos del episodio 13777 son episode_steps:223
Total Steps: 934528 Episode Num: 13777 Reward: 138.54952835688545 avg_loss_c: 35.112382563774894 avg_loss_a: -70.91087892130352
Número de pasos del episodio 13778 son episode_steps:167
Total Steps: 934695 Episode Num: 13778 Reward: 118.14746282868096 avg_loss_c: 35.47674529709502 avg_loss_a: -71.73102423388087
Número de pasos del episodio 13779 son episode_steps:30
Total Steps: 934725 Episode Num: 13779 Reward: -30.63367146716957 avg_loss_c: 37.18677609761556 avg_loss_a: -71.69330342610677
Número de pasos del episodio 13780 son episode_steps:89
Total Steps: 934814 Episode Num: 13780 Reward: 31.57303452210342 avg_loss_c: 35.70508108246192 avg_loss_a: -71.47231421309911
Número de pasos del episodio 13781 son episode_steps:62
Total Steps: 934876 Episode Num: 13781 Reward: -63.154508730648814 avg_loss_c: 36.335654935529156 avg_loss_a: -70.19379474270728
Número de pasos del episodio 13782 son episode_steps:32
Total Steps: 934908 Episode Num: 13782 Reward: -43.664231706695446 avg_loss_c: 37.25268667936325 avg_loss_a: -71.00357866287231
Número de pasos del episodio 13783 son episode_steps:103
Total Steps: 935011 Episode Num: 13783 Reward: 36.736631839251395 avg_loss_c: 37.64776894652728 avg_loss_a: -70.02872926286123
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 96.765570
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13784 son episode_steps:115
Total Steps: 935126 Episode Num: 13784 Reward: 38.79778737640812 avg_loss_c: 37.75178408415421 avg_loss_a: -70.12884242845618
Número de pasos del episodio 13785 son episode_steps:137
Total Steps: 935263 Episode Num: 13785 Reward: 72.01380744138562 avg_loss_c: 36.65445241440822 avg_loss_a: -71.21217596791956
Número de pasos del episodio 13786 son episode_steps:45
Total Steps: 935308 Episode Num: 13786 Reward: -1.0880961070013049 avg_loss_c: 37.69233703613281 avg_loss_a: -70.57835354275174
Número de pasos del episodio 13787 son episode_steps:185
Total Steps: 935493 Episode Num: 13787 Reward: 82.08691553067423 avg_loss_c: 35.4990032092945 avg_loss_a: -70.3594581397804
Número de pasos del episodio 13788 son episode_steps:37
Total Steps: 935530 Episode Num: 13788 Reward: -20.320037462363864 avg_loss_c: 37.86278384440654 avg_loss_a: -70.7557653478674
Número de pasos del episodio 13789 son episode_steps:36
Total Steps: 935566 Episode Num: 13789 Reward: -20.345093840447333 avg_loss_c: 35.065847396850586 avg_loss_a: -71.04868083530002
Número de pasos del episodio 13790 son episode_steps:141
Total Steps: 935707 Episode Num: 13790 Reward: 10.879609875612221 avg_loss_c: 38.11529914368975 avg_loss_a: -69.74689364602379
Número de pasos del episodio 13791 son episode_steps:127
Total Steps: 935834 Episode Num: 13791 Reward: 52.91429006684453 avg_loss_c: 36.720711895800015 avg_loss_a: -70.15911630945881
Número de pasos del episodio 13792 son episode_steps:81
Total Steps: 935915 Episode Num: 13792 Reward: 49.140710247161856 avg_loss_c: 37.322525754386994 avg_loss_a: -71.01906020553024
Número de pasos del episodio 13793 son episode_steps:102
Total Steps: 936017 Episode Num: 13793 Reward: 49.626149541875414 avg_loss_c: 37.761299843881645 avg_loss_a: -70.22305477366729
Número de pasos del episodio 13794 son episode_steps:54
Total Steps: 936071 Episode Num: 13794 Reward: -3.837817612213362 avg_loss_c: 38.25407028198242 avg_loss_a: -70.0779739662453
Número de pasos del episodio 13795 son episode_steps:73
Total Steps: 936144 Episode Num: 13795 Reward: -0.40160117515435 avg_loss_c: 38.910548615129024 avg_loss_a: -69.00974534962275
Número de pasos del episodio 13796 son episode_steps:98
Total Steps: 936242 Episode Num: 13796 Reward: 22.805508082394088 avg_loss_c: 38.117274654154876 avg_loss_a: -69.6563230242048
Número de pasos del episodio 13797 son episode_steps:249
Total Steps: 936491 Episode Num: 13797 Reward: 231.98246972161527 avg_loss_c: 37.33812892867858 avg_loss_a: -70.12818553265798
Número de pasos del episodio 13798 son episode_steps:46
Total Steps: 936537 Episode Num: 13798 Reward: -3.2516069550961957 avg_loss_c: 37.759583348813266 avg_loss_a: -70.13719409445058
Número de pasos del episodio 13799 son episode_steps:27
Total Steps: 936564 Episode Num: 13799 Reward: -50.02154710419889 avg_loss_c: 37.230578387225115 avg_loss_a: -70.96976499204283
Número de pasos del episodio 13800 son episode_steps:149
Total Steps: 936713 Episode Num: 13800 Reward: 34.52032077353472 avg_loss_c: 38.096892107253105 avg_loss_a: -69.75704889489501
Número de pasos del episodio 13801 son episode_steps:48
Total Steps: 936761 Episode Num: 13801 Reward: -38.78029179817865 avg_loss_c: 38.04249004522959 avg_loss_a: -70.19145727157593
Número de pasos del episodio 13802 son episode_steps:55
Total Steps: 936816 Episode Num: 13802 Reward: 32.242009127088096 avg_loss_c: 38.390060598200016 avg_loss_a: -70.11311922940341
Número de pasos del episodio 13803 son episode_steps:44
Total Steps: 936860 Episode Num: 13803 Reward: -16.279579557319487 avg_loss_c: 39.20067319003019 avg_loss_a: -69.57156961614436
Número de pasos del episodio 13804 son episode_steps:62
Total Steps: 936922 Episode Num: 13804 Reward: 37.55595354299526 avg_loss_c: 39.154102140857326 avg_loss_a: -70.21707300986013
Número de pasos del episodio 13805 son episode_steps:63
Total Steps: 936985 Episode Num: 13805 Reward: 24.04926903755795 avg_loss_c: 38.125252193874786 avg_loss_a: -69.78706480964782
Número de pasos del episodio 13806 son episode_steps:88
Total Steps: 937073 Episode Num: 13806 Reward: 57.010440628935854 avg_loss_c: 38.53791195696051 avg_loss_a: -70.80040116743608
Número de pasos del episodio 13807 son episode_steps:55
Total Steps: 937128 Episode Num: 13807 Reward: 3.208437727015485 avg_loss_c: 37.81456538113681 avg_loss_a: -70.25660067471591
Número de pasos del episodio 13808 son episode_steps:194
Total Steps: 937322 Episode Num: 13808 Reward: 78.06294507025224 avg_loss_c: 38.15697773215697 avg_loss_a: -69.95758693734395
Número de pasos del episodio 13809 son episode_steps:169
Total Steps: 937491 Episode Num: 13809 Reward: 112.55941439361676 avg_loss_c: 37.786738728630475 avg_loss_a: -69.74541270239114
Número de pasos del episodio 13810 son episode_steps:76
Total Steps: 937567 Episode Num: 13810 Reward: -63.66641943020038 avg_loss_c: 36.6188329144528 avg_loss_a: -70.2682950873124
Número de pasos del episodio 13811 son episode_steps:100
Total Steps: 937667 Episode Num: 13811 Reward: -6.701088205787199 avg_loss_c: 38.71429077148437 avg_loss_a: -69.71367179870606
Número de pasos del episodio 13812 son episode_steps:45
Total Steps: 937712 Episode Num: 13812 Reward: 10.46465626568557 avg_loss_c: 38.70658692253961 avg_loss_a: -68.44645351833768
Número de pasos del episodio 13813 son episode_steps:67
Total Steps: 937779 Episode Num: 13813 Reward: -78.81454554469599 avg_loss_c: 37.24264893602969 avg_loss_a: -67.99048967503789
Número de pasos del episodio 13814 son episode_steps:149
Total Steps: 937928 Episode Num: 13814 Reward: 16.851411391615393 avg_loss_c: 39.38289543766303 avg_loss_a: -68.76864726431418
Número de pasos del episodio 13815 son episode_steps:62
Total Steps: 937990 Episode Num: 13815 Reward: -9.318929561591553 avg_loss_c: 37.55185788677585 avg_loss_a: -68.78238407258064
Número de pasos del episodio 13816 son episode_steps:146
Total Steps: 938136 Episode Num: 13816 Reward: 43.43937523195209 avg_loss_c: 36.40118894185105 avg_loss_a: -69.40290095708141
Número de pasos del episodio 13817 son episode_steps:146
Total Steps: 938282 Episode Num: 13817 Reward: 75.9220790419407 avg_loss_c: 37.747790245160665 avg_loss_a: -69.2293891384177
Número de pasos del episodio 13818 son episode_steps:101
Total Steps: 938383 Episode Num: 13818 Reward: 20.912132619361202 avg_loss_c: 36.63148549523684 avg_loss_a: -68.93999549185875
Número de pasos del episodio 13819 son episode_steps:64
Total Steps: 938447 Episode Num: 13819 Reward: -28.211694188403268 avg_loss_c: 35.911547750234604 avg_loss_a: -68.83598721027374
Número de pasos del episodio 13820 son episode_steps:217
Total Steps: 938664 Episode Num: 13820 Reward: 134.04783759302342 avg_loss_c: 36.85731626765519 avg_loss_a: -69.11942699098367
Número de pasos del episodio 13821 son episode_steps:105
Total Steps: 938769 Episode Num: 13821 Reward: -16.2326809902274 avg_loss_c: 36.350583158220566 avg_loss_a: -68.56136481875465
Número de pasos del episodio 13822 son episode_steps:83
Total Steps: 938852 Episode Num: 13822 Reward: 39.608468761784046 avg_loss_c: 36.902816083057814 avg_loss_a: -69.27847740449101
Número de pasos del episodio 13823 son episode_steps:218
Total Steps: 939070 Episode Num: 13823 Reward: 191.75945616346684 avg_loss_c: 36.12545728246006 avg_loss_a: -68.8687659097374
Número de pasos del episodio 13824 son episode_steps:69
Total Steps: 939139 Episode Num: 13824 Reward: 33.865586954757056 avg_loss_c: 35.902756317802094 avg_loss_a: -69.48419360838075
Número de pasos del episodio 13825 son episode_steps:105
Total Steps: 939244 Episode Num: 13825 Reward: 64.58681345447067 avg_loss_c: 35.86369637988862 avg_loss_a: -70.13613804408482
Número de pasos del episodio 13826 son episode_steps:414
Total Steps: 939658 Episode Num: 13826 Reward: 387.2483049992616 avg_loss_c: 34.72851816352439 avg_loss_a: -69.96403005848761
Número de pasos del episodio 13827 son episode_steps:173
Total Steps: 939831 Episode Num: 13827 Reward: 144.2792225792474 avg_loss_c: 33.2974180982292 avg_loss_a: -70.3287741159428
Número de pasos del episodio 13828 son episode_steps:200
Total Steps: 940031 Episode Num: 13828 Reward: 96.38422997140772 avg_loss_c: 34.976756963729855 avg_loss_a: -70.61286796569824
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 210.886755
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13829 son episode_steps:173
Total Steps: 940204 Episode Num: 13829 Reward: 136.38113008054393 avg_loss_c: 32.73697803475264 avg_loss_a: -71.37158789662267
Número de pasos del episodio 13830 son episode_steps:155
Total Steps: 940359 Episode Num: 13830 Reward: 38.20199452919351 avg_loss_c: 33.29204764827605 avg_loss_a: -70.56693169378465
Número de pasos del episodio 13831 son episode_steps:19
Total Steps: 940378 Episode Num: 13831 Reward: -45.881348924357496 avg_loss_c: 40.71142307080721 avg_loss_a: -71.02722007349918
Número de pasos del episodio 13832 son episode_steps:90
Total Steps: 940468 Episode Num: 13832 Reward: 40.80372410277894 avg_loss_c: 34.24078261057536 avg_loss_a: -70.4807518005371
Número de pasos del episodio 13833 son episode_steps:104
Total Steps: 940572 Episode Num: 13833 Reward: 28.363280224061945 avg_loss_c: 33.87494553052462 avg_loss_a: -71.96705964895395
Número de pasos del episodio 13834 son episode_steps:67
Total Steps: 940639 Episode Num: 13834 Reward: -30.096796833160656 avg_loss_c: 34.389570492417064 avg_loss_a: -70.38310150601971
Número de pasos del episodio 13835 son episode_steps:160
Total Steps: 940799 Episode Num: 13835 Reward: 119.265262417999 avg_loss_c: 34.23210872411728 avg_loss_a: -70.84157056808472
Número de pasos del episodio 13836 son episode_steps:32
Total Steps: 940831 Episode Num: 13836 Reward: -35.983234105677354 avg_loss_c: 32.659152150154114 avg_loss_a: -71.36245822906494
Número de pasos del episodio 13837 son episode_steps:45
Total Steps: 940876 Episode Num: 13837 Reward: -34.24275833436409 avg_loss_c: 35.02085647583008 avg_loss_a: -71.11355590820312
Número de pasos del episodio 13838 son episode_steps:174
Total Steps: 941050 Episode Num: 13838 Reward: 130.14106291789764 avg_loss_c: 34.962792440392505 avg_loss_a: -71.82874973340967
Número de pasos del episodio 13839 son episode_steps:61
Total Steps: 941111 Episode Num: 13839 Reward: 14.19886754315456 avg_loss_c: 33.41499706956207 avg_loss_a: -71.1731743734391
Número de pasos del episodio 13840 son episode_steps:210
Total Steps: 941321 Episode Num: 13840 Reward: 55.16987360349063 avg_loss_c: 34.868969099862234 avg_loss_a: -71.44251400175548
Número de pasos del episodio 13841 son episode_steps:33
Total Steps: 941354 Episode Num: 13841 Reward: -0.5049404820622458 avg_loss_c: 34.54531074292732 avg_loss_a: -70.80530363140684
Número de pasos del episodio 13842 son episode_steps:66
Total Steps: 941420 Episode Num: 13842 Reward: 17.250834500539717 avg_loss_c: 33.86662312709924 avg_loss_a: -71.63627821026427
Número de pasos del episodio 13843 son episode_steps:38
Total Steps: 941458 Episode Num: 13843 Reward: -19.284547913281305 avg_loss_c: 35.571339205691686 avg_loss_a: -71.21911862021999
Número de pasos del episodio 13844 son episode_steps:82
Total Steps: 941540 Episode Num: 13844 Reward: -1.937321357295458 avg_loss_c: 34.04584068205298 avg_loss_a: -71.66716691924304
Número de pasos del episodio 13845 son episode_steps:236
Total Steps: 941776 Episode Num: 13845 Reward: 140.9046548016734 avg_loss_c: 34.7470840761217 avg_loss_a: -71.72449202456717
Número de pasos del episodio 13846 son episode_steps:245
Total Steps: 942021 Episode Num: 13846 Reward: 162.82142688552995 avg_loss_c: 34.511553737095426 avg_loss_a: -72.8488630956533
Número de pasos del episodio 13847 son episode_steps:62
Total Steps: 942083 Episode Num: 13847 Reward: -17.728317925019905 avg_loss_c: 34.976582281051144 avg_loss_a: -72.0023544065414
Número de pasos del episodio 13848 son episode_steps:70
Total Steps: 942153 Episode Num: 13848 Reward: 8.636651158234336 avg_loss_c: 35.44441800798688 avg_loss_a: -71.15557599748884
Número de pasos del episodio 13849 son episode_steps:74
Total Steps: 942227 Episode Num: 13849 Reward: -29.79361084490697 avg_loss_c: 34.51355080991178 avg_loss_a: -72.97390190330711
Número de pasos del episodio 13850 son episode_steps:308
Total Steps: 942535 Episode Num: 13850 Reward: 226.8946337438336 avg_loss_c: 33.92735905461497 avg_loss_a: -73.16339106373972
Número de pasos del episodio 13851 son episode_steps:110
Total Steps: 942645 Episode Num: 13851 Reward: 73.14103959366224 avg_loss_c: 32.78438590656627 avg_loss_a: -72.50421364524148
Número de pasos del episodio 13852 son episode_steps:70
Total Steps: 942715 Episode Num: 13852 Reward: -59.131331839909215 avg_loss_c: 34.76561636243548 avg_loss_a: -72.60551343645368
Número de pasos del episodio 13853 son episode_steps:202
Total Steps: 942917 Episode Num: 13853 Reward: 130.89214900323702 avg_loss_c: 33.725284651954574 avg_loss_a: -72.30042342384263
Número de pasos del episodio 13854 son episode_steps:247
Total Steps: 943164 Episode Num: 13854 Reward: 190.4674334805922 avg_loss_c: 33.109697473193954 avg_loss_a: -73.90961545874715
Número de pasos del episodio 13855 son episode_steps:92
Total Steps: 943256 Episode Num: 13855 Reward: -5.123040042537467 avg_loss_c: 32.87404601470284 avg_loss_a: -73.14266038977581
Número de pasos del episodio 13856 son episode_steps:110
Total Steps: 943366 Episode Num: 13856 Reward: 70.4557601644932 avg_loss_c: 33.22036425850608 avg_loss_a: -72.98995541659268
Número de pasos del episodio 13857 son episode_steps:19
Total Steps: 943385 Episode Num: 13857 Reward: -34.33757676713521 avg_loss_c: 31.519368021111738 avg_loss_a: -72.02814523797286
Número de pasos del episodio 13858 son episode_steps:148
Total Steps: 943533 Episode Num: 13858 Reward: 61.3116224649212 avg_loss_c: 33.9854474067688 avg_loss_a: -73.65752050038931
Número de pasos del episodio 13859 son episode_steps:126
Total Steps: 943659 Episode Num: 13859 Reward: 39.89118609688002 avg_loss_c: 32.01543474954272 avg_loss_a: -73.53693002367777
Número de pasos del episodio 13860 son episode_steps:26
Total Steps: 943685 Episode Num: 13860 Reward: -40.263578190956906 avg_loss_c: 33.11091114924504 avg_loss_a: -73.44386643629808
Número de pasos del episodio 13861 son episode_steps:58
Total Steps: 943743 Episode Num: 13861 Reward: -21.419234391024077 avg_loss_c: 32.01612110795646 avg_loss_a: -73.3899365129142
Número de pasos del episodio 13862 son episode_steps:69
Total Steps: 943812 Episode Num: 13862 Reward: 28.718606147825586 avg_loss_c: 32.33596928914388 avg_loss_a: -73.72118488256483
Número de pasos del episodio 13863 son episode_steps:48
Total Steps: 943860 Episode Num: 13863 Reward: 14.350044482447583 avg_loss_c: 33.93387067317963 avg_loss_a: -73.38433074951172
Número de pasos del episodio 13864 son episode_steps:128
Total Steps: 943988 Episode Num: 13864 Reward: 73.46363740296938 avg_loss_c: 33.014543667435646 avg_loss_a: -74.5564888715744
Número de pasos del episodio 13865 son episode_steps:188
Total Steps: 944176 Episode Num: 13865 Reward: 139.8182774319832 avg_loss_c: 33.091967643575465 avg_loss_a: -73.62636744722407
Número de pasos del episodio 13866 son episode_steps:238
Total Steps: 944414 Episode Num: 13866 Reward: 179.6865975968805 avg_loss_c: 32.63026580489984 avg_loss_a: -73.83795621214794
Número de pasos del episodio 13867 son episode_steps:56
Total Steps: 944470 Episode Num: 13867 Reward: -2.0726922638069047 avg_loss_c: 31.134389298302786 avg_loss_a: -75.04927171979632
Número de pasos del episodio 13868 son episode_steps:75
Total Steps: 944545 Episode Num: 13868 Reward: 1.1942470452508709 avg_loss_c: 33.5181111907959 avg_loss_a: -73.47651611328125
Número de pasos del episodio 13869 son episode_steps:34
Total Steps: 944579 Episode Num: 13869 Reward: -44.870793839548746 avg_loss_c: 32.75486087799072 avg_loss_a: -75.05427596148323
Número de pasos del episodio 13870 son episode_steps:65
Total Steps: 944644 Episode Num: 13870 Reward: 15.996750483255518 avg_loss_c: 31.885430145263673 avg_loss_a: -75.21532311072717
Número de pasos del episodio 13871 son episode_steps:32
Total Steps: 944676 Episode Num: 13871 Reward: -54.768829731258144 avg_loss_c: 32.010938942432404 avg_loss_a: -73.86120891571045
Número de pasos del episodio 13872 son episode_steps:134
Total Steps: 944810 Episode Num: 13872 Reward: 5.288803562247574 avg_loss_c: 32.9321181880894 avg_loss_a: -74.22081272637666
Número de pasos del episodio 13873 son episode_steps:96
Total Steps: 944906 Episode Num: 13873 Reward: -18.823065701782646 avg_loss_c: 33.96745026111603 avg_loss_a: -74.45117966334026
Número de pasos del episodio 13874 son episode_steps:184
Total Steps: 945090 Episode Num: 13874 Reward: 96.0088507976296 avg_loss_c: 33.569518037464306 avg_loss_a: -74.33250468710195
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 32.153885
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13875 son episode_steps:79
Total Steps: 945169 Episode Num: 13875 Reward: -19.80421850421072 avg_loss_c: 33.43723888638653 avg_loss_a: -73.82905752447587
Número de pasos del episodio 13876 son episode_steps:102
Total Steps: 945271 Episode Num: 13876 Reward: 17.935747168706094 avg_loss_c: 33.2721014770807 avg_loss_a: -73.58389057832606
Número de pasos del episodio 13877 son episode_steps:43
Total Steps: 945314 Episode Num: 13877 Reward: -13.309245685070831 avg_loss_c: 34.76403422688329 avg_loss_a: -74.39519926559093
Número de pasos del episodio 13878 son episode_steps:37
Total Steps: 945351 Episode Num: 13878 Reward: -35.241002099751725 avg_loss_c: 34.61801281490841 avg_loss_a: -73.52366617563608
Número de pasos del episodio 13879 son episode_steps:36
Total Steps: 945387 Episode Num: 13879 Reward: -20.054776990402242 avg_loss_c: 32.780774964226616 avg_loss_a: -72.88681115044488
Número de pasos del episodio 13880 son episode_steps:31
Total Steps: 945418 Episode Num: 13880 Reward: -26.671514054757107 avg_loss_c: 35.64219247141192 avg_loss_a: -73.98106851885396
Número de pasos del episodio 13881 son episode_steps:31
Total Steps: 945449 Episode Num: 13881 Reward: -30.389700168320896 avg_loss_c: 33.67317605787708 avg_loss_a: -73.29398862777218
Número de pasos del episodio 13882 son episode_steps:39
Total Steps: 945488 Episode Num: 13882 Reward: -9.867655177777781 avg_loss_c: 34.4011159554506 avg_loss_a: -73.34115854899089
Número de pasos del episodio 13883 son episode_steps:48
Total Steps: 945536 Episode Num: 13883 Reward: 16.410997253644958 avg_loss_c: 33.30203608671824 avg_loss_a: -73.5747496287028
Número de pasos del episodio 13884 son episode_steps:195
Total Steps: 945731 Episode Num: 13884 Reward: 184.32656500371752 avg_loss_c: 34.065479141626604 avg_loss_a: -73.70923536251753
Número de pasos del episodio 13885 son episode_steps:295
Total Steps: 946026 Episode Num: 13885 Reward: 243.27210406182954 avg_loss_c: 33.68585769524009 avg_loss_a: -73.81511222710044
Número de pasos del episodio 13886 son episode_steps:150
Total Steps: 946176 Episode Num: 13886 Reward: 92.34065185770491 avg_loss_c: 32.61122628529866 avg_loss_a: -74.96495676676432
Número de pasos del episodio 13887 son episode_steps:47
Total Steps: 946223 Episode Num: 13887 Reward: -88.83227807810555 avg_loss_c: 33.5921882467067 avg_loss_a: -73.25557367852393
Número de pasos del episodio 13888 son episode_steps:53
Total Steps: 946276 Episode Num: 13888 Reward: 8.367740711362991 avg_loss_c: 33.55252805745827 avg_loss_a: -73.9421974038178
Número de pasos del episodio 13889 son episode_steps:157
Total Steps: 946433 Episode Num: 13889 Reward: 90.8361428862239 avg_loss_c: 33.866553057530886 avg_loss_a: -73.94745339557623
Número de pasos del episodio 13890 son episode_steps:49
Total Steps: 946482 Episode Num: 13890 Reward: -39.87837971472186 avg_loss_c: 31.81421758690659 avg_loss_a: -75.30508391711177
Número de pasos del episodio 13891 son episode_steps:51
Total Steps: 946533 Episode Num: 13891 Reward: -11.090855203704656 avg_loss_c: 32.82503969529096 avg_loss_a: -74.6114279055128
Número de pasos del episodio 13892 son episode_steps:82
Total Steps: 946615 Episode Num: 13892 Reward: -71.89939973397391 avg_loss_c: 34.41934059887397 avg_loss_a: -74.35108333680688
Número de pasos del episodio 13893 son episode_steps:145
Total Steps: 946760 Episode Num: 13893 Reward: 23.509643983967756 avg_loss_c: 33.786942093947836 avg_loss_a: -74.03573508427061
Número de pasos del episodio 13894 son episode_steps:130
Total Steps: 946890 Episode Num: 13894 Reward: 89.20950949856267 avg_loss_c: 34.710375330998346 avg_loss_a: -74.06900446965145
Número de pasos del episodio 13895 son episode_steps:47
Total Steps: 946937 Episode Num: 13895 Reward: -24.365779944033473 avg_loss_c: 33.52816147499896 avg_loss_a: -75.28307082805227
Número de pasos del episodio 13896 son episode_steps:137
Total Steps: 947074 Episode Num: 13896 Reward: 81.40440056773888 avg_loss_c: 34.05464470299491 avg_loss_a: -75.11724987169252
Número de pasos del episodio 13897 son episode_steps:50
Total Steps: 947124 Episode Num: 13897 Reward: 23.03416044863532 avg_loss_c: 33.09881633758545 avg_loss_a: -74.93938568115234
Número de pasos del episodio 13898 son episode_steps:274
Total Steps: 947398 Episode Num: 13898 Reward: 252.30582185492844 avg_loss_c: 33.30370406686825 avg_loss_a: -74.9121502507342
Número de pasos del episodio 13899 son episode_steps:90
Total Steps: 947488 Episode Num: 13899 Reward: 37.73200287431881 avg_loss_c: 33.24777632819281 avg_loss_a: -75.53397623697917
Número de pasos del episodio 13900 son episode_steps:51
Total Steps: 947539 Episode Num: 13900 Reward: -22.369360687183764 avg_loss_c: 33.92227337407131 avg_loss_a: -75.12838685278798
Número de pasos del episodio 13901 son episode_steps:52
Total Steps: 947591 Episode Num: 13901 Reward: -16.40327789226786 avg_loss_c: 33.88990248166598 avg_loss_a: -75.40333967942458
Número de pasos del episodio 13902 son episode_steps:93
Total Steps: 947684 Episode Num: 13902 Reward: 4.8856340043174775 avg_loss_c: 32.53876747623567 avg_loss_a: -76.32431120513588
Número de pasos del episodio 13903 son episode_steps:67
Total Steps: 947751 Episode Num: 13903 Reward: -51.197012733695615 avg_loss_c: 35.104575427610484 avg_loss_a: -75.60554424684439
Número de pasos del episodio 13904 son episode_steps:122
Total Steps: 947873 Episode Num: 13904 Reward: 35.387886147808125 avg_loss_c: 35.24613023976811 avg_loss_a: -75.3158369220671
Número de pasos del episodio 13905 son episode_steps:84
Total Steps: 947957 Episode Num: 13905 Reward: 23.366627102698583 avg_loss_c: 33.83994717825027 avg_loss_a: -75.66187504359654
Número de pasos del episodio 13906 son episode_steps:72
Total Steps: 948029 Episode Num: 13906 Reward: -10.198682710081378 avg_loss_c: 33.64611922370063 avg_loss_a: -75.40220027499728
Número de pasos del episodio 13907 son episode_steps:129
Total Steps: 948158 Episode Num: 13907 Reward: 100.67180555143877 avg_loss_c: 35.00371819133906 avg_loss_a: -75.13637483582016
Número de pasos del episodio 13908 son episode_steps:54
Total Steps: 948212 Episode Num: 13908 Reward: -5.39968291005229 avg_loss_c: 33.227839646516024 avg_loss_a: -75.03404009783709
Número de pasos del episodio 13909 son episode_steps:147
Total Steps: 948359 Episode Num: 13909 Reward: 75.69222942049164 avg_loss_c: 34.47912068269691 avg_loss_a: -74.98024926218046
Número de pasos del episodio 13910 son episode_steps:50
Total Steps: 948409 Episode Num: 13910 Reward: -47.99816852967197 avg_loss_c: 33.873418159484864 avg_loss_a: -75.33441864013672
Número de pasos del episodio 13911 son episode_steps:17
Total Steps: 948426 Episode Num: 13911 Reward: -54.58630410938159 avg_loss_c: 33.772620032815375 avg_loss_a: -76.40995743695427
Número de pasos del episodio 13912 son episode_steps:63
Total Steps: 948489 Episode Num: 13912 Reward: -35.59379523655169 avg_loss_c: 34.28237052190872 avg_loss_a: -74.54021817161923
Número de pasos del episodio 13913 son episode_steps:159
Total Steps: 948648 Episode Num: 13913 Reward: -9.158718581636162 avg_loss_c: 35.15885073583831 avg_loss_a: -75.80609452349584
Número de pasos del episodio 13914 son episode_steps:70
Total Steps: 948718 Episode Num: 13914 Reward: 10.4890100163161 avg_loss_c: 35.59696957724435 avg_loss_a: -74.16905604771205
Número de pasos del episodio 13915 son episode_steps:105
Total Steps: 948823 Episode Num: 13915 Reward: 43.88995412050043 avg_loss_c: 36.44910467238653 avg_loss_a: -74.51369178408669
Número de pasos del episodio 13916 son episode_steps:94
Total Steps: 948917 Episode Num: 13916 Reward: 37.03494309138933 avg_loss_c: 33.95408303686913 avg_loss_a: -74.82506447650016
Número de pasos del episodio 13917 son episode_steps:67
Total Steps: 948984 Episode Num: 13917 Reward: 1.9936730543015955 avg_loss_c: 34.594195693286494 avg_loss_a: -74.7347680846257
Número de pasos del episodio 13918 son episode_steps:72
Total Steps: 949056 Episode Num: 13918 Reward: -29.00653413619219 avg_loss_c: 34.46894852320353 avg_loss_a: -74.55408350626628
Número de pasos del episodio 13919 son episode_steps:182
Total Steps: 949238 Episode Num: 13919 Reward: 148.87610898356476 avg_loss_c: 35.287789229508284 avg_loss_a: -75.31590514130644
Número de pasos del episodio 13920 son episode_steps:23
Total Steps: 949261 Episode Num: 13920 Reward: -41.63605846756992 avg_loss_c: 36.60251169619353 avg_loss_a: -73.45082092285156
Número de pasos del episodio 13921 son episode_steps:141
Total Steps: 949402 Episode Num: 13921 Reward: 128.35850177292673 avg_loss_c: 34.83478201196549 avg_loss_a: -75.495684955137
Número de pasos del episodio 13922 son episode_steps:70
Total Steps: 949472 Episode Num: 13922 Reward: 36.903427055374785 avg_loss_c: 33.026812308175224 avg_loss_a: -74.97989741734096
Número de pasos del episodio 13923 son episode_steps:80
Total Steps: 949552 Episode Num: 13923 Reward: 21.12148372055487 avg_loss_c: 35.808980393409726 avg_loss_a: -75.30487041473388
Número de pasos del episodio 13924 son episode_steps:58
Total Steps: 949610 Episode Num: 13924 Reward: 17.797580862039126 avg_loss_c: 35.376997750380944 avg_loss_a: -77.25894875362002
Número de pasos del episodio 13925 son episode_steps:207
Total Steps: 949817 Episode Num: 13925 Reward: 195.5142738737276 avg_loss_c: 34.97115266956569 avg_loss_a: -76.17869958555065
Número de pasos del episodio 13926 son episode_steps:41
Total Steps: 949858 Episode Num: 13926 Reward: -44.70378470018785 avg_loss_c: 35.60517883300781 avg_loss_a: -74.597133729516
Número de pasos del episodio 13927 son episode_steps:32
Total Steps: 949890 Episode Num: 13927 Reward: -72.43358121557921 avg_loss_c: 34.76325339078903 avg_loss_a: -75.27934885025024
Número de pasos del episodio 13928 son episode_steps:100
Total Steps: 949990 Episode Num: 13928 Reward: 69.6373374921842 avg_loss_c: 33.93168876647949 avg_loss_a: -75.34428146362305
Número de pasos del episodio 13929 son episode_steps:62
Total Steps: 950052 Episode Num: 13929 Reward: -14.2313819099612 avg_loss_c: 33.661309334539595 avg_loss_a: -75.5666991203062
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 194.225018
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13930 son episode_steps:34
Total Steps: 950086 Episode Num: 13930 Reward: -44.9773497492313 avg_loss_c: 35.24701550427605 avg_loss_a: -74.7199841667624
Número de pasos del episodio 13931 son episode_steps:83
Total Steps: 950169 Episode Num: 13931 Reward: 26.940802393383827 avg_loss_c: 34.211360035172426 avg_loss_a: -76.57123620826077
Número de pasos del episodio 13932 son episode_steps:57
Total Steps: 950226 Episode Num: 13932 Reward: -12.19956632391772 avg_loss_c: 35.098485243947884 avg_loss_a: -76.38959409479509
Número de pasos del episodio 13933 son episode_steps:150
Total Steps: 950376 Episode Num: 13933 Reward: 92.76930643753799 avg_loss_c: 35.18907372792562 avg_loss_a: -76.19291788736979
Número de pasos del episodio 13934 son episode_steps:94
Total Steps: 950470 Episode Num: 13934 Reward: 3.076070882151483 avg_loss_c: 34.960356387686225 avg_loss_a: -76.28161345136927
Número de pasos del episodio 13935 son episode_steps:138
Total Steps: 950608 Episode Num: 13935 Reward: 82.56573495856445 avg_loss_c: 35.10465334463811 avg_loss_a: -76.89276465816775
Número de pasos del episodio 13936 son episode_steps:21
Total Steps: 950629 Episode Num: 13936 Reward: -37.29936874584577 avg_loss_c: 32.77672531491234 avg_loss_a: -76.08565848214286
Número de pasos del episodio 13937 son episode_steps:66
Total Steps: 950695 Episode Num: 13937 Reward: 17.540584524543686 avg_loss_c: 34.560506762880266 avg_loss_a: -75.34307502977776
Número de pasos del episodio 13938 son episode_steps:188
Total Steps: 950883 Episode Num: 13938 Reward: 138.9042136550574 avg_loss_c: 35.02147958633748 avg_loss_a: -76.67301632495636
Número de pasos del episodio 13939 son episode_steps:55
Total Steps: 950938 Episode Num: 13939 Reward: -11.955501799639913 avg_loss_c: 35.540988714044744 avg_loss_a: -76.95391068892046
Número de pasos del episodio 13940 son episode_steps:92
Total Steps: 951030 Episode Num: 13940 Reward: 40.98676212659494 avg_loss_c: 34.52538886277572 avg_loss_a: -77.19018123460853
Número de pasos del episodio 13941 son episode_steps:195
Total Steps: 951225 Episode Num: 13941 Reward: 180.41734452351258 avg_loss_c: 33.57693783686711 avg_loss_a: -76.43999723776793
Número de pasos del episodio 13942 son episode_steps:467
Total Steps: 951692 Episode Num: 13942 Reward: 424.40883030885124 avg_loss_c: 34.23105584579566 avg_loss_a: -77.5232212140167
Número de pasos del episodio 13943 son episode_steps:81
Total Steps: 951773 Episode Num: 13943 Reward: -2.5139709773391803 avg_loss_c: 33.22574271684812 avg_loss_a: -77.51139878637997
Número de pasos del episodio 13944 son episode_steps:54
Total Steps: 951827 Episode Num: 13944 Reward: -10.543837845050476 avg_loss_c: 34.75994184282091 avg_loss_a: -77.727948224103
Número de pasos del episodio 13945 son episode_steps:45
Total Steps: 951872 Episode Num: 13945 Reward: -43.86434324104227 avg_loss_c: 35.304891967773436 avg_loss_a: -77.43607923719618
Número de pasos del episodio 13946 son episode_steps:239
Total Steps: 952111 Episode Num: 13946 Reward: 226.83962449240116 avg_loss_c: 33.766371403777946 avg_loss_a: -78.11007712775195
Número de pasos del episodio 13947 son episode_steps:131
Total Steps: 952242 Episode Num: 13947 Reward: 50.34530100696734 avg_loss_c: 34.02929022111965 avg_loss_a: -77.90477962348298
Número de pasos del episodio 13948 son episode_steps:115
Total Steps: 952357 Episode Num: 13948 Reward: -15.878570167406904 avg_loss_c: 34.347952287093456 avg_loss_a: -77.42759260094684
Número de pasos del episodio 13949 son episode_steps:90
Total Steps: 952447 Episode Num: 13949 Reward: 36.69014089920128 avg_loss_c: 33.76855186886257 avg_loss_a: -77.35719943576389
Número de pasos del episodio 13950 son episode_steps:153
Total Steps: 952600 Episode Num: 13950 Reward: 122.94081056339985 avg_loss_c: 33.11998979406419 avg_loss_a: -77.63482162375855
Número de pasos del episodio 13951 son episode_steps:91
Total Steps: 952691 Episode Num: 13951 Reward: -24.110731165702607 avg_loss_c: 34.80468171507447 avg_loss_a: -77.89507427844373
Número de pasos del episodio 13952 son episode_steps:167
Total Steps: 952858 Episode Num: 13952 Reward: 131.58578653141961 avg_loss_c: 33.53652766793074 avg_loss_a: -77.76619464623
Número de pasos del episodio 13953 son episode_steps:59
Total Steps: 952917 Episode Num: 13953 Reward: -7.983808754873184 avg_loss_c: 33.28292345596572 avg_loss_a: -77.56596206406415
Número de pasos del episodio 13954 son episode_steps:197
Total Steps: 953114 Episode Num: 13954 Reward: 133.45804127682715 avg_loss_c: 33.26353530109231 avg_loss_a: -77.86905120229963
Número de pasos del episodio 13955 son episode_steps:98
Total Steps: 953212 Episode Num: 13955 Reward: 39.286008092176296 avg_loss_c: 32.56645517933126 avg_loss_a: -77.7123191989198
Número de pasos del episodio 13956 son episode_steps:92
Total Steps: 953304 Episode Num: 13956 Reward: 23.67312517341535 avg_loss_c: 33.67518346206002 avg_loss_a: -77.70892499840778
Número de pasos del episodio 13957 son episode_steps:148
Total Steps: 953452 Episode Num: 13957 Reward: 131.4773822527099 avg_loss_c: 32.820234195606126 avg_loss_a: -78.37151346979914
Número de pasos del episodio 13958 son episode_steps:52
Total Steps: 953504 Episode Num: 13958 Reward: -66.40143109802665 avg_loss_c: 33.920366287231445 avg_loss_a: -78.37446711613582
Número de pasos del episodio 13959 son episode_steps:142
Total Steps: 953646 Episode Num: 13959 Reward: 28.77555920883236 avg_loss_c: 34.608546888324575 avg_loss_a: -78.34177130040987
Número de pasos del episodio 13960 son episode_steps:118
Total Steps: 953764 Episode Num: 13960 Reward: 47.73652243402516 avg_loss_c: 34.05977326732571 avg_loss_a: -78.62645346431408
Número de pasos del episodio 13961 son episode_steps:74
Total Steps: 953838 Episode Num: 13961 Reward: 31.375247759530687 avg_loss_c: 33.281813595746016 avg_loss_a: -78.2283469535209
Número de pasos del episodio 13962 son episode_steps:49
Total Steps: 953887 Episode Num: 13962 Reward: 0.33496401184072866 avg_loss_c: 33.14964092021086 avg_loss_a: -77.22580563292212
Número de pasos del episodio 13963 son episode_steps:48
Total Steps: 953935 Episode Num: 13963 Reward: -3.72431930194779 avg_loss_c: 33.339409828186035 avg_loss_a: -78.47053050994873
Número de pasos del episodio 13964 son episode_steps:134
Total Steps: 954069 Episode Num: 13964 Reward: -7.481745522274563 avg_loss_c: 32.697150999040744 avg_loss_a: -77.82399396754023
Número de pasos del episodio 13965 son episode_steps:63
Total Steps: 954132 Episode Num: 13965 Reward: 12.030655416755339 avg_loss_c: 33.28593020968967 avg_loss_a: -78.37069811139789
Número de pasos del episodio 13966 son episode_steps:49
Total Steps: 954181 Episode Num: 13966 Reward: -37.65323327270605 avg_loss_c: 34.89127042342206 avg_loss_a: -77.37279354796118
Número de pasos del episodio 13967 son episode_steps:81
Total Steps: 954262 Episode Num: 13967 Reward: -71.09781527220811 avg_loss_c: 35.13236121189447 avg_loss_a: -77.52888865529755
Número de pasos del episodio 13968 son episode_steps:117
Total Steps: 954379 Episode Num: 13968 Reward: 86.2952569534993 avg_loss_c: 34.466763716477615 avg_loss_a: -77.38178246652978
Número de pasos del episodio 13969 son episode_steps:39
Total Steps: 954418 Episode Num: 13969 Reward: -3.4434226336421734 avg_loss_c: 34.366763579539764 avg_loss_a: -78.08085319323418
Número de pasos del episodio 13970 son episode_steps:68
Total Steps: 954486 Episode Num: 13970 Reward: 31.19585473173087 avg_loss_c: 35.289923471563 avg_loss_a: -77.37897401697495
Número de pasos del episodio 13971 son episode_steps:56
Total Steps: 954542 Episode Num: 13971 Reward: 11.809380528300249 avg_loss_c: 36.775860275541035 avg_loss_a: -77.08970669337681
Número de pasos del episodio 13972 son episode_steps:134
Total Steps: 954676 Episode Num: 13972 Reward: 59.51645928350882 avg_loss_c: 33.496231904670374 avg_loss_a: -77.1988268040899
Número de pasos del episodio 13973 son episode_steps:61
Total Steps: 954737 Episode Num: 13973 Reward: 14.622868014538927 avg_loss_c: 34.905204210125035 avg_loss_a: -77.61010754694703
Número de pasos del episodio 13974 son episode_steps:74
Total Steps: 954811 Episode Num: 13974 Reward: -51.36566205309798 avg_loss_c: 35.129743472949876 avg_loss_a: -77.57320816452439
Número de pasos del episodio 13975 son episode_steps:74
Total Steps: 954885 Episode Num: 13975 Reward: 10.760727350244458 avg_loss_c: 35.84336200920311 avg_loss_a: -76.51734285096865
Número de pasos del episodio 13976 son episode_steps:150
Total Steps: 955035 Episode Num: 13976 Reward: 71.4703637353923 avg_loss_c: 36.19194774627685 avg_loss_a: -76.77034739176432
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 131.522037
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 13977 son episode_steps:64
Total Steps: 955099 Episode Num: 13977 Reward: -2.088304891484319 avg_loss_c: 35.252441734075546 avg_loss_a: -76.7771372795105
Número de pasos del episodio 13978 son episode_steps:223
Total Steps: 955322 Episode Num: 13978 Reward: 116.42935184235179 avg_loss_c: 35.08641913546575 avg_loss_a: -77.79265197617056
Número de pasos del episodio 13979 son episode_steps:214
Total Steps: 955536 Episode Num: 13979 Reward: -10.8699921333486 avg_loss_c: 35.86069718476768 avg_loss_a: -76.9658312931239
Número de pasos del episodio 13980 son episode_steps:86
Total Steps: 955622 Episode Num: 13980 Reward: 21.122559792177945 avg_loss_c: 35.164857354275014 avg_loss_a: -76.59230573787245
Número de pasos del episodio 13981 son episode_steps:54
Total Steps: 955676 Episode Num: 13981 Reward: 14.967013448060936 avg_loss_c: 35.52010080549452 avg_loss_a: -78.50322327790437
Número de pasos del episodio 13982 son episode_steps:97
Total Steps: 955773 Episode Num: 13982 Reward: -8.382820338965907 avg_loss_c: 35.619296889944174 avg_loss_a: -78.34299610570534
Número de pasos del episodio 13983 son episode_steps:70
Total Steps: 955843 Episode Num: 13983 Reward: -4.576726111991677 avg_loss_c: 37.824523380824495 avg_loss_a: -76.78581368582589
Número de pasos del episodio 13984 son episode_steps:111
Total Steps: 955954 Episode Num: 13984 Reward: 22.619976746777997 avg_loss_c: 36.74610395689268 avg_loss_a: -77.44367994703688
Número de pasos del episodio 13985 son episode_steps:48
Total Steps: 956002 Episode Num: 13985 Reward: -18.89506563067416 avg_loss_c: 36.382115761439 avg_loss_a: -77.86194070180257
Número de pasos del episodio 13986 son episode_steps:64
Total Steps: 956066 Episode Num: 13986 Reward: -6.00969581740683 avg_loss_c: 35.89401814341545 avg_loss_a: -79.68454027175903
Número de pasos del episodio 13987 son episode_steps:150
Total Steps: 956216 Episode Num: 13987 Reward: 90.22995597820923 avg_loss_c: 35.65262238820394 avg_loss_a: -78.08723592122396
Número de pasos del episodio 13988 son episode_steps:52
Total Steps: 956268 Episode Num: 13988 Reward: 20.213041799421156 avg_loss_c: 35.43365588554969 avg_loss_a: -76.66592759352464
Número de pasos del episodio 13989 son episode_steps:85
Total Steps: 956353 Episode Num: 13989 Reward: 19.76572389778446 avg_loss_c: 34.55737991333008 avg_loss_a: -78.35628096636604
Número de pasos del episodio 13990 son episode_steps:24
Total Steps: 956377 Episode Num: 13990 Reward: -44.221193627599234 avg_loss_c: 39.41783459981283 avg_loss_a: -78.82291730244954
Número de pasos del episodio 13991 son episode_steps:50
Total Steps: 956427 Episode Num: 13991 Reward: -10.460706983738163 avg_loss_c: 38.338138008117674 avg_loss_a: -76.11182647705078
Número de pasos del episodio 13992 son episode_steps:76
Total Steps: 956503 Episode Num: 13992 Reward: 18.451331790891782 avg_loss_c: 35.519153218520316 avg_loss_a: -78.19619269120066
Número de pasos del episodio 13993 son episode_steps:50
Total Steps: 956553 Episode Num: 13993 Reward: 8.042061426544983 avg_loss_c: 36.75776763916016 avg_loss_a: -77.60760559082031
Número de pasos del episodio 13994 son episode_steps:42
Total Steps: 956595 Episode Num: 13994 Reward: -30.631676812927374 avg_loss_c: 35.792812483651296 avg_loss_a: -78.59012058803013
Número de pasos del episodio 13995 son episode_steps:235
Total Steps: 956830 Episode Num: 13995 Reward: 180.96323026211428 avg_loss_c: 37.01502579222334 avg_loss_a: -77.91992145294839
Número de pasos del episodio 13996 son episode_steps:170
Total Steps: 957000 Episode Num: 13996 Reward: 98.54006094315423 avg_loss_c: 34.8652551426607 avg_loss_a: -78.34020942239201
Número de pasos del episodio 13997 son episode_steps:124
Total Steps: 957124 Episode Num: 13997 Reward: 85.81564755488694 avg_loss_c: 35.72227305750693 avg_loss_a: -78.44305518365675
Número de pasos del episodio 13998 son episode_steps:201
Total Steps: 957325 Episode Num: 13998 Reward: 132.85652957836214 avg_loss_c: 35.24075822213396 avg_loss_a: -78.30387863235094
Número de pasos del episodio 13999 son episode_steps:69
Total Steps: 957394 Episode Num: 13999 Reward: -19.00574098292723 avg_loss_c: 34.838059549746305 avg_loss_a: -78.64190839684528
Número de pasos del episodio 14000 son episode_steps:70
Total Steps: 957464 Episode Num: 14000 Reward: -81.97478166539723 avg_loss_c: 36.921426854814804 avg_loss_a: -77.7076668875558
Número de pasos del episodio 14001 son episode_steps:33
Total Steps: 957497 Episode Num: 14001 Reward: -38.922728240455086 avg_loss_c: 36.16076544559363 avg_loss_a: -78.53757731119792
Número de pasos del episodio 14002 son episode_steps:206
Total Steps: 957703 Episode Num: 14002 Reward: 166.3318527682888 avg_loss_c: 35.65331932178979 avg_loss_a: -77.53355785480981
Número de pasos del episodio 14003 son episode_steps:48
Total Steps: 957751 Episode Num: 14003 Reward: -24.6192757048301 avg_loss_c: 36.7603592077891 avg_loss_a: -77.17548370361328
Número de pasos del episodio 14004 son episode_steps:82
Total Steps: 957833 Episode Num: 14004 Reward: 38.805479204449874 avg_loss_c: 34.711419105529785 avg_loss_a: -78.53998044642006
Número de pasos del episodio 14005 son episode_steps:63
Total Steps: 957896 Episode Num: 14005 Reward: -20.463696384150374 avg_loss_c: 35.035484556167845 avg_loss_a: -79.06201559399801
Número de pasos del episodio 14006 son episode_steps:72
Total Steps: 957968 Episode Num: 14006 Reward: -2.7111336087630686 avg_loss_c: 35.33777213096619 avg_loss_a: -77.63417519463434
Número de pasos del episodio 14007 son episode_steps:84
Total Steps: 958052 Episode Num: 14007 Reward: -32.51213036665437 avg_loss_c: 37.74082735606602 avg_loss_a: -78.29348791213263
Número de pasos del episodio 14008 son episode_steps:49
Total Steps: 958101 Episode Num: 14008 Reward: -8.769002494918317 avg_loss_c: 36.10561008842624 avg_loss_a: -76.80061464893575
Número de pasos del episodio 14009 son episode_steps:71
Total Steps: 958172 Episode Num: 14009 Reward: 28.146433842392174 avg_loss_c: 34.815630066562704 avg_loss_a: -79.59019104863556
Número de pasos del episodio 14010 son episode_steps:81
Total Steps: 958253 Episode Num: 14010 Reward: 7.551098339700522 avg_loss_c: 36.31397219057436 avg_loss_a: -78.45581855302976
Número de pasos del episodio 14011 son episode_steps:97
Total Steps: 958350 Episode Num: 14011 Reward: 52.6937928201663 avg_loss_c: 36.09082349796885 avg_loss_a: -77.9779597016954
Número de pasos del episodio 14012 son episode_steps:231
Total Steps: 958581 Episode Num: 14012 Reward: 199.45819632391644 avg_loss_c: 35.1770208945006 avg_loss_a: -77.64021037048076
Número de pasos del episodio 14013 son episode_steps:22
Total Steps: 958603 Episode Num: 14013 Reward: -40.40609227102204 avg_loss_c: 37.46118294108998 avg_loss_a: -77.69847453724255
Número de pasos del episodio 14014 son episode_steps:52
Total Steps: 958655 Episode Num: 14014 Reward: 23.210229634681063 avg_loss_c: 35.062833272493805 avg_loss_a: -78.747437110314
Número de pasos del episodio 14015 son episode_steps:105
Total Steps: 958760 Episode Num: 14015 Reward: 42.69095061559164 avg_loss_c: 36.198066620599654 avg_loss_a: -77.96890593029204
Número de pasos del episodio 14016 son episode_steps:148
Total Steps: 958908 Episode Num: 14016 Reward: 99.47702072620898 avg_loss_c: 35.10728526759792 avg_loss_a: -78.28898331925676
Número de pasos del episodio 14017 son episode_steps:125
Total Steps: 959033 Episode Num: 14017 Reward: 61.99652403946191 avg_loss_c: 36.46879678344727 avg_loss_a: -77.79222216796875
Número de pasos del episodio 14018 son episode_steps:112
Total Steps: 959145 Episode Num: 14018 Reward: 59.87225727684366 avg_loss_c: 35.371310336249216 avg_loss_a: -79.1451279776437
Número de pasos del episodio 14019 son episode_steps:47
Total Steps: 959192 Episode Num: 14019 Reward: -39.23552872498188 avg_loss_c: 35.62952678761584 avg_loss_a: -78.45035163392411
Número de pasos del episodio 14020 son episode_steps:47
Total Steps: 959239 Episode Num: 14020 Reward: -30.046959053783674 avg_loss_c: 37.70469564072629 avg_loss_a: -79.6127223562687
Número de pasos del episodio 14021 son episode_steps:58
Total Steps: 959297 Episode Num: 14021 Reward: 7.051688725329718 avg_loss_c: 36.06743894774338 avg_loss_a: -76.95666845913591
Número de pasos del episodio 14022 son episode_steps:72
Total Steps: 959369 Episode Num: 14022 Reward: -58.19926161748013 avg_loss_c: 39.38906608687507 avg_loss_a: -77.32571156819661
Número de pasos del episodio 14023 son episode_steps:144
Total Steps: 959513 Episode Num: 14023 Reward: 52.6616644332084 avg_loss_c: 37.5104073550966 avg_loss_a: -78.19596640268962
Número de pasos del episodio 14024 son episode_steps:196
Total Steps: 959709 Episode Num: 14024 Reward: 142.31480954310118 avg_loss_c: 38.43906297489088 avg_loss_a: -77.7041319243762
Número de pasos del episodio 14025 son episode_steps:60
Total Steps: 959769 Episode Num: 14025 Reward: -24.967149405662155 avg_loss_c: 36.25523335138957 avg_loss_a: -77.60995025634766
Número de pasos del episodio 14026 son episode_steps:110
Total Steps: 959879 Episode Num: 14026 Reward: 36.29471415540914 avg_loss_c: 37.17955287586559 avg_loss_a: -77.86764970259233
Número de pasos del episodio 14027 son episode_steps:177
Total Steps: 960056 Episode Num: 14027 Reward: 141.10266114503113 avg_loss_c: 35.15177821574238 avg_loss_a: -78.13314681403381
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 72.140659
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 14028 son episode_steps:74
Total Steps: 960130 Episode Num: 14028 Reward: -83.73283532897851 avg_loss_c: 38.172720135869206 avg_loss_a: -78.49495264001794
Número de pasos del episodio 14029 son episode_steps:99
Total Steps: 960229 Episode Num: 14029 Reward: 21.938340518199563 avg_loss_c: 36.5992519879582 avg_loss_a: -78.15210955070727
Número de pasos del episodio 14030 son episode_steps:177
Total Steps: 960406 Episode Num: 14030 Reward: 131.54984574874632 avg_loss_c: 37.06264892405709 avg_loss_a: -77.76435369286834
Número de pasos del episodio 14031 son episode_steps:153
Total Steps: 960559 Episode Num: 14031 Reward: 90.44429647919652 avg_loss_c: 37.398475584641 avg_loss_a: -78.58982270683339
Número de pasos del episodio 14032 son episode_steps:41
Total Steps: 960600 Episode Num: 14032 Reward: -53.879179705689 avg_loss_c: 35.48505187616116 avg_loss_a: -77.35957150342988
Número de pasos del episodio 14033 son episode_steps:28
Total Steps: 960628 Episode Num: 14033 Reward: -22.669126504041543 avg_loss_c: 36.6921272277832 avg_loss_a: -79.3662850516183
Número de pasos del episodio 14034 son episode_steps:78
Total Steps: 960706 Episode Num: 14034 Reward: 14.933294097699441 avg_loss_c: 35.52761931297107 avg_loss_a: -78.11320026104266
Número de pasos del episodio 14035 son episode_steps:74
Total Steps: 960780 Episode Num: 14035 Reward: 17.68945889973203 avg_loss_c: 38.00542439641179 avg_loss_a: -79.14207623455975
Número de pasos del episodio 14036 son episode_steps:112
Total Steps: 960892 Episode Num: 14036 Reward: -9.427808087114968 avg_loss_c: 37.978557756968904 avg_loss_a: -78.12691729409354
Número de pasos del episodio 14037 son episode_steps:18
Total Steps: 960910 Episode Num: 14037 Reward: -24.203670024052837 avg_loss_c: 37.737164391411675 avg_loss_a: -78.16100989447699
Número de pasos del episodio 14038 son episode_steps:162
Total Steps: 961072 Episode Num: 14038 Reward: 44.11491478949562 avg_loss_c: 37.29414055671221 avg_loss_a: -78.06115863941334
Número de pasos del episodio 14039 son episode_steps:90
Total Steps: 961162 Episode Num: 14039 Reward: -7.097070317661226 avg_loss_c: 38.07027969360352 avg_loss_a: -77.55161963568793
Número de pasos del episodio 14040 son episode_steps:200
Total Steps: 961362 Episode Num: 14040 Reward: 151.27960305254012 avg_loss_c: 37.19894059181213 avg_loss_a: -77.48064819335937
Número de pasos del episodio 14041 son episode_steps:83
Total Steps: 961445 Episode Num: 14041 Reward: 35.1222131392163 avg_loss_c: 36.84853792765055 avg_loss_a: -78.21806556058218
Número de pasos del episodio 14042 son episode_steps:68
Total Steps: 961513 Episode Num: 14042 Reward: 29.602640892499764 avg_loss_c: 36.80323247348561 avg_loss_a: -77.94775457943187
Número de pasos del episodio 14043 son episode_steps:75
Total Steps: 961588 Episode Num: 14043 Reward: 31.314988154502544 avg_loss_c: 37.73222262064616 avg_loss_a: -78.69618520100911
Número de pasos del episodio 14044 son episode_steps:115
Total Steps: 961703 Episode Num: 14044 Reward: -40.68238411114295 avg_loss_c: 37.97529406340226 avg_loss_a: -78.12053262461787
Número de pasos del episodio 14045 son episode_steps:57
Total Steps: 961760 Episode Num: 14045 Reward: -36.93075028252213 avg_loss_c: 35.435582980774996 avg_loss_a: -77.94929116232353
Número de pasos del episodio 14046 son episode_steps:136
Total Steps: 961896 Episode Num: 14046 Reward: 14.014263049727152 avg_loss_c: 37.81886609862833 avg_loss_a: -77.70973385081572
Número de pasos del episodio 14047 son episode_steps:152
Total Steps: 962048 Episode Num: 14047 Reward: 104.6506939495851 avg_loss_c: 36.434060498287806 avg_loss_a: -78.20221629895661
Número de pasos del episodio 14048 son episode_steps:78
Total Steps: 962126 Episode Num: 14048 Reward: 15.6342450926149 avg_loss_c: 36.778932449145195 avg_loss_a: -77.99966665414664
Número de pasos del episodio 14049 son episode_steps:132
Total Steps: 962258 Episode Num: 14049 Reward: 60.36343759177178 avg_loss_c: 37.25738197384459 avg_loss_a: -79.65970403497869
Número de pasos del episodio 14050 son episode_steps:31
Total Steps: 962289 Episode Num: 14050 Reward: -7.803346964784761 avg_loss_c: 40.34687152985604 avg_loss_a: -77.64903283888295
Número de pasos del episodio 14051 son episode_steps:33
Total Steps: 962322 Episode Num: 14051 Reward: -42.39070410858629 avg_loss_c: 38.320494160507664 avg_loss_a: -78.56953869443952
Número de pasos del episodio 14052 son episode_steps:52
Total Steps: 962374 Episode Num: 14052 Reward: -28.68639100018832 avg_loss_c: 39.52422310755803 avg_loss_a: -79.40568923950195
Número de pasos del episodio 14053 son episode_steps:53
Total Steps: 962427 Episode Num: 14053 Reward: -18.9576759360763 avg_loss_c: 36.919442338763545 avg_loss_a: -78.29502983813016
Número de pasos del episodio 14054 son episode_steps:269
Total Steps: 962696 Episode Num: 14054 Reward: 169.19412466381922 avg_loss_c: 38.163726572653616 avg_loss_a: -77.23474688334979
Número de pasos del episodio 14055 son episode_steps:18
Total Steps: 962714 Episode Num: 14055 Reward: -35.34529921854984 avg_loss_c: 38.54277875688341 avg_loss_a: -75.55124918619792
Número de pasos del episodio 14056 son episode_steps:113
Total Steps: 962827 Episode Num: 14056 Reward: 32.0819026957342 avg_loss_c: 40.82425038160476 avg_loss_a: -77.61029147257847
Número de pasos del episodio 14057 son episode_steps:323
Total Steps: 963150 Episode Num: 14057 Reward: 249.59993927792323 avg_loss_c: 38.5500389488858 avg_loss_a: -77.71434261924342
Número de pasos del episodio 14058 son episode_steps:111
Total Steps: 963261 Episode Num: 14058 Reward: 66.19957516906491 avg_loss_c: 37.9051375517974 avg_loss_a: -78.39931481163781
Número de pasos del episodio 14059 son episode_steps:91
Total Steps: 963352 Episode Num: 14059 Reward: 31.025937061464226 avg_loss_c: 39.06966159107921 avg_loss_a: -77.55794567066235
Número de pasos del episodio 14060 son episode_steps:51
Total Steps: 963403 Episode Num: 14060 Reward: -10.538237274657611 avg_loss_c: 36.97663325889438 avg_loss_a: -77.99525421740962
Número de pasos del episodio 14061 son episode_steps:159
Total Steps: 963562 Episode Num: 14061 Reward: 107.56978377876263 avg_loss_c: 38.0952695930529 avg_loss_a: -78.38847274300437
Número de pasos del episodio 14062 son episode_steps:31
Total Steps: 963593 Episode Num: 14062 Reward: -25.864306316672106 avg_loss_c: 37.03778402266964 avg_loss_a: -78.20838312948904
Número de pasos del episodio 14063 son episode_steps:75
Total Steps: 963668 Episode Num: 14063 Reward: -31.057582145124528 avg_loss_c: 37.79139971415202 avg_loss_a: -78.56650736490886
Número de pasos del episodio 14064 son episode_steps:203
Total Steps: 963871 Episode Num: 14064 Reward: 172.5923337189763 avg_loss_c: 37.70358951925644 avg_loss_a: -78.29679009949632
Número de pasos del episodio 14065 son episode_steps:56
Total Steps: 963927 Episode Num: 14065 Reward: 2.7467955438288847 avg_loss_c: 38.01419711112976 avg_loss_a: -78.14900888715472
Número de pasos del episodio 14066 son episode_steps:117
Total Steps: 964044 Episode Num: 14066 Reward: 72.63626389079045 avg_loss_c: 37.62278802985819 avg_loss_a: -77.67879186124883
Número de pasos del episodio 14067 son episode_steps:66
Total Steps: 964110 Episode Num: 14067 Reward: 9.899419906985823 avg_loss_c: 39.33994469498143 avg_loss_a: -79.82318207711884
Número de pasos del episodio 14068 son episode_steps:375
Total Steps: 964485 Episode Num: 14068 Reward: 318.65909813061364 avg_loss_c: 37.37531490071615 avg_loss_a: -78.75654852294922
Número de pasos del episodio 14069 son episode_steps:49
Total Steps: 964534 Episode Num: 14069 Reward: -47.749415204084485 avg_loss_c: 37.283969723448465 avg_loss_a: -77.4863883816466
Número de pasos del episodio 14070 son episode_steps:101
Total Steps: 964635 Episode Num: 14070 Reward: 37.841542388136325 avg_loss_c: 35.92201436864268 avg_loss_a: -79.55339775463142
Número de pasos del episodio 14071 son episode_steps:89
Total Steps: 964724 Episode Num: 14071 Reward: 32.79405750292533 avg_loss_c: 37.31525491864494 avg_loss_a: -78.55550898862688
Número de pasos del episodio 14072 son episode_steps:69
Total Steps: 964793 Episode Num: 14072 Reward: 13.637276432777703 avg_loss_c: 37.377970571103305 avg_loss_a: -78.49457981275475
Número de pasos del episodio 14073 son episode_steps:291
Total Steps: 965084 Episode Num: 14073 Reward: 217.31542171620305 avg_loss_c: 36.94858231823059 avg_loss_a: -79.26413391218152
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 332.012122
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 14074 son episode_steps:83
Total Steps: 965167 Episode Num: 14074 Reward: -29.560568437728968 avg_loss_c: 35.749286858432264 avg_loss_a: -80.13631200215903
Número de pasos del episodio 14075 son episode_steps:139
Total Steps: 965306 Episode Num: 14075 Reward: 27.663174538386656 avg_loss_c: 38.887159484753504 avg_loss_a: -78.1936015396667
Número de pasos del episodio 14076 son episode_steps:72
Total Steps: 965378 Episode Num: 14076 Reward: 25.010261231498674 avg_loss_c: 37.837105698055694 avg_loss_a: -79.81210009256999
Número de pasos del episodio 14077 son episode_steps:177
Total Steps: 965555 Episode Num: 14077 Reward: 105.0353839646462 avg_loss_c: 37.11261158743821 avg_loss_a: -79.24215418066682
Número de pasos del episodio 14078 son episode_steps:49
Total Steps: 965604 Episode Num: 14078 Reward: -7.415860690973303 avg_loss_c: 37.83192498343332 avg_loss_a: -79.2996234504544
Número de pasos del episodio 14079 son episode_steps:72
Total Steps: 965676 Episode Num: 14079 Reward: 27.164025386187745 avg_loss_c: 37.15639681286282 avg_loss_a: -78.59465514289008
Número de pasos del episodio 14080 son episode_steps:132
Total Steps: 965808 Episode Num: 14080 Reward: 96.14870667089109 avg_loss_c: 37.22058047670306 avg_loss_a: -80.63011354388613
Número de pasos del episodio 14081 son episode_steps:71
Total Steps: 965879 Episode Num: 14081 Reward: -5.849496006821159 avg_loss_c: 38.206671513302226 avg_loss_a: -80.2768984512544
Número de pasos del episodio 14082 son episode_steps:53
Total Steps: 965932 Episode Num: 14082 Reward: -34.78545252130351 avg_loss_c: 40.048562787613776 avg_loss_a: -79.96795553531287
Número de pasos del episodio 14083 son episode_steps:58
Total Steps: 965990 Episode Num: 14083 Reward: -17.950343600822222 avg_loss_c: 37.06891359131912 avg_loss_a: -78.95805832435344
Número de pasos del episodio 14084 son episode_steps:38
Total Steps: 966028 Episode Num: 14084 Reward: -59.73370614537011 avg_loss_c: 41.02671608171965 avg_loss_a: -77.4854238409745
Número de pasos del episodio 14085 son episode_steps:77
Total Steps: 966105 Episode Num: 14085 Reward: 25.193700283003174 avg_loss_c: 38.86272185189383 avg_loss_a: -78.11737882936156
Número de pasos del episodio 14086 son episode_steps:94
Total Steps: 966199 Episode Num: 14086 Reward: 54.228218664499124 avg_loss_c: 38.98793553291483 avg_loss_a: -78.58893017058676
Número de pasos del episodio 14087 son episode_steps:49
Total Steps: 966248 Episode Num: 14087 Reward: -21.55384108820771 avg_loss_c: 42.00082074379434 avg_loss_a: -78.15037863595145
Número de pasos del episodio 14088 son episode_steps:298
Total Steps: 966546 Episode Num: 14088 Reward: 263.93921801507486 avg_loss_c: 38.732449928386096 avg_loss_a: -78.91336033968318
Número de pasos del episodio 14089 son episode_steps:72
Total Steps: 966618 Episode Num: 14089 Reward: 30.584006056112926 avg_loss_c: 38.22265760103861 avg_loss_a: -78.11868095397949
Número de pasos del episodio 14090 son episode_steps:70
Total Steps: 966688 Episode Num: 14090 Reward: 8.140281117467634 avg_loss_c: 38.495239067077634 avg_loss_a: -78.34270717075893
Número de pasos del episodio 14091 son episode_steps:229
Total Steps: 966917 Episode Num: 14091 Reward: 134.28703937918888 avg_loss_c: 37.246220451255034 avg_loss_a: -79.50204297861157
Número de pasos del episodio 14092 son episode_steps:440
Total Steps: 967357 Episode Num: 14092 Reward: 329.84061779817483 avg_loss_c: 37.14628001559864 avg_loss_a: -79.19774173389781
Número de pasos del episodio 14093 son episode_steps:112
Total Steps: 967469 Episode Num: 14093 Reward: 85.34396526802098 avg_loss_c: 36.32003215381077 avg_loss_a: -79.595153263637
Número de pasos del episodio 14094 son episode_steps:84
Total Steps: 967553 Episode Num: 14094 Reward: 37.68530633048047 avg_loss_c: 36.069648674556184 avg_loss_a: -80.35691415695916
Número de pasos del episodio 14095 son episode_steps:120
Total Steps: 967673 Episode Num: 14095 Reward: 58.126231145688614 avg_loss_c: 36.20251310666402 avg_loss_a: -79.5019957224528
Número de pasos del episodio 14096 son episode_steps:43
Total Steps: 967716 Episode Num: 14096 Reward: -26.66127555762735 avg_loss_c: 35.814767748810524 avg_loss_a: -79.7143625658612
Número de pasos del episodio 14097 son episode_steps:146
Total Steps: 967862 Episode Num: 14097 Reward: 95.9669287298335 avg_loss_c: 37.22305508182473 avg_loss_a: -79.4788016750388
Número de pasos del episodio 14098 son episode_steps:42
Total Steps: 967904 Episode Num: 14098 Reward: -4.972540688527214 avg_loss_c: 34.64523083823068 avg_loss_a: -78.84092748732795
Número de pasos del episodio 14099 son episode_steps:53
Total Steps: 967957 Episode Num: 14099 Reward: -19.935503565713358 avg_loss_c: 36.20809778177513 avg_loss_a: -79.92350625092129
Número de pasos del episodio 14100 son episode_steps:71
Total Steps: 968028 Episode Num: 14100 Reward: -42.4231169973493 avg_loss_c: 37.87649538819219 avg_loss_a: -80.10917760284853
Número de pasos del episodio 14101 son episode_steps:44
Total Steps: 968072 Episode Num: 14101 Reward: 26.241531121556747 avg_loss_c: 37.05752164667303 avg_loss_a: -80.06661432439631
Número de pasos del episodio 14102 son episode_steps:111
Total Steps: 968183 Episode Num: 14102 Reward: 57.05938792700425 avg_loss_c: 36.687536377090595 avg_loss_a: -79.77865744925835
Número de pasos del episodio 14103 son episode_steps:113
Total Steps: 968296 Episode Num: 14103 Reward: 86.77027547642518 avg_loss_c: 36.25570736100188 avg_loss_a: -79.53636554279159
Número de pasos del episodio 14104 son episode_steps:66
Total Steps: 968362 Episode Num: 14104 Reward: 19.877511250671063 avg_loss_c: 38.51885729125052 avg_loss_a: -79.22413982044567
Número de pasos del episodio 14105 son episode_steps:71
Total Steps: 968433 Episode Num: 14105 Reward: 31.61912107835451 avg_loss_c: 34.9318866998377 avg_loss_a: -79.25374248665823
Número de pasos del episodio 14106 son episode_steps:79
Total Steps: 968512 Episode Num: 14106 Reward: -7.329679903137104 avg_loss_c: 36.89929073671751 avg_loss_a: -79.0038569969467
Número de pasos del episodio 14107 son episode_steps:100
Total Steps: 968612 Episode Num: 14107 Reward: 52.125612088436604 avg_loss_c: 36.72304988861084 avg_loss_a: -79.80773712158204
Número de pasos del episodio 14108 son episode_steps:49
Total Steps: 968661 Episode Num: 14108 Reward: -70.17573591789476 avg_loss_c: 37.96528279051489 avg_loss_a: -79.81094469342914
Número de pasos del episodio 14109 son episode_steps:38
Total Steps: 968699 Episode Num: 14109 Reward: -6.782023356857021 avg_loss_c: 37.32785671635678 avg_loss_a: -79.15736750552529
Número de pasos del episodio 14110 son episode_steps:72
Total Steps: 968771 Episode Num: 14110 Reward: -19.74173498830267 avg_loss_c: 36.25379414028592 avg_loss_a: -79.79926300048828
Número de pasos del episodio 14111 son episode_steps:120
Total Steps: 968891 Episode Num: 14111 Reward: 47.51584746228044 avg_loss_c: 35.942582782109575 avg_loss_a: -78.7684331258138
Número de pasos del episodio 14112 son episode_steps:65
Total Steps: 968956 Episode Num: 14112 Reward: -8.327712018144487 avg_loss_c: 37.89266234177809 avg_loss_a: -80.54766176663912
Número de pasos del episodio 14113 son episode_steps:64
Total Steps: 969020 Episode Num: 14113 Reward: 13.84983849438319 avg_loss_c: 36.61333453655243 avg_loss_a: -79.16092133522034
Número de pasos del episodio 14114 son episode_steps:47
Total Steps: 969067 Episode Num: 14114 Reward: -0.7443770424376597 avg_loss_c: 38.22408943987907 avg_loss_a: -80.11208246109334
Número de pasos del episodio 14115 son episode_steps:48
Total Steps: 969115 Episode Num: 14115 Reward: -27.965737872561693 avg_loss_c: 37.1512496471405 avg_loss_a: -79.43908596038818
Número de pasos del episodio 14116 son episode_steps:353
Total Steps: 969468 Episode Num: 14116 Reward: 252.338194401985 avg_loss_c: 37.24924246920405 avg_loss_a: -79.80668471555197
Número de pasos del episodio 14117 son episode_steps:60
Total Steps: 969528 Episode Num: 14117 Reward: -6.8474740515879295 avg_loss_c: 38.59722884496053 avg_loss_a: -79.52628631591797
Número de pasos del episodio 14118 son episode_steps:128
Total Steps: 969656 Episode Num: 14118 Reward: 56.01681436255002 avg_loss_c: 37.173944145441055 avg_loss_a: -79.1367654800415
Número de pasos del episodio 14119 son episode_steps:143
Total Steps: 969799 Episode Num: 14119 Reward: 82.40623991461706 avg_loss_c: 37.712647831523334 avg_loss_a: -79.45067073581936
Número de pasos del episodio 14120 son episode_steps:186
Total Steps: 969985 Episode Num: 14120 Reward: 127.26309356243833 avg_loss_c: 37.050256554798416 avg_loss_a: -79.72538544029318
Número de pasos del episodio 14121 son episode_steps:81
Total Steps: 970066 Episode Num: 14121 Reward: -13.934479648137355 avg_loss_c: 37.24709428386924 avg_loss_a: -80.0496967456959
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 92.957787
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 14122 son episode_steps:125
Total Steps: 970191 Episode Num: 14122 Reward: -3.0078674927435896 avg_loss_c: 39.37898794555664 avg_loss_a: -80.15694030761719
Número de pasos del episodio 14123 son episode_steps:33
Total Steps: 970224 Episode Num: 14123 Reward: -58.674274895524526 avg_loss_c: 38.858292030565664 avg_loss_a: -80.76688685561672
Número de pasos del episodio 14124 son episode_steps:55
Total Steps: 970279 Episode Num: 14124 Reward: -40.27818641884607 avg_loss_c: 39.33769611011852 avg_loss_a: -78.78350524902343
Número de pasos del episodio 14125 son episode_steps:82
Total Steps: 970361 Episode Num: 14125 Reward: 41.273992218248985 avg_loss_c: 36.766586420012686 avg_loss_a: -81.94497717880621
Número de pasos del episodio 14126 son episode_steps:74
Total Steps: 970435 Episode Num: 14126 Reward: 4.844355969545317 avg_loss_c: 38.89311994088663 avg_loss_a: -79.66904428842905
Número de pasos del episodio 14127 son episode_steps:61
Total Steps: 970496 Episode Num: 14127 Reward: -2.674980960878505 avg_loss_c: 39.1314332680624 avg_loss_a: -79.56163750320185
Número de pasos del episodio 14128 son episode_steps:62
Total Steps: 970558 Episode Num: 14128 Reward: -39.63591893384411 avg_loss_c: 37.414338481041696 avg_loss_a: -78.0702416204637
Número de pasos del episodio 14129 son episode_steps:132
Total Steps: 970690 Episode Num: 14129 Reward: -7.874363571099917 avg_loss_c: 40.5571715037028 avg_loss_a: -80.03997536861536
Número de pasos del episodio 14130 son episode_steps:74
Total Steps: 970764 Episode Num: 14130 Reward: -0.27848844496488034 avg_loss_c: 40.23258320060936 avg_loss_a: -79.22434399579022
Número de pasos del episodio 14131 son episode_steps:158
Total Steps: 970922 Episode Num: 14131 Reward: 90.00652878598287 avg_loss_c: 40.60386034808582 avg_loss_a: -79.28692955306813
Número de pasos del episodio 14132 son episode_steps:53
Total Steps: 970975 Episode Num: 14132 Reward: 7.359277023736825 avg_loss_c: 39.59562064116856 avg_loss_a: -78.365234375
Número de pasos del episodio 14133 son episode_steps:81
Total Steps: 971056 Episode Num: 14133 Reward: 24.681689342253406 avg_loss_c: 39.053958162849334 avg_loss_a: -78.53667063771942
Número de pasos del episodio 14134 son episode_steps:60
Total Steps: 971116 Episode Num: 14134 Reward: -3.109836180677582 avg_loss_c: 41.84804865519206 avg_loss_a: -78.29920832316081
Número de pasos del episodio 14135 son episode_steps:119
Total Steps: 971235 Episode Num: 14135 Reward: 63.56796205454564 avg_loss_c: 37.431351381189685 avg_loss_a: -79.63332206661961
Número de pasos del episodio 14136 son episode_steps:101
Total Steps: 971336 Episode Num: 14136 Reward: 2.3481206797084253 avg_loss_c: 40.932945836888685 avg_loss_a: -78.67647582705658
Número de pasos del episodio 14137 son episode_steps:11
Total Steps: 971347 Episode Num: 14137 Reward: -60.62782092691492 avg_loss_c: 41.95868960293856 avg_loss_a: -78.71231148459695
Número de pasos del episodio 14138 son episode_steps:115
Total Steps: 971462 Episode Num: 14138 Reward: 37.897990288781976 avg_loss_c: 42.55496456312097 avg_loss_a: -78.96891214121943
Número de pasos del episodio 14139 son episode_steps:63
Total Steps: 971525 Episode Num: 14139 Reward: 1.7639410200477164 avg_loss_c: 39.606721151442756 avg_loss_a: -77.5155759538923
Número de pasos del episodio 14140 son episode_steps:42
Total Steps: 971567 Episode Num: 14140 Reward: -12.334080016313003 avg_loss_c: 41.80647981734503 avg_loss_a: -77.80000632149833
Número de pasos del episodio 14141 son episode_steps:14
Total Steps: 971581 Episode Num: 14141 Reward: -53.3239803708033 avg_loss_c: 37.906287738255095 avg_loss_a: -79.4447740827288
Número de pasos del episodio 14142 son episode_steps:19
Total Steps: 971600 Episode Num: 14142 Reward: -34.952401490565 avg_loss_c: 40.77141008879009 avg_loss_a: -80.29058717426501
Número de pasos del episodio 14143 son episode_steps:157
Total Steps: 971757 Episode Num: 14143 Reward: -15.255636410889355 avg_loss_c: 41.32969435916585 avg_loss_a: -77.34718590025689
Número de pasos del episodio 14144 son episode_steps:31
Total Steps: 971788 Episode Num: 14144 Reward: -55.25890237599319 avg_loss_c: 46.96757482713269 avg_loss_a: -77.07134148382372
Número de pasos del episodio 14145 son episode_steps:46
Total Steps: 971834 Episode Num: 14145 Reward: -24.74466201126243 avg_loss_c: 41.7140530295994 avg_loss_a: -77.89015562637992
Número de pasos del episodio 14146 son episode_steps:96
Total Steps: 971930 Episode Num: 14146 Reward: 35.926293282061565 avg_loss_c: 42.057618498802185 avg_loss_a: -77.9291745821635
Número de pasos del episodio 14147 son episode_steps:65
Total Steps: 971995 Episode Num: 14147 Reward: -9.285821207853392 avg_loss_c: 40.79529160719652 avg_loss_a: -77.84010913555439
Número de pasos del episodio 14148 son episode_steps:74
Total Steps: 972069 Episode Num: 14148 Reward: 31.29252765257519 avg_loss_c: 39.64041846507305 avg_loss_a: -78.23119869747677
Número de pasos del episodio 14149 son episode_steps:125
Total Steps: 972194 Episode Num: 14149 Reward: 40.095478980255415 avg_loss_c: 42.11228691101074 avg_loss_a: -77.8621669921875
Número de pasos del episodio 14150 son episode_steps:189
Total Steps: 972383 Episode Num: 14150 Reward: 157.80650995204817 avg_loss_c: 41.5378812255052 avg_loss_a: -78.30826055940497
Número de pasos del episodio 14151 son episode_steps:23
Total Steps: 972406 Episode Num: 14151 Reward: -44.05471224913656 avg_loss_c: 39.173983200736664 avg_loss_a: -76.38680167820142
Número de pasos del episodio 14152 son episode_steps:109
Total Steps: 972515 Episode Num: 14152 Reward: 39.91122728617982 avg_loss_c: 41.18906798056506 avg_loss_a: -77.11860047786608
Número de pasos del episodio 14153 son episode_steps:154
Total Steps: 972669 Episode Num: 14153 Reward: 112.66266202008275 avg_loss_c: 41.29467415499997 avg_loss_a: -76.95448788729581
Número de pasos del episodio 14154 son episode_steps:40
Total Steps: 972709 Episode Num: 14154 Reward: -40.853273976294076 avg_loss_c: 38.63607940673828 avg_loss_a: -79.11335678100586
Número de pasos del episodio 14155 son episode_steps:59
Total Steps: 972768 Episode Num: 14155 Reward: -66.02021883733019 avg_loss_c: 39.24073600769043 avg_loss_a: -78.5460744308213
Número de pasos del episodio 14156 son episode_steps:130
Total Steps: 972898 Episode Num: 14156 Reward: 40.15971089420999 avg_loss_c: 40.135208819462704 avg_loss_a: -77.47906752366286
Número de pasos del episodio 14157 son episode_steps:131
Total Steps: 973029 Episode Num: 14157 Reward: 108.00685872208766 avg_loss_c: 40.57420649055306 avg_loss_a: -77.54412981572042
Número de pasos del episodio 14158 son episode_steps:65
Total Steps: 973094 Episode Num: 14158 Reward: -41.63094054166033 avg_loss_c: 40.039628425011266 avg_loss_a: -77.43244018554688
Número de pasos del episodio 14159 son episode_steps:106
Total Steps: 973200 Episode Num: 14159 Reward: 17.571693691564114 avg_loss_c: 39.981498412366186 avg_loss_a: -77.2739243417416
Número de pasos del episodio 14160 son episode_steps:85
Total Steps: 973285 Episode Num: 14160 Reward: -83.5836760545904 avg_loss_c: 41.167530957390284 avg_loss_a: -77.16019493551815
Número de pasos del episodio 14161 son episode_steps:295
Total Steps: 973580 Episode Num: 14161 Reward: 265.5801526968557 avg_loss_c: 40.70760609901558 avg_loss_a: -77.72541286662474
Número de pasos del episodio 14162 son episode_steps:61
Total Steps: 973641 Episode Num: 14162 Reward: -25.34640203061606 avg_loss_c: 38.203563252433405 avg_loss_a: -77.20940624299597
Número de pasos del episodio 14163 son episode_steps:228
Total Steps: 973869 Episode Num: 14163 Reward: 139.85886732371193 avg_loss_c: 38.308740507092395 avg_loss_a: -77.8295843559399
Número de pasos del episodio 14164 son episode_steps:261
Total Steps: 974130 Episode Num: 14164 Reward: 166.8907123530304 avg_loss_c: 38.18106484687191 avg_loss_a: -79.00461990531834
Número de pasos del episodio 14165 son episode_steps:194
Total Steps: 974324 Episode Num: 14165 Reward: 146.11500730854314 avg_loss_c: 38.70806218176773 avg_loss_a: -78.99503861260169
Número de pasos del episodio 14166 son episode_steps:186
Total Steps: 974510 Episode Num: 14166 Reward: 123.88105373640636 avg_loss_c: 38.164262443460444 avg_loss_a: -78.70565738472887
Número de pasos del episodio 14167 son episode_steps:314
Total Steps: 974824 Episode Num: 14167 Reward: 172.9510921098269 avg_loss_c: 38.22378735633413 avg_loss_a: -79.06080437921415
Número de pasos del episodio 14168 son episode_steps:39
Total Steps: 974863 Episode Num: 14168 Reward: -33.5005530667019 avg_loss_c: 38.66121918115861 avg_loss_a: -78.54562632242839
Número de pasos del episodio 14169 son episode_steps:55
Total Steps: 974918 Episode Num: 14169 Reward: -20.950797975163567 avg_loss_c: 37.6439076163552 avg_loss_a: -78.99276927601207
Número de pasos del episodio 14170 son episode_steps:113
Total Steps: 975031 Episode Num: 14170 Reward: -17.679442949841196 avg_loss_c: 37.633261030754156 avg_loss_a: -78.89575148050764
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 127.721283
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 14171 son episode_steps:100
Total Steps: 975131 Episode Num: 14171 Reward: 35.334881877929654 avg_loss_c: 38.307103843688964 avg_loss_a: -77.76172073364258
Número de pasos del episodio 14172 son episode_steps:74
Total Steps: 975205 Episode Num: 14172 Reward: -11.086540352049122 avg_loss_c: 38.112823795627904 avg_loss_a: -78.69488793450432
Número de pasos del episodio 14173 son episode_steps:59
Total Steps: 975264 Episode Num: 14173 Reward: 22.0853457814823 avg_loss_c: 37.822271734981214 avg_loss_a: -79.44878878835904
Número de pasos del episodio 14174 son episode_steps:122
Total Steps: 975386 Episode Num: 14174 Reward: 80.8608193329014 avg_loss_c: 37.54948136063873 avg_loss_a: -78.60569700647574
Número de pasos del episodio 14175 son episode_steps:78
Total Steps: 975464 Episode Num: 14175 Reward: -27.785323019587736 avg_loss_c: 38.95850558158679 avg_loss_a: -77.36761748485075
Número de pasos del episodio 14176 son episode_steps:78
Total Steps: 975542 Episode Num: 14176 Reward: 14.214932045835901 avg_loss_c: 37.73126883384509 avg_loss_a: -79.66622357490735
Número de pasos del episodio 14177 son episode_steps:101
Total Steps: 975643 Episode Num: 14177 Reward: 33.11831844676272 avg_loss_c: 38.867950061760325 avg_loss_a: -78.05958013251276
Número de pasos del episodio 14178 son episode_steps:114
Total Steps: 975757 Episode Num: 14178 Reward: 44.87487303395514 avg_loss_c: 37.900801273814416 avg_loss_a: -77.8080491183097
Número de pasos del episodio 14179 son episode_steps:70
Total Steps: 975827 Episode Num: 14179 Reward: 10.99596502876695 avg_loss_c: 36.43207274845668 avg_loss_a: -78.15966469900948
Número de pasos del episodio 14180 son episode_steps:176
Total Steps: 976003 Episode Num: 14180 Reward: 147.72345425826288 avg_loss_c: 36.63685789975253 avg_loss_a: -79.08928168903698
Número de pasos del episodio 14181 son episode_steps:53
Total Steps: 976056 Episode Num: 14181 Reward: -43.2100523480096 avg_loss_c: 38.61511856654905 avg_loss_a: -77.41770128933888
Número de pasos del episodio 14182 son episode_steps:107
Total Steps: 976163 Episode Num: 14182 Reward: 1.4878599435012347 avg_loss_c: 38.69495365107171 avg_loss_a: -78.2632365716952
Número de pasos del episodio 14183 son episode_steps:182
Total Steps: 976345 Episode Num: 14183 Reward: 133.27513472240213 avg_loss_c: 37.69257462679685 avg_loss_a: -78.67598389007233
Número de pasos del episodio 14184 son episode_steps:140
Total Steps: 976485 Episode Num: 14184 Reward: 98.89549711456617 avg_loss_c: 37.99317117418562 avg_loss_a: -79.2365936279297
Número de pasos del episodio 14185 son episode_steps:130
Total Steps: 976615 Episode Num: 14185 Reward: 76.3842925570517 avg_loss_c: 35.792557466947116 avg_loss_a: -79.46637667142429
Número de pasos del episodio 14186 son episode_steps:46
Total Steps: 976661 Episode Num: 14186 Reward: -18.778405084067938 avg_loss_c: 36.78247965937076 avg_loss_a: -79.54191523012908
Número de pasos del episodio 14187 son episode_steps:42
Total Steps: 976703 Episode Num: 14187 Reward: -21.687150706238366 avg_loss_c: 37.29490925016857 avg_loss_a: -78.57777150472005
Número de pasos del episodio 14188 son episode_steps:84
Total Steps: 976787 Episode Num: 14188 Reward: -16.463197129160154 avg_loss_c: 38.30699834369478 avg_loss_a: -76.94937188284737
Número de pasos del episodio 14189 son episode_steps:44
Total Steps: 976831 Episode Num: 14189 Reward: -27.83244133617609 avg_loss_c: 38.36004517295144 avg_loss_a: -78.12301601063122
Número de pasos del episodio 14190 son episode_steps:129
Total Steps: 976960 Episode Num: 14190 Reward: 61.97976649632673 avg_loss_c: 38.9650536470635 avg_loss_a: -79.36584360285323
Número de pasos del episodio 14191 son episode_steps:206
Total Steps: 977166 Episode Num: 14191 Reward: 127.26130035222376 avg_loss_c: 37.988027331898515 avg_loss_a: -78.01572055261111
Número de pasos del episodio 14192 son episode_steps:68
Total Steps: 977234 Episode Num: 14192 Reward: 28.228238046371075 avg_loss_c: 36.680757746976965 avg_loss_a: -78.01514726526597
Número de pasos del episodio 14193 son episode_steps:34
Total Steps: 977268 Episode Num: 14193 Reward: -17.64758881208059 avg_loss_c: 36.1123384587905 avg_loss_a: -79.45060281192555
Número de pasos del episodio 14194 son episode_steps:27
Total Steps: 977295 Episode Num: 14194 Reward: -29.058473021760317 avg_loss_c: 38.097343656751846 avg_loss_a: -78.13075736716941
Número de pasos del episodio 14195 son episode_steps:69
Total Steps: 977364 Episode Num: 14195 Reward: -35.17329297691438 avg_loss_c: 38.35079417021378 avg_loss_a: -77.31014130080956
Número de pasos del episodio 14196 son episode_steps:52
Total Steps: 977416 Episode Num: 14196 Reward: -26.069889639314408 avg_loss_c: 40.08269412700947 avg_loss_a: -76.44504459087665
Número de pasos del episodio 14197 son episode_steps:259
Total Steps: 977675 Episode Num: 14197 Reward: 188.16720475380112 avg_loss_c: 37.2585195519289 avg_loss_a: -78.32253668943427
Número de pasos del episodio 14198 son episode_steps:126
Total Steps: 977801 Episode Num: 14198 Reward: -26.31652099235442 avg_loss_c: 37.33220374394977 avg_loss_a: -78.24947296626983
Número de pasos del episodio 14199 son episode_steps:83
Total Steps: 977884 Episode Num: 14199 Reward: -9.933404231330286 avg_loss_c: 38.07656324915139 avg_loss_a: -77.83849941391543
Número de pasos del episodio 14200 son episode_steps:231
Total Steps: 978115 Episode Num: 14200 Reward: 194.8269966266573 avg_loss_c: 37.428571057010004 avg_loss_a: -77.82864799334374
Número de pasos del episodio 14201 son episode_steps:242
Total Steps: 978357 Episode Num: 14201 Reward: 201.40033289742195 avg_loss_c: 37.09083360876919 avg_loss_a: -78.14257680089021
Número de pasos del episodio 14202 son episode_steps:70
Total Steps: 978427 Episode Num: 14202 Reward: -10.332747534994564 avg_loss_c: 36.43900617871966 avg_loss_a: -78.53112182617187
Número de pasos del episodio 14203 son episode_steps:188
Total Steps: 978615 Episode Num: 14203 Reward: 131.22537478316505 avg_loss_c: 36.17137904877358 avg_loss_a: -78.89423443408722
Número de pasos del episodio 14204 son episode_steps:215
Total Steps: 978830 Episode Num: 14204 Reward: 72.09058101012221 avg_loss_c: 37.3886511691781 avg_loss_a: -78.12596864922102
Número de pasos del episodio 14205 son episode_steps:103
Total Steps: 978933 Episode Num: 14205 Reward: 28.56763772025319 avg_loss_c: 36.92522500788124 avg_loss_a: -78.55975267725083
Número de pasos del episodio 14206 son episode_steps:65
Total Steps: 978998 Episode Num: 14206 Reward: -12.448222222327274 avg_loss_c: 37.481592589158275 avg_loss_a: -78.72522770808293
Número de pasos del episodio 14207 son episode_steps:95
Total Steps: 979093 Episode Num: 14207 Reward: 32.992117364701976 avg_loss_c: 37.14573247809159 avg_loss_a: -78.23376633493524
Número de pasos del episodio 14208 son episode_steps:121
Total Steps: 979214 Episode Num: 14208 Reward: 77.04933604657779 avg_loss_c: 35.856117484983336 avg_loss_a: -77.63987801291726
Número de pasos del episodio 14209 son episode_steps:97
Total Steps: 979311 Episode Num: 14209 Reward: 50.1452470014472 avg_loss_c: 36.5366091580735 avg_loss_a: -78.88529055880517
Número de pasos del episodio 14210 son episode_steps:47
Total Steps: 979358 Episode Num: 14210 Reward: -27.75116840553702 avg_loss_c: 35.590424070967 avg_loss_a: -77.6452456535177
Número de pasos del episodio 14211 son episode_steps:122
Total Steps: 979480 Episode Num: 14211 Reward: 63.864638068614795 avg_loss_c: 36.638577492510684 avg_loss_a: -78.59535154749136
Número de pasos del episodio 14212 son episode_steps:146
Total Steps: 979626 Episode Num: 14212 Reward: 42.7503512930406 avg_loss_c: 37.19379938465275 avg_loss_a: -78.56449294416872
Número de pasos del episodio 14213 son episode_steps:128
Total Steps: 979754 Episode Num: 14213 Reward: 40.27847772878772 avg_loss_c: 37.40498721599579 avg_loss_a: -78.0148333311081
Número de pasos del episodio 14214 son episode_steps:85
Total Steps: 979839 Episode Num: 14214 Reward: 50.07222565453095 avg_loss_c: 36.46563144010656 avg_loss_a: -79.80525817871094
Número de pasos del episodio 14215 son episode_steps:151
Total Steps: 979990 Episode Num: 14215 Reward: 61.16494057137909 avg_loss_c: 36.65090394177974 avg_loss_a: -78.1725010650837
Número de pasos del episodio 14216 son episode_steps:152
Total Steps: 980142 Episode Num: 14216 Reward: 113.81457330897246 avg_loss_c: 37.16189319209049 avg_loss_a: -78.50815120496247
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 256.364049
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 14217 son episode_steps:83
Total Steps: 980225 Episode Num: 14217 Reward: 51.86560516829944 avg_loss_c: 37.19980933867305 avg_loss_a: -79.01953979859869
Número de pasos del episodio 14218 son episode_steps:272
Total Steps: 980497 Episode Num: 14218 Reward: 224.3741542162155 avg_loss_c: 35.72531505893259 avg_loss_a: -79.42395558076747
Número de pasos del episodio 14219 son episode_steps:135
Total Steps: 980632 Episode Num: 14219 Reward: 110.24855736656457 avg_loss_c: 35.495791611848055 avg_loss_a: -78.60848716453269
Número de pasos del episodio 14220 son episode_steps:73
Total Steps: 980705 Episode Num: 14220 Reward: -36.82446931326381 avg_loss_c: 37.39587796877508 avg_loss_a: -78.74088538182924
Número de pasos del episodio 14221 son episode_steps:63
Total Steps: 980768 Episode Num: 14221 Reward: -22.778118993790525 avg_loss_c: 37.376778738839285 avg_loss_a: -78.03982677156964
Número de pasos del episodio 14222 son episode_steps:103
Total Steps: 980871 Episode Num: 14222 Reward: 16.038938479555775 avg_loss_c: 37.77455337302199 avg_loss_a: -79.10826481198802
Número de pasos del episodio 14223 son episode_steps:140
Total Steps: 981011 Episode Num: 14223 Reward: 107.63941783746499 avg_loss_c: 35.555727182115824 avg_loss_a: -78.45425229753766
Número de pasos del episodio 14224 son episode_steps:190
Total Steps: 981201 Episode Num: 14224 Reward: 188.54071747162516 avg_loss_c: 35.57437475104081 avg_loss_a: -79.56229312294408
Número de pasos del episodio 14225 son episode_steps:142
Total Steps: 981343 Episode Num: 14225 Reward: 133.27032948915036 avg_loss_c: 34.973105538059286 avg_loss_a: -78.7026435959507
Número de pasos del episodio 14226 son episode_steps:110
Total Steps: 981453 Episode Num: 14226 Reward: 18.82774585560138 avg_loss_c: 34.256045098738234 avg_loss_a: -78.87320820201526
Número de pasos del episodio 14227 son episode_steps:119
Total Steps: 981572 Episode Num: 14227 Reward: 8.738098663647932 avg_loss_c: 34.728976850750065 avg_loss_a: -79.77710172508945
Número de pasos del episodio 14228 son episode_steps:83
Total Steps: 981655 Episode Num: 14228 Reward: 4.138357024222634 avg_loss_c: 35.04382232298334 avg_loss_a: -78.69797001114812
Número de pasos del episodio 14229 son episode_steps:68
Total Steps: 981723 Episode Num: 14229 Reward: -33.080190566029174 avg_loss_c: 35.075837808496814 avg_loss_a: -78.8825335783117
Número de pasos del episodio 14230 son episode_steps:66
Total Steps: 981789 Episode Num: 14230 Reward: 26.11545441698297 avg_loss_c: 36.49405207778468 avg_loss_a: -78.72269763368548
Número de pasos del episodio 14231 son episode_steps:139
Total Steps: 981928 Episode Num: 14231 Reward: 105.31065711740801 avg_loss_c: 34.15104160720496 avg_loss_a: -78.93879886325315
Número de pasos del episodio 14232 son episode_steps:44
Total Steps: 981972 Episode Num: 14232 Reward: -10.6174228844054 avg_loss_c: 33.74476796930487 avg_loss_a: -79.502835707231
Número de pasos del episodio 14233 son episode_steps:125
Total Steps: 982097 Episode Num: 14233 Reward: 101.0457036051805 avg_loss_c: 34.33821714782715 avg_loss_a: -78.5614130859375
Número de pasos del episodio 14234 son episode_steps:60
Total Steps: 982157 Episode Num: 14234 Reward: 14.913624070338914 avg_loss_c: 34.04389111200968 avg_loss_a: -78.83065923055013
Número de pasos del episodio 14235 son episode_steps:45
Total Steps: 982202 Episode Num: 14235 Reward: -30.92545933855483 avg_loss_c: 35.788020324707034 avg_loss_a: -78.61442396375868
Número de pasos del episodio 14236 son episode_steps:68
Total Steps: 982270 Episode Num: 14236 Reward: -13.541297451410916 avg_loss_c: 36.49715157116161 avg_loss_a: -78.85755426743451
Número de pasos del episodio 14237 son episode_steps:48
Total Steps: 982318 Episode Num: 14237 Reward: -41.05920201386062 avg_loss_c: 34.611311872800194 avg_loss_a: -80.62321631113689
Número de pasos del episodio 14238 son episode_steps:135
Total Steps: 982453 Episode Num: 14238 Reward: 91.99393890025796 avg_loss_c: 35.72374264752423 avg_loss_a: -78.43705353913484
Número de pasos del episodio 14239 son episode_steps:39
Total Steps: 982492 Episode Num: 14239 Reward: -28.419215368161346 avg_loss_c: 34.55297626593174 avg_loss_a: -77.20048014322917
Número de pasos del episodio 14240 son episode_steps:126
Total Steps: 982618 Episode Num: 14240 Reward: 58.542978335443976 avg_loss_c: 34.02623536851671 avg_loss_a: -79.30921512179904
Número de pasos del episodio 14241 son episode_steps:125
Total Steps: 982743 Episode Num: 14241 Reward: 76.05374222445774 avg_loss_c: 34.14476399230957 avg_loss_a: -78.47474383544922
Número de pasos del episodio 14242 son episode_steps:107
Total Steps: 982850 Episode Num: 14242 Reward: 50.729004266943804 avg_loss_c: 33.94526164331169 avg_loss_a: -78.50003429662401
Número de pasos del episodio 14243 son episode_steps:137
Total Steps: 982987 Episode Num: 14243 Reward: 56.92850340815126 avg_loss_c: 33.71523550827138 avg_loss_a: -79.21524092402771
Número de pasos del episodio 14244 son episode_steps:66
Total Steps: 983053 Episode Num: 14244 Reward: -65.14866541926541 avg_loss_c: 37.721623160622336 avg_loss_a: -79.48995347456498
Número de pasos del episodio 14245 son episode_steps:70
Total Steps: 983123 Episode Num: 14245 Reward: -16.06401186803018 avg_loss_c: 35.428367260524205 avg_loss_a: -77.40681457519531
Número de pasos del episodio 14246 son episode_steps:324
Total Steps: 983447 Episode Num: 14246 Reward: 173.27737683408702 avg_loss_c: 35.08435810936822 avg_loss_a: -78.77602612530744
Número de pasos del episodio 14247 son episode_steps:147
Total Steps: 983594 Episode Num: 14247 Reward: 67.45741914514673 avg_loss_c: 33.888787963763384 avg_loss_a: -78.58386899987046
Número de pasos del episodio 14248 son episode_steps:98
Total Steps: 983692 Episode Num: 14248 Reward: 45.03417141801004 avg_loss_c: 34.56054512335329 avg_loss_a: -78.22703225272042
Número de pasos del episodio 14249 son episode_steps:94
Total Steps: 983786 Episode Num: 14249 Reward: 15.962672471758005 avg_loss_c: 35.21627825879036 avg_loss_a: -78.14908534922499
Número de pasos del episodio 14250 son episode_steps:48
Total Steps: 983834 Episode Num: 14250 Reward: -45.97691020215332 avg_loss_c: 35.82790251572927 avg_loss_a: -78.0156618754069
Número de pasos del episodio 14251 son episode_steps:63
Total Steps: 983897 Episode Num: 14251 Reward: -79.88662733704848 avg_loss_c: 34.68114241342696 avg_loss_a: -77.84341515435113
Número de pasos del episodio 14252 son episode_steps:47
Total Steps: 983944 Episode Num: 14252 Reward: -9.382876270187996 avg_loss_c: 37.61772058365193 avg_loss_a: -79.1489460721929
Número de pasos del episodio 14253 son episode_steps:136
Total Steps: 984080 Episode Num: 14253 Reward: 90.78059806055197 avg_loss_c: 35.38388572019689 avg_loss_a: -78.5403902390424
Número de pasos del episodio 14254 son episode_steps:220
Total Steps: 984300 Episode Num: 14254 Reward: 158.78539191272156 avg_loss_c: 35.37376617951826 avg_loss_a: -77.91303287852894
Número de pasos del episodio 14255 son episode_steps:78
Total Steps: 984378 Episode Num: 14255 Reward: 15.300291423108089 avg_loss_c: 35.17409799037836 avg_loss_a: -79.27760588817107
Número de pasos del episodio 14256 son episode_steps:65
Total Steps: 984443 Episode Num: 14256 Reward: -42.64803098477314 avg_loss_c: 35.91665590726412 avg_loss_a: -78.70947030874399
Número de pasos del episodio 14257 son episode_steps:58
Total Steps: 984501 Episode Num: 14257 Reward: -22.24127349066537 avg_loss_c: 35.9938672493244 avg_loss_a: -77.52283135775862
Número de pasos del episodio 14258 son episode_steps:98
Total Steps: 984599 Episode Num: 14258 Reward: 22.85667123170741 avg_loss_c: 35.19952534656135 avg_loss_a: -77.69275244887994
Número de pasos del episodio 14259 son episode_steps:28
Total Steps: 984627 Episode Num: 14259 Reward: -23.917705666168754 avg_loss_c: 35.46073995317732 avg_loss_a: -78.47364861624581
Número de pasos del episodio 14260 son episode_steps:230
Total Steps: 984857 Episode Num: 14260 Reward: 200.3487857404477 avg_loss_c: 34.55268954401431 avg_loss_a: -77.99438881252122
Número de pasos del episodio 14261 son episode_steps:353
Total Steps: 985210 Episode Num: 14261 Reward: 324.09511136832447 avg_loss_c: 35.69224906575578 avg_loss_a: -78.75307434341387
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 192.343534
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 14262 son episode_steps:41
Total Steps: 985251 Episode Num: 14262 Reward: -44.560980067232094 avg_loss_c: 35.374567124901745 avg_loss_a: -79.03930905970131
Número de pasos del episodio 14263 son episode_steps:57
Total Steps: 985308 Episode Num: 14263 Reward: 19.930250979063814 avg_loss_c: 34.46225745217842 avg_loss_a: -78.91996109276486
Número de pasos del episodio 14264 son episode_steps:52
Total Steps: 985360 Episode Num: 14264 Reward: -26.24202899288097 avg_loss_c: 34.7895089662992 avg_loss_a: -78.12435560960036
Número de pasos del episodio 14265 son episode_steps:37
Total Steps: 985397 Episode Num: 14265 Reward: -33.33049487263625 avg_loss_c: 34.327701774803366 avg_loss_a: -79.32915476206186
Número de pasos del episodio 14266 son episode_steps:122
Total Steps: 985519 Episode Num: 14266 Reward: 114.26470880457686 avg_loss_c: 34.81590865088291 avg_loss_a: -77.73028364337858
Número de pasos del episodio 14267 son episode_steps:299
Total Steps: 985818 Episode Num: 14267 Reward: 272.55964130925713 avg_loss_c: 35.159151676905196 avg_loss_a: -79.26595791207508
Número de pasos del episodio 14268 son episode_steps:43
Total Steps: 985861 Episode Num: 14268 Reward: -30.36194258565886 avg_loss_c: 34.47467537813409 avg_loss_a: -78.08523524084757
Número de pasos del episodio 14269 son episode_steps:50
Total Steps: 985911 Episode Num: 14269 Reward: -1.4956712031745503 avg_loss_c: 35.71790882110596 avg_loss_a: -76.96302490234375
Número de pasos del episodio 14270 son episode_steps:65
Total Steps: 985976 Episode Num: 14270 Reward: -16.76436523897817 avg_loss_c: 34.53138656616211 avg_loss_a: -77.68863443227914
Número de pasos del episodio 14271 son episode_steps:66
Total Steps: 986042 Episode Num: 14271 Reward: 3.367959209589597 avg_loss_c: 35.35359212123986 avg_loss_a: -78.14065204967152
Número de pasos del episodio 14272 son episode_steps:133
Total Steps: 986175 Episode Num: 14272 Reward: 52.73653782155261 avg_loss_c: 34.48903199963104 avg_loss_a: -78.38812450896529
Número de pasos del episodio 14273 son episode_steps:64
Total Steps: 986239 Episode Num: 14273 Reward: 3.884344680847221 avg_loss_c: 34.99921217560768 avg_loss_a: -79.00256991386414
Número de pasos del episodio 14274 son episode_steps:51
Total Steps: 986290 Episode Num: 14274 Reward: -11.798956131515018 avg_loss_c: 35.740249446794095 avg_loss_a: -78.74316136977252
Número de pasos del episodio 14275 son episode_steps:249
Total Steps: 986539 Episode Num: 14275 Reward: 174.91009386573367 avg_loss_c: 35.25443691422183 avg_loss_a: -79.86543990905027
Número de pasos del episodio 14276 son episode_steps:137
Total Steps: 986676 Episode Num: 14276 Reward: 16.457375662029747 avg_loss_c: 34.253185230450036 avg_loss_a: -79.35248866394488
Número de pasos del episodio 14277 son episode_steps:138
Total Steps: 986814 Episode Num: 14277 Reward: 90.75504229822214 avg_loss_c: 35.27808558422586 avg_loss_a: -79.74684286808622
Número de pasos del episodio 14278 son episode_steps:39
Total Steps: 986853 Episode Num: 14278 Reward: -36.03076247507053 avg_loss_c: 34.51428296015813 avg_loss_a: -80.61637056790866
Número de pasos del episodio 14279 son episode_steps:60
Total Steps: 986913 Episode Num: 14279 Reward: -2.952373262844553 avg_loss_c: 33.81130727132162 avg_loss_a: -78.71532745361328
Número de pasos del episodio 14280 son episode_steps:80
Total Steps: 986993 Episode Num: 14280 Reward: 12.575275019294455 avg_loss_c: 36.15461044311523 avg_loss_a: -78.92720794677734
Número de pasos del episodio 14281 son episode_steps:147
Total Steps: 987140 Episode Num: 14281 Reward: 50.10145342296116 avg_loss_c: 35.34955238809391 avg_loss_a: -78.45878320810746
Número de pasos del episodio 14282 son episode_steps:68
Total Steps: 987208 Episode Num: 14282 Reward: -2.046699095724581 avg_loss_c: 34.58920097351074 avg_loss_a: -77.1642505421358
Número de pasos del episodio 14283 son episode_steps:55
Total Steps: 987263 Episode Num: 14283 Reward: -86.10190690898852 avg_loss_c: 36.465514061667704 avg_loss_a: -78.09568509188566
Número de pasos del episodio 14284 son episode_steps:98
Total Steps: 987361 Episode Num: 14284 Reward: 51.6072051913311 avg_loss_c: 35.166282439718444 avg_loss_a: -78.88803676683075
Número de pasos del episodio 14285 son episode_steps:244
Total Steps: 987605 Episode Num: 14285 Reward: 161.33221469859336 avg_loss_c: 36.04850641625826 avg_loss_a: -78.2461115102299
Número de pasos del episodio 14286 son episode_steps:307
Total Steps: 987912 Episode Num: 14286 Reward: 308.0163717457675 avg_loss_c: 34.46206102153766 avg_loss_a: -78.65789451971892
Número de pasos del episodio 14287 son episode_steps:43
Total Steps: 987955 Episode Num: 14287 Reward: -34.955936036200995 avg_loss_c: 36.28614886971407 avg_loss_a: -78.66349881194358
Número de pasos del episodio 14288 son episode_steps:99
Total Steps: 988054 Episode Num: 14288 Reward: 51.54100224732155 avg_loss_c: 36.07996832722365 avg_loss_a: -79.69067960796934
Número de pasos del episodio 14289 son episode_steps:80
Total Steps: 988134 Episode Num: 14289 Reward: -35.03126641717368 avg_loss_c: 36.629600167274475 avg_loss_a: -79.50242309570312
Número de pasos del episodio 14290 son episode_steps:71
Total Steps: 988205 Episode Num: 14290 Reward: -31.266689883714243 avg_loss_c: 35.490356069215586 avg_loss_a: -78.53138947822679
Número de pasos del episodio 14291 son episode_steps:92
Total Steps: 988297 Episode Num: 14291 Reward: 18.8476957570477 avg_loss_c: 35.50597041586171 avg_loss_a: -79.31393731158713
Número de pasos del episodio 14292 son episode_steps:39
Total Steps: 988336 Episode Num: 14292 Reward: -15.470090907510784 avg_loss_c: 37.07968041835687 avg_loss_a: -79.98582556308844
Número de pasos del episodio 14293 son episode_steps:129
Total Steps: 988465 Episode Num: 14293 Reward: 58.15679252852062 avg_loss_c: 35.518541543058646 avg_loss_a: -77.69851235086604
Número de pasos del episodio 14294 son episode_steps:122
Total Steps: 988587 Episode Num: 14294 Reward: 10.762780089658179 avg_loss_c: 35.34839813044814 avg_loss_a: -79.2323974859519
Número de pasos del episodio 14295 son episode_steps:70
Total Steps: 988657 Episode Num: 14295 Reward: -39.950960182380456 avg_loss_c: 35.86615101950509 avg_loss_a: -79.58337663922991
Número de pasos del episodio 14296 son episode_steps:43
Total Steps: 988700 Episode Num: 14296 Reward: -33.83217697208802 avg_loss_c: 35.32641503977221 avg_loss_a: -80.48804864218069
Número de pasos del episodio 14297 son episode_steps:83
Total Steps: 988783 Episode Num: 14297 Reward: 34.596491841099265 avg_loss_c: 36.12887030911733 avg_loss_a: -79.29457763304194
Número de pasos del episodio 14298 son episode_steps:56
Total Steps: 988839 Episode Num: 14298 Reward: -3.8420322573167773 avg_loss_c: 36.88852228437151 avg_loss_a: -78.25103105817523
Número de pasos del episodio 14299 son episode_steps:71
Total Steps: 988910 Episode Num: 14299 Reward: -13.710641207038414 avg_loss_c: 36.694618386282045 avg_loss_a: -78.02746625013755
Número de pasos del episodio 14300 son episode_steps:93
Total Steps: 989003 Episode Num: 14300 Reward: -0.4117946976008131 avg_loss_c: 38.00054092817409 avg_loss_a: -78.35157291863554
Número de pasos del episodio 14301 son episode_steps:77
Total Steps: 989080 Episode Num: 14301 Reward: -2.602452884182096 avg_loss_c: 36.65833654032125 avg_loss_a: -78.56397148231407
Número de pasos del episodio 14302 son episode_steps:126
Total Steps: 989206 Episode Num: 14302 Reward: 27.29896935523765 avg_loss_c: 35.973826559763104 avg_loss_a: -79.11227077907986
Número de pasos del episodio 14303 son episode_steps:48
Total Steps: 989254 Episode Num: 14303 Reward: -25.032893495083837 avg_loss_c: 36.42970089117686 avg_loss_a: -78.81030400594075
Número de pasos del episodio 14304 son episode_steps:182
Total Steps: 989436 Episode Num: 14304 Reward: 160.27342492150294 avg_loss_c: 36.660273719619916 avg_loss_a: -78.01309556227464
Número de pasos del episodio 14305 son episode_steps:69
Total Steps: 989505 Episode Num: 14305 Reward: -27.59046093955352 avg_loss_c: 36.59740052706953 avg_loss_a: -77.35193490290987
Número de pasos del episodio 14306 son episode_steps:54
Total Steps: 989559 Episode Num: 14306 Reward: -28.3306907106395 avg_loss_c: 36.10096546455666 avg_loss_a: -78.1152106391059
Número de pasos del episodio 14307 son episode_steps:39
Total Steps: 989598 Episode Num: 14307 Reward: -13.199475548312272 avg_loss_c: 37.016279758551185 avg_loss_a: -77.18118579571063
Número de pasos del episodio 14308 son episode_steps:103
Total Steps: 989701 Episode Num: 14308 Reward: -6.793804050693238 avg_loss_c: 37.78647533898215 avg_loss_a: -78.51391238610721
Número de pasos del episodio 14309 son episode_steps:59
Total Steps: 989760 Episode Num: 14309 Reward: 5.209567316807987 avg_loss_c: 38.12483279987917 avg_loss_a: -78.7517226914228
Número de pasos del episodio 14310 son episode_steps:105
Total Steps: 989865 Episode Num: 14310 Reward: 28.45855261697805 avg_loss_c: 37.494960657755534 avg_loss_a: -77.31467655726841
Número de pasos del episodio 14311 son episode_steps:87
Total Steps: 989952 Episode Num: 14311 Reward: 0.33599280642521023 avg_loss_c: 35.52145951369713 avg_loss_a: -76.50483124831626
Número de pasos del episodio 14312 son episode_steps:87
Total Steps: 990039 Episode Num: 14312 Reward: 49.62727786774923 avg_loss_c: 35.52874661588121 avg_loss_a: -76.80086982113191
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 67.416660
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 14313 son episode_steps:156
Total Steps: 990195 Episode Num: 14313 Reward: 15.350713862621037 avg_loss_c: 37.98254404312525 avg_loss_a: -78.38573925311749
Número de pasos del episodio 14314 son episode_steps:175
Total Steps: 990370 Episode Num: 14314 Reward: 157.94756771335258 avg_loss_c: 35.453880168369835 avg_loss_a: -77.23812744140625
Número de pasos del episodio 14315 son episode_steps:140
Total Steps: 990510 Episode Num: 14315 Reward: 78.16718017056785 avg_loss_c: 35.3192595073155 avg_loss_a: -78.01051199776786
Número de pasos del episodio 14316 son episode_steps:27
Total Steps: 990537 Episode Num: 14316 Reward: -29.94574149367783 avg_loss_c: 34.957267337375214 avg_loss_a: -77.31433529324002
Número de pasos del episodio 14317 son episode_steps:108
Total Steps: 990645 Episode Num: 14317 Reward: 20.941437579334515 avg_loss_c: 36.89352478804412 avg_loss_a: -78.93044153849284
Número de pasos del episodio 14318 son episode_steps:46
Total Steps: 990691 Episode Num: 14318 Reward: -25.230605499712052 avg_loss_c: 34.80483764150868 avg_loss_a: -78.60443347433339
Número de pasos del episodio 14319 son episode_steps:57
Total Steps: 990748 Episode Num: 14319 Reward: 31.49286687749649 avg_loss_c: 35.78433267693771 avg_loss_a: -77.59447920949836
Número de pasos del episodio 14320 son episode_steps:195
Total Steps: 990943 Episode Num: 14320 Reward: 116.51836130909555 avg_loss_c: 34.75738187936636 avg_loss_a: -77.91278115296976
Número de pasos del episodio 14321 son episode_steps:141
Total Steps: 991084 Episode Num: 14321 Reward: 68.03372042853917 avg_loss_c: 34.765145430328154 avg_loss_a: -78.16741537540517
Número de pasos del episodio 14322 son episode_steps:105
Total Steps: 991189 Episode Num: 14322 Reward: 68.52030628014198 avg_loss_c: 35.686283111572266 avg_loss_a: -77.75995338076638
Número de pasos del episodio 14323 son episode_steps:223
Total Steps: 991412 Episode Num: 14323 Reward: 129.15863038170153 avg_loss_c: 35.48732957711669 avg_loss_a: -78.41811001354269
Número de pasos del episodio 14324 son episode_steps:193
Total Steps: 991605 Episode Num: 14324 Reward: 163.13704660381907 avg_loss_c: 35.07707688721968 avg_loss_a: -79.50982231179667
Número de pasos del episodio 14325 son episode_steps:141
Total Steps: 991746 Episode Num: 14325 Reward: 97.8907268667929 avg_loss_c: 34.59982386379377 avg_loss_a: -79.89119292996453
Número de pasos del episodio 14326 son episode_steps:49
Total Steps: 991795 Episode Num: 14326 Reward: -55.388480575543284 avg_loss_c: 35.0966205207669 avg_loss_a: -79.12244913529376
Número de pasos del episodio 14327 son episode_steps:180
Total Steps: 991975 Episode Num: 14327 Reward: 159.80828089929128 avg_loss_c: 34.34763300153944 avg_loss_a: -79.65404188368055
Número de pasos del episodio 14328 son episode_steps:45
Total Steps: 992020 Episode Num: 14328 Reward: -4.306589770028484 avg_loss_c: 33.66228069729275 avg_loss_a: -80.68427666558159
Número de pasos del episodio 14329 son episode_steps:50
Total Steps: 992070 Episode Num: 14329 Reward: -55.04987780708152 avg_loss_c: 35.05419509887695 avg_loss_a: -81.65205810546875
Número de pasos del episodio 14330 son episode_steps:54
Total Steps: 992124 Episode Num: 14330 Reward: 14.289332083335163 avg_loss_c: 35.83089916794388 avg_loss_a: -79.32490370008681
Número de pasos del episodio 14331 son episode_steps:62
Total Steps: 992186 Episode Num: 14331 Reward: 10.63613436195246 avg_loss_c: 33.62574214320029 avg_loss_a: -79.15469877181515
Número de pasos del episodio 14332 son episode_steps:33
Total Steps: 992219 Episode Num: 14332 Reward: -20.611225726102045 avg_loss_c: 34.65253292430531 avg_loss_a: -79.35933338512073
Número de pasos del episodio 14333 son episode_steps:72
Total Steps: 992291 Episode Num: 14333 Reward: 51.03403901528906 avg_loss_c: 34.51340945561727 avg_loss_a: -79.12847095065646
Número de pasos del episodio 14334 son episode_steps:70
Total Steps: 992361 Episode Num: 14334 Reward: -14.210702787776247 avg_loss_c: 35.111120087759836 avg_loss_a: -78.73103288922991
Número de pasos del episodio 14335 son episode_steps:56
Total Steps: 992417 Episode Num: 14335 Reward: -69.00378439050408 avg_loss_c: 34.12961844035557 avg_loss_a: -79.08935001918248
Número de pasos del episodio 14336 son episode_steps:116
Total Steps: 992533 Episode Num: 14336 Reward: 25.99260369435517 avg_loss_c: 35.76164732308224 avg_loss_a: -79.23446589502795
Número de pasos del episodio 14337 son episode_steps:131
Total Steps: 992664 Episode Num: 14337 Reward: 81.69136406300781 avg_loss_c: 35.7650248840565 avg_loss_a: -78.582612656455
Número de pasos del episodio 14338 son episode_steps:64
Total Steps: 992728 Episode Num: 14338 Reward: -1.5694589173775761 avg_loss_c: 34.999917179346085 avg_loss_a: -79.31942319869995
Número de pasos del episodio 14339 son episode_steps:32
Total Steps: 992760 Episode Num: 14339 Reward: -41.869996949695114 avg_loss_c: 36.4210461974144 avg_loss_a: -79.19254541397095
Número de pasos del episodio 14340 son episode_steps:79
Total Steps: 992839 Episode Num: 14340 Reward: 29.974500566918454 avg_loss_c: 35.78455244136762 avg_loss_a: -77.64432429060152
Número de pasos del episodio 14341 son episode_steps:159
Total Steps: 992998 Episode Num: 14341 Reward: 90.86419953086067 avg_loss_c: 35.47422610588794 avg_loss_a: -78.95611965731256
Número de pasos del episodio 14342 son episode_steps:79
Total Steps: 993077 Episode Num: 14342 Reward: 0.03775961709589759 avg_loss_c: 35.507983437067345 avg_loss_a: -79.61490573158747
Número de pasos del episodio 14343 son episode_steps:198
Total Steps: 993275 Episode Num: 14343 Reward: 141.18334710760027 avg_loss_c: 34.73559007740984 avg_loss_a: -79.44549229169132
Número de pasos del episodio 14344 son episode_steps:73
Total Steps: 993348 Episode Num: 14344 Reward: 31.97076208430902 avg_loss_c: 36.211048387501336 avg_loss_a: -79.56883511477953
Número de pasos del episodio 14345 son episode_steps:70
Total Steps: 993418 Episode Num: 14345 Reward: 18.847353083267826 avg_loss_c: 35.8936826978411 avg_loss_a: -79.28860342843193
Número de pasos del episodio 14346 son episode_steps:351
Total Steps: 993769 Episode Num: 14346 Reward: 304.0436354287254 avg_loss_c: 34.6696761313327 avg_loss_a: -79.42223112535612
Número de pasos del episodio 14347 son episode_steps:32
Total Steps: 993801 Episode Num: 14347 Reward: -15.09200764831646 avg_loss_c: 35.0875358581543 avg_loss_a: -77.76238489151001
Número de pasos del episodio 14348 son episode_steps:65
Total Steps: 993866 Episode Num: 14348 Reward: 12.693408593113537 avg_loss_c: 35.606187321589545 avg_loss_a: -78.2184065598708
Número de pasos del episodio 14349 son episode_steps:79
Total Steps: 993945 Episode Num: 14349 Reward: -16.61996329770964 avg_loss_c: 36.07847023010254 avg_loss_a: -79.82401555701148
Número de pasos del episodio 14350 son episode_steps:86
Total Steps: 994031 Episode Num: 14350 Reward: 45.699295963220116 avg_loss_c: 34.813968924588934 avg_loss_a: -78.3365320604901
Número de pasos del episodio 14351 son episode_steps:110
Total Steps: 994141 Episode Num: 14351 Reward: 63.985615585724766 avg_loss_c: 34.397112014076924 avg_loss_a: -78.5656068281694
Número de pasos del episodio 14352 son episode_steps:137
Total Steps: 994278 Episode Num: 14352 Reward: 104.99120678098195 avg_loss_c: 34.3441540794651 avg_loss_a: -77.99073022995552
Número de pasos del episodio 14353 son episode_steps:71
Total Steps: 994349 Episode Num: 14353 Reward: -2.354831823983049 avg_loss_c: 34.75462779192857 avg_loss_a: -78.45295833533919
Número de pasos del episodio 14354 son episode_steps:103
Total Steps: 994452 Episode Num: 14354 Reward: 2.154489554423649 avg_loss_c: 35.65671833742012 avg_loss_a: -78.49215313068872
Número de pasos del episodio 14355 son episode_steps:121
Total Steps: 994573 Episode Num: 14355 Reward: 23.2732862852981 avg_loss_c: 36.25683210703952 avg_loss_a: -78.65634079610021
Número de pasos del episodio 14356 son episode_steps:99
Total Steps: 994672 Episode Num: 14356 Reward: 46.74143719026313 avg_loss_c: 34.93123761572019 avg_loss_a: -77.5080372974126
Número de pasos del episodio 14357 son episode_steps:61
Total Steps: 994733 Episode Num: 14357 Reward: -62.010838898660346 avg_loss_c: 35.42520113460353 avg_loss_a: -78.64925997374488
Número de pasos del episodio 14358 son episode_steps:54
Total Steps: 994787 Episode Num: 14358 Reward: 5.608571990703075 avg_loss_c: 34.44435585869683 avg_loss_a: -79.28630970142505
Número de pasos del episodio 14359 son episode_steps:68
Total Steps: 994855 Episode Num: 14359 Reward: -66.87731433113777 avg_loss_c: 35.28513843872968 avg_loss_a: -78.10915778664982
Número de pasos del episodio 14360 son episode_steps:66
Total Steps: 994921 Episode Num: 14360 Reward: -26.598529283086762 avg_loss_c: 35.730854121121496 avg_loss_a: -78.59081684459339
Número de pasos del episodio 14361 son episode_steps:72
Total Steps: 994993 Episode Num: 14361 Reward: 43.183219236576534 avg_loss_c: 35.30405486954583 avg_loss_a: -78.35449769761827
Número de pasos del episodio 14362 son episode_steps:62
Total Steps: 995055 Episode Num: 14362 Reward: 0.5802188999100117 avg_loss_c: 35.863017851306545 avg_loss_a: -79.24202531383884
-------------------------------------------------
Recompensa promedio en el paso de Evaluación: 694.943449
-------------------------------------------------
Object serialized and saved to './results/replay_buffer_memory_v2.pickle'.
Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v2.pickle'.
Número de pasos del episodio 14363 son episode_steps:124
Total Steps: 995179 Episode Num: 14363 Reward: 80.99187813408079 avg_loss_c: 35.47542736607213 avg_loss_a: -78.17213969076833
Número de pasos del episodio 14364 son episode_steps:59
Total Steps: 995238 Episode Num: 14364 Reward: 0.4522444174247484 avg_loss_c: 36.81752625158278 avg_loss_a: -78.53050503488315
Número de pasos del episodio 14365 son episode_steps:62
Total Steps: 995300 Episode Num: 14365 Reward: 16.480979867808188 avg_loss_c: 34.88821398827337 avg_loss_a: -78.76498560751638
Número de pasos del episodio 14366 son episode_steps:167
Total Steps: 995467 Episode Num: 14366 Reward: 63.71607269685909 avg_loss_c: 36.97301132521943 avg_loss_a: -78.28329157115456
Número de pasos del episodio 14367 son episode_steps:65
Total Steps: 995532 Episode Num: 14367 Reward: -37.167539004639444 avg_loss_c: 36.08262138366699 avg_loss_a: -78.45125849797175
Número de pasos del episodio 14368 son episode_steps:187
Total Steps: 995719 Episode Num: 14368 Reward: 115.83225530778105 avg_loss_c: 35.74847538585969 avg_loss_a: -78.15005117814171
Número de pasos del episodio 14369 son episode_steps:127
Total Steps: 995846 Episode Num: 14369 Reward: 44.1136455563312 avg_loss_c: 34.917736819409946 avg_loss_a: -78.3995115024837
Número de pasos del episodio 14370 son episode_steps:57
Total Steps: 995903 Episode Num: 14370 Reward: 6.843101019933039 avg_loss_c: 35.37581002084833 avg_loss_a: -78.37704213460286
Número de pasos del episodio 14371 son episode_steps:65
Total Steps: 995968 Episode Num: 14371 Reward: 34.913321933957896 avg_loss_c: 35.59928072415865 avg_loss_a: -77.69211073655349
Número de pasos del episodio 14372 son episode_steps:359
Total Steps: 996327 Episode Num: 14372 Reward: 313.8086810577952 avg_loss_c: 34.57271119014134 avg_loss_a: -78.22555654626703
Número de pasos del episodio 14373 son episode_steps:148
Total Steps: 996475 Episode Num: 14373 Reward: 103.91891238543457 avg_loss_c: 33.565709900211644 avg_loss_a: -77.14565483299461
Número de pasos del episodio 14374 son episode_steps:93
Total Steps: 996568 Episode Num: 14374 Reward: 32.91705704599373 avg_loss_c: 33.56400990229781 avg_loss_a: -78.20272179060085
Número de pasos del episodio 14375 son episode_steps:41
Total Steps: 996609 Episode Num: 14375 Reward: -9.936888344094386 avg_loss_c: 37.4062131090862 avg_loss_a: -77.74852026962652
Número de pasos del episodio 14376 son episode_steps:54
Total Steps: 996663 Episode Num: 14376 Reward: -26.160192234747043 avg_loss_c: 32.99201170603434 avg_loss_a: -77.15678434018736
Número de pasos del episodio 14377 son episode_steps:98
Total Steps: 996761 Episode Num: 14377 Reward: 51.51866715644923 avg_loss_c: 34.88011367953553 avg_loss_a: -78.13226256078603
Número de pasos del episodio 14378 son episode_steps:40
Total Steps: 996801 Episode Num: 14378 Reward: -27.836548145424082 avg_loss_c: 35.06153841018677 avg_loss_a: -78.62821464538574
Número de pasos del episodio 14379 son episode_steps:31
Total Steps: 996832 Episode Num: 14379 Reward: -49.782558875317484 avg_loss_c: 36.99050774112825 avg_loss_a: -77.31849252024004
Número de pasos del episodio 14380 son episode_steps:29
Total Steps: 996861 Episode Num: 14380 Reward: -3.254043128086738 avg_loss_c: 36.86331222797262 avg_loss_a: -79.31114617709456
Número de pasos del episodio 14381 son episode_steps:45
Total Steps: 996906 Episode Num: 14381 Reward: -36.1897092752423 avg_loss_c: 35.738074917263454 avg_loss_a: -78.5399661593967
Número de pasos del episodio 14382 son episode_steps:175
Total Steps: 997081 Episode Num: 14382 Reward: -14.81645907137679 avg_loss_c: 36.03385044642857 avg_loss_a: -77.70869245256696
Número de pasos del episodio 14383 son episode_steps:229
Total Steps: 997310 Episode Num: 14383 Reward: 96.89378846474023 avg_loss_c: 37.737588357717186 avg_loss_a: -78.182890812903
Número de pasos del episodio 14384 son episode_steps:99
Total Steps: 997409 Episode Num: 14384 Reward: 19.987575928966574 avg_loss_c: 36.55740884337762 avg_loss_a: -77.81453774192117
Número de pasos del episodio 14385 son episode_steps:45
Total Steps: 997454 Episode Num: 14385 Reward: -9.497554340331964 avg_loss_c: 35.934839163886174 avg_loss_a: -77.91979505750868
Número de pasos del episodio 14386 son episode_steps:57
Total Steps: 997511 Episode Num: 14386 Reward: -3.7835242130485662 avg_loss_c: 35.18647147061532 avg_loss_a: -77.9553127623441
Número de pasos del episodio 14387 son episode_steps:136
Total Steps: 997647 Episode Num: 14387 Reward: 30.597376271719515 avg_loss_c: 37.07406137971317 avg_loss_a: -77.51048514422249
Número de pasos del episodio 14388 son episode_steps:79
Total Steps: 997726 Episode Num: 14388 Reward: 19.040095378208452 avg_loss_c: 34.60289807862873 avg_loss_a: -77.47766277458095
Número de pasos del episodio 14389 son episode_steps:45
Total Steps: 997771 Episode Num: 14389 Reward: -43.18996048567163 avg_loss_c: 35.734534666273326 avg_loss_a: -78.90929497612848
Número de pasos del episodio 14390 son episode_steps:76
Total Steps: 997847 Episode Num: 14390 Reward: -3.549565420167548 avg_loss_c: 36.48351194984034 avg_loss_a: -77.91046644511975
Número de pasos del episodio 14391 son episode_steps:251
Total Steps: 998098 Episode Num: 14391 Reward: 180.0180658891697 avg_loss_c: 37.29632888277214 avg_loss_a: -77.84548208533056
Número de pasos del episodio 14392 son episode_steps:235
Total Steps: 998333 Episode Num: 14392 Reward: 81.22751669308732 avg_loss_c: 37.107712287091196 avg_loss_a: -77.03560683879446
Número de pasos del episodio 14393 son episode_steps:643
Total Steps: 998976 Episode Num: 14393 Reward: 565.1993145600702 avg_loss_c: 36.32327881274661 avg_loss_a: -77.94480281373019
Número de pasos del episodio 14394 son episode_steps:63
Total Steps: 999039 Episode Num: 14394 Reward: -25.205471023252635 avg_loss_c: 36.44150031559051 avg_loss_a: -76.98779042561848
Número de pasos del episodio 14395 son episode_steps:52
Total Steps: 999091 Episode Num: 14395 Reward: -41.314763543821286 avg_loss_c: 38.51633710127611 avg_loss_a: -78.26732283372145
Número de pasos del episodio 14396 son episode_steps:28
Total Steps: 999119 Episode Num: 14396 Reward: -39.988903573566674 avg_loss_c: 37.88804817199707 avg_loss_a: -79.18895394461495
Número de pasos del episodio 14397 son episode_steps:164
Total Steps: 999283 Episode Num: 14397 Reward: 68.31669943634249 avg_loss_c: 37.57399502033141 avg_loss_a: -77.65198665711938
Número de pasos del episodio 14398 son episode_steps:55
Total Steps: 999338 Episode Num: 14398 Reward: -16.053551114551826 avg_loss_c: 38.48324175747958 avg_loss_a: -77.64783769087357
Número de pasos del episodio 14399 son episode_steps:98
Total Steps: 999436 Episode Num: 14399 Reward: 43.78869822002949 avg_loss_c: 37.07085385614512 avg_loss_a: -78.30744778380102
Número de pasos del episodio 14400 son episode_steps:39
Total Steps: 999475 Episode Num: 14400 Reward: -13.618456629197633 avg_loss_c: 36.21954110952524 avg_loss_a: -78.90107883551183
Número de pasos del episodio 14401 son episode_steps:61
Total Steps: 999536 Episode Num: 14401 Reward: -8.265113242083022 avg_loss_c: 36.118278253273886 avg_loss_a: -77.34581806620614
Número de pasos del episodio 14402 son episode_steps:32
Total Steps: 999568 Episode Num: 14402 Reward: -21.31973169206416 avg_loss_c: 37.58542078733444 avg_loss_a: -77.96094083786011
Número de pasos del episodio 14403 son episode_steps:74
Total Steps: 999642 Episode Num: 14403 Reward: 41.68798361421703 avg_loss_c: 35.92475202921275 avg_loss_a: -79.51330215866501
Número de pasos del episodio 14404 son episode_steps:75
Total Steps: 999717 Episode Num: 14404 Reward: 26.427135143570766 avg_loss_c: 37.12161417643229 avg_loss_a: -78.69411539713542
Número de pasos del episodio 14405 son episode_steps:113
Total Steps: 999830 Episode Num: 14405 Reward: 56.32157521648743 avg_loss_c: 37.74949718576617 avg_loss_a: -77.45330986090465
Número de pasos del episodio 14406 son episode_steps:69
Total Steps: 999899 Episode Num: 14406 Reward: -13.578568833510362 avg_loss_c: 37.8133120605911 avg_loss_a: -76.30347608483356
Datos de entrenamiento serializados correctamente en './results/datos_entrenamiento_v2.pkl'.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AttributeError</span>                            Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-8-74ecfa09f57f&gt;</span> in <span class="ansi-cyan-fg">&lt;cell line: 226&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">    224</span> serialize_training <span class="ansi-blue-fg">(</span>t0<span class="ansi-blue-fg">,</span> tf<span class="ansi-blue-fg">,</span> total_steps<span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">"v2"</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    225</span> <span class="ansi-red-fg"># Añadir la última actualización de la política a la lista de evaluaciones previa y guardar nuestro modelo</span>
<span class="ansi-green-fg">--&gt; 226</span><span class="ansi-red-fg"> </span>evaluations<span class="ansi-blue-fg">.</span>appen <span class="ansi-blue-fg">(</span>evaluate_train_policy <span class="ansi-blue-fg">(</span>policy<span class="ansi-blue-fg">,</span> env<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    227</span> <span class="ansi-green-fg">if</span> save_models<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    228</span>     policy<span class="ansi-blue-fg">.</span>save<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"gready_%s_v2_1"</span> <span class="ansi-blue-fg">%</span> <span class="ansi-blue-fg">(</span>file_model_name<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> directory<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">"./pytorch_models"</span><span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">AttributeError</span>: 'list' object has no attribute 'appen'</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=ba69f560-ac18-462b-858e-d2c915ee91e0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Step-4:-Evaluaci%C3%B3n-para-extraeer-videos-de-la-politicca-entrenada"><strong>Step 4:</strong> Evaluación para extraeer videos de la politicca entrenada<a class="anchor-link" href="#Step-4:-Evaluaci%C3%B3n-para-extraeer-videos-de-la-politicca-entrenada">¶</a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=5ab85407-30d3-483d-ac18-529f25a2e251">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pybullet_envs</span>
<span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">gym</span> <span class="kn">import</span> <span class="n">wrappers</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="c1">#import mujoco_py</span>
<span class="kn">from</span> <span class="nn">TD3</span> <span class="kn">import</span> <span class="n">TD3</span><span class="p">,</span> <span class="n">evaluate_policy</span><span class="p">,</span> <span class="n">created_models_directory</span>
<span class="kn">import</span> <span class="nn">pybullet</span> <span class="k">as</span> <span class="nn">p</span>

<span class="c1"># Iniciar el servidor de física de PyBullet</span>
<span class="n">p</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">DIRECT</span><span class="p">)</span>



<span class="c1">#######################################</span>
<span class="c1">###</span>
<span class="c1">######################################</span>
<span class="n">env_name</span>           <span class="o">=</span> <span class="s2">"HumanoidBulletEnv-v0"</span>  <span class="c1"># Nombre del entorno que vamos a entrena. Con forme se ha implementado el modelo TD3 poría ser cuaalquier entorno (preferiblemente de estados de acciones continuos)</span>
<span class="n">seed</span>               <span class="o">=</span> <span class="mi">0</span>        <span class="c1"># Semilla utilizada para garantizar la reproducibilidad de los resultados</span>
<span class="n">start_steps</span>        <span class="o">=</span> <span class="mf">1e4</span>      <span class="c1"># Número de iteraciones/timesteps antes de que el modelo comience a utilizar la red de políticas en lugar de elegir acciones al azar</span>
<span class="n">eval_frequency</span>     <span class="o">=</span> <span class="mf">5e3</span>      <span class="c1"># Frecuencia de evaluación, es decir, cada cuántos pasos/timesteps se evalúa el desempeño del modelo</span>
<span class="n">max_timesteps</span>      <span class="o">=</span> <span class="mf">5e12</span>     <span class="c1"># Número máximo de iteraciones/timesteps permitidos</span>
<span class="n">save_models</span>        <span class="o">=</span> <span class="kc">True</span>     <span class="c1"># Booleano que indica si se deben guardar los modelos pre-entrenados o no</span>
<span class="n">explore_noise</span>      <span class="o">=</span> <span class="mf">0.1</span>      <span class="c1"># Desviación estándar del ruido gaussiano utilizado para la exploración</span>
<span class="n">batch_size</span>         <span class="o">=</span> <span class="mi">100</span>      <span class="c1"># Tamaño del lote de muestras utilizadas en cada iteración de entrenamiento</span>
<span class="n">gamma</span>              <span class="o">=</span> <span class="mf">0.99</span>     <span class="c1"># Factor de descuento gamma que afecta la importancia de las recompensas futuras en la función de pérdida</span>
<span class="n">target_update_freq</span> <span class="o">=</span> <span class="mf">0.005</span>    <span class="c1"># Tasa de actualización para suavizar los parámetros de la red objetivo</span>
<span class="n">policy_noise</span>       <span class="o">=</span> <span class="mf">0.2</span>      <span class="c1"># Desviación estándar del ruido gaussiano agregado a las acciones para promover la exploración</span>
<span class="n">noise_clip</span>         <span class="o">=</span> <span class="mf">0.5</span>      <span class="c1"># Valor máximo permitido para el ruido gaussiano agregado a las acciones (política)</span>
<span class="n">policy_freq</span>        <span class="o">=</span> <span class="mi">2</span>        <span class="c1"># Número de iteraciones entre actualizaciones de la red de políticas (modelo actor)</span>

<span class="n">env_name</span> <span class="o">=</span> <span class="s2">"HumanoidBulletEnv-v0"</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">work_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">'exp'</span><span class="p">,</span> <span class="s1">'brs'</span><span class="p">)</span>
<span class="n">monitor_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">work_dir</span><span class="p">,</span> <span class="s1">'monitor'</span><span class="p">)</span>


<span class="n">file_model_name</span> <span class="o">=</span> <span class="n">created_models_directory</span> <span class="p">(</span><span class="n">env_name</span><span class="p">,</span> <span class="n">seed</span><span class="p">,</span> <span class="n">save_models</span><span class="p">,</span> <span class="s2">"v2_1"</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">"---------------------------------------"</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">"Configuración: </span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">file_model_name</span><span class="p">))</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">"---------------------------------------"</span><span class="p">)</span>

<span class="n">eval_episodes</span> <span class="o">=</span> <span class="mi">1000000</span>
<span class="n">save_env_vid</span>  <span class="o">=</span> <span class="kc">True</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span> <span class="p">(</span><span class="n">env_name</span><span class="p">)</span>
<span class="n">max_episode_steps</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">_max_episode_steps</span>
<span class="k">if</span> <span class="n">save_env_vid</span><span class="p">:</span>
  <span class="n">env</span> <span class="o">=</span> <span class="n">wrappers</span><span class="o">.</span><span class="n">Monitor</span> <span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">monitor_dir</span><span class="p">,</span> <span class="n">force</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
  <span class="c1"># env = RecordEpisodeStatistics (env)</span>
  <span class="n">env</span><span class="o">.</span><span class="n">reset</span> <span class="p">()</span>
<span class="n">env</span><span class="o">.</span><span class="n">seed</span> <span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span> <span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span> <span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">state_dim</span>  <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">action_dim</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">shape</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">max_action</span> <span class="o">=</span> <span class="nb">float</span> <span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">high</span> <span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">policy</span> <span class="o">=</span> <span class="n">TD3</span> <span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">max_action</span><span class="p">,</span><span class="n">max_timesteps</span><span class="p">,</span> <span class="n">initial_lr</span> <span class="o">=</span>  <span class="mf">1e-4</span><span class="p">)</span> <span class="c1"># Notar que realmente el objeto entrenado definirá la política a seguir por el agente</span>
<span class="n">policy</span><span class="o">.</span><span class="n">load</span> <span class="p">(</span><span class="n">file_model_name</span><span class="p">,</span> <span class="s1">'./pytorch_models/'</span><span class="p">)</span>
<span class="n">avg_reward</span><span class="p">,</span> <span class="n">episode_rewards</span> <span class="o">=</span> <span class="n">evaluate_policy</span> <span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">eval_episodes</span> <span class="o">=</span> <span class="n">eval_episodes</span><span class="p">)</span>

<span class="c1"># Graficar las recompensas por episodio</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">episode_rewards</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Episodio'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Recompensa'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Recompensa por Episodio durante la Evaluación'</span><span class="p">)</span>

<span class="c1"># Guardar la gráfica en un archivo de imagen (por ejemplo, en formato PNG)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">'./results/recompensas_por_episodio_evaluacion_v2_1.png'</span><span class="p">)</span>

<span class="c1"># Mostrar la gráfica en la ventana</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>---------------------------------------
Fichero de los modelos entrenados: TD3_HumanoidBulletEnv-v0_0_v2_1
---------------------------------------
---------------------------------------
Configuración: TD3_HumanoidBulletEnv-v0_0_v2_1
---------------------------------------
</pre>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>
