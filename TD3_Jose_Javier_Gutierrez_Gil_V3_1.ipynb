{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0e99c767-45d0-4607-9f0d-3b152077be77",
      "metadata": {
        "id": "0e99c767-45d0-4607-9f0d-3b152077be77"
      },
      "source": [
        "---\n",
        "# **Title**:TRABAJO AP. DDPG TD(3) (Gradiente de política determinista profunda (TD3) de doble retardo. Entornos de estados continuos: Humanoide). + Conexión Chatgpt (o similar)  + modelo dalle (similr)\n",
        "\n",
        "Versión 3: Modificamos la estrategia de Exploracion Vs Explotción. Haremos un entrenamiento en dos partes.\n",
        "\n",
        "1 ) Recorremos el entorno en busca de observaciones y acciones asociadas subóptmas. Rellenamos la memoria de repetición con estas observciones.\n",
        "\n",
        "2) Entrenamos de forma normal tal que cuando vayamos a seleccionar la acción tenemos varias fases.:\n",
        "\n",
        "  a ) primera fase donde usamos las acciones almacenadas en el replaybuffer.\n",
        "\n",
        "  b ) segunda fase de esplotación de las acciones de la política pero con una probabilidad de realizar mñas explotaciones, tal que eta probabilidad va en decaimiento a medida que hacemos más pasos.\n",
        "\n",
        "Nota:\n",
        "  - Para seleccionar la acción dentro de la memoria de repetición en la primera fase, lo que hacemos es buscar aquella transición que maas se aprezca a la observación (estado) del momento actual.\n",
        "\n",
        "  - Cuando añadimos una nueva transición a la memoria de repetición si el buffer esta lleno, lo que hacemos es buscar la transición con menor reward y la intercambiamos con la nueva transición.\n",
        "\n",
        "# ESTA VERSIÓN ES LA PEOR DE TODAS. SÓLO CONSIGUE SOBREAJUSTE TANTO DEL CRíTICO COMO DEL ACTOR AL CERRARSE EXCLUSIVAMENTE A UNAS POCAS ACCIONES (con reward >0)\n",
        "\n",
        "# **Author**: José Javier Gutiérrez Gil\n",
        "# **Date**: 2024-02-18\n",
        "# ***Univeridad de Valencia. Grado de Ciencia de Datos***\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "af2cc5c5-06ce-4d3b-98c2-fcf65da40a3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af2cc5c5-06ce-4d3b-98c2-fcf65da40a3e",
        "outputId": "e5b22a59-19b8-42b2-ff2a-82b6a9e5514a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e4cb48b5-7944-484d-86e2-db2442f1e142",
      "metadata": {
        "id": "e4cb48b5-7944-484d-86e2-db2442f1e142"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/td3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "652d3241-1d25-43fc-bf6d-b30ceec5e36f",
      "metadata": {
        "id": "652d3241-1d25-43fc-bf6d-b30ceec5e36f"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/td3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b98ca0fc-f908-46ac-bea4-402b52106e97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b98ca0fc-f908-46ac-bea4-402b52106e97",
        "outputId": "605d561a-fb12-41df-a576-de67782aeaed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pybullet\n",
            "  Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybullet\n",
            "Successfully installed pybullet-3.2.6\n",
            "Collecting gym==0.22.0\n",
            "  Downloading gym-0.22.0.tar.gz (631 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m631.1/631.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.22.0) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.22.0) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.22.0) (0.0.8)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.22.0-py3-none-any.whl size=708364 sha256=df87f9b58b6eafcd6610a1f35f4d0b04074b0cc247bfd90bb7d1973e03082c01\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/e8/e8/6dfbc92a1dcd76c1a5e2bb982750fd6b7e792239f46039e6b1\n",
            "Successfully built gym\n",
            "Installing collected packages: gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed gym-0.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pybullet\n",
        "!pip install gym==0.22.0 # Versión más actual que contiene la calse Monitor y así poder crear los videos del entrenamiento. Al monos en la 0.23 me da error"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1f2438c-79e2-440a-b42f-0d0b55f131f4",
      "metadata": {
        "id": "d1f2438c-79e2-440a-b42f-0d0b55f131f4"
      },
      "source": [
        "# **Step 0:** Cargamos las funciones necesarias de nuestra libreria y de python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "96b52b6e-2a56-4d65-b098-7257b1d7bd81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96b52b6e-2a56-4d65-b098-7257b1d7bd81",
        "outputId": "3305ad51-498b-49c5-c055-063510018068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#####\n",
        "import gym\n",
        "import pybullet_envs\n",
        "from gym import wrappers\n",
        "##\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#####\n",
        "from TD3 import TD3, ReplayBufferPos\n",
        "from TD3 import created_models_directory, mkdir\n",
        "from TD3 import evaluate_train_policy, evaluate_policy\n",
        "from TD3 import noisy_action_wrapper, save_env, load_env, create__metrics_imagen\n",
        "from TD3 import serialize_object, lists_to_serializable_object, serialize_training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2abfbcd-1534-4894-9d4c-ab55bceb028a",
      "metadata": {
        "id": "d2abfbcd-1534-4894-9d4c-ab55bceb028a"
      },
      "source": [
        "# **Step 1:** Inicializamos los hiperparámetros del modelo e implementación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cf9e1e60-97b7-4483-b65a-16e7318f2ac4",
      "metadata": {
        "id": "cf9e1e60-97b7-4483-b65a-16e7318f2ac4"
      },
      "outputs": [],
      "source": [
        "\n",
        "env_name            =  \"HumanoidBulletEnv-v0\"  # Nombre del entorno que vamos a entrena. Con forme se ha implementado el modelo TD3 poría ser cuaalquier entorno (preferiblemente de estados de acciones continuos)\n",
        "seed                = 0        # Semilla utilizada para garantizar la reproducibilidad de los resultados\n",
        "initial_memory_prob = 0.1      # Define la probabilidad inicial de tomar una acción de la memoria de repetición\n",
        "max_start_steps     = 1e4      # Define el número máximo de pasos iniciales\n",
        "#start_steps         = 1e4#1e4  --123-- lo modificamos por un decaimiento según los pasos de entrenamiento # Número de iteraciones/timesteps antes de que el modelo comience a utilizar la red de políticas en lugar de elegir acciones al azar\n",
        "eval_frequency      = 5e3      # Frecuencia de evaluación, es decir, cada cuántos pasos/timesteps se evalúa el desempeño del modelo\n",
        "max_timesteps       = 1e6      # Número máximo de iteraciones/timesteps permitidos\n",
        "save_models         = True     # Booleano que indica si se deben guardar los modelos pre-entrenados o no\n",
        "max_explore_noise   = 0.1      # Desviación estándar del ruido gaussiano utilizado para la exploración...--123-- CaMBIO  0.01 por 0.2 y creo un current_noise_explore dependiendo del steo en el que estamos\n",
        "batch_size          = 100      # Tamaño del lote de muestras utilizadas en cada iteración de entrenamiento\n",
        "gamma               = 0.99     # Factor de descuento gamma que afecta la importancia de las recompensas futuras en la función de pérdida\n",
        "target_update_freq  = 0.005    # Tasa de actualización para suavizar los parámetros de la red objetivo\n",
        "policy_noise        = 0.2     # Desviación estándar del ruido gaussiano agregado a las acciones para promover la exploración\n",
        "noise_clip          = 0.5      # Valor máximo permitido para el ruido gaussiano agregado a las acciones (política)\n",
        "policy_freq         = 2        # Número de iteraciones entre actualizaciones de la red de políticas (modelo actor)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48fc757e-1f59-4156-8f8d-ef70f6f73ef5",
      "metadata": {
        "id": "48fc757e-1f59-4156-8f8d-ef70f6f73ef5"
      },
      "source": [
        "# **Step 2:** Creamos los directorios y cargamos el entorno de trabajo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1d64e59c-0696-40b5-b558-8eb8e96c362a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d64e59c-0696-40b5-b558-8eb8e96c362a",
        "outputId": "3db28472-abef-4ed3-a21a-d7656c2e6a27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------\n",
            "Fichero de los modelos entrenados: TD3_HumanoidBulletEnv-v0_0_v3_1\n",
            "---------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#Creamos los directorios de almacenamento de resultados y métricas\n",
        "file_model_name = created_models_directory (env_name, seed, save_models, \"v3_1\")\n",
        "\n",
        "# Cargamos el entorno sobre el cual ejecutaremso el modelo DDPG TD3\n",
        "###############################################################################\n",
        "##  CARGAMOS EL ENTORNO HUMANOIDE V0 Y LE INTRODUCIMOS EL WRAPPER PARA AÑADIR RUIDO A\n",
        "##  LAS ACCIONES OBTENIDAS POR EXPLORACIÓN.\n",
        "################################################################################\n",
        "env = gym.make (env_name)\n",
        "max_episode_steps = env._max_episode_steps\n",
        "env = noisy_action_wrapper (env, noise_level = policy_noise) #le agregamos ruido a la accion obtenida del entorno para darle ms estabilidad al entrenamiento\n",
        "# Fijamos la semilla y obtenemos información del entorno (Estados, acciones)\n",
        "env.seed (seed)\n",
        "torch.manual_seed (seed)\n",
        "np.random.seed (seed)\n",
        "\n",
        "state_dim  = env.observation_space.shape [0]\n",
        "action_dim = env.action_space.shape [0]\n",
        "max_action = float(env.action_space.high [0])\n",
        "\n",
        "#Creamos los directorios de trabajo donde guardará los videos del entrenamiento\n",
        "work_dir          = mkdir ('exp', 'brs')\n",
        "monitor_dir       = mkdir (work_dir, 'monitor')\n",
        "\n",
        "save_env_vid      = False\n",
        "if save_env_vid:\n",
        "  env = wrappers.Monitor (env, monitor_dir, force = True)\n",
        "  env.reset()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb6ceeb0-ff57-4215-8401-aabefcf31305",
      "metadata": {
        "id": "cb6ceeb0-ff57-4215-8401-aabefcf31305"
      },
      "source": [
        "# **Step 3:** Proceso de entrenamiento : por semiimitación\n",
        "\n",
        "En lugar de seguir la tradicional división entre las fases de exploración y explotación durante el entrenamiento, optamos por dos etapas diferenciadas. En la primera etapa, nos enfocaremos exclusivamente en buscar transiciones en el entorno que resulten en recompensas positivas. Esta fase se llevará a cabo durante un número fijo de pasos hasta que hayamos recopilado un replay buffer completo con transiciones positivas. Una vez completada esta fase y con la memoria de repetición llena de transiciones subóptimas, procederemos con el entrenamiento normal. Aunque nos centramos en la explotación, el proceso de añadir ruido a las acciones durante esta fase puede considerarse una forma de semi-exploración. Hemos observado que esta estrategia nos ha brindado mayores beneficios en comparación con la exploración aleatoria en un entorno con un espacio de acciones infinitas, ya que nos ayuda a evitar mínimos locales y a mejorar la calidad del movimiento del agente."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eLHc5OqcC-KJ",
      "metadata": {
        "id": "eLHc5OqcC-KJ"
      },
      "source": [
        "# Step 3.1: Etapa de explotación y busqueda en el entorno Humanoide\n",
        "\n",
        "Creamos la memoria de repetición y almacenamos directamente tantas transiciones como encuentre con una recompensa positiva. Hasta el máximo de la capacidad de la memoria de repetición (ReplayBufferPos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "XVIgf0pyDGns",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVIgf0pyDGns",
        "outputId": "d6d71ff1-0edc-4e35-f0ab-cdafd2a85fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "Total de pasos: 2995840/3000000.0 - Recompensa: -1.4337121669480068\n",
            "Total de pasos: 2995841/3000000.0 - Recompensa: -3.1581809364769287\n",
            "Total de pasos: 2995842/3000000.0 - Recompensa: -0.8638081098753155\n",
            "Total de pasos: 2995843/3000000.0 - Recompensa: -2.7029144935477554\n",
            "Total de pasos: 2995844/3000000.0 - Recompensa: 0.16747020533865506\n",
            "0.16747020533865506\n",
            "Total de pasos: 2995845/3000000.0 - Recompensa: -0.47296619810660656\n",
            "Total de pasos: 2995846/3000000.0 - Recompensa: -1.4812942504504623\n",
            "Total de pasos: 2995847/3000000.0 - Recompensa: -0.17470262882903134\n",
            "Total de pasos: 2995848/3000000.0 - Recompensa: 0.76339051732221\n",
            "0.76339051732221\n",
            "Total de pasos: 2995849/3000000.0 - Recompensa: -1.528381327928526\n",
            "Total de pasos: 2995850/3000000.0 - Recompensa: -1.0441676482283242\n",
            "Total de pasos: 2995851/3000000.0 - Recompensa: 0.4716361912349824\n",
            "0.4716361912349824\n",
            "Total de pasos: 2995852/3000000.0 - Recompensa: -1.0829299742378962\n",
            "Total de pasos: 2995853/3000000.0 - Recompensa: 0.154043643241191\n",
            "0.154043643241191\n",
            "Total de pasos: 2995854/3000000.0 - Recompensa: 0.9402763235281125\n",
            "0.9402763235281125\n",
            "Total de pasos: 2995855/3000000.0 - Recompensa: -0.331488021004778\n",
            "Total de pasos: 2995856/3000000.0 - Recompensa: 0.2812026239235642\n",
            "0.2812026239235642\n",
            "Total de pasos: 2995857/3000000.0 - Recompensa: -0.0034328324734593796\n",
            "Total de pasos: 2995858/3000000.0 - Recompensa: -2.2328153090246436\n",
            "Total de pasos: 2995859/3000000.0 - Recompensa: 0.6996866743163925\n",
            "0.6996866743163925\n",
            "Total de pasos: 2995860/3000000.0 - Recompensa: -0.5411997561630484\n",
            "Total de pasos: 2995861/3000000.0 - Recompensa: -0.8860268327701462\n",
            "Total de pasos: 2995862/3000000.0 - Recompensa: -0.2175105248470807\n",
            "Total de pasos: 2995863/3000000.0 - Recompensa: -0.4318815688472679\n",
            "Total de pasos: 2995864/3000000.0 - Recompensa: -0.9409434408979774\n",
            "Total de pasos: 2995865/3000000.0 - Recompensa: -0.13375296757336166\n",
            "Total de pasos: 2995866/3000000.0 - Recompensa: -0.9807454573707337\n",
            "Total de pasos: 2995867/3000000.0 - Recompensa: -2.831100650650791\n",
            "Total de pasos: 2995868/3000000.0 - Recompensa: -5.221058672838968\n",
            "Total de pasos: 2995869/3000000.0 - Recompensa: -0.019448241705793123\n",
            "Total de pasos: 2995870/3000000.0 - Recompensa: 0.6826443924034616\n",
            "0.6826443924034616\n",
            "Total de pasos: 2995871/3000000.0 - Recompensa: -1.3594045348062216\n",
            "Total de pasos: 2995872/3000000.0 - Recompensa: -0.7631822015563435\n",
            "Total de pasos: 2995873/3000000.0 - Recompensa: -0.060322578200158544\n",
            "Total de pasos: 2995874/3000000.0 - Recompensa: 0.5063717366941518\n",
            "0.5063717366941518\n",
            "Total de pasos: 2995875/3000000.0 - Recompensa: 0.1626572582175176\n",
            "0.1626572582175176\n",
            "Total de pasos: 2995876/3000000.0 - Recompensa: -0.5914953339287015\n",
            "Total de pasos: 2995877/3000000.0 - Recompensa: -0.12682441435272543\n",
            "Total de pasos: 2995878/3000000.0 - Recompensa: -1.2095225995491918\n",
            "Total de pasos: 2995879/3000000.0 - Recompensa: -1.2854728809290772\n",
            "Total de pasos: 2995880/3000000.0 - Recompensa: 0.7834653262459972\n",
            "0.7834653262459972\n",
            "Total de pasos: 2995881/3000000.0 - Recompensa: -0.4574424188023446\n",
            "Total de pasos: 2995882/3000000.0 - Recompensa: -0.7668608154497133\n",
            "Total de pasos: 2995883/3000000.0 - Recompensa: -0.6420204502271675\n",
            "Total de pasos: 2995884/3000000.0 - Recompensa: 1.1707624081435095\n",
            "1.1707624081435095\n",
            "Total de pasos: 2995885/3000000.0 - Recompensa: 0.4196377750771862\n",
            "0.4196377750771862\n",
            "Total de pasos: 2995886/3000000.0 - Recompensa: -0.4018936649151848\n",
            "Total de pasos: 2995887/3000000.0 - Recompensa: -0.07558294352834866\n",
            "Total de pasos: 2995888/3000000.0 - Recompensa: -0.9310286844943942\n",
            "Total de pasos: 2995889/3000000.0 - Recompensa: -1.2096283856609775\n",
            "Total de pasos: 2995890/3000000.0 - Recompensa: 0.21801224484605214\n",
            "0.21801224484605214\n",
            "Total de pasos: 2995891/3000000.0 - Recompensa: -1.0091550312789261\n",
            "Total de pasos: 2995892/3000000.0 - Recompensa: -0.3599759310969309\n",
            "Total de pasos: 2995893/3000000.0 - Recompensa: -0.8598216279397719\n",
            "Total de pasos: 2995894/3000000.0 - Recompensa: -0.496245819544164\n",
            "Total de pasos: 2995895/3000000.0 - Recompensa: -0.4750979475790878\n",
            "Total de pasos: 2995896/3000000.0 - Recompensa: 0.3489538540862331\n",
            "0.3489538540862331\n",
            "Total de pasos: 2995897/3000000.0 - Recompensa: -1.321797048872677\n",
            "Total de pasos: 2995898/3000000.0 - Recompensa: 0.6160354418667273\n",
            "0.6160354418667273\n",
            "Total de pasos: 2995899/3000000.0 - Recompensa: -1.742046673243331\n",
            "Total de pasos: 2995900/3000000.0 - Recompensa: -0.2655303167874181\n",
            "Total de pasos: 2995901/3000000.0 - Recompensa: 0.13823768692922841\n",
            "0.13823768692922841\n",
            "Total de pasos: 2995902/3000000.0 - Recompensa: 0.5676017690892652\n",
            "0.5676017690892652\n",
            "Total de pasos: 2995903/3000000.0 - Recompensa: -3.053711818009264\n",
            "Total de pasos: 2995904/3000000.0 - Recompensa: 1.2547818503899222\n",
            "1.2547818503899222\n",
            "Total de pasos: 2995905/3000000.0 - Recompensa: -1.5092390113082237\n",
            "Total de pasos: 2995906/3000000.0 - Recompensa: -0.04358605420255168\n",
            "Total de pasos: 2995907/3000000.0 - Recompensa: -1.2905088177164823\n",
            "Total de pasos: 2995908/3000000.0 - Recompensa: 0.6674403633853004\n",
            "0.6674403633853004\n",
            "Total de pasos: 2995909/3000000.0 - Recompensa: -0.5045406886912576\n",
            "Total de pasos: 2995910/3000000.0 - Recompensa: -0.805844818358487\n",
            "Total de pasos: 2995911/3000000.0 - Recompensa: -1.4456399803844262\n",
            "Total de pasos: 2995912/3000000.0 - Recompensa: -2.327215274022902\n",
            "Total de pasos: 2995913/3000000.0 - Recompensa: 0.10149320959468819\n",
            "0.10149320959468819\n",
            "Total de pasos: 2995914/3000000.0 - Recompensa: -0.6131821240155676\n",
            "Total de pasos: 2995915/3000000.0 - Recompensa: -1.2911558568305304\n",
            "Total de pasos: 2995916/3000000.0 - Recompensa: 0.7272523943844214\n",
            "0.7272523943844214\n",
            "Total de pasos: 2995917/3000000.0 - Recompensa: -0.9134721022625292\n",
            "Total de pasos: 2995918/3000000.0 - Recompensa: -1.2022058264391846\n",
            "Total de pasos: 2995919/3000000.0 - Recompensa: -2.2200583984509406\n",
            "Total de pasos: 2995920/3000000.0 - Recompensa: 0.10969314560640253\n",
            "0.10969314560640253\n",
            "Total de pasos: 2995921/3000000.0 - Recompensa: -4.088789876406731\n",
            "Total de pasos: 2995922/3000000.0 - Recompensa: -2.389554414523265\n",
            "Total de pasos: 2995923/3000000.0 - Recompensa: -1.57051565365517\n",
            "Total de pasos: 2995924/3000000.0 - Recompensa: -1.0845755948183382\n",
            "Total de pasos: 2995925/3000000.0 - Recompensa: -0.2504996549960586\n",
            "Total de pasos: 2995926/3000000.0 - Recompensa: -1.1386144008097079\n",
            "Total de pasos: 2995927/3000000.0 - Recompensa: -0.7801395471518255\n",
            "Total de pasos: 2995928/3000000.0 - Recompensa: -0.7229492431335908\n",
            "Total de pasos: 2995929/3000000.0 - Recompensa: -1.6928889401959033\n",
            "Total de pasos: 2995930/3000000.0 - Recompensa: -1.230896594653489\n",
            "Total de pasos: 2995931/3000000.0 - Recompensa: -1.1243385960667975\n",
            "Total de pasos: 2995932/3000000.0 - Recompensa: -1.0111927517627168\n",
            "Total de pasos: 2995933/3000000.0 - Recompensa: 0.15225899811054971\n",
            "0.15225899811054971\n",
            "Total de pasos: 2995934/3000000.0 - Recompensa: -1.3182874331477243\n",
            "Total de pasos: 2995935/3000000.0 - Recompensa: -0.8283729255339818\n",
            "Total de pasos: 2995936/3000000.0 - Recompensa: -0.8339020850146677\n",
            "Total de pasos: 2995937/3000000.0 - Recompensa: -0.9532571570270124\n",
            "Total de pasos: 2995938/3000000.0 - Recompensa: -0.957680295408163\n",
            "Total de pasos: 2995939/3000000.0 - Recompensa: -0.6422720734867811\n",
            "Total de pasos: 2995940/3000000.0 - Recompensa: -1.6853678221328603\n",
            "Total de pasos: 2995941/3000000.0 - Recompensa: -0.6049277082626718\n",
            "Total de pasos: 2995942/3000000.0 - Recompensa: -0.9550539087847725\n",
            "Total de pasos: 2995943/3000000.0 - Recompensa: 1.0645554806131527\n",
            "1.0645554806131527\n",
            "Total de pasos: 2995944/3000000.0 - Recompensa: -2.3677155439665394\n",
            "Total de pasos: 2995945/3000000.0 - Recompensa: -1.4489286575716271\n",
            "Total de pasos: 2995946/3000000.0 - Recompensa: -1.5484151409762217\n",
            "Total de pasos: 2995947/3000000.0 - Recompensa: -1.7244536121542766\n",
            "Total de pasos: 2995948/3000000.0 - Recompensa: -1.8016469658734455\n",
            "Total de pasos: 2995949/3000000.0 - Recompensa: -0.21406070312670417\n",
            "Total de pasos: 2995950/3000000.0 - Recompensa: -0.26208026138730683\n",
            "Total de pasos: 2995951/3000000.0 - Recompensa: -4.765526768969398\n",
            "Total de pasos: 2995952/3000000.0 - Recompensa: 0.060318267745050835\n",
            "0.060318267745050835\n",
            "Total de pasos: 2995953/3000000.0 - Recompensa: 0.4528749795359195\n",
            "0.4528749795359195\n",
            "Total de pasos: 2995954/3000000.0 - Recompensa: 0.5663643138299107\n",
            "0.5663643138299107\n",
            "Total de pasos: 2995955/3000000.0 - Recompensa: 0.4625190012397293\n",
            "0.4625190012397293\n",
            "Total de pasos: 2995956/3000000.0 - Recompensa: -0.3550754331117687\n",
            "Total de pasos: 2995957/3000000.0 - Recompensa: -0.1943894237173301\n",
            "Total de pasos: 2995958/3000000.0 - Recompensa: 0.42229355335695934\n",
            "0.42229355335695934\n",
            "Total de pasos: 2995959/3000000.0 - Recompensa: -0.3156298053740059\n",
            "Total de pasos: 2995960/3000000.0 - Recompensa: 0.10820182475762116\n",
            "0.10820182475762116\n",
            "Total de pasos: 2995961/3000000.0 - Recompensa: -2.2925706606063985\n",
            "Total de pasos: 2995962/3000000.0 - Recompensa: -1.676633739068898\n",
            "Total de pasos: 2995963/3000000.0 - Recompensa: -1.6190553321040166\n",
            "Total de pasos: 2995964/3000000.0 - Recompensa: -1.6600075791516964\n",
            "Total de pasos: 2995965/3000000.0 - Recompensa: -0.11732657954491699\n",
            "Total de pasos: 2995966/3000000.0 - Recompensa: -0.819599230121945\n",
            "Total de pasos: 2995967/3000000.0 - Recompensa: -1.6789064889813656\n",
            "Total de pasos: 2995968/3000000.0 - Recompensa: -1.6465273088817693\n",
            "Total de pasos: 2995969/3000000.0 - Recompensa: -0.9873153863298549\n",
            "Total de pasos: 2995970/3000000.0 - Recompensa: 0.05096327904204209\n",
            "0.05096327904204209\n",
            "Total de pasos: 2995971/3000000.0 - Recompensa: -0.24058196667589984\n",
            "Total de pasos: 2995972/3000000.0 - Recompensa: -1.4285433841686923\n",
            "Total de pasos: 2995973/3000000.0 - Recompensa: 0.5309179899421239\n",
            "0.5309179899421239\n",
            "Total de pasos: 2995974/3000000.0 - Recompensa: -0.9352332284519906\n",
            "Total de pasos: 2995975/3000000.0 - Recompensa: 0.33120126341938094\n",
            "0.33120126341938094\n",
            "Total de pasos: 2995976/3000000.0 - Recompensa: -1.1659728907495643\n",
            "Total de pasos: 2995977/3000000.0 - Recompensa: -1.2318614357128224\n",
            "Total de pasos: 2995978/3000000.0 - Recompensa: -0.790966094218944\n",
            "Total de pasos: 2995979/3000000.0 - Recompensa: -0.2645164543243553\n",
            "Total de pasos: 2995980/3000000.0 - Recompensa: -0.25545443547141433\n",
            "Total de pasos: 2995981/3000000.0 - Recompensa: -0.46308409925089206\n",
            "Total de pasos: 2995982/3000000.0 - Recompensa: -0.4316037429401652\n",
            "Total de pasos: 2995983/3000000.0 - Recompensa: -1.1878982081594542\n",
            "Total de pasos: 2995984/3000000.0 - Recompensa: 0.18946601374234281\n",
            "0.18946601374234281\n",
            "Total de pasos: 2995985/3000000.0 - Recompensa: -0.5319205068151638\n",
            "Total de pasos: 2995986/3000000.0 - Recompensa: -0.426802215019502\n",
            "Total de pasos: 2995987/3000000.0 - Recompensa: -1.8522831218556761\n",
            "Total de pasos: 2995988/3000000.0 - Recompensa: -0.07582739264836524\n",
            "Total de pasos: 2995989/3000000.0 - Recompensa: -0.6144153878656539\n",
            "Total de pasos: 2995990/3000000.0 - Recompensa: -0.8252419508481922\n",
            "Total de pasos: 2995991/3000000.0 - Recompensa: -0.2983888984756352\n",
            "Total de pasos: 2995992/3000000.0 - Recompensa: 0.5059150336994717\n",
            "0.5059150336994717\n",
            "Total de pasos: 2995993/3000000.0 - Recompensa: -2.1882260377084437\n",
            "Total de pasos: 2995994/3000000.0 - Recompensa: -0.5475365268777107\n",
            "Total de pasos: 2995995/3000000.0 - Recompensa: -1.9173443419327325\n",
            "Total de pasos: 2995996/3000000.0 - Recompensa: 0.4075101774508189\n",
            "0.4075101774508189\n",
            "Total de pasos: 2995997/3000000.0 - Recompensa: 0.23732792548564693\n",
            "0.23732792548564693\n",
            "Total de pasos: 2995998/3000000.0 - Recompensa: 0.8882106137069827\n",
            "0.8882106137069827\n",
            "Total de pasos: 2995999/3000000.0 - Recompensa: -1.3706412950661744\n",
            "Total de pasos: 2996000/3000000.0 - Recompensa: -1.351102172507615\n",
            "Total de pasos: 2996001/3000000.0 - Recompensa: 0.36394763675833114\n",
            "0.36394763675833114\n",
            "Total de pasos: 2996002/3000000.0 - Recompensa: -1.298913121294186\n",
            "Total de pasos: 2996003/3000000.0 - Recompensa: 1.0697919095774973\n",
            "1.0697919095774973\n",
            "Total de pasos: 2996004/3000000.0 - Recompensa: -1.0844318302656561\n",
            "Total de pasos: 2996005/3000000.0 - Recompensa: -1.9191959515564394\n",
            "Total de pasos: 2996006/3000000.0 - Recompensa: -3.1879406284949523\n",
            "Total de pasos: 2996007/3000000.0 - Recompensa: -0.2120672800753785\n",
            "Total de pasos: 2996008/3000000.0 - Recompensa: 0.21907422533124388\n",
            "0.21907422533124388\n",
            "Total de pasos: 2996009/3000000.0 - Recompensa: -0.8089708780628937\n",
            "Total de pasos: 2996010/3000000.0 - Recompensa: -1.8717828291154552\n",
            "Total de pasos: 2996011/3000000.0 - Recompensa: -0.7672454608832717\n",
            "Total de pasos: 2996012/3000000.0 - Recompensa: -0.4182506196526039\n",
            "Total de pasos: 2996013/3000000.0 - Recompensa: -0.512822753964248\n",
            "Total de pasos: 2996014/3000000.0 - Recompensa: -0.5736310555916324\n",
            "Total de pasos: 2996015/3000000.0 - Recompensa: -1.5702810802219171\n",
            "Total de pasos: 2996016/3000000.0 - Recompensa: 0.22638881930213314\n",
            "0.22638881930213314\n",
            "Total de pasos: 2996017/3000000.0 - Recompensa: -0.6384641648427991\n",
            "Total de pasos: 2996018/3000000.0 - Recompensa: -1.7472534687509484\n",
            "Total de pasos: 2996019/3000000.0 - Recompensa: -0.6633717731617326\n",
            "Total de pasos: 2996020/3000000.0 - Recompensa: 0.5025417202232172\n",
            "0.5025417202232172\n",
            "Total de pasos: 2996021/3000000.0 - Recompensa: -0.9124308665035484\n",
            "Total de pasos: 2996022/3000000.0 - Recompensa: -2.4479739904645665\n",
            "Total de pasos: 2996023/3000000.0 - Recompensa: -1.9929637440423096\n",
            "Total de pasos: 2996024/3000000.0 - Recompensa: -0.18677368125082064\n",
            "Total de pasos: 2996025/3000000.0 - Recompensa: 0.26109306430091994\n",
            "0.26109306430091994\n",
            "Total de pasos: 2996026/3000000.0 - Recompensa: -0.23338835294161592\n",
            "Total de pasos: 2996027/3000000.0 - Recompensa: -0.25861833361228237\n",
            "Total de pasos: 2996028/3000000.0 - Recompensa: -0.718840265581615\n",
            "Total de pasos: 2996029/3000000.0 - Recompensa: -1.3752790666325219\n",
            "Total de pasos: 2996030/3000000.0 - Recompensa: 0.1653804143978534\n",
            "0.1653804143978534\n",
            "Total de pasos: 2996031/3000000.0 - Recompensa: -0.5451100949889895\n",
            "Total de pasos: 2996032/3000000.0 - Recompensa: -0.3379348461634913\n",
            "Total de pasos: 2996033/3000000.0 - Recompensa: 0.17615495162928427\n",
            "0.17615495162928427\n",
            "Total de pasos: 2996034/3000000.0 - Recompensa: 0.12005811882897727\n",
            "0.12005811882897727\n",
            "Total de pasos: 2996035/3000000.0 - Recompensa: -1.9165471230679265\n",
            "Total de pasos: 2996036/3000000.0 - Recompensa: -0.31319406484428425\n",
            "Total de pasos: 2996037/3000000.0 - Recompensa: -0.6860363937389085\n",
            "Total de pasos: 2996038/3000000.0 - Recompensa: -0.1250955722352102\n",
            "Total de pasos: 2996039/3000000.0 - Recompensa: -0.6825816427750516\n",
            "Total de pasos: 2996040/3000000.0 - Recompensa: -0.1725690356030148\n",
            "Total de pasos: 2996041/3000000.0 - Recompensa: -3.2033418262691886\n",
            "Total de pasos: 2996042/3000000.0 - Recompensa: -0.46235429612318446\n",
            "Total de pasos: 2996043/3000000.0 - Recompensa: -1.4859862630923109\n",
            "Total de pasos: 2996044/3000000.0 - Recompensa: -1.2949610569675167\n",
            "Total de pasos: 2996045/3000000.0 - Recompensa: -0.8455894614643797\n",
            "Total de pasos: 2996046/3000000.0 - Recompensa: -1.3761359404248148\n",
            "Total de pasos: 2996047/3000000.0 - Recompensa: -0.2809104282277799\n",
            "Total de pasos: 2996048/3000000.0 - Recompensa: 0.28027999315620733\n",
            "0.28027999315620733\n",
            "Total de pasos: 2996049/3000000.0 - Recompensa: 0.6869524804818656\n",
            "0.6869524804818656\n",
            "Total de pasos: 2996050/3000000.0 - Recompensa: -1.2434594406819413\n",
            "Total de pasos: 2996051/3000000.0 - Recompensa: 0.5423996651696333\n",
            "0.5423996651696333\n",
            "Total de pasos: 2996052/3000000.0 - Recompensa: -0.6591698074867883\n",
            "Total de pasos: 2996053/3000000.0 - Recompensa: -0.45149278308255064\n",
            "Total de pasos: 2996054/3000000.0 - Recompensa: -1.2378042279705264\n",
            "Total de pasos: 2996055/3000000.0 - Recompensa: 0.27874188055856813\n",
            "0.27874188055856813\n",
            "Total de pasos: 2996056/3000000.0 - Recompensa: -1.1332199028012753\n",
            "Total de pasos: 2996057/3000000.0 - Recompensa: -3.9348739987316543\n",
            "Total de pasos: 2996058/3000000.0 - Recompensa: 0.007485138103423716\n",
            "0.007485138103423716\n",
            "Total de pasos: 2996059/3000000.0 - Recompensa: -1.3846064487077463\n",
            "Total de pasos: 2996060/3000000.0 - Recompensa: -2.04743307122516\n",
            "Total de pasos: 2996061/3000000.0 - Recompensa: 0.2955905728741667\n",
            "0.2955905728741667\n",
            "Total de pasos: 2996062/3000000.0 - Recompensa: 0.2851882195815004\n",
            "0.2851882195815004\n",
            "Total de pasos: 2996063/3000000.0 - Recompensa: -1.689869635988937\n",
            "Total de pasos: 2996064/3000000.0 - Recompensa: -0.593251180428318\n",
            "Total de pasos: 2996065/3000000.0 - Recompensa: 0.4825144355222341\n",
            "0.4825144355222341\n",
            "Total de pasos: 2996066/3000000.0 - Recompensa: -0.2523466464173064\n",
            "Total de pasos: 2996067/3000000.0 - Recompensa: -1.2932219085865397\n",
            "Total de pasos: 2996068/3000000.0 - Recompensa: -1.506867114225513\n",
            "Total de pasos: 2996069/3000000.0 - Recompensa: -0.754664242503498\n",
            "Total de pasos: 2996070/3000000.0 - Recompensa: -1.7863859538658722\n",
            "Total de pasos: 2996071/3000000.0 - Recompensa: -0.2506912656428598\n",
            "Total de pasos: 2996072/3000000.0 - Recompensa: -1.2674814971317936\n",
            "Total de pasos: 2996073/3000000.0 - Recompensa: -0.37250305671800304\n",
            "Total de pasos: 2996074/3000000.0 - Recompensa: -0.7758503428421568\n",
            "Total de pasos: 2996075/3000000.0 - Recompensa: -3.4558093991968355\n",
            "Total de pasos: 2996076/3000000.0 - Recompensa: 1.0245859410430525\n",
            "1.0245859410430525\n",
            "Total de pasos: 2996077/3000000.0 - Recompensa: -0.14532813926559102\n",
            "Total de pasos: 2996078/3000000.0 - Recompensa: -0.9731404150676143\n",
            "Total de pasos: 2996079/3000000.0 - Recompensa: -0.4345442611356057\n",
            "Total de pasos: 2996080/3000000.0 - Recompensa: -0.8867051750431346\n",
            "Total de pasos: 2996081/3000000.0 - Recompensa: -2.1539004562732296\n",
            "Total de pasos: 2996082/3000000.0 - Recompensa: -1.3911282377792893\n",
            "Total de pasos: 2996083/3000000.0 - Recompensa: -2.368779777898154\n",
            "Total de pasos: 2996084/3000000.0 - Recompensa: -2.136770170148592\n",
            "Total de pasos: 2996085/3000000.0 - Recompensa: 0.038655578868067975\n",
            "0.038655578868067975\n",
            "Total de pasos: 2996086/3000000.0 - Recompensa: 0.4203545841257343\n",
            "0.4203545841257343\n",
            "Total de pasos: 2996087/3000000.0 - Recompensa: -0.7734209771968803\n",
            "Total de pasos: 2996088/3000000.0 - Recompensa: 0.6167429829529947\n",
            "0.6167429829529947\n",
            "Total de pasos: 2996089/3000000.0 - Recompensa: -1.98427372384278\n",
            "Total de pasos: 2996090/3000000.0 - Recompensa: -3.2032200568728246\n",
            "Total de pasos: 2996091/3000000.0 - Recompensa: 0.2677490583005986\n",
            "0.2677490583005986\n",
            "Total de pasos: 2996092/3000000.0 - Recompensa: 1.2792451688185613\n",
            "1.2792451688185613\n",
            "Total de pasos: 2996093/3000000.0 - Recompensa: -0.4350644078757522\n",
            "Total de pasos: 2996094/3000000.0 - Recompensa: -0.28426091487053085\n",
            "Total de pasos: 2996095/3000000.0 - Recompensa: -0.7632267325429519\n",
            "Total de pasos: 2996096/3000000.0 - Recompensa: -1.2452488113761873\n",
            "Total de pasos: 2996097/3000000.0 - Recompensa: -1.443156545251692\n",
            "Total de pasos: 2996098/3000000.0 - Recompensa: 0.42623994977758706\n",
            "0.42623994977758706\n",
            "Total de pasos: 2996099/3000000.0 - Recompensa: -1.2898060219944696\n",
            "Total de pasos: 2996100/3000000.0 - Recompensa: -2.0311407065259717\n",
            "Total de pasos: 2996101/3000000.0 - Recompensa: -1.2498633806210684\n",
            "Total de pasos: 2996102/3000000.0 - Recompensa: -1.918055588350435\n",
            "Total de pasos: 2996103/3000000.0 - Recompensa: -0.6560439491974591\n",
            "Total de pasos: 2996104/3000000.0 - Recompensa: -0.24147274150104608\n",
            "Total de pasos: 2996105/3000000.0 - Recompensa: -2.5686418326468345\n",
            "Total de pasos: 2996106/3000000.0 - Recompensa: -3.434678569935409\n",
            "Total de pasos: 2996107/3000000.0 - Recompensa: -1.7328200401865035\n",
            "Total de pasos: 2996108/3000000.0 - Recompensa: -2.334018591240094\n",
            "Total de pasos: 2996109/3000000.0 - Recompensa: 0.0121016106675563\n",
            "0.0121016106675563\n",
            "Total de pasos: 2996110/3000000.0 - Recompensa: -0.227064944233811\n",
            "Total de pasos: 2996111/3000000.0 - Recompensa: -1.8240152558832772\n",
            "Total de pasos: 2996112/3000000.0 - Recompensa: 0.2662734102922137\n",
            "0.2662734102922137\n",
            "Total de pasos: 2996113/3000000.0 - Recompensa: -0.7056628333449065\n",
            "Total de pasos: 2996114/3000000.0 - Recompensa: -1.5330401127206121\n",
            "Total de pasos: 2996115/3000000.0 - Recompensa: -0.25734713046071345\n",
            "Total de pasos: 2996116/3000000.0 - Recompensa: -0.790384002029292\n",
            "Total de pasos: 2996117/3000000.0 - Recompensa: -0.7587596099241013\n",
            "Total de pasos: 2996118/3000000.0 - Recompensa: -0.1141925059918994\n",
            "Total de pasos: 2996119/3000000.0 - Recompensa: 0.043716191271486515\n",
            "0.043716191271486515\n",
            "Total de pasos: 2996120/3000000.0 - Recompensa: -0.4493604417247282\n",
            "Total de pasos: 2996121/3000000.0 - Recompensa: -1.9702946430935644\n",
            "Total de pasos: 2996122/3000000.0 - Recompensa: -0.6785498023627564\n",
            "Total de pasos: 2996123/3000000.0 - Recompensa: -1.248486311560517\n",
            "Total de pasos: 2996124/3000000.0 - Recompensa: -0.7621622481884047\n",
            "Total de pasos: 2996125/3000000.0 - Recompensa: -0.6305648041426427\n",
            "Total de pasos: 2996126/3000000.0 - Recompensa: -0.7640962784679853\n",
            "Total de pasos: 2996127/3000000.0 - Recompensa: -0.502264952370082\n",
            "Total de pasos: 2996128/3000000.0 - Recompensa: -0.2523363038123197\n",
            "Total de pasos: 2996129/3000000.0 - Recompensa: -2.4859510349922256\n",
            "Total de pasos: 2996130/3000000.0 - Recompensa: -0.5371667458126255\n",
            "Total de pasos: 2996131/3000000.0 - Recompensa: 0.9484495261710705\n",
            "0.9484495261710705\n",
            "Total de pasos: 2996132/3000000.0 - Recompensa: -0.46521500636249097\n",
            "Total de pasos: 2996133/3000000.0 - Recompensa: -0.5946566408465029\n",
            "Total de pasos: 2996134/3000000.0 - Recompensa: 0.10330036618739674\n",
            "0.10330036618739674\n",
            "Total de pasos: 2996135/3000000.0 - Recompensa: 0.5536887673474236\n",
            "0.5536887673474236\n",
            "Total de pasos: 2996136/3000000.0 - Recompensa: -0.5670920538749737\n",
            "Total de pasos: 2996137/3000000.0 - Recompensa: -0.07839402043858718\n",
            "Total de pasos: 2996138/3000000.0 - Recompensa: -2.012616505065314\n",
            "Total de pasos: 2996139/3000000.0 - Recompensa: -0.2575587222109499\n",
            "Total de pasos: 2996140/3000000.0 - Recompensa: -0.6385397822353067\n",
            "Total de pasos: 2996141/3000000.0 - Recompensa: -1.6256099915480189\n",
            "Total de pasos: 2996142/3000000.0 - Recompensa: 0.03433014857123448\n",
            "0.03433014857123448\n",
            "Total de pasos: 2996143/3000000.0 - Recompensa: -1.2363915088732684\n",
            "Total de pasos: 2996144/3000000.0 - Recompensa: -0.12042688703461951\n",
            "Total de pasos: 2996145/3000000.0 - Recompensa: -0.6577563599029512\n",
            "Total de pasos: 2996146/3000000.0 - Recompensa: 0.42046754262338115\n",
            "0.42046754262338115\n",
            "Total de pasos: 2996147/3000000.0 - Recompensa: -0.9139449293843128\n",
            "Total de pasos: 2996148/3000000.0 - Recompensa: 0.7871494928633378\n",
            "0.7871494928633378\n",
            "Total de pasos: 2996149/3000000.0 - Recompensa: -1.4011450635848646\n",
            "Total de pasos: 2996150/3000000.0 - Recompensa: -1.2007285734806619\n",
            "Total de pasos: 2996151/3000000.0 - Recompensa: -1.2974951321991508\n",
            "Total de pasos: 2996152/3000000.0 - Recompensa: -2.1240968960709288\n",
            "Total de pasos: 2996153/3000000.0 - Recompensa: -1.163146194761736\n",
            "Total de pasos: 2996154/3000000.0 - Recompensa: -3.3191091718668058\n",
            "Total de pasos: 2996155/3000000.0 - Recompensa: -1.0933448509598667\n",
            "Total de pasos: 2996156/3000000.0 - Recompensa: -1.5462627668003688\n",
            "Total de pasos: 2996157/3000000.0 - Recompensa: -0.7452621080439505\n",
            "Total de pasos: 2996158/3000000.0 - Recompensa: 0.17932974801953336\n",
            "0.17932974801953336\n",
            "Total de pasos: 2996159/3000000.0 - Recompensa: -1.1613961304895877\n",
            "Total de pasos: 2996160/3000000.0 - Recompensa: 0.6526660317600677\n",
            "0.6526660317600677\n",
            "Total de pasos: 2996161/3000000.0 - Recompensa: -1.073901279218266\n",
            "Total de pasos: 2996162/3000000.0 - Recompensa: -1.1029523927504716\n",
            "Total de pasos: 2996163/3000000.0 - Recompensa: -2.6781332401907227\n",
            "Total de pasos: 2996164/3000000.0 - Recompensa: -0.9396294803851951\n",
            "Total de pasos: 2996165/3000000.0 - Recompensa: 0.09615665306233664\n",
            "0.09615665306233664\n",
            "Total de pasos: 2996166/3000000.0 - Recompensa: -0.46829632716749786\n",
            "Total de pasos: 2996167/3000000.0 - Recompensa: -0.4041797099330407\n",
            "Total de pasos: 2996168/3000000.0 - Recompensa: -0.47769311706714346\n",
            "Total de pasos: 2996169/3000000.0 - Recompensa: -0.012568147276586894\n",
            "Total de pasos: 2996170/3000000.0 - Recompensa: -0.8122330794868395\n",
            "Total de pasos: 2996171/3000000.0 - Recompensa: -0.42295977334923673\n",
            "Total de pasos: 2996172/3000000.0 - Recompensa: 0.8667169168244188\n",
            "0.8667169168244188\n",
            "Total de pasos: 2996173/3000000.0 - Recompensa: -0.2565647390975382\n",
            "Total de pasos: 2996174/3000000.0 - Recompensa: 0.004408240709158795\n",
            "0.004408240709158795\n",
            "Total de pasos: 2996175/3000000.0 - Recompensa: -0.23330501042544194\n",
            "Total de pasos: 2996176/3000000.0 - Recompensa: -1.640514160199246\n",
            "Total de pasos: 2996177/3000000.0 - Recompensa: -0.1684063915943717\n",
            "Total de pasos: 2996178/3000000.0 - Recompensa: -1.5767990265680365\n",
            "Total de pasos: 2996179/3000000.0 - Recompensa: 0.1332717928621976\n",
            "0.1332717928621976\n",
            "Total de pasos: 2996180/3000000.0 - Recompensa: -0.30841342011397616\n",
            "Total de pasos: 2996181/3000000.0 - Recompensa: 0.26011672851284356\n",
            "0.26011672851284356\n",
            "Total de pasos: 2996182/3000000.0 - Recompensa: 0.018120939665004776\n",
            "0.018120939665004776\n",
            "Total de pasos: 2996183/3000000.0 - Recompensa: -1.5636949570795808\n",
            "Total de pasos: 2996184/3000000.0 - Recompensa: 0.2595934397102987\n",
            "0.2595934397102987\n",
            "Total de pasos: 2996185/3000000.0 - Recompensa: -1.3968078921456537\n",
            "Total de pasos: 2996186/3000000.0 - Recompensa: -0.15330676074588637\n",
            "Total de pasos: 2996187/3000000.0 - Recompensa: -1.1262866647850667\n",
            "Total de pasos: 2996188/3000000.0 - Recompensa: 0.15819918909153924\n",
            "0.15819918909153924\n",
            "Total de pasos: 2996189/3000000.0 - Recompensa: -1.872373584997938\n",
            "Total de pasos: 2996190/3000000.0 - Recompensa: -1.864443557318127\n",
            "Total de pasos: 2996191/3000000.0 - Recompensa: -0.7811267675844225\n",
            "Total de pasos: 2996192/3000000.0 - Recompensa: 0.5594743180360866\n",
            "0.5594743180360866\n",
            "Total de pasos: 2996193/3000000.0 - Recompensa: -3.9874846350175446\n",
            "Total de pasos: 2996194/3000000.0 - Recompensa: -1.0859076928114586\n",
            "Total de pasos: 2996195/3000000.0 - Recompensa: -0.01544613743571338\n",
            "Total de pasos: 2996196/3000000.0 - Recompensa: -0.6348718559067179\n",
            "Total de pasos: 2996197/3000000.0 - Recompensa: 0.17425096035825288\n",
            "0.17425096035825288\n",
            "Total de pasos: 2996198/3000000.0 - Recompensa: -0.5590476267800714\n",
            "Total de pasos: 2996199/3000000.0 - Recompensa: -0.73021369307855\n",
            "Total de pasos: 2996200/3000000.0 - Recompensa: -1.11690784329602\n",
            "Total de pasos: 2996201/3000000.0 - Recompensa: -0.3489895058117896\n",
            "Total de pasos: 2996202/3000000.0 - Recompensa: -0.2714841571086878\n",
            "Total de pasos: 2996203/3000000.0 - Recompensa: -0.07202297173978525\n",
            "Total de pasos: 2996204/3000000.0 - Recompensa: -0.27469972698633854\n",
            "Total de pasos: 2996205/3000000.0 - Recompensa: -0.9069339703728831\n",
            "Total de pasos: 2996206/3000000.0 - Recompensa: -0.6262958528042806\n",
            "Total de pasos: 2996207/3000000.0 - Recompensa: -3.505553646102993\n",
            "Total de pasos: 2996208/3000000.0 - Recompensa: -0.17802351478663958\n",
            "Total de pasos: 2996209/3000000.0 - Recompensa: -1.851676679018591\n",
            "Total de pasos: 2996210/3000000.0 - Recompensa: -2.0645460846559334\n",
            "Total de pasos: 2996211/3000000.0 - Recompensa: 0.43380812555259707\n",
            "0.43380812555259707\n",
            "Total de pasos: 2996212/3000000.0 - Recompensa: -1.7235359635890797\n",
            "Total de pasos: 2996213/3000000.0 - Recompensa: -2.0704783244738465\n",
            "Total de pasos: 2996214/3000000.0 - Recompensa: -0.4809131589255514\n",
            "Total de pasos: 2996215/3000000.0 - Recompensa: -0.716359685831326\n",
            "Total de pasos: 2996216/3000000.0 - Recompensa: -1.1977635022287865\n",
            "Total de pasos: 2996217/3000000.0 - Recompensa: -1.6966273333305124\n",
            "Total de pasos: 2996218/3000000.0 - Recompensa: -2.586379951507916\n",
            "Total de pasos: 2996219/3000000.0 - Recompensa: -0.5682782288292436\n",
            "Total de pasos: 2996220/3000000.0 - Recompensa: -2.0442803035714805\n",
            "Total de pasos: 2996221/3000000.0 - Recompensa: -0.22663727944099482\n",
            "Total de pasos: 2996222/3000000.0 - Recompensa: -0.7304905618213423\n",
            "Total de pasos: 2996223/3000000.0 - Recompensa: -0.866691839802969\n",
            "Total de pasos: 2996224/3000000.0 - Recompensa: 0.7164665710368606\n",
            "0.7164665710368606\n",
            "Total de pasos: 2996225/3000000.0 - Recompensa: -0.5822921823367866\n",
            "Total de pasos: 2996226/3000000.0 - Recompensa: -0.5416823705688794\n",
            "Total de pasos: 2996227/3000000.0 - Recompensa: -4.448170893930229\n",
            "Total de pasos: 2996228/3000000.0 - Recompensa: -0.7352499540851645\n",
            "Total de pasos: 2996229/3000000.0 - Recompensa: -0.606578631758793\n",
            "Total de pasos: 2996230/3000000.0 - Recompensa: 0.21602342227457658\n",
            "0.21602342227457658\n",
            "Total de pasos: 2996231/3000000.0 - Recompensa: -0.5658716047507266\n",
            "Total de pasos: 2996232/3000000.0 - Recompensa: 0.18082584986357428\n",
            "0.18082584986357428\n",
            "Total de pasos: 2996233/3000000.0 - Recompensa: 0.22989028232854167\n",
            "0.22989028232854167\n",
            "Total de pasos: 2996234/3000000.0 - Recompensa: -4.028687522600042\n",
            "Total de pasos: 2996235/3000000.0 - Recompensa: -0.597587359604743\n",
            "Total de pasos: 2996236/3000000.0 - Recompensa: -1.6960892328525567\n",
            "Total de pasos: 2996237/3000000.0 - Recompensa: -0.9374142163982605\n",
            "Total de pasos: 2996238/3000000.0 - Recompensa: -0.9534408702833533\n",
            "Total de pasos: 2996239/3000000.0 - Recompensa: -0.9003054978774053\n",
            "Total de pasos: 2996240/3000000.0 - Recompensa: -0.9571343091238509\n",
            "Total de pasos: 2996241/3000000.0 - Recompensa: -0.05370301854847029\n",
            "Total de pasos: 2996242/3000000.0 - Recompensa: 0.686675315489085\n",
            "0.686675315489085\n",
            "Total de pasos: 2996243/3000000.0 - Recompensa: -2.29148517324978\n",
            "Total de pasos: 2996244/3000000.0 - Recompensa: -1.5349709774891849\n",
            "Total de pasos: 2996245/3000000.0 - Recompensa: -0.032454631833118974\n",
            "Total de pasos: 2996246/3000000.0 - Recompensa: -0.2695051047458146\n",
            "Total de pasos: 2996247/3000000.0 - Recompensa: -2.0470917047254202\n",
            "Total de pasos: 2996248/3000000.0 - Recompensa: 0.49835191913928145\n",
            "0.49835191913928145\n",
            "Total de pasos: 2996249/3000000.0 - Recompensa: -0.7505874766844184\n",
            "Total de pasos: 2996250/3000000.0 - Recompensa: 0.19976204350139953\n",
            "0.19976204350139953\n",
            "Total de pasos: 2996251/3000000.0 - Recompensa: -0.8066498494795138\n",
            "Total de pasos: 2996252/3000000.0 - Recompensa: 0.25825376884409684\n",
            "0.25825376884409684\n",
            "Total de pasos: 2996253/3000000.0 - Recompensa: -0.8433677070661789\n",
            "Total de pasos: 2996254/3000000.0 - Recompensa: -2.1945503595313194\n",
            "Total de pasos: 2996255/3000000.0 - Recompensa: -1.4043347495693994\n",
            "Total de pasos: 2996256/3000000.0 - Recompensa: -0.7263529462593249\n",
            "Total de pasos: 2996257/3000000.0 - Recompensa: -1.1569411518827009\n",
            "Total de pasos: 2996258/3000000.0 - Recompensa: -1.1691614437625473\n",
            "Total de pasos: 2996259/3000000.0 - Recompensa: -0.9056433222327749\n",
            "Total de pasos: 2996260/3000000.0 - Recompensa: 0.16954072026801342\n",
            "0.16954072026801342\n",
            "Total de pasos: 2996261/3000000.0 - Recompensa: -0.9057578070803591\n",
            "Total de pasos: 2996262/3000000.0 - Recompensa: 0.0267557290469726\n",
            "0.0267557290469726\n",
            "Total de pasos: 2996263/3000000.0 - Recompensa: -0.048740182134684146\n",
            "Total de pasos: 2996264/3000000.0 - Recompensa: 0.023827782344193693\n",
            "0.023827782344193693\n",
            "Total de pasos: 2996265/3000000.0 - Recompensa: -0.2501146574043166\n",
            "Total de pasos: 2996266/3000000.0 - Recompensa: 0.25343570661438164\n",
            "0.25343570661438164\n",
            "Total de pasos: 2996267/3000000.0 - Recompensa: -1.1023123805624246\n",
            "Total de pasos: 2996268/3000000.0 - Recompensa: 0.6699191901131909\n",
            "0.6699191901131909\n",
            "Total de pasos: 2996269/3000000.0 - Recompensa: -0.13720927089453677\n",
            "Total de pasos: 2996270/3000000.0 - Recompensa: -1.0595123703223452\n",
            "Total de pasos: 2996271/3000000.0 - Recompensa: -0.6180182148714637\n",
            "Total de pasos: 2996272/3000000.0 - Recompensa: -0.6408300000579271\n",
            "Total de pasos: 2996273/3000000.0 - Recompensa: 0.006571123737690365\n",
            "0.006571123737690365\n",
            "Total de pasos: 2996274/3000000.0 - Recompensa: 0.25431395946992164\n",
            "0.25431395946992164\n",
            "Total de pasos: 2996275/3000000.0 - Recompensa: 0.2556356905512515\n",
            "0.2556356905512515\n",
            "Total de pasos: 2996276/3000000.0 - Recompensa: 0.07372070924150592\n",
            "0.07372070924150592\n",
            "Total de pasos: 2996277/3000000.0 - Recompensa: -1.8098299715649233\n",
            "Total de pasos: 2996278/3000000.0 - Recompensa: -0.66415236071448\n",
            "Total de pasos: 2996279/3000000.0 - Recompensa: -0.7908862637849879\n",
            "Total de pasos: 2996280/3000000.0 - Recompensa: -2.740013981525897\n",
            "Total de pasos: 2996281/3000000.0 - Recompensa: -0.033565795683110355\n",
            "Total de pasos: 2996282/3000000.0 - Recompensa: 0.41781880724006004\n",
            "0.41781880724006004\n",
            "Total de pasos: 2996283/3000000.0 - Recompensa: 0.03788860888939832\n",
            "0.03788860888939832\n",
            "Total de pasos: 2996284/3000000.0 - Recompensa: 0.8659131507213628\n",
            "0.8659131507213628\n",
            "Total de pasos: 2996285/3000000.0 - Recompensa: -0.1765849797998676\n",
            "Total de pasos: 2996286/3000000.0 - Recompensa: 0.5646450790659854\n",
            "0.5646450790659854\n",
            "Total de pasos: 2996287/3000000.0 - Recompensa: -1.084237590342776\n",
            "Total de pasos: 2996288/3000000.0 - Recompensa: -3.7183312291591\n",
            "Total de pasos: 2996289/3000000.0 - Recompensa: -0.28286244523801224\n",
            "Total de pasos: 2996290/3000000.0 - Recompensa: -2.290423438611504\n",
            "Total de pasos: 2996291/3000000.0 - Recompensa: -1.326661436421065\n",
            "Total de pasos: 2996292/3000000.0 - Recompensa: -1.0824629103839596\n",
            "Total de pasos: 2996293/3000000.0 - Recompensa: -1.9524492228603703\n",
            "Total de pasos: 2996294/3000000.0 - Recompensa: -2.2039912746585473\n",
            "Total de pasos: 2996295/3000000.0 - Recompensa: 0.0621192227480451\n",
            "0.0621192227480451\n",
            "Total de pasos: 2996296/3000000.0 - Recompensa: -0.544333356874584\n",
            "Total de pasos: 2996297/3000000.0 - Recompensa: -0.6078571016999692\n",
            "Total de pasos: 2996298/3000000.0 - Recompensa: -0.1587401474591375\n",
            "Total de pasos: 2996299/3000000.0 - Recompensa: -5.661140895848175\n",
            "Total de pasos: 2996300/3000000.0 - Recompensa: 0.24576900774685323\n",
            "0.24576900774685323\n",
            "Total de pasos: 2996301/3000000.0 - Recompensa: -2.479583562474775\n",
            "Total de pasos: 2996302/3000000.0 - Recompensa: -2.221570805714216\n",
            "Total de pasos: 2996303/3000000.0 - Recompensa: 0.277614128790722\n",
            "0.277614128790722\n",
            "Total de pasos: 2996304/3000000.0 - Recompensa: -2.1295488256748833\n",
            "Total de pasos: 2996305/3000000.0 - Recompensa: -0.23869221666650722\n",
            "Total de pasos: 2996306/3000000.0 - Recompensa: -0.4302683047518494\n",
            "Total de pasos: 2996307/3000000.0 - Recompensa: -0.49667537135155887\n",
            "Total de pasos: 2996308/3000000.0 - Recompensa: -0.08877084337210822\n",
            "Total de pasos: 2996309/3000000.0 - Recompensa: -0.6416502965058732\n",
            "Total de pasos: 2996310/3000000.0 - Recompensa: -0.9890756890063414\n",
            "Total de pasos: 2996311/3000000.0 - Recompensa: -0.5097231916602806\n",
            "Total de pasos: 2996312/3000000.0 - Recompensa: -0.16936129343671397\n",
            "Total de pasos: 2996313/3000000.0 - Recompensa: -0.661749733281878\n",
            "Total de pasos: 2996314/3000000.0 - Recompensa: -0.572385209464171\n",
            "Total de pasos: 2996315/3000000.0 - Recompensa: -1.5374627459502765\n",
            "Total de pasos: 2996316/3000000.0 - Recompensa: -0.3002103509484443\n",
            "Total de pasos: 2996317/3000000.0 - Recompensa: -2.5674803601628344\n",
            "Total de pasos: 2996318/3000000.0 - Recompensa: -2.531853232111078\n",
            "Total de pasos: 2996319/3000000.0 - Recompensa: -0.5786353266608797\n",
            "Total de pasos: 2996320/3000000.0 - Recompensa: -0.10032177614279494\n",
            "Total de pasos: 2996321/3000000.0 - Recompensa: -0.19253079388061245\n",
            "Total de pasos: 2996322/3000000.0 - Recompensa: -2.2287106149918934\n",
            "Total de pasos: 2996323/3000000.0 - Recompensa: 0.1936482365793279\n",
            "0.1936482365793279\n",
            "Total de pasos: 2996324/3000000.0 - Recompensa: 0.5182855832799309\n",
            "0.5182855832799309\n",
            "Total de pasos: 2996325/3000000.0 - Recompensa: -0.374188367615645\n",
            "Total de pasos: 2996326/3000000.0 - Recompensa: -0.7107623787496848\n",
            "Total de pasos: 2996327/3000000.0 - Recompensa: 0.8471303762488793\n",
            "0.8471303762488793\n",
            "Total de pasos: 2996328/3000000.0 - Recompensa: -0.540067445081766\n",
            "Total de pasos: 2996329/3000000.0 - Recompensa: -1.6723653872418875\n",
            "Total de pasos: 2996330/3000000.0 - Recompensa: -2.3338463716796656\n",
            "Total de pasos: 2996331/3000000.0 - Recompensa: -0.15326024756251377\n",
            "Total de pasos: 2996332/3000000.0 - Recompensa: 0.8715606018701016\n",
            "0.8715606018701016\n",
            "Total de pasos: 2996333/3000000.0 - Recompensa: -0.7823829066730663\n",
            "Total de pasos: 2996334/3000000.0 - Recompensa: -0.04927977063786454\n",
            "Total de pasos: 2996335/3000000.0 - Recompensa: -1.5295888918960903\n",
            "Total de pasos: 2996336/3000000.0 - Recompensa: -1.0045243027762147\n",
            "Total de pasos: 2996337/3000000.0 - Recompensa: 0.6429462827355106\n",
            "0.6429462827355106\n",
            "Total de pasos: 2996338/3000000.0 - Recompensa: 0.4886829964733734\n",
            "0.4886829964733734\n",
            "Total de pasos: 2996339/3000000.0 - Recompensa: -0.6543937187011257\n",
            "Total de pasos: 2996340/3000000.0 - Recompensa: -0.4542568058520165\n",
            "Total de pasos: 2996341/3000000.0 - Recompensa: -1.151868100205383\n",
            "Total de pasos: 2996342/3000000.0 - Recompensa: -2.0510961184325147\n",
            "Total de pasos: 2996343/3000000.0 - Recompensa: -0.48750053153020756\n",
            "Total de pasos: 2996344/3000000.0 - Recompensa: -0.35535713093311855\n",
            "Total de pasos: 2996345/3000000.0 - Recompensa: -1.9164529254133145\n",
            "Total de pasos: 2996346/3000000.0 - Recompensa: -0.24564057715913137\n",
            "Total de pasos: 2996347/3000000.0 - Recompensa: -1.2160018361111755\n",
            "Total de pasos: 2996348/3000000.0 - Recompensa: -0.14630443138206042\n",
            "Total de pasos: 2996349/3000000.0 - Recompensa: -1.8061673610743558\n",
            "Total de pasos: 2996350/3000000.0 - Recompensa: -0.8158533927132535\n",
            "Total de pasos: 2996351/3000000.0 - Recompensa: -0.5118611883423813\n",
            "Total de pasos: 2996352/3000000.0 - Recompensa: -0.34958965371910355\n",
            "Total de pasos: 2996353/3000000.0 - Recompensa: -0.5435533410716022\n",
            "Total de pasos: 2996354/3000000.0 - Recompensa: -0.8528865848158581\n",
            "Total de pasos: 2996355/3000000.0 - Recompensa: -1.7039182152003605\n",
            "Total de pasos: 2996356/3000000.0 - Recompensa: 0.8273501003164863\n",
            "0.8273501003164863\n",
            "Total de pasos: 2996357/3000000.0 - Recompensa: -0.7185781961644672\n",
            "Total de pasos: 2996358/3000000.0 - Recompensa: -0.2018791688438232\n",
            "Total de pasos: 2996359/3000000.0 - Recompensa: -0.7678862642024059\n",
            "Total de pasos: 2996360/3000000.0 - Recompensa: -0.0593538239376839\n",
            "Total de pasos: 2996361/3000000.0 - Recompensa: -1.5139680044010424\n",
            "Total de pasos: 2996362/3000000.0 - Recompensa: -3.1212128133945103\n",
            "Total de pasos: 2996363/3000000.0 - Recompensa: -0.813361480911819\n",
            "Total de pasos: 2996364/3000000.0 - Recompensa: -0.14687635845938943\n",
            "Total de pasos: 2996365/3000000.0 - Recompensa: -0.7769204650916899\n",
            "Total de pasos: 2996366/3000000.0 - Recompensa: -0.19743217851948094\n",
            "Total de pasos: 2996367/3000000.0 - Recompensa: -1.1961616459665558\n",
            "Total de pasos: 2996368/3000000.0 - Recompensa: 0.5200814618544906\n",
            "0.5200814618544906\n",
            "Total de pasos: 2996369/3000000.0 - Recompensa: -2.285630441374607\n",
            "Total de pasos: 2996370/3000000.0 - Recompensa: 0.749285285211346\n",
            "0.749285285211346\n",
            "Total de pasos: 2996371/3000000.0 - Recompensa: -1.6260198009136684\n",
            "Total de pasos: 2996372/3000000.0 - Recompensa: -0.9878694702513661\n",
            "Total de pasos: 2996373/3000000.0 - Recompensa: 0.44887766459021655\n",
            "0.44887766459021655\n",
            "Total de pasos: 2996374/3000000.0 - Recompensa: 0.3043375843231201\n",
            "0.3043375843231201\n",
            "Total de pasos: 2996375/3000000.0 - Recompensa: 0.10760655292703908\n",
            "0.10760655292703908\n",
            "Total de pasos: 2996376/3000000.0 - Recompensa: -0.4260801858652892\n",
            "Total de pasos: 2996377/3000000.0 - Recompensa: -1.1836008633588786\n",
            "Total de pasos: 2996378/3000000.0 - Recompensa: 0.34475769085957747\n",
            "0.34475769085957747\n",
            "Total de pasos: 2996379/3000000.0 - Recompensa: -0.3041800661223018\n",
            "Total de pasos: 2996380/3000000.0 - Recompensa: -0.43659604326221296\n",
            "Total de pasos: 2996381/3000000.0 - Recompensa: 0.021526473089819198\n",
            "0.021526473089819198\n",
            "Total de pasos: 2996382/3000000.0 - Recompensa: -1.2666380418161736\n",
            "Total de pasos: 2996383/3000000.0 - Recompensa: -1.9416400966417044\n",
            "Total de pasos: 2996384/3000000.0 - Recompensa: -0.08423437525696423\n",
            "Total de pasos: 2996385/3000000.0 - Recompensa: -0.6072706064937412\n",
            "Total de pasos: 2996386/3000000.0 - Recompensa: -0.7891463647129129\n",
            "Total de pasos: 2996387/3000000.0 - Recompensa: -0.7484955081237359\n",
            "Total de pasos: 2996388/3000000.0 - Recompensa: -0.7234918391793763\n",
            "Total de pasos: 2996389/3000000.0 - Recompensa: -3.0092660871141077\n",
            "Total de pasos: 2996390/3000000.0 - Recompensa: -1.7759147839749032\n",
            "Total de pasos: 2996391/3000000.0 - Recompensa: -0.557238169932487\n",
            "Total de pasos: 2996392/3000000.0 - Recompensa: 0.10084531100875188\n",
            "0.10084531100875188\n",
            "Total de pasos: 2996393/3000000.0 - Recompensa: -0.22120746454778306\n",
            "Total de pasos: 2996394/3000000.0 - Recompensa: -0.8759423234072365\n",
            "Total de pasos: 2996395/3000000.0 - Recompensa: -0.03037813622345814\n",
            "Total de pasos: 2996396/3000000.0 - Recompensa: -2.205550139234027\n",
            "Total de pasos: 2996397/3000000.0 - Recompensa: -0.429824777626618\n",
            "Total de pasos: 2996398/3000000.0 - Recompensa: -3.2286161751744884\n",
            "Total de pasos: 2996399/3000000.0 - Recompensa: 0.12500235574287108\n",
            "0.12500235574287108\n",
            "Total de pasos: 2996400/3000000.0 - Recompensa: -0.8054833042554769\n",
            "Total de pasos: 2996401/3000000.0 - Recompensa: -0.03862583844618994\n",
            "Total de pasos: 2996402/3000000.0 - Recompensa: 0.20427135765286736\n",
            "0.20427135765286736\n",
            "Total de pasos: 2996403/3000000.0 - Recompensa: -0.24899528088537465\n",
            "Total de pasos: 2996404/3000000.0 - Recompensa: -0.3953022824890299\n",
            "Total de pasos: 2996405/3000000.0 - Recompensa: -0.8013900635161437\n",
            "Total de pasos: 2996406/3000000.0 - Recompensa: 0.0653159207991516\n",
            "0.0653159207991516\n",
            "Total de pasos: 2996407/3000000.0 - Recompensa: -0.4619840740349324\n",
            "Total de pasos: 2996408/3000000.0 - Recompensa: 0.9879429414786116\n",
            "0.9879429414786116\n",
            "Total de pasos: 2996409/3000000.0 - Recompensa: -1.1246947322895389\n",
            "Total de pasos: 2996410/3000000.0 - Recompensa: -0.30327842660645243\n",
            "Total de pasos: 2996411/3000000.0 - Recompensa: -1.0691116231276052\n",
            "Total de pasos: 2996412/3000000.0 - Recompensa: -1.4341103239818487\n",
            "Total de pasos: 2996413/3000000.0 - Recompensa: -0.4653466647825021\n",
            "Total de pasos: 2996414/3000000.0 - Recompensa: 1.147608485762579\n",
            "1.147608485762579\n",
            "Total de pasos: 2996415/3000000.0 - Recompensa: -2.657369312927577\n",
            "Total de pasos: 2996416/3000000.0 - Recompensa: -1.786817061411671\n",
            "Total de pasos: 2996417/3000000.0 - Recompensa: -4.528705137751216\n",
            "Total de pasos: 2996418/3000000.0 - Recompensa: -2.180594613053003\n",
            "Total de pasos: 2996419/3000000.0 - Recompensa: 0.22984642255133814\n",
            "0.22984642255133814\n",
            "Total de pasos: 2996420/3000000.0 - Recompensa: -0.6710156230917267\n",
            "Total de pasos: 2996421/3000000.0 - Recompensa: 0.553784857440019\n",
            "0.553784857440019\n",
            "Total de pasos: 2996422/3000000.0 - Recompensa: -0.13358974569169396\n",
            "Total de pasos: 2996423/3000000.0 - Recompensa: -2.28780826725965\n",
            "Total de pasos: 2996424/3000000.0 - Recompensa: 0.4561413033426315\n",
            "0.4561413033426315\n",
            "Total de pasos: 2996425/3000000.0 - Recompensa: -2.018585919152689\n",
            "Total de pasos: 2996426/3000000.0 - Recompensa: -2.027355779556919\n",
            "Total de pasos: 2996427/3000000.0 - Recompensa: -1.1062175797660456\n",
            "Total de pasos: 2996428/3000000.0 - Recompensa: -1.833923818129221\n",
            "Total de pasos: 2996429/3000000.0 - Recompensa: -2.7615403055052856\n",
            "Total de pasos: 2996430/3000000.0 - Recompensa: 0.25644857723006076\n",
            "0.25644857723006076\n",
            "Total de pasos: 2996431/3000000.0 - Recompensa: 0.37570152451538963\n",
            "0.37570152451538963\n",
            "Total de pasos: 2996432/3000000.0 - Recompensa: 0.045558386798374956\n",
            "0.045558386798374956\n",
            "Total de pasos: 2996433/3000000.0 - Recompensa: -1.154288246015003\n",
            "Total de pasos: 2996434/3000000.0 - Recompensa: -0.47954425683497204\n",
            "Total de pasos: 2996435/3000000.0 - Recompensa: -0.5430561799955144\n",
            "Total de pasos: 2996436/3000000.0 - Recompensa: -1.359864172375548\n",
            "Total de pasos: 2996437/3000000.0 - Recompensa: -0.45189222186912287\n",
            "Total de pasos: 2996438/3000000.0 - Recompensa: -1.6197544245226303\n",
            "Total de pasos: 2996439/3000000.0 - Recompensa: 0.38366006665943025\n",
            "0.38366006665943025\n",
            "Total de pasos: 2996440/3000000.0 - Recompensa: -0.43663812505784105\n",
            "Total de pasos: 2996441/3000000.0 - Recompensa: -0.007404043880937211\n",
            "Total de pasos: 2996442/3000000.0 - Recompensa: -0.1585582412639433\n",
            "Total de pasos: 2996443/3000000.0 - Recompensa: -2.0405041659143395\n",
            "Total de pasos: 2996444/3000000.0 - Recompensa: -0.8506927569264446\n",
            "Total de pasos: 2996445/3000000.0 - Recompensa: -0.6503140427662915\n",
            "Total de pasos: 2996446/3000000.0 - Recompensa: -0.3282979428255478\n",
            "Total de pasos: 2996447/3000000.0 - Recompensa: -0.9400944794518702\n",
            "Total de pasos: 2996448/3000000.0 - Recompensa: -0.053265783796585364\n",
            "Total de pasos: 2996449/3000000.0 - Recompensa: 0.16466089705838435\n",
            "0.16466089705838435\n",
            "Total de pasos: 2996450/3000000.0 - Recompensa: -2.176691635458947\n",
            "Total de pasos: 2996451/3000000.0 - Recompensa: -0.6062401260348074\n",
            "Total de pasos: 2996452/3000000.0 - Recompensa: 0.4234386301643857\n",
            "0.4234386301643857\n",
            "Total de pasos: 2996453/3000000.0 - Recompensa: -0.5366882037320952\n",
            "Total de pasos: 2996454/3000000.0 - Recompensa: -0.7874461824719285\n",
            "Total de pasos: 2996455/3000000.0 - Recompensa: -1.6353769800065503\n",
            "Total de pasos: 2996456/3000000.0 - Recompensa: -1.814569536232446\n",
            "Total de pasos: 2996457/3000000.0 - Recompensa: -1.3327548211377818\n",
            "Total de pasos: 2996458/3000000.0 - Recompensa: -2.1677212387617955\n",
            "Total de pasos: 2996459/3000000.0 - Recompensa: -2.2069812119776335\n",
            "Total de pasos: 2996460/3000000.0 - Recompensa: 0.4659988565997161\n",
            "0.4659988565997161\n",
            "Total de pasos: 2996461/3000000.0 - Recompensa: -1.5724365701597278\n",
            "Total de pasos: 2996462/3000000.0 - Recompensa: 1.1587059506842394\n",
            "1.1587059506842394\n",
            "Total de pasos: 2996463/3000000.0 - Recompensa: -0.7668648487155314\n",
            "Total de pasos: 2996464/3000000.0 - Recompensa: -2.0519200909088484\n",
            "Total de pasos: 2996465/3000000.0 - Recompensa: -0.9885755276330619\n",
            "Total de pasos: 2996466/3000000.0 - Recompensa: -0.2702634235106374\n",
            "Total de pasos: 2996467/3000000.0 - Recompensa: 0.057420860996444556\n",
            "0.057420860996444556\n",
            "Total de pasos: 2996468/3000000.0 - Recompensa: -1.5730978234046484\n",
            "Total de pasos: 2996469/3000000.0 - Recompensa: -0.8400311385193174\n",
            "Total de pasos: 2996470/3000000.0 - Recompensa: -1.4607669113337998\n",
            "Total de pasos: 2996471/3000000.0 - Recompensa: -0.06907831131207592\n",
            "Total de pasos: 2996472/3000000.0 - Recompensa: -0.11985415943632499\n",
            "Total de pasos: 2996473/3000000.0 - Recompensa: -1.0960707705462958\n",
            "Total de pasos: 2996474/3000000.0 - Recompensa: -1.6165235936701086\n",
            "Total de pasos: 2996475/3000000.0 - Recompensa: -0.918223582550706\n",
            "Total de pasos: 2996476/3000000.0 - Recompensa: -2.4172092899914475\n",
            "Total de pasos: 2996477/3000000.0 - Recompensa: -0.4448030112226003\n",
            "Total de pasos: 2996478/3000000.0 - Recompensa: -1.7559817158128967\n",
            "Total de pasos: 2996479/3000000.0 - Recompensa: -1.276096902379611\n",
            "Total de pasos: 2996480/3000000.0 - Recompensa: -0.458333937732068\n",
            "Total de pasos: 2996481/3000000.0 - Recompensa: -4.2145282986065045\n",
            "Total de pasos: 2996482/3000000.0 - Recompensa: -1.0948276488917204\n",
            "Total de pasos: 2996483/3000000.0 - Recompensa: -0.2945098103534689\n",
            "Total de pasos: 2996484/3000000.0 - Recompensa: -0.21633488187874664\n",
            "Total de pasos: 2996485/3000000.0 - Recompensa: -3.159705645527865\n",
            "Total de pasos: 2996486/3000000.0 - Recompensa: -1.5073909343601917\n",
            "Total de pasos: 2996487/3000000.0 - Recompensa: 0.0876758349884422\n",
            "0.0876758349884422\n",
            "Total de pasos: 2996488/3000000.0 - Recompensa: -0.6955573893540977\n",
            "Total de pasos: 2996489/3000000.0 - Recompensa: -0.9186123638542631\n",
            "Total de pasos: 2996490/3000000.0 - Recompensa: -0.40339421378607276\n",
            "Total de pasos: 2996491/3000000.0 - Recompensa: -0.5350148857322423\n",
            "Total de pasos: 2996492/3000000.0 - Recompensa: -0.6649716134990826\n",
            "Total de pasos: 2996493/3000000.0 - Recompensa: -0.623028400198063\n",
            "Total de pasos: 2996494/3000000.0 - Recompensa: -1.1291054738201978\n",
            "Total de pasos: 2996495/3000000.0 - Recompensa: -0.2662264188708388\n",
            "Total de pasos: 2996496/3000000.0 - Recompensa: -1.3616831901572384\n",
            "Total de pasos: 2996497/3000000.0 - Recompensa: -0.07453156971719146\n",
            "Total de pasos: 2996498/3000000.0 - Recompensa: -0.28682009629544636\n",
            "Total de pasos: 2996499/3000000.0 - Recompensa: -0.1072805656217665\n",
            "Total de pasos: 2996500/3000000.0 - Recompensa: 1.2374840321967997\n",
            "1.2374840321967997\n",
            "Total de pasos: 2996501/3000000.0 - Recompensa: 0.04393529285835357\n",
            "0.04393529285835357\n",
            "Total de pasos: 2996502/3000000.0 - Recompensa: 0.5829951875059884\n",
            "0.5829951875059884\n",
            "Total de pasos: 2996503/3000000.0 - Recompensa: -0.762263835742625\n",
            "Total de pasos: 2996504/3000000.0 - Recompensa: 0.21601720515143213\n",
            "0.21601720515143213\n",
            "Total de pasos: 2996505/3000000.0 - Recompensa: -2.895187667891671\n",
            "Total de pasos: 2996506/3000000.0 - Recompensa: -1.486879505126136\n",
            "Total de pasos: 2996507/3000000.0 - Recompensa: -1.4551027259661509\n",
            "Total de pasos: 2996508/3000000.0 - Recompensa: 0.296067459155469\n",
            "0.296067459155469\n",
            "Total de pasos: 2996509/3000000.0 - Recompensa: -1.1254891879692055\n",
            "Total de pasos: 2996510/3000000.0 - Recompensa: -0.7498707602172602\n",
            "Total de pasos: 2996511/3000000.0 - Recompensa: -0.6706859738302711\n",
            "Total de pasos: 2996512/3000000.0 - Recompensa: -0.22411003517359696\n",
            "Total de pasos: 2996513/3000000.0 - Recompensa: -0.5192210481612916\n",
            "Total de pasos: 2996514/3000000.0 - Recompensa: 0.6105233039921267\n",
            "0.6105233039921267\n",
            "Total de pasos: 2996515/3000000.0 - Recompensa: 0.08683385962411\n",
            "0.08683385962411\n",
            "Total de pasos: 2996516/3000000.0 - Recompensa: -0.08362180966481195\n",
            "Total de pasos: 2996517/3000000.0 - Recompensa: -0.462626669753431\n",
            "Total de pasos: 2996518/3000000.0 - Recompensa: -0.2455072654050249\n",
            "Total de pasos: 2996519/3000000.0 - Recompensa: -1.719954943749606\n",
            "Total de pasos: 2996520/3000000.0 - Recompensa: -1.2414865848941725\n",
            "Total de pasos: 2996521/3000000.0 - Recompensa: 0.26091424997594354\n",
            "0.26091424997594354\n",
            "Total de pasos: 2996522/3000000.0 - Recompensa: 0.05419569560793991\n",
            "0.05419569560793991\n",
            "Total de pasos: 2996523/3000000.0 - Recompensa: -2.8192556406545712\n",
            "Total de pasos: 2996524/3000000.0 - Recompensa: -1.4944475952757517\n",
            "Total de pasos: 2996525/3000000.0 - Recompensa: 0.3247801503567255\n",
            "0.3247801503567255\n",
            "Total de pasos: 2996526/3000000.0 - Recompensa: -1.2757987906123462\n",
            "Total de pasos: 2996527/3000000.0 - Recompensa: -1.1216559370275614\n",
            "Total de pasos: 2996528/3000000.0 - Recompensa: -1.7339947788566343\n",
            "Total de pasos: 2996529/3000000.0 - Recompensa: 0.2310532899796419\n",
            "0.2310532899796419\n",
            "Total de pasos: 2996530/3000000.0 - Recompensa: -2.439789311829637\n",
            "Total de pasos: 2996531/3000000.0 - Recompensa: 0.8446054805358332\n",
            "0.8446054805358332\n",
            "Total de pasos: 2996532/3000000.0 - Recompensa: -2.3446698049775128\n",
            "Total de pasos: 2996533/3000000.0 - Recompensa: -1.328250598379851\n",
            "Total de pasos: 2996534/3000000.0 - Recompensa: -0.5853192168048128\n",
            "Total de pasos: 2996535/3000000.0 - Recompensa: -0.7983435847884552\n",
            "Total de pasos: 2996536/3000000.0 - Recompensa: -2.295874817671245\n",
            "Total de pasos: 2996537/3000000.0 - Recompensa: -1.9377932137798912\n",
            "Total de pasos: 2996538/3000000.0 - Recompensa: 0.2894476108837373\n",
            "0.2894476108837373\n",
            "Total de pasos: 2996539/3000000.0 - Recompensa: 0.43494774534883607\n",
            "0.43494774534883607\n",
            "Total de pasos: 2996540/3000000.0 - Recompensa: -1.0011956783590685\n",
            "Total de pasos: 2996541/3000000.0 - Recompensa: -0.08329393404268881\n",
            "Total de pasos: 2996542/3000000.0 - Recompensa: -0.35319126854500943\n",
            "Total de pasos: 2996543/3000000.0 - Recompensa: -1.2373112510392283\n",
            "Total de pasos: 2996544/3000000.0 - Recompensa: 0.1257584470816767\n",
            "0.1257584470816767\n",
            "Total de pasos: 2996545/3000000.0 - Recompensa: -0.45789592421212066\n",
            "Total de pasos: 2996546/3000000.0 - Recompensa: -0.9961231268015218\n",
            "Total de pasos: 2996547/3000000.0 - Recompensa: -0.031399222344513644\n",
            "Total de pasos: 2996548/3000000.0 - Recompensa: 0.26819905327564675\n",
            "0.26819905327564675\n",
            "Total de pasos: 2996549/3000000.0 - Recompensa: -0.3323792750197113\n",
            "Total de pasos: 2996550/3000000.0 - Recompensa: 0.874372991362495\n",
            "0.874372991362495\n",
            "Total de pasos: 2996551/3000000.0 - Recompensa: -0.5553931591032683\n",
            "Total de pasos: 2996552/3000000.0 - Recompensa: -1.2840812595107163\n",
            "Total de pasos: 2996553/3000000.0 - Recompensa: -0.8013072466859928\n",
            "Total de pasos: 2996554/3000000.0 - Recompensa: -0.030190134651283312\n",
            "Total de pasos: 2996555/3000000.0 - Recompensa: -1.7310646662499782\n",
            "Total de pasos: 2996556/3000000.0 - Recompensa: -1.4123422211040075\n",
            "Total de pasos: 2996557/3000000.0 - Recompensa: -3.0459363584432317\n",
            "Total de pasos: 2996558/3000000.0 - Recompensa: 0.020122082631092775\n",
            "0.020122082631092775\n",
            "Total de pasos: 2996559/3000000.0 - Recompensa: -4.768266495399197\n",
            "Total de pasos: 2996560/3000000.0 - Recompensa: -1.9761535519605853\n",
            "Total de pasos: 2996561/3000000.0 - Recompensa: -2.8709124593612207\n",
            "Total de pasos: 2996562/3000000.0 - Recompensa: -0.7388447918520831\n",
            "Total de pasos: 2996563/3000000.0 - Recompensa: -0.6323928423176872\n",
            "Total de pasos: 2996564/3000000.0 - Recompensa: -1.1202576128340165\n",
            "Total de pasos: 2996565/3000000.0 - Recompensa: -1.4971478611548448\n",
            "Total de pasos: 2996566/3000000.0 - Recompensa: -1.3015542305037349\n",
            "Total de pasos: 2996567/3000000.0 - Recompensa: -2.7696955365008447\n",
            "Total de pasos: 2996568/3000000.0 - Recompensa: -1.4832364297922376\n",
            "Total de pasos: 2996569/3000000.0 - Recompensa: -0.5931629096641424\n",
            "Total de pasos: 2996570/3000000.0 - Recompensa: 0.74040965644867\n",
            "0.74040965644867\n",
            "Total de pasos: 2996571/3000000.0 - Recompensa: -1.962816809898027\n",
            "Total de pasos: 2996572/3000000.0 - Recompensa: -5.8864930401287765\n",
            "Total de pasos: 2996573/3000000.0 - Recompensa: 0.040024852150842255\n",
            "0.040024852150842255\n",
            "Total de pasos: 2996574/3000000.0 - Recompensa: -0.3002257744711976\n",
            "Total de pasos: 2996575/3000000.0 - Recompensa: -1.2890696893913796\n",
            "Total de pasos: 2996576/3000000.0 - Recompensa: -1.8103621921348825\n",
            "Total de pasos: 2996577/3000000.0 - Recompensa: -0.7739465720878018\n",
            "Total de pasos: 2996578/3000000.0 - Recompensa: 1.0302108994535377\n",
            "1.0302108994535377\n",
            "Total de pasos: 2996579/3000000.0 - Recompensa: -1.736817024497829\n",
            "Total de pasos: 2996580/3000000.0 - Recompensa: -0.425004298238166\n",
            "Total de pasos: 2996581/3000000.0 - Recompensa: -1.0786147813430291\n",
            "Total de pasos: 2996582/3000000.0 - Recompensa: -0.33751833206167026\n",
            "Total de pasos: 2996583/3000000.0 - Recompensa: -0.2415448672583005\n",
            "Total de pasos: 2996584/3000000.0 - Recompensa: -0.6202589210308358\n",
            "Total de pasos: 2996585/3000000.0 - Recompensa: -1.156488661189579\n",
            "Total de pasos: 2996586/3000000.0 - Recompensa: -0.6765406716717263\n",
            "Total de pasos: 2996587/3000000.0 - Recompensa: -1.1443990928768262\n",
            "Total de pasos: 2996588/3000000.0 - Recompensa: -2.720304267024257\n",
            "Total de pasos: 2996589/3000000.0 - Recompensa: -1.7494083673637373\n",
            "Total de pasos: 2996590/3000000.0 - Recompensa: -0.8143655626870795\n",
            "Total de pasos: 2996591/3000000.0 - Recompensa: -2.790670585964209\n",
            "Total de pasos: 2996592/3000000.0 - Recompensa: -0.5408225495363492\n",
            "Total de pasos: 2996593/3000000.0 - Recompensa: -0.8297767963335234\n",
            "Total de pasos: 2996594/3000000.0 - Recompensa: -0.5172636684901037\n",
            "Total de pasos: 2996595/3000000.0 - Recompensa: 0.6643226857414499\n",
            "0.6643226857414499\n",
            "Total de pasos: 2996596/3000000.0 - Recompensa: -0.5883197777283369\n",
            "Total de pasos: 2996597/3000000.0 - Recompensa: 0.06451628417984717\n",
            "0.06451628417984717\n",
            "Total de pasos: 2996598/3000000.0 - Recompensa: 0.12933895819970304\n",
            "0.12933895819970304\n",
            "Total de pasos: 2996599/3000000.0 - Recompensa: -1.3354457769794539\n",
            "Total de pasos: 2996600/3000000.0 - Recompensa: -0.8691741958874404\n",
            "Total de pasos: 2996601/3000000.0 - Recompensa: 0.952369064444216\n",
            "0.952369064444216\n",
            "Total de pasos: 2996602/3000000.0 - Recompensa: 0.13739888565793387\n",
            "0.13739888565793387\n",
            "Total de pasos: 2996603/3000000.0 - Recompensa: -1.8906995914585423\n",
            "Total de pasos: 2996604/3000000.0 - Recompensa: -1.439887677601867\n",
            "Total de pasos: 2996605/3000000.0 - Recompensa: -0.20221195040388099\n",
            "Total de pasos: 2996606/3000000.0 - Recompensa: -3.0118946660029526\n",
            "Total de pasos: 2996607/3000000.0 - Recompensa: -1.1258050539246358\n",
            "Total de pasos: 2996608/3000000.0 - Recompensa: -1.7746980652438757\n",
            "Total de pasos: 2996609/3000000.0 - Recompensa: -1.9707144284612574\n",
            "Total de pasos: 2996610/3000000.0 - Recompensa: 0.4402833687746614\n",
            "0.4402833687746614\n",
            "Total de pasos: 2996611/3000000.0 - Recompensa: -1.7107870988286784\n",
            "Total de pasos: 2996612/3000000.0 - Recompensa: -1.537179166082956\n",
            "Total de pasos: 2996613/3000000.0 - Recompensa: -2.757653300195094\n",
            "Total de pasos: 2996614/3000000.0 - Recompensa: 0.5642828598910333\n",
            "0.5642828598910333\n",
            "Total de pasos: 2996615/3000000.0 - Recompensa: -0.9877558920669594\n",
            "Total de pasos: 2996616/3000000.0 - Recompensa: -0.5465601023068437\n",
            "Total de pasos: 2996617/3000000.0 - Recompensa: -1.1558207990512464\n",
            "Total de pasos: 2996618/3000000.0 - Recompensa: -1.4175519228078401\n",
            "Total de pasos: 2996619/3000000.0 - Recompensa: 0.49169942888406104\n",
            "0.49169942888406104\n",
            "Total de pasos: 2996620/3000000.0 - Recompensa: -2.4103651526788616\n",
            "Total de pasos: 2996621/3000000.0 - Recompensa: -1.130759494695726\n",
            "Total de pasos: 2996622/3000000.0 - Recompensa: 0.3349764031912365\n",
            "0.3349764031912365\n",
            "Total de pasos: 2996623/3000000.0 - Recompensa: -0.9404118037253604\n",
            "Total de pasos: 2996624/3000000.0 - Recompensa: -2.6140272126611355\n",
            "Total de pasos: 2996625/3000000.0 - Recompensa: 0.1957793464703425\n",
            "0.1957793464703425\n",
            "Total de pasos: 2996626/3000000.0 - Recompensa: -2.3294327012126423\n",
            "Total de pasos: 2996627/3000000.0 - Recompensa: -3.045992368487159\n",
            "Total de pasos: 2996628/3000000.0 - Recompensa: -0.4814362015678933\n",
            "Total de pasos: 2996629/3000000.0 - Recompensa: -3.9613614478195323\n",
            "Total de pasos: 2996630/3000000.0 - Recompensa: -1.2762417127784522\n",
            "Total de pasos: 2996631/3000000.0 - Recompensa: -1.803324391521329\n",
            "Total de pasos: 2996632/3000000.0 - Recompensa: 0.19270835263340355\n",
            "0.19270835263340355\n",
            "Total de pasos: 2996633/3000000.0 - Recompensa: -0.9322376425490554\n",
            "Total de pasos: 2996634/3000000.0 - Recompensa: -0.9360940319311267\n",
            "Total de pasos: 2996635/3000000.0 - Recompensa: -1.4278349266051875\n",
            "Total de pasos: 2996636/3000000.0 - Recompensa: 0.33276219108051047\n",
            "0.33276219108051047\n",
            "Total de pasos: 2996637/3000000.0 - Recompensa: -0.04670594982786369\n",
            "Total de pasos: 2996638/3000000.0 - Recompensa: -0.5900538757935875\n",
            "Total de pasos: 2996639/3000000.0 - Recompensa: -0.06284777410762402\n",
            "Total de pasos: 2996640/3000000.0 - Recompensa: -1.2146696372693073\n",
            "Total de pasos: 2996641/3000000.0 - Recompensa: -0.1987601845206343\n",
            "Total de pasos: 2996642/3000000.0 - Recompensa: 0.03342077583050557\n",
            "0.03342077583050557\n",
            "Total de pasos: 2996643/3000000.0 - Recompensa: -0.7719134766222331\n",
            "Total de pasos: 2996644/3000000.0 - Recompensa: -2.2656148959825693\n",
            "Total de pasos: 2996645/3000000.0 - Recompensa: -0.6429160539778727\n",
            "Total de pasos: 2996646/3000000.0 - Recompensa: -0.9160979781599845\n",
            "Total de pasos: 2996647/3000000.0 - Recompensa: 0.403246562012203\n",
            "0.403246562012203\n",
            "Total de pasos: 2996648/3000000.0 - Recompensa: 0.3823051451370138\n",
            "0.3823051451370138\n",
            "Total de pasos: 2996649/3000000.0 - Recompensa: -0.7969092188853135\n",
            "Total de pasos: 2996650/3000000.0 - Recompensa: -1.1737273952374716\n",
            "Total de pasos: 2996651/3000000.0 - Recompensa: -0.855607155046209\n",
            "Total de pasos: 2996652/3000000.0 - Recompensa: -0.8755199948322216\n",
            "Total de pasos: 2996653/3000000.0 - Recompensa: -0.4534249691121277\n",
            "Total de pasos: 2996654/3000000.0 - Recompensa: -0.5645089763584175\n",
            "Total de pasos: 2996655/3000000.0 - Recompensa: -0.9483968141464794\n",
            "Total de pasos: 2996656/3000000.0 - Recompensa: 0.39412685651836127\n",
            "0.39412685651836127\n",
            "Total de pasos: 2996657/3000000.0 - Recompensa: -1.64583121220519\n",
            "Total de pasos: 2996658/3000000.0 - Recompensa: 0.6213044098468214\n",
            "0.6213044098468214\n",
            "Total de pasos: 2996659/3000000.0 - Recompensa: -0.45053970938928956\n",
            "Total de pasos: 2996660/3000000.0 - Recompensa: -0.19209000470713625\n",
            "Total de pasos: 2996661/3000000.0 - Recompensa: -0.8096694288190907\n",
            "Total de pasos: 2996662/3000000.0 - Recompensa: 0.11182422299065359\n",
            "0.11182422299065359\n",
            "Total de pasos: 2996663/3000000.0 - Recompensa: -0.9046987981047281\n",
            "Total de pasos: 2996664/3000000.0 - Recompensa: -0.8702373470707164\n",
            "Total de pasos: 2996665/3000000.0 - Recompensa: -1.9509406138683492\n",
            "Total de pasos: 2996666/3000000.0 - Recompensa: -0.6728949711419467\n",
            "Total de pasos: 2996667/3000000.0 - Recompensa: -1.3245805818207614\n",
            "Total de pasos: 2996668/3000000.0 - Recompensa: -0.5738618681490946\n",
            "Total de pasos: 2996669/3000000.0 - Recompensa: -1.741042324019806\n",
            "Total de pasos: 2996670/3000000.0 - Recompensa: 0.8860893920291347\n",
            "0.8860893920291347\n",
            "Total de pasos: 2996671/3000000.0 - Recompensa: -0.49313435666411953\n",
            "Total de pasos: 2996672/3000000.0 - Recompensa: -1.3067405144181063\n",
            "Total de pasos: 2996673/3000000.0 - Recompensa: -0.4670361946182687\n",
            "Total de pasos: 2996674/3000000.0 - Recompensa: -0.9971846454005585\n",
            "Total de pasos: 2996675/3000000.0 - Recompensa: -0.29209271948599663\n",
            "Total de pasos: 2996676/3000000.0 - Recompensa: -1.3730441508707356\n",
            "Total de pasos: 2996677/3000000.0 - Recompensa: -1.538777045493124\n",
            "Total de pasos: 2996678/3000000.0 - Recompensa: -0.0623457697942528\n",
            "Total de pasos: 2996679/3000000.0 - Recompensa: -1.9585788379618214\n",
            "Total de pasos: 2996680/3000000.0 - Recompensa: 0.19400647089213535\n",
            "0.19400647089213535\n",
            "Total de pasos: 2996681/3000000.0 - Recompensa: -0.1170500258980412\n",
            "Total de pasos: 2996682/3000000.0 - Recompensa: -0.8348743276429531\n",
            "Total de pasos: 2996683/3000000.0 - Recompensa: -1.498110681618201\n",
            "Total de pasos: 2996684/3000000.0 - Recompensa: -0.5890096969595499\n",
            "Total de pasos: 2996685/3000000.0 - Recompensa: -0.06776440328927835\n",
            "Total de pasos: 2996686/3000000.0 - Recompensa: -2.2629292806913055\n",
            "Total de pasos: 2996687/3000000.0 - Recompensa: -1.2835806513956467\n",
            "Total de pasos: 2996688/3000000.0 - Recompensa: 0.1965064003079841\n",
            "0.1965064003079841\n",
            "Total de pasos: 2996689/3000000.0 - Recompensa: -0.6918603532993857\n",
            "Total de pasos: 2996690/3000000.0 - Recompensa: -0.16427132146299997\n",
            "Total de pasos: 2996691/3000000.0 - Recompensa: 0.6217099264467623\n",
            "0.6217099264467623\n",
            "Total de pasos: 2996692/3000000.0 - Recompensa: -0.7195031444524249\n",
            "Total de pasos: 2996693/3000000.0 - Recompensa: -1.7906213621782003\n",
            "Total de pasos: 2996694/3000000.0 - Recompensa: -2.1712386492876896\n",
            "Total de pasos: 2996695/3000000.0 - Recompensa: -0.8062803680864196\n",
            "Total de pasos: 2996696/3000000.0 - Recompensa: 0.17521394282900155\n",
            "0.17521394282900155\n",
            "Total de pasos: 2996697/3000000.0 - Recompensa: -0.47119429557522874\n",
            "Total de pasos: 2996698/3000000.0 - Recompensa: 0.07811921049804446\n",
            "0.07811921049804446\n",
            "Total de pasos: 2996699/3000000.0 - Recompensa: 0.690319585946941\n",
            "0.690319585946941\n",
            "Total de pasos: 2996700/3000000.0 - Recompensa: -1.103099041170609\n",
            "Total de pasos: 2996701/3000000.0 - Recompensa: -1.2512953232286192\n",
            "Total de pasos: 2996702/3000000.0 - Recompensa: -1.5818334528978937\n",
            "Total de pasos: 2996703/3000000.0 - Recompensa: 0.24502225556489637\n",
            "0.24502225556489637\n",
            "Total de pasos: 2996704/3000000.0 - Recompensa: -1.1361225259896712\n",
            "Total de pasos: 2996705/3000000.0 - Recompensa: 0.26498075960752965\n",
            "0.26498075960752965\n",
            "Total de pasos: 2996706/3000000.0 - Recompensa: -1.928040154080384\n",
            "Total de pasos: 2996707/3000000.0 - Recompensa: -0.7357703095579193\n",
            "Total de pasos: 2996708/3000000.0 - Recompensa: 0.10414209810789829\n",
            "0.10414209810789829\n",
            "Total de pasos: 2996709/3000000.0 - Recompensa: 0.8284182380629562\n",
            "0.8284182380629562\n",
            "Total de pasos: 2996710/3000000.0 - Recompensa: -1.4728091281152151\n",
            "Total de pasos: 2996711/3000000.0 - Recompensa: -1.5602686519475022\n",
            "Total de pasos: 2996712/3000000.0 - Recompensa: -0.5843213743621466\n",
            "Total de pasos: 2996713/3000000.0 - Recompensa: -1.1104040175614203\n",
            "Total de pasos: 2996714/3000000.0 - Recompensa: -1.013721811636638\n",
            "Total de pasos: 2996715/3000000.0 - Recompensa: -0.5130640425344144\n",
            "Total de pasos: 2996716/3000000.0 - Recompensa: -5.089301925387969\n",
            "Total de pasos: 2996717/3000000.0 - Recompensa: -1.6813038294722409\n",
            "Total de pasos: 2996718/3000000.0 - Recompensa: -0.6451132458803722\n",
            "Total de pasos: 2996719/3000000.0 - Recompensa: -1.333586808680761\n",
            "Total de pasos: 2996720/3000000.0 - Recompensa: -0.529509973305214\n",
            "Total de pasos: 2996721/3000000.0 - Recompensa: 0.14974905894042861\n",
            "0.14974905894042861\n",
            "Total de pasos: 2996722/3000000.0 - Recompensa: -0.6804247447037682\n",
            "Total de pasos: 2996723/3000000.0 - Recompensa: -0.8969950696812738\n",
            "Total de pasos: 2996724/3000000.0 - Recompensa: -1.5118191634155882\n",
            "Total de pasos: 2996725/3000000.0 - Recompensa: -2.2989008679759\n",
            "Total de pasos: 2996726/3000000.0 - Recompensa: -1.0640154356525477\n",
            "Total de pasos: 2996727/3000000.0 - Recompensa: 1.2562668317442085\n",
            "1.2562668317442085\n",
            "Total de pasos: 2996728/3000000.0 - Recompensa: -1.526688272532753\n",
            "Total de pasos: 2996729/3000000.0 - Recompensa: 0.19845005744491617\n",
            "0.19845005744491617\n",
            "Total de pasos: 2996730/3000000.0 - Recompensa: 1.0002923166221414\n",
            "1.0002923166221414\n",
            "Total de pasos: 2996731/3000000.0 - Recompensa: -0.3555562903409844\n",
            "Total de pasos: 2996732/3000000.0 - Recompensa: -0.7329727544303312\n",
            "Total de pasos: 2996733/3000000.0 - Recompensa: -0.7514545990791545\n",
            "Total de pasos: 2996734/3000000.0 - Recompensa: -2.000366292677707\n",
            "Total de pasos: 2996735/3000000.0 - Recompensa: -0.16508258766061595\n",
            "Total de pasos: 2996736/3000000.0 - Recompensa: -0.9245476132986326\n",
            "Total de pasos: 2996737/3000000.0 - Recompensa: -2.7599658793312325\n",
            "Total de pasos: 2996738/3000000.0 - Recompensa: -0.4428079355495206\n",
            "Total de pasos: 2996739/3000000.0 - Recompensa: -1.4575899493110982\n",
            "Total de pasos: 2996740/3000000.0 - Recompensa: -1.0217836036803594\n",
            "Total de pasos: 2996741/3000000.0 - Recompensa: -1.0051347730614089\n",
            "Total de pasos: 2996742/3000000.0 - Recompensa: -0.40286207923575235\n",
            "Total de pasos: 2996743/3000000.0 - Recompensa: 0.7402096583666854\n",
            "0.7402096583666854\n",
            "Total de pasos: 2996744/3000000.0 - Recompensa: -0.5035636192211772\n",
            "Total de pasos: 2996745/3000000.0 - Recompensa: 0.3523003879290484\n",
            "0.3523003879290484\n",
            "Total de pasos: 2996746/3000000.0 - Recompensa: -0.5099548894892724\n",
            "Total de pasos: 2996747/3000000.0 - Recompensa: -0.7957221397982555\n",
            "Total de pasos: 2996748/3000000.0 - Recompensa: -0.06463365734101903\n",
            "Total de pasos: 2996749/3000000.0 - Recompensa: 0.39020096238205626\n",
            "0.39020096238205626\n",
            "Total de pasos: 2996750/3000000.0 - Recompensa: -3.102105139492628\n",
            "Total de pasos: 2996751/3000000.0 - Recompensa: -0.20134437091047525\n",
            "Total de pasos: 2996752/3000000.0 - Recompensa: -2.601879622403675\n",
            "Total de pasos: 2996753/3000000.0 - Recompensa: -1.9963944358747971\n",
            "Total de pasos: 2996754/3000000.0 - Recompensa: -1.4687157524488033\n",
            "Total de pasos: 2996755/3000000.0 - Recompensa: -1.112232493089362\n",
            "Total de pasos: 2996756/3000000.0 - Recompensa: -1.0935288201463875\n",
            "Total de pasos: 2996757/3000000.0 - Recompensa: -1.0277926176278949\n",
            "Total de pasos: 2996758/3000000.0 - Recompensa: 0.4347638073019284\n",
            "0.4347638073019284\n",
            "Total de pasos: 2996759/3000000.0 - Recompensa: -0.8109612713049129\n",
            "Total de pasos: 2996760/3000000.0 - Recompensa: -1.1781354757313933\n",
            "Total de pasos: 2996761/3000000.0 - Recompensa: 0.28485951670096155\n",
            "0.28485951670096155\n",
            "Total de pasos: 2996762/3000000.0 - Recompensa: -0.6075648313774015\n",
            "Total de pasos: 2996763/3000000.0 - Recompensa: -1.0533874451418277\n",
            "Total de pasos: 2996764/3000000.0 - Recompensa: -0.830631691691574\n",
            "Total de pasos: 2996765/3000000.0 - Recompensa: -1.7001254912682828\n",
            "Total de pasos: 2996766/3000000.0 - Recompensa: -2.9424939017167793\n",
            "Total de pasos: 2996767/3000000.0 - Recompensa: -0.5232314511677103\n",
            "Total de pasos: 2996768/3000000.0 - Recompensa: -0.32158436934685836\n",
            "Total de pasos: 2996769/3000000.0 - Recompensa: 0.8622261641346556\n",
            "0.8622261641346556\n",
            "Total de pasos: 2996770/3000000.0 - Recompensa: -0.00770091479643803\n",
            "Total de pasos: 2996771/3000000.0 - Recompensa: -0.7405400210726162\n",
            "Total de pasos: 2996772/3000000.0 - Recompensa: -0.9851983984355972\n",
            "Total de pasos: 2996773/3000000.0 - Recompensa: -0.3564273121592353\n",
            "Total de pasos: 2996774/3000000.0 - Recompensa: -1.7585685170073584\n",
            "Total de pasos: 2996775/3000000.0 - Recompensa: -0.7242456691148582\n",
            "Total de pasos: 2996776/3000000.0 - Recompensa: -1.0703962616875762\n",
            "Total de pasos: 2996777/3000000.0 - Recompensa: -1.459740142072665\n",
            "Total de pasos: 2996778/3000000.0 - Recompensa: -1.6613431526261293\n",
            "Total de pasos: 2996779/3000000.0 - Recompensa: -1.285819552931063\n",
            "Total de pasos: 2996780/3000000.0 - Recompensa: -1.338695318565747\n",
            "Total de pasos: 2996781/3000000.0 - Recompensa: -1.098929536881121\n",
            "Total de pasos: 2996782/3000000.0 - Recompensa: 0.0661922852430869\n",
            "0.0661922852430869\n",
            "Total de pasos: 2996783/3000000.0 - Recompensa: -0.24638873478364723\n",
            "Total de pasos: 2996784/3000000.0 - Recompensa: -0.16938338534796032\n",
            "Total de pasos: 2996785/3000000.0 - Recompensa: -1.0577660466819125\n",
            "Total de pasos: 2996786/3000000.0 - Recompensa: -1.3435867481489032\n",
            "Total de pasos: 2996787/3000000.0 - Recompensa: -2.5098348754605686\n",
            "Total de pasos: 2996788/3000000.0 - Recompensa: -2.710302840137808\n",
            "Total de pasos: 2996789/3000000.0 - Recompensa: -0.8760732199011112\n",
            "Total de pasos: 2996790/3000000.0 - Recompensa: -1.1845305136525275\n",
            "Total de pasos: 2996791/3000000.0 - Recompensa: -0.20072581708270737\n",
            "Total de pasos: 2996792/3000000.0 - Recompensa: -0.3492887758679969\n",
            "Total de pasos: 2996793/3000000.0 - Recompensa: -0.052031256733250514\n",
            "Total de pasos: 2996794/3000000.0 - Recompensa: 0.967269742014432\n",
            "0.967269742014432\n",
            "Total de pasos: 2996795/3000000.0 - Recompensa: -3.592684598666603\n",
            "Total de pasos: 2996796/3000000.0 - Recompensa: -0.7073712485250992\n",
            "Total de pasos: 2996797/3000000.0 - Recompensa: -1.192866863667418\n",
            "Total de pasos: 2996798/3000000.0 - Recompensa: -0.09759533401553591\n",
            "Total de pasos: 2996799/3000000.0 - Recompensa: -1.2420415647927434\n",
            "Total de pasos: 2996800/3000000.0 - Recompensa: -0.8222265677829673\n",
            "Total de pasos: 2996801/3000000.0 - Recompensa: -2.3494478862327575\n",
            "Total de pasos: 2996802/3000000.0 - Recompensa: -1.1117771286378688\n",
            "Total de pasos: 2996803/3000000.0 - Recompensa: -1.661783481976887\n",
            "Total de pasos: 2996804/3000000.0 - Recompensa: -0.39832748561178544\n",
            "Total de pasos: 2996805/3000000.0 - Recompensa: -2.3036462020952184\n",
            "Total de pasos: 2996806/3000000.0 - Recompensa: -2.2030298361096525\n",
            "Total de pasos: 2996807/3000000.0 - Recompensa: -1.4613542644002018\n",
            "Total de pasos: 2996808/3000000.0 - Recompensa: -1.0682443125660275\n",
            "Total de pasos: 2996809/3000000.0 - Recompensa: -0.8355759243233132\n",
            "Total de pasos: 2996810/3000000.0 - Recompensa: -0.6611168616451382\n",
            "Total de pasos: 2996811/3000000.0 - Recompensa: -1.180789003545002\n",
            "Total de pasos: 2996812/3000000.0 - Recompensa: -0.3578620441873624\n",
            "Total de pasos: 2996813/3000000.0 - Recompensa: -0.3340019642269401\n",
            "Total de pasos: 2996814/3000000.0 - Recompensa: -0.826569925843655\n",
            "Total de pasos: 2996815/3000000.0 - Recompensa: -1.7666872422466706\n",
            "Total de pasos: 2996816/3000000.0 - Recompensa: -1.300982290372255\n",
            "Total de pasos: 2996817/3000000.0 - Recompensa: -1.3515429997423491\n",
            "Total de pasos: 2996818/3000000.0 - Recompensa: -0.39662286470591096\n",
            "Total de pasos: 2996819/3000000.0 - Recompensa: 0.2205957233295973\n",
            "0.2205957233295973\n",
            "Total de pasos: 2996820/3000000.0 - Recompensa: 1.123854533657013\n",
            "1.123854533657013\n",
            "Total de pasos: 2996821/3000000.0 - Recompensa: -0.8224438292302584\n",
            "Total de pasos: 2996822/3000000.0 - Recompensa: -0.47339238392072225\n",
            "Total de pasos: 2996823/3000000.0 - Recompensa: -2.3887685026017467\n",
            "Total de pasos: 2996824/3000000.0 - Recompensa: -1.6682979928600323\n",
            "Total de pasos: 2996825/3000000.0 - Recompensa: -0.5934384720246568\n",
            "Total de pasos: 2996826/3000000.0 - Recompensa: -0.36179024002373994\n",
            "Total de pasos: 2996827/3000000.0 - Recompensa: -2.8276157101324113\n",
            "Total de pasos: 2996828/3000000.0 - Recompensa: -2.787146727642067\n",
            "Total de pasos: 2996829/3000000.0 - Recompensa: 0.02587175607811898\n",
            "0.02587175607811898\n",
            "Total de pasos: 2996830/3000000.0 - Recompensa: -0.6375529239568642\n",
            "Total de pasos: 2996831/3000000.0 - Recompensa: -0.0554442888863112\n",
            "Total de pasos: 2996832/3000000.0 - Recompensa: -2.2832116174773445\n",
            "Total de pasos: 2996833/3000000.0 - Recompensa: 0.009232151445171588\n",
            "0.009232151445171588\n",
            "Total de pasos: 2996834/3000000.0 - Recompensa: -0.8407946217834014\n",
            "Total de pasos: 2996835/3000000.0 - Recompensa: -1.2871147619512084\n",
            "Total de pasos: 2996836/3000000.0 - Recompensa: -2.849486494545564\n",
            "Total de pasos: 2996837/3000000.0 - Recompensa: -0.0763788398728305\n",
            "Total de pasos: 2996838/3000000.0 - Recompensa: 0.005053453107867589\n",
            "0.005053453107867589\n",
            "Total de pasos: 2996839/3000000.0 - Recompensa: -0.2551726583240742\n",
            "Total de pasos: 2996840/3000000.0 - Recompensa: -0.41498622432623417\n",
            "Total de pasos: 2996841/3000000.0 - Recompensa: -0.8528338224390203\n",
            "Total de pasos: 2996842/3000000.0 - Recompensa: -1.5432199666267854\n",
            "Total de pasos: 2996843/3000000.0 - Recompensa: -2.9718725528921333\n",
            "Total de pasos: 2996844/3000000.0 - Recompensa: -1.192577243529792\n",
            "Total de pasos: 2996845/3000000.0 - Recompensa: -0.021847743288073762\n",
            "Total de pasos: 2996846/3000000.0 - Recompensa: -0.23611734079940688\n",
            "Total de pasos: 2996847/3000000.0 - Recompensa: -0.6901706334135338\n",
            "Total de pasos: 2996848/3000000.0 - Recompensa: -0.14595815996018052\n",
            "Total de pasos: 2996849/3000000.0 - Recompensa: -0.8249964552549183\n",
            "Total de pasos: 2996850/3000000.0 - Recompensa: 0.2865177174708543\n",
            "0.2865177174708543\n",
            "Total de pasos: 2996851/3000000.0 - Recompensa: -1.5783980229932941\n",
            "Total de pasos: 2996852/3000000.0 - Recompensa: -3.4795224353376177\n",
            "Total de pasos: 2996853/3000000.0 - Recompensa: -0.0760703533536658\n",
            "Total de pasos: 2996854/3000000.0 - Recompensa: -2.8101413982157246\n",
            "Total de pasos: 2996855/3000000.0 - Recompensa: -1.6501208169260213\n",
            "Total de pasos: 2996856/3000000.0 - Recompensa: -1.322928516535614\n",
            "Total de pasos: 2996857/3000000.0 - Recompensa: -1.545573341642418\n",
            "Total de pasos: 2996858/3000000.0 - Recompensa: -3.3152158898257267\n",
            "Total de pasos: 2996859/3000000.0 - Recompensa: -0.9540321480911164\n",
            "Total de pasos: 2996860/3000000.0 - Recompensa: -1.198463941035765\n",
            "Total de pasos: 2996861/3000000.0 - Recompensa: -0.4800183925799562\n",
            "Total de pasos: 2996862/3000000.0 - Recompensa: -1.3109755250408004\n",
            "Total de pasos: 2996863/3000000.0 - Recompensa: -0.9799233086825527\n",
            "Total de pasos: 2996864/3000000.0 - Recompensa: -0.9457647331081985\n",
            "Total de pasos: 2996865/3000000.0 - Recompensa: -0.9843400904957305\n",
            "Total de pasos: 2996866/3000000.0 - Recompensa: -0.29605167103713664\n",
            "Total de pasos: 2996867/3000000.0 - Recompensa: 0.011761307875828825\n",
            "0.011761307875828825\n",
            "Total de pasos: 2996868/3000000.0 - Recompensa: -2.986017078836751\n",
            "Total de pasos: 2996869/3000000.0 - Recompensa: -0.697994418323036\n",
            "Total de pasos: 2996870/3000000.0 - Recompensa: -0.5145122179826535\n",
            "Total de pasos: 2996871/3000000.0 - Recompensa: -0.7735706917821966\n",
            "Total de pasos: 2996872/3000000.0 - Recompensa: -1.5143414658592844\n",
            "Total de pasos: 2996873/3000000.0 - Recompensa: -1.4867659582628818\n",
            "Total de pasos: 2996874/3000000.0 - Recompensa: -0.7151037839790092\n",
            "Total de pasos: 2996875/3000000.0 - Recompensa: -2.1975552588759455\n",
            "Total de pasos: 2996876/3000000.0 - Recompensa: -1.7007055865611727\n",
            "Total de pasos: 2996877/3000000.0 - Recompensa: -0.5674632935020647\n",
            "Total de pasos: 2996878/3000000.0 - Recompensa: -1.9038536917583222\n",
            "Total de pasos: 2996879/3000000.0 - Recompensa: -0.5814346061714699\n",
            "Total de pasos: 2996880/3000000.0 - Recompensa: -1.4517311004100344\n",
            "Total de pasos: 2996881/3000000.0 - Recompensa: 0.4997502864231626\n",
            "0.4997502864231626\n",
            "Total de pasos: 2996882/3000000.0 - Recompensa: -0.5456510743672836\n",
            "Total de pasos: 2996883/3000000.0 - Recompensa: 0.45588877526848015\n",
            "0.45588877526848015\n",
            "Total de pasos: 2996884/3000000.0 - Recompensa: 0.06174358034249136\n",
            "0.06174358034249136\n",
            "Total de pasos: 2996885/3000000.0 - Recompensa: -0.6082085686457395\n",
            "Total de pasos: 2996886/3000000.0 - Recompensa: -0.9146054071902545\n",
            "Total de pasos: 2996887/3000000.0 - Recompensa: -2.0330822524892183\n",
            "Total de pasos: 2996888/3000000.0 - Recompensa: -0.5752403980717323\n",
            "Total de pasos: 2996889/3000000.0 - Recompensa: -1.0205038854771826\n",
            "Total de pasos: 2996890/3000000.0 - Recompensa: 0.030737121451186844\n",
            "0.030737121451186844\n",
            "Total de pasos: 2996891/3000000.0 - Recompensa: -2.0169063853149503\n",
            "Total de pasos: 2996892/3000000.0 - Recompensa: -0.7324095770439664\n",
            "Total de pasos: 2996893/3000000.0 - Recompensa: -1.560388901351622\n",
            "Total de pasos: 2996894/3000000.0 - Recompensa: -1.4980575653222579\n",
            "Total de pasos: 2996895/3000000.0 - Recompensa: 0.5778971693981659\n",
            "0.5778971693981659\n",
            "Total de pasos: 2996896/3000000.0 - Recompensa: -0.6050462499457162\n",
            "Total de pasos: 2996897/3000000.0 - Recompensa: 0.19154262573546837\n",
            "0.19154262573546837\n",
            "Total de pasos: 2996898/3000000.0 - Recompensa: -0.21670402704215955\n",
            "Total de pasos: 2996899/3000000.0 - Recompensa: -3.005737099194768\n",
            "Total de pasos: 2996900/3000000.0 - Recompensa: 0.0076602465533017194\n",
            "0.0076602465533017194\n",
            "Total de pasos: 2996901/3000000.0 - Recompensa: -1.3332799503462107\n",
            "Total de pasos: 2996902/3000000.0 - Recompensa: -3.0464877249997557\n",
            "Total de pasos: 2996903/3000000.0 - Recompensa: -0.8191983242041567\n",
            "Total de pasos: 2996904/3000000.0 - Recompensa: -0.2207184672983773\n",
            "Total de pasos: 2996905/3000000.0 - Recompensa: -1.9113178423658947\n",
            "Total de pasos: 2996906/3000000.0 - Recompensa: -0.4719269431899965\n",
            "Total de pasos: 2996907/3000000.0 - Recompensa: -0.9946651207098738\n",
            "Total de pasos: 2996908/3000000.0 - Recompensa: -1.640476396193067\n",
            "Total de pasos: 2996909/3000000.0 - Recompensa: -0.7674453508016146\n",
            "Total de pasos: 2996910/3000000.0 - Recompensa: -3.555107125049845\n",
            "Total de pasos: 2996911/3000000.0 - Recompensa: -0.7768112319119682\n",
            "Total de pasos: 2996912/3000000.0 - Recompensa: -0.057287845479156246\n",
            "Total de pasos: 2996913/3000000.0 - Recompensa: -1.247364533017202\n",
            "Total de pasos: 2996914/3000000.0 - Recompensa: 0.0006205922960528798\n",
            "0.0006205922960528798\n",
            "Total de pasos: 2996915/3000000.0 - Recompensa: -1.1586881184921962\n",
            "Total de pasos: 2996916/3000000.0 - Recompensa: -1.852745773013277\n",
            "Total de pasos: 2996917/3000000.0 - Recompensa: -1.1622039791876202\n",
            "Total de pasos: 2996918/3000000.0 - Recompensa: -0.9128143371216464\n",
            "Total de pasos: 2996919/3000000.0 - Recompensa: -1.2778273716888644\n",
            "Total de pasos: 2996920/3000000.0 - Recompensa: -0.0228880634865877\n",
            "Total de pasos: 2996921/3000000.0 - Recompensa: -0.6944534755494882\n",
            "Total de pasos: 2996922/3000000.0 - Recompensa: -0.5408710400192848\n",
            "Total de pasos: 2996923/3000000.0 - Recompensa: -0.15597939362592178\n",
            "Total de pasos: 2996924/3000000.0 - Recompensa: -0.9252740545198995\n",
            "Total de pasos: 2996925/3000000.0 - Recompensa: -1.3300412456243607\n",
            "Total de pasos: 2996926/3000000.0 - Recompensa: -0.9423621297842133\n",
            "Total de pasos: 2996927/3000000.0 - Recompensa: -1.1455855375418391\n",
            "Total de pasos: 2996928/3000000.0 - Recompensa: 0.32464382569791883\n",
            "0.32464382569791883\n",
            "Total de pasos: 2996929/3000000.0 - Recompensa: -1.3633471964581112\n",
            "Total de pasos: 2996930/3000000.0 - Recompensa: 0.6932702240579507\n",
            "0.6932702240579507\n",
            "Total de pasos: 2996931/3000000.0 - Recompensa: -0.013239911269899235\n",
            "Total de pasos: 2996932/3000000.0 - Recompensa: 0.009942944983909408\n",
            "0.009942944983909408\n",
            "Total de pasos: 2996933/3000000.0 - Recompensa: 0.3358798254229393\n",
            "0.3358798254229393\n",
            "Total de pasos: 2996934/3000000.0 - Recompensa: 0.05889387181147482\n",
            "0.05889387181147482\n",
            "Total de pasos: 2996935/3000000.0 - Recompensa: -0.8055732710335003\n",
            "Total de pasos: 2996936/3000000.0 - Recompensa: -1.9583493504921665\n",
            "Total de pasos: 2996937/3000000.0 - Recompensa: -0.27543986950597876\n",
            "Total de pasos: 2996938/3000000.0 - Recompensa: -0.7533416853919052\n",
            "Total de pasos: 2996939/3000000.0 - Recompensa: -3.5212709330042116\n",
            "Total de pasos: 2996940/3000000.0 - Recompensa: -1.523725807461401\n",
            "Total de pasos: 2996941/3000000.0 - Recompensa: -1.4781684629758602\n",
            "Total de pasos: 2996942/3000000.0 - Recompensa: -0.9803596023417861\n",
            "Total de pasos: 2996943/3000000.0 - Recompensa: -1.139695416849873\n",
            "Total de pasos: 2996944/3000000.0 - Recompensa: -0.4420574860341125\n",
            "Total de pasos: 2996945/3000000.0 - Recompensa: -1.3733072614292534\n",
            "Total de pasos: 2996946/3000000.0 - Recompensa: -2.884356957709554\n",
            "Total de pasos: 2996947/3000000.0 - Recompensa: -1.4762673425068056\n",
            "Total de pasos: 2996948/3000000.0 - Recompensa: -0.13818191723787804\n",
            "Total de pasos: 2996949/3000000.0 - Recompensa: 0.5786189001579527\n",
            "0.5786189001579527\n",
            "Total de pasos: 2996950/3000000.0 - Recompensa: 0.1125360324839128\n",
            "0.1125360324839128\n",
            "Total de pasos: 2996951/3000000.0 - Recompensa: -0.24262327795846464\n",
            "Total de pasos: 2996952/3000000.0 - Recompensa: -1.7866385423184623\n",
            "Total de pasos: 2996953/3000000.0 - Recompensa: -0.24658913825913303\n",
            "Total de pasos: 2996954/3000000.0 - Recompensa: -1.7277404448258955\n",
            "Total de pasos: 2996955/3000000.0 - Recompensa: -1.7814735421618713\n",
            "Total de pasos: 2996956/3000000.0 - Recompensa: 0.09401242512308458\n",
            "0.09401242512308458\n",
            "Total de pasos: 2996957/3000000.0 - Recompensa: -2.47956421312272\n",
            "Total de pasos: 2996958/3000000.0 - Recompensa: 0.67988562735018\n",
            "0.67988562735018\n",
            "Total de pasos: 2996959/3000000.0 - Recompensa: 0.8772673466877476\n",
            "0.8772673466877476\n",
            "Total de pasos: 2996960/3000000.0 - Recompensa: -1.6170388195979468\n",
            "Total de pasos: 2996961/3000000.0 - Recompensa: 0.2821045226620748\n",
            "0.2821045226620748\n",
            "Total de pasos: 2996962/3000000.0 - Recompensa: -1.9480033372292516\n",
            "Total de pasos: 2996963/3000000.0 - Recompensa: -0.6494952912245847\n",
            "Total de pasos: 2996964/3000000.0 - Recompensa: -0.11988615222219018\n",
            "Total de pasos: 2996965/3000000.0 - Recompensa: -1.7389806720520713\n",
            "Total de pasos: 2996966/3000000.0 - Recompensa: -0.17559121398661662\n",
            "Total de pasos: 2996967/3000000.0 - Recompensa: 0.6413036332472014\n",
            "0.6413036332472014\n",
            "Total de pasos: 2996968/3000000.0 - Recompensa: -3.9880069719848326\n",
            "Total de pasos: 2996969/3000000.0 - Recompensa: -0.22934884720038512\n",
            "Total de pasos: 2996970/3000000.0 - Recompensa: -0.5916148463632367\n",
            "Total de pasos: 2996971/3000000.0 - Recompensa: -1.9211612315755136\n",
            "Total de pasos: 2996972/3000000.0 - Recompensa: -2.2907155857742914\n",
            "Total de pasos: 2996973/3000000.0 - Recompensa: -0.28445570099637224\n",
            "Total de pasos: 2996974/3000000.0 - Recompensa: -0.291049340255688\n",
            "Total de pasos: 2996975/3000000.0 - Recompensa: -0.9903999532646102\n",
            "Total de pasos: 2996976/3000000.0 - Recompensa: -1.1054675857751062\n",
            "Total de pasos: 2996977/3000000.0 - Recompensa: -2.134073815244008\n",
            "Total de pasos: 2996978/3000000.0 - Recompensa: -0.2824185244887335\n",
            "Total de pasos: 2996979/3000000.0 - Recompensa: -0.7508381214201093\n",
            "Total de pasos: 2996980/3000000.0 - Recompensa: -0.0886590827933258\n",
            "Total de pasos: 2996981/3000000.0 - Recompensa: -3.0993368672519\n",
            "Total de pasos: 2996982/3000000.0 - Recompensa: -0.2366397125206679\n",
            "Total de pasos: 2996983/3000000.0 - Recompensa: -2.56855041295118\n",
            "Total de pasos: 2996984/3000000.0 - Recompensa: -1.462063992224289\n",
            "Total de pasos: 2996985/3000000.0 - Recompensa: -1.9297404637145248\n",
            "Total de pasos: 2996986/3000000.0 - Recompensa: -4.580453484757492\n",
            "Total de pasos: 2996987/3000000.0 - Recompensa: 0.28609098204059535\n",
            "0.28609098204059535\n",
            "Total de pasos: 2996988/3000000.0 - Recompensa: -0.09910127048227402\n",
            "Total de pasos: 2996989/3000000.0 - Recompensa: -1.2634503614318071\n",
            "Total de pasos: 2996990/3000000.0 - Recompensa: 0.2243737755306452\n",
            "0.2243737755306452\n",
            "Total de pasos: 2996991/3000000.0 - Recompensa: -2.592624061813777\n",
            "Total de pasos: 2996992/3000000.0 - Recompensa: 0.42194371431327726\n",
            "0.42194371431327726\n",
            "Total de pasos: 2996993/3000000.0 - Recompensa: -2.405530292801501\n",
            "Total de pasos: 2996994/3000000.0 - Recompensa: -1.852326176186842\n",
            "Total de pasos: 2996995/3000000.0 - Recompensa: -2.1614958042590584\n",
            "Total de pasos: 2996996/3000000.0 - Recompensa: -0.38727462694356546\n",
            "Total de pasos: 2996997/3000000.0 - Recompensa: -0.635228791393297\n",
            "Total de pasos: 2996998/3000000.0 - Recompensa: -0.8739814915015105\n",
            "Total de pasos: 2996999/3000000.0 - Recompensa: -0.6286622806574738\n",
            "Total de pasos: 2997000/3000000.0 - Recompensa: -0.33871162540495786\n",
            "Total de pasos: 2997001/3000000.0 - Recompensa: -0.41269327112584914\n",
            "Total de pasos: 2997002/3000000.0 - Recompensa: -0.3633754109907502\n",
            "Total de pasos: 2997003/3000000.0 - Recompensa: -0.9226288242599766\n",
            "Total de pasos: 2997004/3000000.0 - Recompensa: -0.9119938224446894\n",
            "Total de pasos: 2997005/3000000.0 - Recompensa: -0.5159267660384481\n",
            "Total de pasos: 2997006/3000000.0 - Recompensa: -1.3172022197507804\n",
            "Total de pasos: 2997007/3000000.0 - Recompensa: -0.18424043181900843\n",
            "Total de pasos: 2997008/3000000.0 - Recompensa: -0.08875518301771629\n",
            "Total de pasos: 2997009/3000000.0 - Recompensa: 0.12551916078184674\n",
            "0.12551916078184674\n",
            "Total de pasos: 2997010/3000000.0 - Recompensa: -2.799648937042365\n",
            "Total de pasos: 2997011/3000000.0 - Recompensa: -1.5438946453566915\n",
            "Total de pasos: 2997012/3000000.0 - Recompensa: 0.5758137681463079\n",
            "0.5758137681463079\n",
            "Total de pasos: 2997013/3000000.0 - Recompensa: -0.09200265329488966\n",
            "Total de pasos: 2997014/3000000.0 - Recompensa: -1.271793439212071\n",
            "Total de pasos: 2997015/3000000.0 - Recompensa: -0.9995115201307402\n",
            "Total de pasos: 2997016/3000000.0 - Recompensa: -0.9903028801452137\n",
            "Total de pasos: 2997017/3000000.0 - Recompensa: -0.5713492718156807\n",
            "Total de pasos: 2997018/3000000.0 - Recompensa: -0.8881323312322655\n",
            "Total de pasos: 2997019/3000000.0 - Recompensa: -1.6603724701336673\n",
            "Total de pasos: 2997020/3000000.0 - Recompensa: -2.558354807456695\n",
            "Total de pasos: 2997021/3000000.0 - Recompensa: -1.9297393734844352\n",
            "Total de pasos: 2997022/3000000.0 - Recompensa: -0.33091682947550255\n",
            "Total de pasos: 2997023/3000000.0 - Recompensa: -1.107872637261055\n",
            "Total de pasos: 2997024/3000000.0 - Recompensa: -1.4512070816537843\n",
            "Total de pasos: 2997025/3000000.0 - Recompensa: -2.6374535572406548\n",
            "Total de pasos: 2997026/3000000.0 - Recompensa: -0.3486091600491624\n",
            "Total de pasos: 2997027/3000000.0 - Recompensa: -0.48493579452943214\n",
            "Total de pasos: 2997028/3000000.0 - Recompensa: -0.13738404705138235\n",
            "Total de pasos: 2997029/3000000.0 - Recompensa: -0.28689471393659877\n",
            "Total de pasos: 2997030/3000000.0 - Recompensa: 0.5628424503224616\n",
            "0.5628424503224616\n",
            "Total de pasos: 2997031/3000000.0 - Recompensa: 0.20040290448952977\n",
            "0.20040290448952977\n",
            "Total de pasos: 2997032/3000000.0 - Recompensa: 0.4266408508354228\n",
            "0.4266408508354228\n",
            "Total de pasos: 2997033/3000000.0 - Recompensa: -1.5631516215792167\n",
            "Total de pasos: 2997034/3000000.0 - Recompensa: -1.0882886663786961\n",
            "Total de pasos: 2997035/3000000.0 - Recompensa: -2.027526838888652\n",
            "Total de pasos: 2997036/3000000.0 - Recompensa: -0.8907780984633307\n",
            "Total de pasos: 2997037/3000000.0 - Recompensa: -1.4189445503552855\n",
            "Total de pasos: 2997038/3000000.0 - Recompensa: -1.0848915937483616\n",
            "Total de pasos: 2997039/3000000.0 - Recompensa: -0.7283117963277819\n",
            "Total de pasos: 2997040/3000000.0 - Recompensa: -3.3254086866771595\n",
            "Total de pasos: 2997041/3000000.0 - Recompensa: -4.738955864780373\n",
            "Total de pasos: 2997042/3000000.0 - Recompensa: 0.037339705899807146\n",
            "0.037339705899807146\n",
            "Total de pasos: 2997043/3000000.0 - Recompensa: -0.8156739355426768\n",
            "Total de pasos: 2997044/3000000.0 - Recompensa: -2.076848003731094\n",
            "Total de pasos: 2997045/3000000.0 - Recompensa: -0.5110676878451614\n",
            "Total de pasos: 2997046/3000000.0 - Recompensa: -2.152567200529305\n",
            "Total de pasos: 2997047/3000000.0 - Recompensa: -3.303882066362246\n",
            "Total de pasos: 2997048/3000000.0 - Recompensa: -3.159357910539153\n",
            "Total de pasos: 2997049/3000000.0 - Recompensa: -0.981300061484088\n",
            "Total de pasos: 2997050/3000000.0 - Recompensa: -3.467075120168553\n",
            "Total de pasos: 2997051/3000000.0 - Recompensa: -1.7399481680996232\n",
            "Total de pasos: 2997052/3000000.0 - Recompensa: 0.7698554016010951\n",
            "0.7698554016010951\n",
            "Total de pasos: 2997053/3000000.0 - Recompensa: -0.7949079057353495\n",
            "Total de pasos: 2997054/3000000.0 - Recompensa: -0.16550496597919243\n",
            "Total de pasos: 2997055/3000000.0 - Recompensa: -0.9165702497381691\n",
            "Total de pasos: 2997056/3000000.0 - Recompensa: -3.3551758737789426\n",
            "Total de pasos: 2997057/3000000.0 - Recompensa: 0.16925249119499747\n",
            "0.16925249119499747\n",
            "Total de pasos: 2997058/3000000.0 - Recompensa: 0.05896580184490427\n",
            "0.05896580184490427\n",
            "Total de pasos: 2997059/3000000.0 - Recompensa: -0.5348525202434832\n",
            "Total de pasos: 2997060/3000000.0 - Recompensa: 0.4118667753686266\n",
            "0.4118667753686266\n",
            "Total de pasos: 2997061/3000000.0 - Recompensa: 0.09107486643171175\n",
            "0.09107486643171175\n",
            "Total de pasos: 2997062/3000000.0 - Recompensa: -1.802399895850393\n",
            "Total de pasos: 2997063/3000000.0 - Recompensa: 0.03887082792020488\n",
            "0.03887082792020488\n",
            "Total de pasos: 2997064/3000000.0 - Recompensa: -1.1805538744322825\n",
            "Total de pasos: 2997065/3000000.0 - Recompensa: -0.6713575613071566\n",
            "Total de pasos: 2997066/3000000.0 - Recompensa: -0.4548252855991727\n",
            "Total de pasos: 2997067/3000000.0 - Recompensa: -0.7898073316626355\n",
            "Total de pasos: 2997068/3000000.0 - Recompensa: 0.6327465740222928\n",
            "0.6327465740222928\n",
            "Total de pasos: 2997069/3000000.0 - Recompensa: -3.932452654341767\n",
            "Total de pasos: 2997070/3000000.0 - Recompensa: -1.14389510119359\n",
            "Total de pasos: 2997071/3000000.0 - Recompensa: 0.4186760814784082\n",
            "0.4186760814784082\n",
            "Total de pasos: 2997072/3000000.0 - Recompensa: -0.7384697287767323\n",
            "Total de pasos: 2997073/3000000.0 - Recompensa: -0.7806539932099906\n",
            "Total de pasos: 2997074/3000000.0 - Recompensa: -1.6067786027366688\n",
            "Total de pasos: 2997075/3000000.0 - Recompensa: -1.3061315216483504\n",
            "Total de pasos: 2997076/3000000.0 - Recompensa: -1.7888418110133095\n",
            "Total de pasos: 2997077/3000000.0 - Recompensa: 0.11415290684308771\n",
            "0.11415290684308771\n",
            "Total de pasos: 2997078/3000000.0 - Recompensa: -0.2859088542624607\n",
            "Total de pasos: 2997079/3000000.0 - Recompensa: -0.5934885414554499\n",
            "Total de pasos: 2997080/3000000.0 - Recompensa: -0.8760328689994892\n",
            "Total de pasos: 2997081/3000000.0 - Recompensa: -0.47741272554094205\n",
            "Total de pasos: 2997082/3000000.0 - Recompensa: -2.902812931278242\n",
            "Total de pasos: 2997083/3000000.0 - Recompensa: -1.0276913917437884\n",
            "Total de pasos: 2997084/3000000.0 - Recompensa: -0.953427563243818\n",
            "Total de pasos: 2997085/3000000.0 - Recompensa: -0.9965894865711156\n",
            "Total de pasos: 2997086/3000000.0 - Recompensa: -1.566699486317524\n",
            "Total de pasos: 2997087/3000000.0 - Recompensa: -1.0922848780012946\n",
            "Total de pasos: 2997088/3000000.0 - Recompensa: -0.7120757247105669\n",
            "Total de pasos: 2997089/3000000.0 - Recompensa: -1.062480924623445\n",
            "Total de pasos: 2997090/3000000.0 - Recompensa: 0.22311474066404896\n",
            "0.22311474066404896\n",
            "Total de pasos: 2997091/3000000.0 - Recompensa: -0.0417953987294212\n",
            "Total de pasos: 2997092/3000000.0 - Recompensa: 0.2646950754041601\n",
            "0.2646950754041601\n",
            "Total de pasos: 2997093/3000000.0 - Recompensa: -0.49863031027421983\n",
            "Total de pasos: 2997094/3000000.0 - Recompensa: -0.2270527387775199\n",
            "Total de pasos: 2997095/3000000.0 - Recompensa: -1.699736555566223\n",
            "Total de pasos: 2997096/3000000.0 - Recompensa: -0.7513914386922835\n",
            "Total de pasos: 2997097/3000000.0 - Recompensa: -1.026963167380114\n",
            "Total de pasos: 2997098/3000000.0 - Recompensa: -1.3153226664631479\n",
            "Total de pasos: 2997099/3000000.0 - Recompensa: 0.5722470072708334\n",
            "0.5722470072708334\n",
            "Total de pasos: 2997100/3000000.0 - Recompensa: 0.308892239510852\n",
            "0.308892239510852\n",
            "Total de pasos: 2997101/3000000.0 - Recompensa: -0.724897653553094\n",
            "Total de pasos: 2997102/3000000.0 - Recompensa: -1.4540654635248078\n",
            "Total de pasos: 2997103/3000000.0 - Recompensa: -0.8244870201137176\n",
            "Total de pasos: 2997104/3000000.0 - Recompensa: -0.2283091827058378\n",
            "Total de pasos: 2997105/3000000.0 - Recompensa: -2.5367172457187737\n",
            "Total de pasos: 2997106/3000000.0 - Recompensa: -0.5295064926063733\n",
            "Total de pasos: 2997107/3000000.0 - Recompensa: -0.0016571582119340733\n",
            "Total de pasos: 2997108/3000000.0 - Recompensa: -0.701724373180017\n",
            "Total de pasos: 2997109/3000000.0 - Recompensa: -0.44561957082767806\n",
            "Total de pasos: 2997110/3000000.0 - Recompensa: -0.30893319923053914\n",
            "Total de pasos: 2997111/3000000.0 - Recompensa: -0.5268337902617664\n",
            "Total de pasos: 2997112/3000000.0 - Recompensa: -0.47692780875178437\n",
            "Total de pasos: 2997113/3000000.0 - Recompensa: -0.48930472860079527\n",
            "Total de pasos: 2997114/3000000.0 - Recompensa: -1.4949448585162706\n",
            "Total de pasos: 2997115/3000000.0 - Recompensa: -1.2551810886748684\n",
            "Total de pasos: 2997116/3000000.0 - Recompensa: -1.377193722784736\n",
            "Total de pasos: 2997117/3000000.0 - Recompensa: -1.1019150303191936\n",
            "Total de pasos: 2997118/3000000.0 - Recompensa: -0.9242363556629314\n",
            "Total de pasos: 2997119/3000000.0 - Recompensa: -0.7819126961484625\n",
            "Total de pasos: 2997120/3000000.0 - Recompensa: 0.08121270016488799\n",
            "0.08121270016488799\n",
            "Total de pasos: 2997121/3000000.0 - Recompensa: -2.9038270131077963\n",
            "Total de pasos: 2997122/3000000.0 - Recompensa: -0.09449350792296377\n",
            "Total de pasos: 2997123/3000000.0 - Recompensa: 0.23131620620028198\n",
            "0.23131620620028198\n",
            "Total de pasos: 2997124/3000000.0 - Recompensa: -1.6851726788267003\n",
            "Total de pasos: 2997125/3000000.0 - Recompensa: -0.9958791029135241\n",
            "Total de pasos: 2997126/3000000.0 - Recompensa: -1.6960401481988887\n",
            "Total de pasos: 2997127/3000000.0 - Recompensa: 0.4153690341401387\n",
            "0.4153690341401387\n",
            "Total de pasos: 2997128/3000000.0 - Recompensa: -1.141935951312209\n",
            "Total de pasos: 2997129/3000000.0 - Recompensa: -0.317030641934393\n",
            "Total de pasos: 2997130/3000000.0 - Recompensa: -0.012903993180834933\n",
            "Total de pasos: 2997131/3000000.0 - Recompensa: 0.3621607886762982\n",
            "0.3621607886762982\n",
            "Total de pasos: 2997132/3000000.0 - Recompensa: -0.40239343362418\n",
            "Total de pasos: 2997133/3000000.0 - Recompensa: -1.003755842324813\n",
            "Total de pasos: 2997134/3000000.0 - Recompensa: 0.021141552383903306\n",
            "0.021141552383903306\n",
            "Total de pasos: 2997135/3000000.0 - Recompensa: -2.1242990667151003\n",
            "Total de pasos: 2997136/3000000.0 - Recompensa: -0.4201038311718568\n",
            "Total de pasos: 2997137/3000000.0 - Recompensa: -1.147471435236397\n",
            "Total de pasos: 2997138/3000000.0 - Recompensa: -2.7291143608039015\n",
            "Total de pasos: 2997139/3000000.0 - Recompensa: 0.02455086961002756\n",
            "0.02455086961002756\n",
            "Total de pasos: 2997140/3000000.0 - Recompensa: -1.0987853362093782\n",
            "Total de pasos: 2997141/3000000.0 - Recompensa: -0.9684293791892971\n",
            "Total de pasos: 2997142/3000000.0 - Recompensa: -0.22233426435525444\n",
            "Total de pasos: 2997143/3000000.0 - Recompensa: -0.7324476938710573\n",
            "Total de pasos: 2997144/3000000.0 - Recompensa: -2.269745493765055\n",
            "Total de pasos: 2997145/3000000.0 - Recompensa: -1.3871188981488616\n",
            "Total de pasos: 2997146/3000000.0 - Recompensa: -1.2090746685896372\n",
            "Total de pasos: 2997147/3000000.0 - Recompensa: 0.0990946277507497\n",
            "0.0990946277507497\n",
            "Total de pasos: 2997148/3000000.0 - Recompensa: 0.2323780273452562\n",
            "0.2323780273452562\n",
            "Total de pasos: 2997149/3000000.0 - Recompensa: -0.6168972647249729\n",
            "Total de pasos: 2997150/3000000.0 - Recompensa: -3.636841736473421\n",
            "Total de pasos: 2997151/3000000.0 - Recompensa: -0.32857537498328276\n",
            "Total de pasos: 2997152/3000000.0 - Recompensa: -0.554604510263231\n",
            "Total de pasos: 2997153/3000000.0 - Recompensa: -3.836410233935283\n",
            "Total de pasos: 2997154/3000000.0 - Recompensa: -0.3290381859708485\n",
            "Total de pasos: 2997155/3000000.0 - Recompensa: -0.5935600935742642\n",
            "Total de pasos: 2997156/3000000.0 - Recompensa: -1.9951889719539904\n",
            "Total de pasos: 2997157/3000000.0 - Recompensa: -0.35809419416310406\n",
            "Total de pasos: 2997158/3000000.0 - Recompensa: -0.723933077283791\n",
            "Total de pasos: 2997159/3000000.0 - Recompensa: -1.5596632950813727\n",
            "Total de pasos: 2997160/3000000.0 - Recompensa: 0.6010304977068628\n",
            "0.6010304977068628\n",
            "Total de pasos: 2997161/3000000.0 - Recompensa: -1.5402491365715014\n",
            "Total de pasos: 2997162/3000000.0 - Recompensa: -1.4296117944109357\n",
            "Total de pasos: 2997163/3000000.0 - Recompensa: -3.703521940775489\n",
            "Total de pasos: 2997164/3000000.0 - Recompensa: -1.4176969180862444\n",
            "Total de pasos: 2997165/3000000.0 - Recompensa: -2.0553905851809837\n",
            "Total de pasos: 2997166/3000000.0 - Recompensa: -0.5251282723745401\n",
            "Total de pasos: 2997167/3000000.0 - Recompensa: -0.47194338732045515\n",
            "Total de pasos: 2997168/3000000.0 - Recompensa: -1.1726231265932356\n",
            "Total de pasos: 2997169/3000000.0 - Recompensa: -1.821748595207703\n",
            "Total de pasos: 2997170/3000000.0 - Recompensa: -0.472308213192936\n",
            "Total de pasos: 2997171/3000000.0 - Recompensa: -2.1446259399095284\n",
            "Total de pasos: 2997172/3000000.0 - Recompensa: -0.1790956228329273\n",
            "Total de pasos: 2997173/3000000.0 - Recompensa: -0.4185112848434519\n",
            "Total de pasos: 2997174/3000000.0 - Recompensa: -0.30680837239654124\n",
            "Total de pasos: 2997175/3000000.0 - Recompensa: 0.4830115132341885\n",
            "0.4830115132341885\n",
            "Total de pasos: 2997176/3000000.0 - Recompensa: -0.6637376849266768\n",
            "Total de pasos: 2997177/3000000.0 - Recompensa: -0.05049913762757835\n",
            "Total de pasos: 2997178/3000000.0 - Recompensa: -1.5920815750956523\n",
            "Total de pasos: 2997179/3000000.0 - Recompensa: -2.9948634758850754\n",
            "Total de pasos: 2997180/3000000.0 - Recompensa: 0.5595135045482494\n",
            "0.5595135045482494\n",
            "Total de pasos: 2997181/3000000.0 - Recompensa: -4.968334207814439\n",
            "Total de pasos: 2997182/3000000.0 - Recompensa: -0.6471400982464804\n",
            "Total de pasos: 2997183/3000000.0 - Recompensa: -0.4955121250938122\n",
            "Total de pasos: 2997184/3000000.0 - Recompensa: -1.1735863562692153\n",
            "Total de pasos: 2997185/3000000.0 - Recompensa: -1.4813642888554543\n",
            "Total de pasos: 2997186/3000000.0 - Recompensa: -1.8003333323213324\n",
            "Total de pasos: 2997187/3000000.0 - Recompensa: -1.3926438065651783\n",
            "Total de pasos: 2997188/3000000.0 - Recompensa: 0.4165702630651464\n",
            "0.4165702630651464\n",
            "Total de pasos: 2997189/3000000.0 - Recompensa: 0.4250082650422275\n",
            "0.4250082650422275\n",
            "Total de pasos: 2997190/3000000.0 - Recompensa: -0.005996503890071114\n",
            "Total de pasos: 2997191/3000000.0 - Recompensa: -0.618186161278335\n",
            "Total de pasos: 2997192/3000000.0 - Recompensa: 0.050226399003618694\n",
            "0.050226399003618694\n",
            "Total de pasos: 2997193/3000000.0 - Recompensa: -0.8087190239619193\n",
            "Total de pasos: 2997194/3000000.0 - Recompensa: -0.06343293329195632\n",
            "Total de pasos: 2997195/3000000.0 - Recompensa: -1.9832144117496218\n",
            "Total de pasos: 2997196/3000000.0 - Recompensa: 0.04208454086154684\n",
            "0.04208454086154684\n",
            "Total de pasos: 2997197/3000000.0 - Recompensa: -4.714899491714564\n",
            "Total de pasos: 2997198/3000000.0 - Recompensa: -0.11169449651649913\n",
            "Total de pasos: 2997199/3000000.0 - Recompensa: -0.2128783746939468\n",
            "Total de pasos: 2997200/3000000.0 - Recompensa: -1.3101392747304632\n",
            "Total de pasos: 2997201/3000000.0 - Recompensa: -2.086401937189388\n",
            "Total de pasos: 2997202/3000000.0 - Recompensa: -4.473132726859454\n",
            "Total de pasos: 2997203/3000000.0 - Recompensa: -0.6613909543546699\n",
            "Total de pasos: 2997204/3000000.0 - Recompensa: 0.08647169443724473\n",
            "0.08647169443724473\n",
            "Total de pasos: 2997205/3000000.0 - Recompensa: -1.449413637269379\n",
            "Total de pasos: 2997206/3000000.0 - Recompensa: -2.6301253313754622\n",
            "Total de pasos: 2997207/3000000.0 - Recompensa: -0.33088004704535906\n",
            "Total de pasos: 2997208/3000000.0 - Recompensa: -1.59134354338888\n",
            "Total de pasos: 2997209/3000000.0 - Recompensa: 0.4938939352216886\n",
            "0.4938939352216886\n",
            "Total de pasos: 2997210/3000000.0 - Recompensa: -1.027578467622316\n",
            "Total de pasos: 2997211/3000000.0 - Recompensa: -1.2961083367626856\n",
            "Total de pasos: 2997212/3000000.0 - Recompensa: -3.3052437204641407\n",
            "Total de pasos: 2997213/3000000.0 - Recompensa: -1.4682439301320107\n",
            "Total de pasos: 2997214/3000000.0 - Recompensa: -0.2555494999327375\n",
            "Total de pasos: 2997215/3000000.0 - Recompensa: -1.7799520162184843\n",
            "Total de pasos: 2997216/3000000.0 - Recompensa: -0.40831614889829726\n",
            "Total de pasos: 2997217/3000000.0 - Recompensa: -1.621001373879447\n",
            "Total de pasos: 2997218/3000000.0 - Recompensa: -0.2260378862182252\n",
            "Total de pasos: 2997219/3000000.0 - Recompensa: -2.8732921303040038\n",
            "Total de pasos: 2997220/3000000.0 - Recompensa: -4.427468529196186\n",
            "Total de pasos: 2997221/3000000.0 - Recompensa: -0.1721868794300428\n",
            "Total de pasos: 2997222/3000000.0 - Recompensa: -0.14366436924632292\n",
            "Total de pasos: 2997223/3000000.0 - Recompensa: -1.661239359326208\n",
            "Total de pasos: 2997224/3000000.0 - Recompensa: 0.42857891055421893\n",
            "0.42857891055421893\n",
            "Total de pasos: 2997225/3000000.0 - Recompensa: -0.42756480554464266\n",
            "Total de pasos: 2997226/3000000.0 - Recompensa: -0.282794548701155\n",
            "Total de pasos: 2997227/3000000.0 - Recompensa: 0.19810083014947816\n",
            "0.19810083014947816\n",
            "Total de pasos: 2997228/3000000.0 - Recompensa: -0.7711261835090232\n",
            "Total de pasos: 2997229/3000000.0 - Recompensa: 0.8067269654071527\n",
            "0.8067269654071527\n",
            "Total de pasos: 2997230/3000000.0 - Recompensa: -2.581456708625918\n",
            "Total de pasos: 2997231/3000000.0 - Recompensa: -0.27308889183918234\n",
            "Total de pasos: 2997232/3000000.0 - Recompensa: 0.7233994924753584\n",
            "0.7233994924753584\n",
            "Total de pasos: 2997233/3000000.0 - Recompensa: -2.1934487606001314\n",
            "Total de pasos: 2997234/3000000.0 - Recompensa: -2.15575522603374\n",
            "Total de pasos: 2997235/3000000.0 - Recompensa: 0.39873476815428005\n",
            "0.39873476815428005\n",
            "Total de pasos: 2997236/3000000.0 - Recompensa: -0.02810303934560482\n",
            "Total de pasos: 2997237/3000000.0 - Recompensa: -0.9136752421732836\n",
            "Total de pasos: 2997238/3000000.0 - Recompensa: 0.05991695613451195\n",
            "0.05991695613451195\n",
            "Total de pasos: 2997239/3000000.0 - Recompensa: -1.2722131614801464\n",
            "Total de pasos: 2997240/3000000.0 - Recompensa: 0.5297007165971015\n",
            "0.5297007165971015\n",
            "Total de pasos: 2997241/3000000.0 - Recompensa: -0.8962705149534351\n",
            "Total de pasos: 2997242/3000000.0 - Recompensa: -0.8802828437193292\n",
            "Total de pasos: 2997243/3000000.0 - Recompensa: -0.30600883327891804\n",
            "Total de pasos: 2997244/3000000.0 - Recompensa: -0.7817779548653798\n",
            "Total de pasos: 2997245/3000000.0 - Recompensa: -0.7353917188673557\n",
            "Total de pasos: 2997246/3000000.0 - Recompensa: -0.648304819453297\n",
            "Total de pasos: 2997247/3000000.0 - Recompensa: -0.2894845939645706\n",
            "Total de pasos: 2997248/3000000.0 - Recompensa: 0.2471343585385672\n",
            "0.2471343585385672\n",
            "Total de pasos: 2997249/3000000.0 - Recompensa: -1.0895379988334557\n",
            "Total de pasos: 2997250/3000000.0 - Recompensa: 0.5215380659516006\n",
            "0.5215380659516006\n",
            "Total de pasos: 2997251/3000000.0 - Recompensa: -0.38871399540859997\n",
            "Total de pasos: 2997252/3000000.0 - Recompensa: 0.23304861768212976\n",
            "0.23304861768212976\n",
            "Total de pasos: 2997253/3000000.0 - Recompensa: -6.005410481544903\n",
            "Total de pasos: 2997254/3000000.0 - Recompensa: -1.0127368634631555\n",
            "Total de pasos: 2997255/3000000.0 - Recompensa: -2.5519797552405454\n",
            "Total de pasos: 2997256/3000000.0 - Recompensa: -0.8208755173544809\n",
            "Total de pasos: 2997257/3000000.0 - Recompensa: -0.6171104538087835\n",
            "Total de pasos: 2997258/3000000.0 - Recompensa: -1.0350410135325627\n",
            "Total de pasos: 2997259/3000000.0 - Recompensa: -0.36487750173377875\n",
            "Total de pasos: 2997260/3000000.0 - Recompensa: -2.7770540010708236\n",
            "Total de pasos: 2997261/3000000.0 - Recompensa: 0.05061043099120849\n",
            "0.05061043099120849\n",
            "Total de pasos: 2997262/3000000.0 - Recompensa: -1.523975317371611\n",
            "Total de pasos: 2997263/3000000.0 - Recompensa: 0.21928786671324535\n",
            "0.21928786671324535\n",
            "Total de pasos: 2997264/3000000.0 - Recompensa: -0.9418785070523958\n",
            "Total de pasos: 2997265/3000000.0 - Recompensa: -1.6502238264643794\n",
            "Total de pasos: 2997266/3000000.0 - Recompensa: -3.403753533927225\n",
            "Total de pasos: 2997267/3000000.0 - Recompensa: -2.369290389911943\n",
            "Total de pasos: 2997268/3000000.0 - Recompensa: 0.3474514008610638\n",
            "0.3474514008610638\n",
            "Total de pasos: 2997269/3000000.0 - Recompensa: -1.4667907526453365\n",
            "Total de pasos: 2997270/3000000.0 - Recompensa: -0.4186473323418574\n",
            "Total de pasos: 2997271/3000000.0 - Recompensa: -1.1129383776653856\n",
            "Total de pasos: 2997272/3000000.0 - Recompensa: -0.1833770968063244\n",
            "Total de pasos: 2997273/3000000.0 - Recompensa: -0.25884677842712717\n",
            "Total de pasos: 2997274/3000000.0 - Recompensa: -1.1673793844333278\n",
            "Total de pasos: 2997275/3000000.0 - Recompensa: -0.6137136469894588\n",
            "Total de pasos: 2997276/3000000.0 - Recompensa: -0.1788984192818011\n",
            "Total de pasos: 2997277/3000000.0 - Recompensa: -3.3251838266549303\n",
            "Total de pasos: 2997278/3000000.0 - Recompensa: -0.9320898222323039\n",
            "Total de pasos: 2997279/3000000.0 - Recompensa: 0.25121403486798244\n",
            "0.25121403486798244\n",
            "Total de pasos: 2997280/3000000.0 - Recompensa: -2.4567507125847596\n",
            "Total de pasos: 2997281/3000000.0 - Recompensa: -1.854242943046485\n",
            "Total de pasos: 2997282/3000000.0 - Recompensa: -3.6975781173656292\n",
            "Total de pasos: 2997283/3000000.0 - Recompensa: -3.4905790248961024\n",
            "Total de pasos: 2997284/3000000.0 - Recompensa: -2.112559981273354\n",
            "Total de pasos: 2997285/3000000.0 - Recompensa: -0.41852630965435134\n",
            "Total de pasos: 2997286/3000000.0 - Recompensa: -1.8569307089988112\n",
            "Total de pasos: 2997287/3000000.0 - Recompensa: 0.24144540771005224\n",
            "0.24144540771005224\n",
            "Total de pasos: 2997288/3000000.0 - Recompensa: -1.4023695146381274\n",
            "Total de pasos: 2997289/3000000.0 - Recompensa: -2.237097211050354\n",
            "Total de pasos: 2997290/3000000.0 - Recompensa: -0.21637355201929803\n",
            "Total de pasos: 2997291/3000000.0 - Recompensa: -1.1651251906717486\n",
            "Total de pasos: 2997292/3000000.0 - Recompensa: -0.20931566359194403\n",
            "Total de pasos: 2997293/3000000.0 - Recompensa: -1.8656022150809621\n",
            "Total de pasos: 2997294/3000000.0 - Recompensa: 0.4617873618752856\n",
            "0.4617873618752856\n",
            "Total de pasos: 2997295/3000000.0 - Recompensa: 1.1030131304713324\n",
            "1.1030131304713324\n",
            "Total de pasos: 2997296/3000000.0 - Recompensa: -1.6202081011692635\n",
            "Total de pasos: 2997297/3000000.0 - Recompensa: -0.22417509233924485\n",
            "Total de pasos: 2997298/3000000.0 - Recompensa: -0.5173631891673115\n",
            "Total de pasos: 2997299/3000000.0 - Recompensa: -0.7568834023988884\n",
            "Total de pasos: 2997300/3000000.0 - Recompensa: -1.7778540408115502\n",
            "Total de pasos: 2997301/3000000.0 - Recompensa: -0.8498332535094336\n",
            "Total de pasos: 2997302/3000000.0 - Recompensa: -1.1560929035350493\n",
            "Total de pasos: 2997303/3000000.0 - Recompensa: -0.72510958660049\n",
            "Total de pasos: 2997304/3000000.0 - Recompensa: 0.1270597189905009\n",
            "0.1270597189905009\n",
            "Total de pasos: 2997305/3000000.0 - Recompensa: -1.0511134102629038\n",
            "Total de pasos: 2997306/3000000.0 - Recompensa: -2.1531155279397862\n",
            "Total de pasos: 2997307/3000000.0 - Recompensa: -0.8829380686444013\n",
            "Total de pasos: 2997308/3000000.0 - Recompensa: -0.9216394994559826\n",
            "Total de pasos: 2997309/3000000.0 - Recompensa: -0.6803642569805975\n",
            "Total de pasos: 2997310/3000000.0 - Recompensa: -0.916804612091996\n",
            "Total de pasos: 2997311/3000000.0 - Recompensa: -0.3512357144688071\n",
            "Total de pasos: 2997312/3000000.0 - Recompensa: -0.10983715617197842\n",
            "Total de pasos: 2997313/3000000.0 - Recompensa: -1.280282490388939\n",
            "Total de pasos: 2997314/3000000.0 - Recompensa: 0.06397089289436972\n",
            "0.06397089289436972\n",
            "Total de pasos: 2997315/3000000.0 - Recompensa: -1.8611373389717067\n",
            "Total de pasos: 2997316/3000000.0 - Recompensa: -0.5016789866371355\n",
            "Total de pasos: 2997317/3000000.0 - Recompensa: -1.315712651469366\n",
            "Total de pasos: 2997318/3000000.0 - Recompensa: 0.09749364704086325\n",
            "0.09749364704086325\n",
            "Total de pasos: 2997319/3000000.0 - Recompensa: -0.002904923224351791\n",
            "Total de pasos: 2997320/3000000.0 - Recompensa: 0.0904175815884325\n",
            "0.0904175815884325\n",
            "Total de pasos: 2997321/3000000.0 - Recompensa: -0.15914023779010691\n",
            "Total de pasos: 2997322/3000000.0 - Recompensa: -1.5669752453363452\n",
            "Total de pasos: 2997323/3000000.0 - Recompensa: 0.12207875819280395\n",
            "0.12207875819280395\n",
            "Total de pasos: 2997324/3000000.0 - Recompensa: -2.086191786930913\n",
            "Total de pasos: 2997325/3000000.0 - Recompensa: -1.0554150707948247\n",
            "Total de pasos: 2997326/3000000.0 - Recompensa: -2.971950439696075\n",
            "Total de pasos: 2997327/3000000.0 - Recompensa: 0.1947320912741532\n",
            "0.1947320912741532\n",
            "Total de pasos: 2997328/3000000.0 - Recompensa: -0.2950962676576506\n",
            "Total de pasos: 2997329/3000000.0 - Recompensa: -1.4548333601248011\n",
            "Total de pasos: 2997330/3000000.0 - Recompensa: 1.0962527199969172\n",
            "1.0962527199969172\n",
            "Total de pasos: 2997331/3000000.0 - Recompensa: 0.20486081368422288\n",
            "0.20486081368422288\n",
            "Total de pasos: 2997332/3000000.0 - Recompensa: -0.8980699685141158\n",
            "Total de pasos: 2997333/3000000.0 - Recompensa: 0.26905310418955886\n",
            "0.26905310418955886\n",
            "Total de pasos: 2997334/3000000.0 - Recompensa: -1.0597987130587943\n",
            "Total de pasos: 2997335/3000000.0 - Recompensa: -0.08964515185330582\n",
            "Total de pasos: 2997336/3000000.0 - Recompensa: -0.33609571169835195\n",
            "Total de pasos: 2997337/3000000.0 - Recompensa: -1.0305149547745431\n",
            "Total de pasos: 2997338/3000000.0 - Recompensa: -1.2701771190601212\n",
            "Total de pasos: 2997339/3000000.0 - Recompensa: 0.05213033710342696\n",
            "0.05213033710342696\n",
            "Total de pasos: 2997340/3000000.0 - Recompensa: -0.36267371858980446\n",
            "Total de pasos: 2997341/3000000.0 - Recompensa: -0.409778687202435\n",
            "Total de pasos: 2997342/3000000.0 - Recompensa: -1.814825446999573\n",
            "Total de pasos: 2997343/3000000.0 - Recompensa: -3.005986703640526\n",
            "Total de pasos: 2997344/3000000.0 - Recompensa: -0.10951482958219\n",
            "Total de pasos: 2997345/3000000.0 - Recompensa: -0.2705409067807948\n",
            "Total de pasos: 2997346/3000000.0 - Recompensa: -0.6998340490053007\n",
            "Total de pasos: 2997347/3000000.0 - Recompensa: -0.7193665638024107\n",
            "Total de pasos: 2997348/3000000.0 - Recompensa: 1.2348375004299623\n",
            "1.2348375004299623\n",
            "Total de pasos: 2997349/3000000.0 - Recompensa: 0.35780126470036955\n",
            "0.35780126470036955\n",
            "Total de pasos: 2997350/3000000.0 - Recompensa: 0.23385340190473286\n",
            "0.23385340190473286\n",
            "Total de pasos: 2997351/3000000.0 - Recompensa: 0.07108064566706127\n",
            "0.07108064566706127\n",
            "Total de pasos: 2997352/3000000.0 - Recompensa: -1.914567225364479\n",
            "Total de pasos: 2997353/3000000.0 - Recompensa: 0.004105907581409107\n",
            "0.004105907581409107\n",
            "Total de pasos: 2997354/3000000.0 - Recompensa: 0.8336137618686797\n",
            "0.8336137618686797\n",
            "Total de pasos: 2997355/3000000.0 - Recompensa: -1.3256849112421079\n",
            "Total de pasos: 2997356/3000000.0 - Recompensa: -2.3627318347742188\n",
            "Total de pasos: 2997357/3000000.0 - Recompensa: -1.608155323963969\n",
            "Total de pasos: 2997358/3000000.0 - Recompensa: -2.0149904246384023\n",
            "Total de pasos: 2997359/3000000.0 - Recompensa: -1.1604891135621904\n",
            "Total de pasos: 2997360/3000000.0 - Recompensa: -2.1038703205164295\n",
            "Total de pasos: 2997361/3000000.0 - Recompensa: -1.8265684294720346\n",
            "Total de pasos: 2997362/3000000.0 - Recompensa: -0.04186667719540496\n",
            "Total de pasos: 2997363/3000000.0 - Recompensa: -0.03496678850948093\n",
            "Total de pasos: 2997364/3000000.0 - Recompensa: -1.725558856571292\n",
            "Total de pasos: 2997365/3000000.0 - Recompensa: -0.5757100853335881\n",
            "Total de pasos: 2997366/3000000.0 - Recompensa: -0.27876660542291304\n",
            "Total de pasos: 2997367/3000000.0 - Recompensa: -0.9258193456778405\n",
            "Total de pasos: 2997368/3000000.0 - Recompensa: -2.561630676169217\n",
            "Total de pasos: 2997369/3000000.0 - Recompensa: -2.817039402146417\n",
            "Total de pasos: 2997370/3000000.0 - Recompensa: -0.10405501900983918\n",
            "Total de pasos: 2997371/3000000.0 - Recompensa: -2.861720044061188\n",
            "Total de pasos: 2997372/3000000.0 - Recompensa: -1.2255343830090675\n",
            "Total de pasos: 2997373/3000000.0 - Recompensa: -2.6142047727882822\n",
            "Total de pasos: 2997374/3000000.0 - Recompensa: -0.6038135628914273\n",
            "Total de pasos: 2997375/3000000.0 - Recompensa: -0.6859124213421394\n",
            "Total de pasos: 2997376/3000000.0 - Recompensa: 0.03087659775219137\n",
            "0.03087659775219137\n",
            "Total de pasos: 2997377/3000000.0 - Recompensa: -1.832707187898004\n",
            "Total de pasos: 2997378/3000000.0 - Recompensa: -0.15715559300150078\n",
            "Total de pasos: 2997379/3000000.0 - Recompensa: -1.2246973853144045\n",
            "Total de pasos: 2997380/3000000.0 - Recompensa: -0.4060702701406659\n",
            "Total de pasos: 2997381/3000000.0 - Recompensa: -1.6549836597226997\n",
            "Total de pasos: 2997382/3000000.0 - Recompensa: -0.9175026269125801\n",
            "Total de pasos: 2997383/3000000.0 - Recompensa: 0.4834907963180385\n",
            "0.4834907963180385\n",
            "Total de pasos: 2997384/3000000.0 - Recompensa: -0.6405017213069153\n",
            "Total de pasos: 2997385/3000000.0 - Recompensa: -2.3655716193691134\n",
            "Total de pasos: 2997386/3000000.0 - Recompensa: 0.39672492428840267\n",
            "0.39672492428840267\n",
            "Total de pasos: 2997387/3000000.0 - Recompensa: -0.5177967435290307\n",
            "Total de pasos: 2997388/3000000.0 - Recompensa: -0.8905933426734722\n",
            "Total de pasos: 2997389/3000000.0 - Recompensa: -1.3953736058630934\n",
            "Total de pasos: 2997390/3000000.0 - Recompensa: -0.3873366017212055\n",
            "Total de pasos: 2997391/3000000.0 - Recompensa: -0.7585547270370201\n",
            "Total de pasos: 2997392/3000000.0 - Recompensa: -0.8773425710560078\n",
            "Total de pasos: 2997393/3000000.0 - Recompensa: 0.23591351192834983\n",
            "0.23591351192834983\n",
            "Total de pasos: 2997394/3000000.0 - Recompensa: 0.1126903613895088\n",
            "0.1126903613895088\n",
            "Total de pasos: 2997395/3000000.0 - Recompensa: -2.9232269018024093\n",
            "Total de pasos: 2997396/3000000.0 - Recompensa: -0.6149371239912547\n",
            "Total de pasos: 2997397/3000000.0 - Recompensa: -1.0955919520300943\n",
            "Total de pasos: 2997398/3000000.0 - Recompensa: -1.5219481150655925\n",
            "Total de pasos: 2997399/3000000.0 - Recompensa: -0.8401597496748299\n",
            "Total de pasos: 2997400/3000000.0 - Recompensa: -0.7230294557179717\n",
            "Total de pasos: 2997401/3000000.0 - Recompensa: -1.4265080482475163\n",
            "Total de pasos: 2997402/3000000.0 - Recompensa: -0.7019250146844266\n",
            "Total de pasos: 2997403/3000000.0 - Recompensa: -0.5961566994652671\n",
            "Total de pasos: 2997404/3000000.0 - Recompensa: -0.07163065900351079\n",
            "Total de pasos: 2997405/3000000.0 - Recompensa: -0.9756491781660104\n",
            "Total de pasos: 2997406/3000000.0 - Recompensa: 0.42685599575195216\n",
            "0.42685599575195216\n",
            "Total de pasos: 2997407/3000000.0 - Recompensa: -4.853155591492117\n",
            "Total de pasos: 2997408/3000000.0 - Recompensa: -1.4222065914177262\n",
            "Total de pasos: 2997409/3000000.0 - Recompensa: -0.3461348137707252\n",
            "Total de pasos: 2997410/3000000.0 - Recompensa: 0.22394649211482903\n",
            "0.22394649211482903\n",
            "Total de pasos: 2997411/3000000.0 - Recompensa: -0.6388859731219512\n",
            "Total de pasos: 2997412/3000000.0 - Recompensa: -0.7668576104119861\n",
            "Total de pasos: 2997413/3000000.0 - Recompensa: -2.824418054600433\n",
            "Total de pasos: 2997414/3000000.0 - Recompensa: 0.05508738761454851\n",
            "0.05508738761454851\n",
            "Total de pasos: 2997415/3000000.0 - Recompensa: -1.2400827623865724\n",
            "Total de pasos: 2997416/3000000.0 - Recompensa: 0.9018335248857635\n",
            "0.9018335248857635\n",
            "Total de pasos: 2997417/3000000.0 - Recompensa: 0.21906088952498556\n",
            "0.21906088952498556\n",
            "Total de pasos: 2997418/3000000.0 - Recompensa: -2.0639083069352706\n",
            "Total de pasos: 2997419/3000000.0 - Recompensa: 0.8944155230170205\n",
            "0.8944155230170205\n",
            "Total de pasos: 2997420/3000000.0 - Recompensa: 1.0578090732881003\n",
            "1.0578090732881003\n",
            "Total de pasos: 2997421/3000000.0 - Recompensa: -1.727412238067148\n",
            "Total de pasos: 2997422/3000000.0 - Recompensa: -0.5927214113568051\n",
            "Total de pasos: 2997423/3000000.0 - Recompensa: -1.3490431109952707\n",
            "Total de pasos: 2997424/3000000.0 - Recompensa: -1.1664325136767495\n",
            "Total de pasos: 2997425/3000000.0 - Recompensa: 0.11370230017893695\n",
            "0.11370230017893695\n",
            "Total de pasos: 2997426/3000000.0 - Recompensa: -0.647274640347462\n",
            "Total de pasos: 2997427/3000000.0 - Recompensa: 0.07850848830673213\n",
            "0.07850848830673213\n",
            "Total de pasos: 2997428/3000000.0 - Recompensa: -0.1901631453461901\n",
            "Total de pasos: 2997429/3000000.0 - Recompensa: -1.1947866335901627\n",
            "Total de pasos: 2997430/3000000.0 - Recompensa: -1.174031619842471\n",
            "Total de pasos: 2997431/3000000.0 - Recompensa: -0.47793995076219165\n",
            "Total de pasos: 2997432/3000000.0 - Recompensa: -0.28465553875442084\n",
            "Total de pasos: 2997433/3000000.0 - Recompensa: -3.379909840460069\n",
            "Total de pasos: 2997434/3000000.0 - Recompensa: -0.3794111279669087\n",
            "Total de pasos: 2997435/3000000.0 - Recompensa: -0.1476720706045232\n",
            "Total de pasos: 2997436/3000000.0 - Recompensa: -2.4809967392460246\n",
            "Total de pasos: 2997437/3000000.0 - Recompensa: -0.1625386714470008\n",
            "Total de pasos: 2997438/3000000.0 - Recompensa: -1.3091219277219661\n",
            "Total de pasos: 2997439/3000000.0 - Recompensa: 0.15493341248789666\n",
            "0.15493341248789666\n",
            "Total de pasos: 2997440/3000000.0 - Recompensa: -2.4585636214607343\n",
            "Total de pasos: 2997441/3000000.0 - Recompensa: -1.389420554545333\n",
            "Total de pasos: 2997442/3000000.0 - Recompensa: -0.4700462792953436\n",
            "Total de pasos: 2997443/3000000.0 - Recompensa: -0.7742482659372272\n",
            "Total de pasos: 2997444/3000000.0 - Recompensa: -0.6098111259122032\n",
            "Total de pasos: 2997445/3000000.0 - Recompensa: -0.2563993712922364\n",
            "Total de pasos: 2997446/3000000.0 - Recompensa: -0.48461057014475306\n",
            "Total de pasos: 2997447/3000000.0 - Recompensa: 0.25662468767142865\n",
            "0.25662468767142865\n",
            "Total de pasos: 2997448/3000000.0 - Recompensa: -0.7113343371129746\n",
            "Total de pasos: 2997449/3000000.0 - Recompensa: -1.0639103550368398\n",
            "Total de pasos: 2997450/3000000.0 - Recompensa: -1.4262820006352133\n",
            "Total de pasos: 2997451/3000000.0 - Recompensa: -0.5945508079981846\n",
            "Total de pasos: 2997452/3000000.0 - Recompensa: -0.734481172604898\n",
            "Total de pasos: 2997453/3000000.0 - Recompensa: 0.2361987309210813\n",
            "0.2361987309210813\n",
            "Total de pasos: 2997454/3000000.0 - Recompensa: -1.1847339229515639\n",
            "Total de pasos: 2997455/3000000.0 - Recompensa: 0.19448381955767918\n",
            "0.19448381955767918\n",
            "Total de pasos: 2997456/3000000.0 - Recompensa: -0.7781387146425865\n",
            "Total de pasos: 2997457/3000000.0 - Recompensa: -3.242134148606054\n",
            "Total de pasos: 2997458/3000000.0 - Recompensa: -1.0388865475681421\n",
            "Total de pasos: 2997459/3000000.0 - Recompensa: -0.6454933265604267\n",
            "Total de pasos: 2997460/3000000.0 - Recompensa: -0.4039132289058676\n",
            "Total de pasos: 2997461/3000000.0 - Recompensa: 0.44520842292605034\n",
            "0.44520842292605034\n",
            "Total de pasos: 2997462/3000000.0 - Recompensa: -1.3164938847446894\n",
            "Total de pasos: 2997463/3000000.0 - Recompensa: 0.11264905679968357\n",
            "0.11264905679968357\n",
            "Total de pasos: 2997464/3000000.0 - Recompensa: -0.13816487937043181\n",
            "Total de pasos: 2997465/3000000.0 - Recompensa: -1.4559800688811808\n",
            "Total de pasos: 2997466/3000000.0 - Recompensa: -0.3238558914823292\n",
            "Total de pasos: 2997467/3000000.0 - Recompensa: 0.47131233972325126\n",
            "0.47131233972325126\n",
            "Total de pasos: 2997468/3000000.0 - Recompensa: 0.018774948785653223\n",
            "0.018774948785653223\n",
            "Total de pasos: 2997469/3000000.0 - Recompensa: -0.5865491901983434\n",
            "Total de pasos: 2997470/3000000.0 - Recompensa: 0.062227180125124126\n",
            "0.062227180125124126\n",
            "Total de pasos: 2997471/3000000.0 - Recompensa: -1.8355442690880848\n",
            "Total de pasos: 2997472/3000000.0 - Recompensa: -0.2052811679489817\n",
            "Total de pasos: 2997473/3000000.0 - Recompensa: -0.09856688951549525\n",
            "Total de pasos: 2997474/3000000.0 - Recompensa: -0.08979820694533297\n",
            "Total de pasos: 2997475/3000000.0 - Recompensa: -1.6443640427587525\n",
            "Total de pasos: 2997476/3000000.0 - Recompensa: 0.5464899136887998\n",
            "0.5464899136887998\n",
            "Total de pasos: 2997477/3000000.0 - Recompensa: 0.13752495700004647\n",
            "0.13752495700004647\n",
            "Total de pasos: 2997478/3000000.0 - Recompensa: -1.161905791921212\n",
            "Total de pasos: 2997479/3000000.0 - Recompensa: -2.5643801725753224\n",
            "Total de pasos: 2997480/3000000.0 - Recompensa: -0.3783957650098591\n",
            "Total de pasos: 2997481/3000000.0 - Recompensa: -0.4870998863554309\n",
            "Total de pasos: 2997482/3000000.0 - Recompensa: -0.6087142898802893\n",
            "Total de pasos: 2997483/3000000.0 - Recompensa: -1.3356134508399657\n",
            "Total de pasos: 2997484/3000000.0 - Recompensa: 0.8244816230469304\n",
            "0.8244816230469304\n",
            "Total de pasos: 2997485/3000000.0 - Recompensa: -2.000167301102799\n",
            "Total de pasos: 2997486/3000000.0 - Recompensa: -1.0599659304755513\n",
            "Total de pasos: 2997487/3000000.0 - Recompensa: -1.048991573540779\n",
            "Total de pasos: 2997488/3000000.0 - Recompensa: -1.2514081545150377\n",
            "Total de pasos: 2997489/3000000.0 - Recompensa: 0.25463187326627146\n",
            "0.25463187326627146\n",
            "Total de pasos: 2997490/3000000.0 - Recompensa: -1.1868427826499457\n",
            "Total de pasos: 2997491/3000000.0 - Recompensa: -1.9930008744126955\n",
            "Total de pasos: 2997492/3000000.0 - Recompensa: -1.0248050045926478\n",
            "Total de pasos: 2997493/3000000.0 - Recompensa: -1.7343831665917078\n",
            "Total de pasos: 2997494/3000000.0 - Recompensa: -0.7134666635697575\n",
            "Total de pasos: 2997495/3000000.0 - Recompensa: -2.4566380598350994\n",
            "Total de pasos: 2997496/3000000.0 - Recompensa: -0.1396211155928179\n",
            "Total de pasos: 2997497/3000000.0 - Recompensa: -1.0171560653748228\n",
            "Total de pasos: 2997498/3000000.0 - Recompensa: 0.2657698155591945\n",
            "0.2657698155591945\n",
            "Total de pasos: 2997499/3000000.0 - Recompensa: -0.5531484935104347\n",
            "Total de pasos: 2997500/3000000.0 - Recompensa: 1.1118682967826345\n",
            "1.1118682967826345\n",
            "Total de pasos: 2997501/3000000.0 - Recompensa: -1.162355780721819\n",
            "Total de pasos: 2997502/3000000.0 - Recompensa: 0.46691729122887937\n",
            "0.46691729122887937\n",
            "Total de pasos: 2997503/3000000.0 - Recompensa: 0.26818761170002986\n",
            "0.26818761170002986\n",
            "Total de pasos: 2997504/3000000.0 - Recompensa: -0.5029004536363426\n",
            "Total de pasos: 2997505/3000000.0 - Recompensa: -2.871474706191624\n",
            "Total de pasos: 2997506/3000000.0 - Recompensa: -0.048461175172403476\n",
            "Total de pasos: 2997507/3000000.0 - Recompensa: -1.557580982688377\n",
            "Total de pasos: 2997508/3000000.0 - Recompensa: 0.2568213508448979\n",
            "0.2568213508448979\n",
            "Total de pasos: 2997509/3000000.0 - Recompensa: -1.4539016022298408\n",
            "Total de pasos: 2997510/3000000.0 - Recompensa: 0.114079183304659\n",
            "0.114079183304659\n",
            "Total de pasos: 2997511/3000000.0 - Recompensa: 0.7545867545607456\n",
            "0.7545867545607456\n",
            "Total de pasos: 2997512/3000000.0 - Recompensa: -1.4354014166988784\n",
            "Total de pasos: 2997513/3000000.0 - Recompensa: -1.5299853153078242\n",
            "Total de pasos: 2997514/3000000.0 - Recompensa: -1.5591222838411718\n",
            "Total de pasos: 2997515/3000000.0 - Recompensa: -0.9349275673760999\n",
            "Total de pasos: 2997516/3000000.0 - Recompensa: -1.4288347765982663\n",
            "Total de pasos: 2997517/3000000.0 - Recompensa: -0.694461409265237\n",
            "Total de pasos: 2997518/3000000.0 - Recompensa: -0.6509135966820911\n",
            "Total de pasos: 2997519/3000000.0 - Recompensa: -0.12380311236853353\n",
            "Total de pasos: 2997520/3000000.0 - Recompensa: -1.2324343154205235\n",
            "Total de pasos: 2997521/3000000.0 - Recompensa: 0.35996397738631203\n",
            "0.35996397738631203\n",
            "Total de pasos: 2997522/3000000.0 - Recompensa: -0.9384859266248369\n",
            "Total de pasos: 2997523/3000000.0 - Recompensa: -0.09767213995986745\n",
            "Total de pasos: 2997524/3000000.0 - Recompensa: -2.1836869046233103\n",
            "Total de pasos: 2997525/3000000.0 - Recompensa: -0.4192804682163412\n",
            "Total de pasos: 2997526/3000000.0 - Recompensa: -0.9280931944390087\n",
            "Total de pasos: 2997527/3000000.0 - Recompensa: -0.797226135030495\n",
            "Total de pasos: 2997528/3000000.0 - Recompensa: -0.673585122888196\n",
            "Total de pasos: 2997529/3000000.0 - Recompensa: -0.8429408807919739\n",
            "Total de pasos: 2997530/3000000.0 - Recompensa: -0.9370003265013032\n",
            "Total de pasos: 2997531/3000000.0 - Recompensa: -1.7825839975600397\n",
            "Total de pasos: 2997532/3000000.0 - Recompensa: 0.10392055194450628\n",
            "0.10392055194450628\n",
            "Total de pasos: 2997533/3000000.0 - Recompensa: -0.5323894040524321\n",
            "Total de pasos: 2997534/3000000.0 - Recompensa: 0.04395547372571315\n",
            "0.04395547372571315\n",
            "Total de pasos: 2997535/3000000.0 - Recompensa: -2.434846640822636\n",
            "Total de pasos: 2997536/3000000.0 - Recompensa: -0.012824891979220931\n",
            "Total de pasos: 2997537/3000000.0 - Recompensa: -1.1632733639031254\n",
            "Total de pasos: 2997538/3000000.0 - Recompensa: 0.8951040756413915\n",
            "0.8951040756413915\n",
            "Total de pasos: 2997539/3000000.0 - Recompensa: -1.0205840642616941\n",
            "Total de pasos: 2997540/3000000.0 - Recompensa: -2.099208987143292\n",
            "Total de pasos: 2997541/3000000.0 - Recompensa: -1.695595296273341\n",
            "Total de pasos: 2997542/3000000.0 - Recompensa: -1.4212817218380285\n",
            "Total de pasos: 2997543/3000000.0 - Recompensa: -2.141095643999975\n",
            "Total de pasos: 2997544/3000000.0 - Recompensa: -1.3787770911780695\n",
            "Total de pasos: 2997545/3000000.0 - Recompensa: -0.4214217514441197\n",
            "Total de pasos: 2997546/3000000.0 - Recompensa: -1.3934985410771927\n",
            "Total de pasos: 2997547/3000000.0 - Recompensa: -1.916744325324637\n",
            "Total de pasos: 2997548/3000000.0 - Recompensa: -1.0637027313110148\n",
            "Total de pasos: 2997549/3000000.0 - Recompensa: -0.8762224733004466\n",
            "Total de pasos: 2997550/3000000.0 - Recompensa: 0.15761299392277522\n",
            "0.15761299392277522\n",
            "Total de pasos: 2997551/3000000.0 - Recompensa: -2.3204872631658904\n",
            "Total de pasos: 2997552/3000000.0 - Recompensa: -1.5239304619929193\n",
            "Total de pasos: 2997553/3000000.0 - Recompensa: -0.2962203639193864\n",
            "Total de pasos: 2997554/3000000.0 - Recompensa: -1.540631263256801\n",
            "Total de pasos: 2997555/3000000.0 - Recompensa: -1.9453257838306892\n",
            "Total de pasos: 2997556/3000000.0 - Recompensa: -0.7030134393550778\n",
            "Total de pasos: 2997557/3000000.0 - Recompensa: 0.04841402097712941\n",
            "0.04841402097712941\n",
            "Total de pasos: 2997558/3000000.0 - Recompensa: -1.6339396007020617\n",
            "Total de pasos: 2997559/3000000.0 - Recompensa: -1.7912920050159777\n",
            "Total de pasos: 2997560/3000000.0 - Recompensa: -1.9550070163362672\n",
            "Total de pasos: 2997561/3000000.0 - Recompensa: 1.0011342292361889\n",
            "1.0011342292361889\n",
            "Total de pasos: 2997562/3000000.0 - Recompensa: -0.8704712573303003\n",
            "Total de pasos: 2997563/3000000.0 - Recompensa: -0.5797650132517476\n",
            "Total de pasos: 2997564/3000000.0 - Recompensa: -1.0412351345205806\n",
            "Total de pasos: 2997565/3000000.0 - Recompensa: -0.4835523458482072\n",
            "Total de pasos: 2997566/3000000.0 - Recompensa: -0.7484488092884225\n",
            "Total de pasos: 2997567/3000000.0 - Recompensa: -0.19458211877042456\n",
            "Total de pasos: 2997568/3000000.0 - Recompensa: 0.4494411415967209\n",
            "0.4494411415967209\n",
            "Total de pasos: 2997569/3000000.0 - Recompensa: -0.7886108875887062\n",
            "Total de pasos: 2997570/3000000.0 - Recompensa: -2.0309179207963535\n",
            "Total de pasos: 2997571/3000000.0 - Recompensa: -1.7513916298477314\n",
            "Total de pasos: 2997572/3000000.0 - Recompensa: -0.4216095485050733\n",
            "Total de pasos: 2997573/3000000.0 - Recompensa: -1.08157753023797\n",
            "Total de pasos: 2997574/3000000.0 - Recompensa: 0.39335607819112817\n",
            "0.39335607819112817\n",
            "Total de pasos: 2997575/3000000.0 - Recompensa: -1.107410827815694\n",
            "Total de pasos: 2997576/3000000.0 - Recompensa: -1.5469991687417735\n",
            "Total de pasos: 2997577/3000000.0 - Recompensa: 1.0902729546572678\n",
            "1.0902729546572678\n",
            "Total de pasos: 2997578/3000000.0 - Recompensa: -2.1486532043398903\n",
            "Total de pasos: 2997579/3000000.0 - Recompensa: -1.023290729009703\n",
            "Total de pasos: 2997580/3000000.0 - Recompensa: -1.250094315412816\n",
            "Total de pasos: 2997581/3000000.0 - Recompensa: 0.5149827889730216\n",
            "0.5149827889730216\n",
            "Total de pasos: 2997582/3000000.0 - Recompensa: -1.4306950981577096\n",
            "Total de pasos: 2997583/3000000.0 - Recompensa: -0.5732056284908847\n",
            "Total de pasos: 2997584/3000000.0 - Recompensa: -0.10289942124424681\n",
            "Total de pasos: 2997585/3000000.0 - Recompensa: 0.5122644873948952\n",
            "0.5122644873948952\n",
            "Total de pasos: 2997586/3000000.0 - Recompensa: -2.5885546470032166\n",
            "Total de pasos: 2997587/3000000.0 - Recompensa: -0.9675082761776614\n",
            "Total de pasos: 2997588/3000000.0 - Recompensa: 0.17289476308296256\n",
            "0.17289476308296256\n",
            "Total de pasos: 2997589/3000000.0 - Recompensa: -1.1968466877824382\n",
            "Total de pasos: 2997590/3000000.0 - Recompensa: -0.7764707184006543\n",
            "Total de pasos: 2997591/3000000.0 - Recompensa: 0.429596327387575\n",
            "0.429596327387575\n",
            "Total de pasos: 2997592/3000000.0 - Recompensa: -1.4825105676452952\n",
            "Total de pasos: 2997593/3000000.0 - Recompensa: -0.019406082611648584\n",
            "Total de pasos: 2997594/3000000.0 - Recompensa: -1.406481340722283\n",
            "Total de pasos: 2997595/3000000.0 - Recompensa: 0.3787270704311322\n",
            "0.3787270704311322\n",
            "Total de pasos: 2997596/3000000.0 - Recompensa: -0.6040331498828427\n",
            "Total de pasos: 2997597/3000000.0 - Recompensa: -0.03723419616646245\n",
            "Total de pasos: 2997598/3000000.0 - Recompensa: -1.138883015476585\n",
            "Total de pasos: 2997599/3000000.0 - Recompensa: -0.33856637408017354\n",
            "Total de pasos: 2997600/3000000.0 - Recompensa: -2.357251397762161\n",
            "Total de pasos: 2997601/3000000.0 - Recompensa: -0.43125317375374717\n",
            "Total de pasos: 2997602/3000000.0 - Recompensa: -1.2084820821854216\n",
            "Total de pasos: 2997603/3000000.0 - Recompensa: -0.3738432999728505\n",
            "Total de pasos: 2997604/3000000.0 - Recompensa: -1.386927224426191\n",
            "Total de pasos: 2997605/3000000.0 - Recompensa: -2.9395235725212974\n",
            "Total de pasos: 2997606/3000000.0 - Recompensa: -0.6106857349820352\n",
            "Total de pasos: 2997607/3000000.0 - Recompensa: -1.4672658660534796\n",
            "Total de pasos: 2997608/3000000.0 - Recompensa: -1.332843861234977\n",
            "Total de pasos: 2997609/3000000.0 - Recompensa: 0.5539159742268545\n",
            "0.5539159742268545\n",
            "Total de pasos: 2997610/3000000.0 - Recompensa: -1.6990780433485133\n",
            "Total de pasos: 2997611/3000000.0 - Recompensa: -0.35321861660863485\n",
            "Total de pasos: 2997612/3000000.0 - Recompensa: -2.8523270542522066\n",
            "Total de pasos: 2997613/3000000.0 - Recompensa: -0.6850278890838684\n",
            "Total de pasos: 2997614/3000000.0 - Recompensa: -0.3658564658665945\n",
            "Total de pasos: 2997615/3000000.0 - Recompensa: -1.5852788097507862\n",
            "Total de pasos: 2997616/3000000.0 - Recompensa: -0.7696064722014777\n",
            "Total de pasos: 2997617/3000000.0 - Recompensa: -1.2278550298572384\n",
            "Total de pasos: 2997618/3000000.0 - Recompensa: 0.2823404641261972\n",
            "0.2823404641261972\n",
            "Total de pasos: 2997619/3000000.0 - Recompensa: -1.9750320261678436\n",
            "Total de pasos: 2997620/3000000.0 - Recompensa: -0.40858066927975434\n",
            "Total de pasos: 2997621/3000000.0 - Recompensa: -0.6369744149206733\n",
            "Total de pasos: 2997622/3000000.0 - Recompensa: -1.1593771373745292\n",
            "Total de pasos: 2997623/3000000.0 - Recompensa: -2.387282818506649\n",
            "Total de pasos: 2997624/3000000.0 - Recompensa: -0.5747198824697958\n",
            "Total de pasos: 2997625/3000000.0 - Recompensa: -4.263833893859234\n",
            "Total de pasos: 2997626/3000000.0 - Recompensa: -1.9459921181163116\n",
            "Total de pasos: 2997627/3000000.0 - Recompensa: -1.0484640769686293\n",
            "Total de pasos: 2997628/3000000.0 - Recompensa: -2.0048565282841495\n",
            "Total de pasos: 2997629/3000000.0 - Recompensa: -1.0355379272346885\n",
            "Total de pasos: 2997630/3000000.0 - Recompensa: -0.1792947685531842\n",
            "Total de pasos: 2997631/3000000.0 - Recompensa: -2.0679384602168023\n",
            "Total de pasos: 2997632/3000000.0 - Recompensa: -0.2823683072896957\n",
            "Total de pasos: 2997633/3000000.0 - Recompensa: -1.8926317365197685\n",
            "Total de pasos: 2997634/3000000.0 - Recompensa: 0.242643733758924\n",
            "0.242643733758924\n",
            "Total de pasos: 2997635/3000000.0 - Recompensa: -1.2329019123736853\n",
            "Total de pasos: 2997636/3000000.0 - Recompensa: -0.6029886180191942\n",
            "Total de pasos: 2997637/3000000.0 - Recompensa: -0.09279111685905878\n",
            "Total de pasos: 2997638/3000000.0 - Recompensa: -1.410209567311255\n",
            "Total de pasos: 2997639/3000000.0 - Recompensa: -0.009300529548091602\n",
            "Total de pasos: 2997640/3000000.0 - Recompensa: 0.867958480428726\n",
            "0.867958480428726\n",
            "Total de pasos: 2997641/3000000.0 - Recompensa: -0.12016701488882986\n",
            "Total de pasos: 2997642/3000000.0 - Recompensa: -0.6209843369664155\n",
            "Total de pasos: 2997643/3000000.0 - Recompensa: -1.3814194748490154\n",
            "Total de pasos: 2997644/3000000.0 - Recompensa: 0.44257045114892646\n",
            "0.44257045114892646\n",
            "Total de pasos: 2997645/3000000.0 - Recompensa: -0.7775544417390601\n",
            "Total de pasos: 2997646/3000000.0 - Recompensa: -1.4378524354022866\n",
            "Total de pasos: 2997647/3000000.0 - Recompensa: 0.014077498384788167\n",
            "0.014077498384788167\n",
            "Total de pasos: 2997648/3000000.0 - Recompensa: 0.012973104702241167\n",
            "0.012973104702241167\n",
            "Total de pasos: 2997649/3000000.0 - Recompensa: -0.5629407593382679\n",
            "Total de pasos: 2997650/3000000.0 - Recompensa: -0.9409067846270357\n",
            "Total de pasos: 2997651/3000000.0 - Recompensa: 0.08633255177198684\n",
            "0.08633255177198684\n",
            "Total de pasos: 2997652/3000000.0 - Recompensa: -0.8481797050297905\n",
            "Total de pasos: 2997653/3000000.0 - Recompensa: -2.4878233885631182\n",
            "Total de pasos: 2997654/3000000.0 - Recompensa: -0.5190334966358193\n",
            "Total de pasos: 2997655/3000000.0 - Recompensa: -0.029342952421835294\n",
            "Total de pasos: 2997656/3000000.0 - Recompensa: -2.0269524889465886\n",
            "Total de pasos: 2997657/3000000.0 - Recompensa: 0.24843148114888933\n",
            "0.24843148114888933\n",
            "Total de pasos: 2997658/3000000.0 - Recompensa: -0.33061502676969196\n",
            "Total de pasos: 2997659/3000000.0 - Recompensa: -2.0673475945685205\n",
            "Total de pasos: 2997660/3000000.0 - Recompensa: -1.2162828244674542\n",
            "Total de pasos: 2997661/3000000.0 - Recompensa: -0.12001909261093058\n",
            "Total de pasos: 2997662/3000000.0 - Recompensa: -0.18986212796239782\n",
            "Total de pasos: 2997663/3000000.0 - Recompensa: 0.3303758527397109\n",
            "0.3303758527397109\n",
            "Total de pasos: 2997664/3000000.0 - Recompensa: -0.7828772495227405\n",
            "Total de pasos: 2997665/3000000.0 - Recompensa: -0.19234047261865142\n",
            "Total de pasos: 2997666/3000000.0 - Recompensa: -0.9541621121702724\n",
            "Total de pasos: 2997667/3000000.0 - Recompensa: -0.734677028027716\n",
            "Total de pasos: 2997668/3000000.0 - Recompensa: -1.3377781483559694\n",
            "Total de pasos: 2997669/3000000.0 - Recompensa: 0.3164165268773903\n",
            "0.3164165268773903\n",
            "Total de pasos: 2997670/3000000.0 - Recompensa: -0.6345549386135481\n",
            "Total de pasos: 2997671/3000000.0 - Recompensa: -0.8982687795930333\n",
            "Total de pasos: 2997672/3000000.0 - Recompensa: -1.3196760055985022\n",
            "Total de pasos: 2997673/3000000.0 - Recompensa: -3.0069242709815955\n",
            "Total de pasos: 2997674/3000000.0 - Recompensa: 1.2058698625415947\n",
            "1.2058698625415947\n",
            "Total de pasos: 2997675/3000000.0 - Recompensa: -0.667882694551117\n",
            "Total de pasos: 2997676/3000000.0 - Recompensa: -0.2067824600639149\n",
            "Total de pasos: 2997677/3000000.0 - Recompensa: -2.0350196087212487\n",
            "Total de pasos: 2997678/3000000.0 - Recompensa: 0.14310394266913792\n",
            "0.14310394266913792\n",
            "Total de pasos: 2997679/3000000.0 - Recompensa: -0.9049386884893739\n",
            "Total de pasos: 2997680/3000000.0 - Recompensa: -0.4096038521277351\n",
            "Total de pasos: 2997681/3000000.0 - Recompensa: 0.6268771851651483\n",
            "0.6268771851651483\n",
            "Total de pasos: 2997682/3000000.0 - Recompensa: -1.6222421182731208\n",
            "Total de pasos: 2997683/3000000.0 - Recompensa: -2.1603270358740176\n",
            "Total de pasos: 2997684/3000000.0 - Recompensa: -0.4484304306617858\n",
            "Total de pasos: 2997685/3000000.0 - Recompensa: -0.007873310035863945\n",
            "Total de pasos: 2997686/3000000.0 - Recompensa: -0.585532593456428\n",
            "Total de pasos: 2997687/3000000.0 - Recompensa: -0.8795659070341849\n",
            "Total de pasos: 2997688/3000000.0 - Recompensa: 0.22894850849961879\n",
            "0.22894850849961879\n",
            "Total de pasos: 2997689/3000000.0 - Recompensa: -2.1198909831822395\n",
            "Total de pasos: 2997690/3000000.0 - Recompensa: -2.1590579550064546\n",
            "Total de pasos: 2997691/3000000.0 - Recompensa: 0.3366914303375972\n",
            "0.3366914303375972\n",
            "Total de pasos: 2997692/3000000.0 - Recompensa: -1.5283486790922325\n",
            "Total de pasos: 2997693/3000000.0 - Recompensa: -0.6633639660210754\n",
            "Total de pasos: 2997694/3000000.0 - Recompensa: -0.5092388448144074\n",
            "Total de pasos: 2997695/3000000.0 - Recompensa: -0.16849718491098056\n",
            "Total de pasos: 2997696/3000000.0 - Recompensa: -1.641151672714377\n",
            "Total de pasos: 2997697/3000000.0 - Recompensa: 0.30451057009505356\n",
            "0.30451057009505356\n",
            "Total de pasos: 2997698/3000000.0 - Recompensa: -1.8911125790074594\n",
            "Total de pasos: 2997699/3000000.0 - Recompensa: -1.162778058562916\n",
            "Total de pasos: 2997700/3000000.0 - Recompensa: -1.8473988142732471\n",
            "Total de pasos: 2997701/3000000.0 - Recompensa: -0.9568167404380538\n",
            "Total de pasos: 2997702/3000000.0 - Recompensa: -1.5613504129483102\n",
            "Total de pasos: 2997703/3000000.0 - Recompensa: 0.514153308245858\n",
            "0.514153308245858\n",
            "Total de pasos: 2997704/3000000.0 - Recompensa: -1.040970803283424\n",
            "Total de pasos: 2997705/3000000.0 - Recompensa: -1.0752642748753392\n",
            "Total de pasos: 2997706/3000000.0 - Recompensa: -0.49028671787652056\n",
            "Total de pasos: 2997707/3000000.0 - Recompensa: -1.1352665097956622\n",
            "Total de pasos: 2997708/3000000.0 - Recompensa: -1.0355272938556033\n",
            "Total de pasos: 2997709/3000000.0 - Recompensa: -0.05779407672221898\n",
            "Total de pasos: 2997710/3000000.0 - Recompensa: 0.5635357724273035\n",
            "0.5635357724273035\n",
            "Total de pasos: 2997711/3000000.0 - Recompensa: -3.7451380725047114\n",
            "Total de pasos: 2997712/3000000.0 - Recompensa: 0.21605009768909386\n",
            "0.21605009768909386\n",
            "Total de pasos: 2997713/3000000.0 - Recompensa: -0.09127391141623789\n",
            "Total de pasos: 2997714/3000000.0 - Recompensa: -2.335071800673975\n",
            "Total de pasos: 2997715/3000000.0 - Recompensa: -0.05153339755682876\n",
            "Total de pasos: 2997716/3000000.0 - Recompensa: -0.29157679964529915\n",
            "Total de pasos: 2997717/3000000.0 - Recompensa: 0.12930534977985503\n",
            "0.12930534977985503\n",
            "Total de pasos: 2997718/3000000.0 - Recompensa: -1.3921751130509394\n",
            "Total de pasos: 2997719/3000000.0 - Recompensa: -0.29844640380306797\n",
            "Total de pasos: 2997720/3000000.0 - Recompensa: -2.091101840015211\n",
            "Total de pasos: 2997721/3000000.0 - Recompensa: -1.1490203818178912\n",
            "Total de pasos: 2997722/3000000.0 - Recompensa: -1.2565885652500806\n",
            "Total de pasos: 2997723/3000000.0 - Recompensa: -0.009072002901371612\n",
            "Total de pasos: 2997724/3000000.0 - Recompensa: -0.7035750726274068\n",
            "Total de pasos: 2997725/3000000.0 - Recompensa: -2.0041578998840754\n",
            "Total de pasos: 2997726/3000000.0 - Recompensa: -1.1721428108117693\n",
            "Total de pasos: 2997727/3000000.0 - Recompensa: 0.0030731793263293894\n",
            "0.0030731793263293894\n",
            "Total de pasos: 2997728/3000000.0 - Recompensa: 0.18529143219177624\n",
            "0.18529143219177624\n",
            "Total de pasos: 2997729/3000000.0 - Recompensa: -0.6000215292622356\n",
            "Total de pasos: 2997730/3000000.0 - Recompensa: -6.716136413756882\n",
            "Total de pasos: 2997731/3000000.0 - Recompensa: -2.133163256510984\n",
            "Total de pasos: 2997732/3000000.0 - Recompensa: -0.416965747630749\n",
            "Total de pasos: 2997733/3000000.0 - Recompensa: 0.14529126583227486\n",
            "0.14529126583227486\n",
            "Total de pasos: 2997734/3000000.0 - Recompensa: -0.06669589076198404\n",
            "Total de pasos: 2997735/3000000.0 - Recompensa: -0.5095272062266261\n",
            "Total de pasos: 2997736/3000000.0 - Recompensa: -1.608695705906796\n",
            "Total de pasos: 2997737/3000000.0 - Recompensa: -0.502085493782298\n",
            "Total de pasos: 2997738/3000000.0 - Recompensa: 0.40682616273602845\n",
            "0.40682616273602845\n",
            "Total de pasos: 2997739/3000000.0 - Recompensa: 1.260280892505184\n",
            "1.260280892505184\n",
            "Total de pasos: 2997740/3000000.0 - Recompensa: -1.156963682993661\n",
            "Total de pasos: 2997741/3000000.0 - Recompensa: 0.9235894198346727\n",
            "0.9235894198346727\n",
            "Total de pasos: 2997742/3000000.0 - Recompensa: -0.5445229167832506\n",
            "Total de pasos: 2997743/3000000.0 - Recompensa: -0.7082634042249704\n",
            "Total de pasos: 2997744/3000000.0 - Recompensa: -1.3905949715119224\n",
            "Total de pasos: 2997745/3000000.0 - Recompensa: 0.0583111515858413\n",
            "0.0583111515858413\n",
            "Total de pasos: 2997746/3000000.0 - Recompensa: -1.6862267395415167\n",
            "Total de pasos: 2997747/3000000.0 - Recompensa: -0.13712694255233152\n",
            "Total de pasos: 2997748/3000000.0 - Recompensa: -0.44769244444747464\n",
            "Total de pasos: 2997749/3000000.0 - Recompensa: -1.7621700714755524\n",
            "Total de pasos: 2997750/3000000.0 - Recompensa: 0.2464766049313109\n",
            "0.2464766049313109\n",
            "Total de pasos: 2997751/3000000.0 - Recompensa: 0.41463354174893063\n",
            "0.41463354174893063\n",
            "Total de pasos: 2997752/3000000.0 - Recompensa: -2.2181750352420138\n",
            "Total de pasos: 2997753/3000000.0 - Recompensa: -1.3052069920016391\n",
            "Total de pasos: 2997754/3000000.0 - Recompensa: -0.09081959388162147\n",
            "Total de pasos: 2997755/3000000.0 - Recompensa: -0.5020175034100788\n",
            "Total de pasos: 2997756/3000000.0 - Recompensa: -1.1839879907774744\n",
            "Total de pasos: 2997757/3000000.0 - Recompensa: -0.6309501479375312\n",
            "Total de pasos: 2997758/3000000.0 - Recompensa: -0.6564084657883973\n",
            "Total de pasos: 2997759/3000000.0 - Recompensa: -1.5953872178555877\n",
            "Total de pasos: 2997760/3000000.0 - Recompensa: -1.6268889352293718\n",
            "Total de pasos: 2997761/3000000.0 - Recompensa: -0.614987600007811\n",
            "Total de pasos: 2997762/3000000.0 - Recompensa: -2.055987070646139\n",
            "Total de pasos: 2997763/3000000.0 - Recompensa: -0.8415488387052286\n",
            "Total de pasos: 2997764/3000000.0 - Recompensa: -0.5310484234062758\n",
            "Total de pasos: 2997765/3000000.0 - Recompensa: -1.595121222805947\n",
            "Total de pasos: 2997766/3000000.0 - Recompensa: 0.413573774418894\n",
            "0.413573774418894\n",
            "Total de pasos: 2997767/3000000.0 - Recompensa: 0.9878693246680126\n",
            "0.9878693246680126\n",
            "Total de pasos: 2997768/3000000.0 - Recompensa: 0.5230893269725845\n",
            "0.5230893269725845\n",
            "Total de pasos: 2997769/3000000.0 - Recompensa: -1.352422981718759\n",
            "Total de pasos: 2997770/3000000.0 - Recompensa: 0.3113486638318143\n",
            "0.3113486638318143\n",
            "Total de pasos: 2997771/3000000.0 - Recompensa: -1.191919589609109\n",
            "Total de pasos: 2997772/3000000.0 - Recompensa: -0.10809591233269611\n",
            "Total de pasos: 2997773/3000000.0 - Recompensa: -0.4199463182300618\n",
            "Total de pasos: 2997774/3000000.0 - Recompensa: -0.5211382852289852\n",
            "Total de pasos: 2997775/3000000.0 - Recompensa: 0.3427464885689357\n",
            "0.3427464885689357\n",
            "Total de pasos: 2997776/3000000.0 - Recompensa: 0.05116212771453629\n",
            "0.05116212771453629\n",
            "Total de pasos: 2997777/3000000.0 - Recompensa: 0.299939070729598\n",
            "0.299939070729598\n",
            "Total de pasos: 2997778/3000000.0 - Recompensa: -1.1549647100701022\n",
            "Total de pasos: 2997779/3000000.0 - Recompensa: -1.6215768072083798\n",
            "Total de pasos: 2997780/3000000.0 - Recompensa: -1.1654768284833719\n",
            "Total de pasos: 2997781/3000000.0 - Recompensa: 0.09378339008431252\n",
            "0.09378339008431252\n",
            "Total de pasos: 2997782/3000000.0 - Recompensa: -0.6614405418852053\n",
            "Total de pasos: 2997783/3000000.0 - Recompensa: -0.17582259794946414\n",
            "Total de pasos: 2997784/3000000.0 - Recompensa: -0.005586528530136331\n",
            "Total de pasos: 2997785/3000000.0 - Recompensa: -5.525693009076761\n",
            "Total de pasos: 2997786/3000000.0 - Recompensa: 0.10907282405612792\n",
            "0.10907282405612792\n",
            "Total de pasos: 2997787/3000000.0 - Recompensa: -0.5996353022930763\n",
            "Total de pasos: 2997788/3000000.0 - Recompensa: -1.3953266100925652\n",
            "Total de pasos: 2997789/3000000.0 - Recompensa: -5.492931293429185\n",
            "Total de pasos: 2997790/3000000.0 - Recompensa: -0.9624309030792374\n",
            "Total de pasos: 2997791/3000000.0 - Recompensa: -1.5086926179740494\n",
            "Total de pasos: 2997792/3000000.0 - Recompensa: -1.763835449390205\n",
            "Total de pasos: 2997793/3000000.0 - Recompensa: -0.226652601777125\n",
            "Total de pasos: 2997794/3000000.0 - Recompensa: -1.116952611980015\n",
            "Total de pasos: 2997795/3000000.0 - Recompensa: -2.9047836489533627\n",
            "Total de pasos: 2997796/3000000.0 - Recompensa: -0.19763648254761748\n",
            "Total de pasos: 2997797/3000000.0 - Recompensa: 0.8758525623255788\n",
            "0.8758525623255788\n",
            "Total de pasos: 2997798/3000000.0 - Recompensa: -2.3831854648321507\n",
            "Total de pasos: 2997799/3000000.0 - Recompensa: 1.335866658381482\n",
            "1.335866658381482\n",
            "Total de pasos: 2997800/3000000.0 - Recompensa: -1.1931602702071182\n",
            "Total de pasos: 2997801/3000000.0 - Recompensa: 0.3220098301156315\n",
            "0.3220098301156315\n",
            "Total de pasos: 2997802/3000000.0 - Recompensa: -0.13677774024867362\n",
            "Total de pasos: 2997803/3000000.0 - Recompensa: -0.603774500869504\n",
            "Total de pasos: 2997804/3000000.0 - Recompensa: -0.07208020180144131\n",
            "Total de pasos: 2997805/3000000.0 - Recompensa: -0.9299191213964594\n",
            "Total de pasos: 2997806/3000000.0 - Recompensa: -1.1921972063402217\n",
            "Total de pasos: 2997807/3000000.0 - Recompensa: 0.3487679550727346\n",
            "0.3487679550727346\n",
            "Total de pasos: 2997808/3000000.0 - Recompensa: -1.5667666986717905\n",
            "Total de pasos: 2997809/3000000.0 - Recompensa: -0.37519419389660225\n",
            "Total de pasos: 2997810/3000000.0 - Recompensa: -2.432031405593486\n",
            "Total de pasos: 2997811/3000000.0 - Recompensa: -0.3809318943741501\n",
            "Total de pasos: 2997812/3000000.0 - Recompensa: -0.011482591771368927\n",
            "Total de pasos: 2997813/3000000.0 - Recompensa: -0.4412521762360333\n",
            "Total de pasos: 2997814/3000000.0 - Recompensa: 0.21651377202324124\n",
            "0.21651377202324124\n",
            "Total de pasos: 2997815/3000000.0 - Recompensa: -1.4119887287619037\n",
            "Total de pasos: 2997816/3000000.0 - Recompensa: 0.9718433352452702\n",
            "0.9718433352452702\n",
            "Total de pasos: 2997817/3000000.0 - Recompensa: -3.105945143902801\n",
            "Total de pasos: 2997818/3000000.0 - Recompensa: -1.1569062139752093\n",
            "Total de pasos: 2997819/3000000.0 - Recompensa: -0.8190485472452689\n",
            "Total de pasos: 2997820/3000000.0 - Recompensa: -1.527149107288144\n",
            "Total de pasos: 2997821/3000000.0 - Recompensa: -0.5483682178900231\n",
            "Total de pasos: 2997822/3000000.0 - Recompensa: -1.6384372294682759\n",
            "Total de pasos: 2997823/3000000.0 - Recompensa: -0.35904671815390793\n",
            "Total de pasos: 2997824/3000000.0 - Recompensa: -1.6737455386875888\n",
            "Total de pasos: 2997825/3000000.0 - Recompensa: -0.6104328812466975\n",
            "Total de pasos: 2997826/3000000.0 - Recompensa: -0.2826314020831572\n",
            "Total de pasos: 2997827/3000000.0 - Recompensa: 0.22317227857689764\n",
            "0.22317227857689764\n",
            "Total de pasos: 2997828/3000000.0 - Recompensa: -1.1747236856421173\n",
            "Total de pasos: 2997829/3000000.0 - Recompensa: 0.7840886898169179\n",
            "0.7840886898169179\n",
            "Total de pasos: 2997830/3000000.0 - Recompensa: -1.2566161602000752\n",
            "Total de pasos: 2997831/3000000.0 - Recompensa: -0.45941577864401745\n",
            "Total de pasos: 2997832/3000000.0 - Recompensa: -0.13435381557796422\n",
            "Total de pasos: 2997833/3000000.0 - Recompensa: -2.1102745961667417\n",
            "Total de pasos: 2997834/3000000.0 - Recompensa: -0.8677903800507802\n",
            "Total de pasos: 2997835/3000000.0 - Recompensa: -1.2448173327133736\n",
            "Total de pasos: 2997836/3000000.0 - Recompensa: 0.061590374500106904\n",
            "0.061590374500106904\n",
            "Total de pasos: 2997837/3000000.0 - Recompensa: -0.37722646746451877\n",
            "Total de pasos: 2997838/3000000.0 - Recompensa: 0.13483158756739985\n",
            "0.13483158756739985\n",
            "Total de pasos: 2997839/3000000.0 - Recompensa: -0.22662077086779525\n",
            "Total de pasos: 2997840/3000000.0 - Recompensa: 0.04069245615309408\n",
            "0.04069245615309408\n",
            "Total de pasos: 2997841/3000000.0 - Recompensa: -0.4738397293298389\n",
            "Total de pasos: 2997842/3000000.0 - Recompensa: 0.07497709990197618\n",
            "0.07497709990197618\n",
            "Total de pasos: 2997843/3000000.0 - Recompensa: -0.7861730518354644\n",
            "Total de pasos: 2997844/3000000.0 - Recompensa: -0.5844764634094914\n",
            "Total de pasos: 2997845/3000000.0 - Recompensa: -2.3726650365391877\n",
            "Total de pasos: 2997846/3000000.0 - Recompensa: -0.8888420859578166\n",
            "Total de pasos: 2997847/3000000.0 - Recompensa: -0.5712636246921148\n",
            "Total de pasos: 2997848/3000000.0 - Recompensa: -0.8399858519664275\n",
            "Total de pasos: 2997849/3000000.0 - Recompensa: -1.8509509273755425\n",
            "Total de pasos: 2997850/3000000.0 - Recompensa: 0.28062179575854984\n",
            "0.28062179575854984\n",
            "Total de pasos: 2997851/3000000.0 - Recompensa: -0.7863176798183991\n",
            "Total de pasos: 2997852/3000000.0 - Recompensa: -1.4763188004712806\n",
            "Total de pasos: 2997853/3000000.0 - Recompensa: -0.46137168304742004\n",
            "Total de pasos: 2997854/3000000.0 - Recompensa: -0.4939504955717003\n",
            "Total de pasos: 2997855/3000000.0 - Recompensa: -0.6151567168518851\n",
            "Total de pasos: 2997856/3000000.0 - Recompensa: 0.2998557041817948\n",
            "0.2998557041817948\n",
            "Total de pasos: 2997857/3000000.0 - Recompensa: 0.05807256812702799\n",
            "0.05807256812702799\n",
            "Total de pasos: 2997858/3000000.0 - Recompensa: -0.6332251691839879\n",
            "Total de pasos: 2997859/3000000.0 - Recompensa: -0.31921049713185773\n",
            "Total de pasos: 2997860/3000000.0 - Recompensa: -2.6587895157820824\n",
            "Total de pasos: 2997861/3000000.0 - Recompensa: -2.61518183297987\n",
            "Total de pasos: 2997862/3000000.0 - Recompensa: -1.6868058301748994\n",
            "Total de pasos: 2997863/3000000.0 - Recompensa: -0.3491496440769251\n",
            "Total de pasos: 2997864/3000000.0 - Recompensa: 0.3404992609478795\n",
            "0.3404992609478795\n",
            "Total de pasos: 2997865/3000000.0 - Recompensa: -0.9031082234079285\n",
            "Total de pasos: 2997866/3000000.0 - Recompensa: 0.4731063938962636\n",
            "0.4731063938962636\n",
            "Total de pasos: 2997867/3000000.0 - Recompensa: -1.176097602371006\n",
            "Total de pasos: 2997868/3000000.0 - Recompensa: 0.8949274673447287\n",
            "0.8949274673447287\n",
            "Total de pasos: 2997869/3000000.0 - Recompensa: -3.5033636445854563\n",
            "Total de pasos: 2997870/3000000.0 - Recompensa: -0.567632273058895\n",
            "Total de pasos: 2997871/3000000.0 - Recompensa: 0.6960608645629874\n",
            "0.6960608645629874\n",
            "Total de pasos: 2997872/3000000.0 - Recompensa: -1.54147234768496\n",
            "Total de pasos: 2997873/3000000.0 - Recompensa: 0.05271530721991877\n",
            "0.05271530721991877\n",
            "Total de pasos: 2997874/3000000.0 - Recompensa: 0.2801057988325092\n",
            "0.2801057988325092\n",
            "Total de pasos: 2997875/3000000.0 - Recompensa: 0.2721229007979004\n",
            "0.2721229007979004\n",
            "Total de pasos: 2997876/3000000.0 - Recompensa: 0.7479431393201397\n",
            "0.7479431393201397\n",
            "Total de pasos: 2997877/3000000.0 - Recompensa: -0.6482696056203232\n",
            "Total de pasos: 2997878/3000000.0 - Recompensa: -0.26845028269113663\n",
            "Total de pasos: 2997879/3000000.0 - Recompensa: -0.6028481616427883\n",
            "Total de pasos: 2997880/3000000.0 - Recompensa: -1.3634844541465512\n",
            "Total de pasos: 2997881/3000000.0 - Recompensa: -1.6708915981771975\n",
            "Total de pasos: 2997882/3000000.0 - Recompensa: -1.0007108647948932\n",
            "Total de pasos: 2997883/3000000.0 - Recompensa: 0.9944921938397231\n",
            "0.9944921938397231\n",
            "Total de pasos: 2997884/3000000.0 - Recompensa: -1.9370525335270505\n",
            "Total de pasos: 2997885/3000000.0 - Recompensa: 0.17635949980927\n",
            "0.17635949980927\n",
            "Total de pasos: 2997886/3000000.0 - Recompensa: -0.2357279758360072\n",
            "Total de pasos: 2997887/3000000.0 - Recompensa: 0.522341417760032\n",
            "0.522341417760032\n",
            "Total de pasos: 2997888/3000000.0 - Recompensa: -1.8197091812267048\n",
            "Total de pasos: 2997889/3000000.0 - Recompensa: -0.05664456015111377\n",
            "Total de pasos: 2997890/3000000.0 - Recompensa: -0.8785057051549006\n",
            "Total de pasos: 2997891/3000000.0 - Recompensa: -0.7188503596786208\n",
            "Total de pasos: 2997892/3000000.0 - Recompensa: -1.3409527899972409\n",
            "Total de pasos: 2997893/3000000.0 - Recompensa: -1.3254700515871687\n",
            "Total de pasos: 2997894/3000000.0 - Recompensa: 0.34230171022902484\n",
            "0.34230171022902484\n",
            "Total de pasos: 2997895/3000000.0 - Recompensa: 0.3512766475940245\n",
            "0.3512766475940245\n",
            "Total de pasos: 2997896/3000000.0 - Recompensa: -0.25419770062906843\n",
            "Total de pasos: 2997897/3000000.0 - Recompensa: -2.0808719711425323\n",
            "Total de pasos: 2997898/3000000.0 - Recompensa: -0.2718940657942051\n",
            "Total de pasos: 2997899/3000000.0 - Recompensa: -0.3707321264969455\n",
            "Total de pasos: 2997900/3000000.0 - Recompensa: -0.8630709976302622\n",
            "Total de pasos: 2997901/3000000.0 - Recompensa: -2.6493859040899372\n",
            "Total de pasos: 2997902/3000000.0 - Recompensa: 0.20944908542590474\n",
            "0.20944908542590474\n",
            "Total de pasos: 2997903/3000000.0 - Recompensa: -1.8493644655175108\n",
            "Total de pasos: 2997904/3000000.0 - Recompensa: -3.612731336848791\n",
            "Total de pasos: 2997905/3000000.0 - Recompensa: 0.10504117410060632\n",
            "0.10504117410060632\n",
            "Total de pasos: 2997906/3000000.0 - Recompensa: -0.5654598314834034\n",
            "Total de pasos: 2997907/3000000.0 - Recompensa: -1.5805310019966707\n",
            "Total de pasos: 2997908/3000000.0 - Recompensa: -0.3359954244180202\n",
            "Total de pasos: 2997909/3000000.0 - Recompensa: -1.4849815936501383\n",
            "Total de pasos: 2997910/3000000.0 - Recompensa: 0.5338872537660694\n",
            "0.5338872537660694\n",
            "Total de pasos: 2997911/3000000.0 - Recompensa: -0.40624040581614135\n",
            "Total de pasos: 2997912/3000000.0 - Recompensa: 0.41346533388029044\n",
            "0.41346533388029044\n",
            "Total de pasos: 2997913/3000000.0 - Recompensa: -0.9627364021426497\n",
            "Total de pasos: 2997914/3000000.0 - Recompensa: -0.8664126189926649\n",
            "Total de pasos: 2997915/3000000.0 - Recompensa: -0.7411291636304166\n",
            "Total de pasos: 2997916/3000000.0 - Recompensa: -2.2748107785516134\n",
            "Total de pasos: 2997917/3000000.0 - Recompensa: -0.784838659550789\n",
            "Total de pasos: 2997918/3000000.0 - Recompensa: -1.1270271225510475\n",
            "Total de pasos: 2997919/3000000.0 - Recompensa: 0.6821627676962568\n",
            "0.6821627676962568\n",
            "Total de pasos: 2997920/3000000.0 - Recompensa: -1.2639895346017331\n",
            "Total de pasos: 2997921/3000000.0 - Recompensa: -0.22436647382445934\n",
            "Total de pasos: 2997922/3000000.0 - Recompensa: 1.13189500549206\n",
            "1.13189500549206\n",
            "Total de pasos: 2997923/3000000.0 - Recompensa: -2.6555166050910994\n",
            "Total de pasos: 2997924/3000000.0 - Recompensa: 0.2255541992544951\n",
            "0.2255541992544951\n",
            "Total de pasos: 2997925/3000000.0 - Recompensa: 0.7452188800149043\n",
            "0.7452188800149043\n",
            "Total de pasos: 2997926/3000000.0 - Recompensa: -2.244620403233221\n",
            "Total de pasos: 2997927/3000000.0 - Recompensa: -1.8778760596625605\n",
            "Total de pasos: 2997928/3000000.0 - Recompensa: -2.9323543351175236\n",
            "Total de pasos: 2997929/3000000.0 - Recompensa: -0.1731915195646419\n",
            "Total de pasos: 2997930/3000000.0 - Recompensa: -0.5460130705231337\n",
            "Total de pasos: 2997931/3000000.0 - Recompensa: -1.3162226125617014\n",
            "Total de pasos: 2997932/3000000.0 - Recompensa: -2.146863733453238\n",
            "Total de pasos: 2997933/3000000.0 - Recompensa: -0.833283497910547\n",
            "Total de pasos: 2997934/3000000.0 - Recompensa: -0.03346577803403111\n",
            "Total de pasos: 2997935/3000000.0 - Recompensa: -0.2300174603523935\n",
            "Total de pasos: 2997936/3000000.0 - Recompensa: -0.7020309842893643\n",
            "Total de pasos: 2997937/3000000.0 - Recompensa: -0.18853874329531975\n",
            "Total de pasos: 2997938/3000000.0 - Recompensa: 0.024115200363224287\n",
            "0.024115200363224287\n",
            "Total de pasos: 2997939/3000000.0 - Recompensa: -0.6824151852824988\n",
            "Total de pasos: 2997940/3000000.0 - Recompensa: -1.2822498096762132\n",
            "Total de pasos: 2997941/3000000.0 - Recompensa: -5.255989494825572\n",
            "Total de pasos: 2997942/3000000.0 - Recompensa: -0.010188311655608129\n",
            "Total de pasos: 2997943/3000000.0 - Recompensa: 0.05838550050253599\n",
            "0.05838550050253599\n",
            "Total de pasos: 2997944/3000000.0 - Recompensa: -1.194940324129313\n",
            "Total de pasos: 2997945/3000000.0 - Recompensa: 0.025859945133219625\n",
            "0.025859945133219625\n",
            "Total de pasos: 2997946/3000000.0 - Recompensa: -0.6084247924727646\n",
            "Total de pasos: 2997947/3000000.0 - Recompensa: -0.4320337039342371\n",
            "Total de pasos: 2997948/3000000.0 - Recompensa: 0.15347944950784406\n",
            "0.15347944950784406\n",
            "Total de pasos: 2997949/3000000.0 - Recompensa: -1.8181833625400574\n",
            "Total de pasos: 2997950/3000000.0 - Recompensa: -1.1194418930528662\n",
            "Total de pasos: 2997951/3000000.0 - Recompensa: -1.0552584164344354\n",
            "Total de pasos: 2997952/3000000.0 - Recompensa: -1.2627149101425428\n",
            "Total de pasos: 2997953/3000000.0 - Recompensa: -1.3068582497910606\n",
            "Total de pasos: 2997954/3000000.0 - Recompensa: -0.5825834566488054\n",
            "Total de pasos: 2997955/3000000.0 - Recompensa: -0.8186046055918988\n",
            "Total de pasos: 2997956/3000000.0 - Recompensa: -1.3565658046802005\n",
            "Total de pasos: 2997957/3000000.0 - Recompensa: -0.04373508232859186\n",
            "Total de pasos: 2997958/3000000.0 - Recompensa: -0.28627168616458515\n",
            "Total de pasos: 2997959/3000000.0 - Recompensa: -0.37262898705931696\n",
            "Total de pasos: 2997960/3000000.0 - Recompensa: -0.23826123121591314\n",
            "Total de pasos: 2997961/3000000.0 - Recompensa: -1.1867619589321001\n",
            "Total de pasos: 2997962/3000000.0 - Recompensa: -0.6207308305846873\n",
            "Total de pasos: 2997963/3000000.0 - Recompensa: -0.23059174214936676\n",
            "Total de pasos: 2997964/3000000.0 - Recompensa: -2.845212484089749\n",
            "Total de pasos: 2997965/3000000.0 - Recompensa: -0.4988245921850905\n",
            "Total de pasos: 2997966/3000000.0 - Recompensa: -0.13250871419622184\n",
            "Total de pasos: 2997967/3000000.0 - Recompensa: -0.8193586432412137\n",
            "Total de pasos: 2997968/3000000.0 - Recompensa: 0.12531939035976508\n",
            "0.12531939035976508\n",
            "Total de pasos: 2997969/3000000.0 - Recompensa: -0.5054975802086571\n",
            "Total de pasos: 2997970/3000000.0 - Recompensa: -0.23797912834520157\n",
            "Total de pasos: 2997971/3000000.0 - Recompensa: -0.0712290641159751\n",
            "Total de pasos: 2997972/3000000.0 - Recompensa: -0.3495400388732848\n",
            "Total de pasos: 2997973/3000000.0 - Recompensa: 0.11956279460872782\n",
            "0.11956279460872782\n",
            "Total de pasos: 2997974/3000000.0 - Recompensa: -3.050743119753628\n",
            "Total de pasos: 2997975/3000000.0 - Recompensa: -3.049026240467784\n",
            "Total de pasos: 2997976/3000000.0 - Recompensa: -1.2044552864936393\n",
            "Total de pasos: 2997977/3000000.0 - Recompensa: 0.49312923076874265\n",
            "0.49312923076874265\n",
            "Total de pasos: 2997978/3000000.0 - Recompensa: -1.2925725330061815\n",
            "Total de pasos: 2997979/3000000.0 - Recompensa: 0.2041299902437462\n",
            "0.2041299902437462\n",
            "Total de pasos: 2997980/3000000.0 - Recompensa: -0.1160328331711559\n",
            "Total de pasos: 2997981/3000000.0 - Recompensa: -3.151238186170274\n",
            "Total de pasos: 2997982/3000000.0 - Recompensa: -0.020056672973134237\n",
            "Total de pasos: 2997983/3000000.0 - Recompensa: -1.6425953663765198\n",
            "Total de pasos: 2997984/3000000.0 - Recompensa: -3.475858019813037\n",
            "Total de pasos: 2997985/3000000.0 - Recompensa: -1.3558501665379723\n",
            "Total de pasos: 2997986/3000000.0 - Recompensa: 0.4240459067299844\n",
            "0.4240459067299844\n",
            "Total de pasos: 2997987/3000000.0 - Recompensa: -1.6368522332938795\n",
            "Total de pasos: 2997988/3000000.0 - Recompensa: -2.179015649302306\n",
            "Total de pasos: 2997989/3000000.0 - Recompensa: -0.18588754770336138\n",
            "Total de pasos: 2997990/3000000.0 - Recompensa: -1.2235883501082432\n",
            "Total de pasos: 2997991/3000000.0 - Recompensa: -1.8188572663183313\n",
            "Total de pasos: 2997992/3000000.0 - Recompensa: 0.5864487616068967\n",
            "0.5864487616068967\n",
            "Total de pasos: 2997993/3000000.0 - Recompensa: -1.3391135080597132\n",
            "Total de pasos: 2997994/3000000.0 - Recompensa: 0.013071933796124119\n",
            "0.013071933796124119\n",
            "Total de pasos: 2997995/3000000.0 - Recompensa: -0.9011692506094539\n",
            "Total de pasos: 2997996/3000000.0 - Recompensa: -0.073248769342427\n",
            "Total de pasos: 2997997/3000000.0 - Recompensa: -0.048526999703899065\n",
            "Total de pasos: 2997998/3000000.0 - Recompensa: -0.5810677733510741\n",
            "Total de pasos: 2997999/3000000.0 - Recompensa: -0.5754660340712386\n",
            "Total de pasos: 2998000/3000000.0 - Recompensa: -0.6989329716918576\n",
            "Total de pasos: 2998001/3000000.0 - Recompensa: 0.24295467905387066\n",
            "0.24295467905387066\n",
            "Total de pasos: 2998002/3000000.0 - Recompensa: 0.19957057704075018\n",
            "0.19957057704075018\n",
            "Total de pasos: 2998003/3000000.0 - Recompensa: -2.1339307698849357\n",
            "Total de pasos: 2998004/3000000.0 - Recompensa: 0.0402334750762105\n",
            "0.0402334750762105\n",
            "Total de pasos: 2998005/3000000.0 - Recompensa: -1.3857782421865914\n",
            "Total de pasos: 2998006/3000000.0 - Recompensa: -0.7508563257661994\n",
            "Total de pasos: 2998007/3000000.0 - Recompensa: -0.3213781180879386\n",
            "Total de pasos: 2998008/3000000.0 - Recompensa: -0.9312757086543745\n",
            "Total de pasos: 2998009/3000000.0 - Recompensa: -0.8695285860485644\n",
            "Total de pasos: 2998010/3000000.0 - Recompensa: -2.551182847715022\n",
            "Total de pasos: 2998011/3000000.0 - Recompensa: 0.7212686371749475\n",
            "0.7212686371749475\n",
            "Total de pasos: 2998012/3000000.0 - Recompensa: -0.2345757515016394\n",
            "Total de pasos: 2998013/3000000.0 - Recompensa: -1.1487466821338428\n",
            "Total de pasos: 2998014/3000000.0 - Recompensa: -0.7179373554690888\n",
            "Total de pasos: 2998015/3000000.0 - Recompensa: -0.6851357252826411\n",
            "Total de pasos: 2998016/3000000.0 - Recompensa: -0.06335194815409412\n",
            "Total de pasos: 2998017/3000000.0 - Recompensa: -0.158398024542885\n",
            "Total de pasos: 2998018/3000000.0 - Recompensa: -0.12619813824859785\n",
            "Total de pasos: 2998019/3000000.0 - Recompensa: 0.0874661110405329\n",
            "0.0874661110405329\n",
            "Total de pasos: 2998020/3000000.0 - Recompensa: 0.4883760871114808\n",
            "0.4883760871114808\n",
            "Total de pasos: 2998021/3000000.0 - Recompensa: 0.2631722327534151\n",
            "0.2631722327534151\n",
            "Total de pasos: 2998022/3000000.0 - Recompensa: -4.141980566768036\n",
            "Total de pasos: 2998023/3000000.0 - Recompensa: -0.6374545594450478\n",
            "Total de pasos: 2998024/3000000.0 - Recompensa: -2.9605383570682244\n",
            "Total de pasos: 2998025/3000000.0 - Recompensa: -0.09074652668437971\n",
            "Total de pasos: 2998026/3000000.0 - Recompensa: -1.2123984014489964\n",
            "Total de pasos: 2998027/3000000.0 - Recompensa: -2.014377373099297\n",
            "Total de pasos: 2998028/3000000.0 - Recompensa: -2.033173160165093\n",
            "Total de pasos: 2998029/3000000.0 - Recompensa: 1.0845194222206143\n",
            "1.0845194222206143\n",
            "Total de pasos: 2998030/3000000.0 - Recompensa: -0.8198018901405495\n",
            "Total de pasos: 2998031/3000000.0 - Recompensa: 0.11488546276656825\n",
            "0.11488546276656825\n",
            "Total de pasos: 2998032/3000000.0 - Recompensa: -0.08717449714849668\n",
            "Total de pasos: 2998033/3000000.0 - Recompensa: -1.0757444466254997\n",
            "Total de pasos: 2998034/3000000.0 - Recompensa: -1.5850105060529978\n",
            "Total de pasos: 2998035/3000000.0 - Recompensa: -5.173512604936877\n",
            "Total de pasos: 2998036/3000000.0 - Recompensa: -1.4416315496698464\n",
            "Total de pasos: 2998037/3000000.0 - Recompensa: -0.2907983863184603\n",
            "Total de pasos: 2998038/3000000.0 - Recompensa: 0.5065638123242828\n",
            "0.5065638123242828\n",
            "Total de pasos: 2998039/3000000.0 - Recompensa: -0.4500646953099066\n",
            "Total de pasos: 2998040/3000000.0 - Recompensa: -3.116296943406137\n",
            "Total de pasos: 2998041/3000000.0 - Recompensa: -0.08970470303951186\n",
            "Total de pasos: 2998042/3000000.0 - Recompensa: -0.6107757415287141\n",
            "Total de pasos: 2998043/3000000.0 - Recompensa: -0.6713516123248102\n",
            "Total de pasos: 2998044/3000000.0 - Recompensa: -2.7932371992555582\n",
            "Total de pasos: 2998045/3000000.0 - Recompensa: -1.3194313284687333\n",
            "Total de pasos: 2998046/3000000.0 - Recompensa: 0.06239500859645228\n",
            "0.06239500859645228\n",
            "Total de pasos: 2998047/3000000.0 - Recompensa: 0.20583785631404403\n",
            "0.20583785631404403\n",
            "Total de pasos: 2998048/3000000.0 - Recompensa: -0.7923955147421438\n",
            "Total de pasos: 2998049/3000000.0 - Recompensa: 0.24062639126419327\n",
            "0.24062639126419327\n",
            "Total de pasos: 2998050/3000000.0 - Recompensa: -2.3964315466160637\n",
            "Total de pasos: 2998051/3000000.0 - Recompensa: -2.6820683543572135\n",
            "Total de pasos: 2998052/3000000.0 - Recompensa: -1.0281360144678087\n",
            "Total de pasos: 2998053/3000000.0 - Recompensa: -1.0011459201234596\n",
            "Total de pasos: 2998054/3000000.0 - Recompensa: -3.735880028406232\n",
            "Total de pasos: 2998055/3000000.0 - Recompensa: -0.8255962814019016\n",
            "Total de pasos: 2998056/3000000.0 - Recompensa: -0.9187564200322922\n",
            "Total de pasos: 2998057/3000000.0 - Recompensa: 0.3901592356526794\n",
            "0.3901592356526794\n",
            "Total de pasos: 2998058/3000000.0 - Recompensa: -1.297846669215645\n",
            "Total de pasos: 2998059/3000000.0 - Recompensa: 0.693579587826335\n",
            "0.693579587826335\n",
            "Total de pasos: 2998060/3000000.0 - Recompensa: -2.0839005873505556\n",
            "Total de pasos: 2998061/3000000.0 - Recompensa: -0.004485352384314079\n",
            "Total de pasos: 2998062/3000000.0 - Recompensa: 0.529553168830596\n",
            "0.529553168830596\n",
            "Total de pasos: 2998063/3000000.0 - Recompensa: -1.6675176036008525\n",
            "Total de pasos: 2998064/3000000.0 - Recompensa: -1.8200994039482912\n",
            "Total de pasos: 2998065/3000000.0 - Recompensa: -0.1838074164931948\n",
            "Total de pasos: 2998066/3000000.0 - Recompensa: 0.3731750136065279\n",
            "0.3731750136065279\n",
            "Total de pasos: 2998067/3000000.0 - Recompensa: -0.9759880687856398\n",
            "Total de pasos: 2998068/3000000.0 - Recompensa: -2.49184845034493\n",
            "Total de pasos: 2998069/3000000.0 - Recompensa: -0.9804712754988997\n",
            "Total de pasos: 2998070/3000000.0 - Recompensa: 0.6531555407712987\n",
            "0.6531555407712987\n",
            "Total de pasos: 2998071/3000000.0 - Recompensa: -5.2303124069680225\n",
            "Total de pasos: 2998072/3000000.0 - Recompensa: 0.2625388966143605\n",
            "0.2625388966143605\n",
            "Total de pasos: 2998073/3000000.0 - Recompensa: -0.07401423062618934\n",
            "Total de pasos: 2998074/3000000.0 - Recompensa: -3.1927569619554372\n",
            "Total de pasos: 2998075/3000000.0 - Recompensa: -0.1105895659952855\n",
            "Total de pasos: 2998076/3000000.0 - Recompensa: -1.2728343550408252\n",
            "Total de pasos: 2998077/3000000.0 - Recompensa: -1.2355859391592334\n",
            "Total de pasos: 2998078/3000000.0 - Recompensa: -1.196814080045551\n",
            "Total de pasos: 2998079/3000000.0 - Recompensa: -0.8511021051899832\n",
            "Total de pasos: 2998080/3000000.0 - Recompensa: -1.5591225994860607\n",
            "Total de pasos: 2998081/3000000.0 - Recompensa: -2.2251952874416463\n",
            "Total de pasos: 2998082/3000000.0 - Recompensa: -0.8214500325231205\n",
            "Total de pasos: 2998083/3000000.0 - Recompensa: -3.3490434348638236\n",
            "Total de pasos: 2998084/3000000.0 - Recompensa: 0.74037797520863\n",
            "0.74037797520863\n",
            "Total de pasos: 2998085/3000000.0 - Recompensa: -2.5579160245960937\n",
            "Total de pasos: 2998086/3000000.0 - Recompensa: -0.15426712370127707\n",
            "Total de pasos: 2998087/3000000.0 - Recompensa: -0.4399554449765998\n",
            "Total de pasos: 2998088/3000000.0 - Recompensa: 0.1685733608602956\n",
            "0.1685733608602956\n",
            "Total de pasos: 2998089/3000000.0 - Recompensa: -0.8943213153426757\n",
            "Total de pasos: 2998090/3000000.0 - Recompensa: -0.5752367628978673\n",
            "Total de pasos: 2998091/3000000.0 - Recompensa: -2.6307746222623254\n",
            "Total de pasos: 2998092/3000000.0 - Recompensa: 0.986693434373694\n",
            "0.986693434373694\n",
            "Total de pasos: 2998093/3000000.0 - Recompensa: -2.501246429879355\n",
            "Total de pasos: 2998094/3000000.0 - Recompensa: -0.5852953901113371\n",
            "Total de pasos: 2998095/3000000.0 - Recompensa: -1.825845947841387\n",
            "Total de pasos: 2998096/3000000.0 - Recompensa: -1.0044440035263984\n",
            "Total de pasos: 2998097/3000000.0 - Recompensa: -0.8217910192989188\n",
            "Total de pasos: 2998098/3000000.0 - Recompensa: 0.3847869399508039\n",
            "0.3847869399508039\n",
            "Total de pasos: 2998099/3000000.0 - Recompensa: -1.2711828870982167\n",
            "Total de pasos: 2998100/3000000.0 - Recompensa: -0.9664823723680674\n",
            "Total de pasos: 2998101/3000000.0 - Recompensa: 0.7000175029436866\n",
            "0.7000175029436866\n",
            "Total de pasos: 2998102/3000000.0 - Recompensa: 0.0682725948697322\n",
            "0.0682725948697322\n",
            "Total de pasos: 2998103/3000000.0 - Recompensa: 0.9270703946398375\n",
            "0.9270703946398375\n",
            "Total de pasos: 2998104/3000000.0 - Recompensa: -0.8988429890830087\n",
            "Total de pasos: 2998105/3000000.0 - Recompensa: -1.1790611460824845\n",
            "Total de pasos: 2998106/3000000.0 - Recompensa: -0.7464988441647499\n",
            "Total de pasos: 2998107/3000000.0 - Recompensa: -0.9932290548353893\n",
            "Total de pasos: 2998108/3000000.0 - Recompensa: -3.732050695597119\n",
            "Total de pasos: 2998109/3000000.0 - Recompensa: 0.7901840618868319\n",
            "0.7901840618868319\n",
            "Total de pasos: 2998110/3000000.0 - Recompensa: -2.0940705149946863\n",
            "Total de pasos: 2998111/3000000.0 - Recompensa: -0.5506693592797622\n",
            "Total de pasos: 2998112/3000000.0 - Recompensa: -0.8761687517031816\n",
            "Total de pasos: 2998113/3000000.0 - Recompensa: -0.7777187884608752\n",
            "Total de pasos: 2998114/3000000.0 - Recompensa: -1.1255702981492508\n",
            "Total de pasos: 2998115/3000000.0 - Recompensa: -0.4962997527999139\n",
            "Total de pasos: 2998116/3000000.0 - Recompensa: -0.29573620771264897\n",
            "Total de pasos: 2998117/3000000.0 - Recompensa: -2.475111200855103\n",
            "Total de pasos: 2998118/3000000.0 - Recompensa: 0.23692117223884432\n",
            "0.23692117223884432\n",
            "Total de pasos: 2998119/3000000.0 - Recompensa: 0.2253119664173075\n",
            "0.2253119664173075\n",
            "Total de pasos: 2998120/3000000.0 - Recompensa: -1.0236492297972528\n",
            "Total de pasos: 2998121/3000000.0 - Recompensa: -1.6591762555419165\n",
            "Total de pasos: 2998122/3000000.0 - Recompensa: -0.8605260607896271\n",
            "Total de pasos: 2998123/3000000.0 - Recompensa: 0.08157356363292187\n",
            "0.08157356363292187\n",
            "Total de pasos: 2998124/3000000.0 - Recompensa: -0.5291623743355326\n",
            "Total de pasos: 2998125/3000000.0 - Recompensa: -3.710108481966836\n",
            "Total de pasos: 2998126/3000000.0 - Recompensa: -0.8867910338110486\n",
            "Total de pasos: 2998127/3000000.0 - Recompensa: -2.591880222722669\n",
            "Total de pasos: 2998128/3000000.0 - Recompensa: 0.1384925187813894\n",
            "0.1384925187813894\n",
            "Total de pasos: 2998129/3000000.0 - Recompensa: -4.132675475759472\n",
            "Total de pasos: 2998130/3000000.0 - Recompensa: -0.3888311334375859\n",
            "Total de pasos: 2998131/3000000.0 - Recompensa: -0.018473123820205828\n",
            "Total de pasos: 2998132/3000000.0 - Recompensa: -2.0566940817229287\n",
            "Total de pasos: 2998133/3000000.0 - Recompensa: -0.9184533175881728\n",
            "Total de pasos: 2998134/3000000.0 - Recompensa: -0.7127552866749471\n",
            "Total de pasos: 2998135/3000000.0 - Recompensa: -1.4633245006620375\n",
            "Total de pasos: 2998136/3000000.0 - Recompensa: 0.29439173717452904\n",
            "0.29439173717452904\n",
            "Total de pasos: 2998137/3000000.0 - Recompensa: -0.028929129993264635\n",
            "Total de pasos: 2998138/3000000.0 - Recompensa: -0.9833414255332613\n",
            "Total de pasos: 2998139/3000000.0 - Recompensa: -0.38986066968727356\n",
            "Total de pasos: 2998140/3000000.0 - Recompensa: -0.5367620901974103\n",
            "Total de pasos: 2998141/3000000.0 - Recompensa: -0.48264226622332257\n",
            "Total de pasos: 2998142/3000000.0 - Recompensa: -3.453213147188544\n",
            "Total de pasos: 2998143/3000000.0 - Recompensa: -0.26734534176812996\n",
            "Total de pasos: 2998144/3000000.0 - Recompensa: -3.17701134375615\n",
            "Total de pasos: 2998145/3000000.0 - Recompensa: -0.26649167109572536\n",
            "Total de pasos: 2998146/3000000.0 - Recompensa: -3.613587213189973\n",
            "Total de pasos: 2998147/3000000.0 - Recompensa: -1.4763990243351\n",
            "Total de pasos: 2998148/3000000.0 - Recompensa: 0.23195773652569834\n",
            "0.23195773652569834\n",
            "Total de pasos: 2998149/3000000.0 - Recompensa: -1.363894635580202\n",
            "Total de pasos: 2998150/3000000.0 - Recompensa: -2.838555245534527\n",
            "Total de pasos: 2998151/3000000.0 - Recompensa: -0.5346048332411869\n",
            "Total de pasos: 2998152/3000000.0 - Recompensa: -0.38784905169270745\n",
            "Total de pasos: 2998153/3000000.0 - Recompensa: -1.4093476324477465\n",
            "Total de pasos: 2998154/3000000.0 - Recompensa: -1.5585806555660273\n",
            "Total de pasos: 2998155/3000000.0 - Recompensa: 0.4497930282242777\n",
            "0.4497930282242777\n",
            "Total de pasos: 2998156/3000000.0 - Recompensa: -2.208776006802931\n",
            "Total de pasos: 2998157/3000000.0 - Recompensa: -0.5467381489829755\n",
            "Total de pasos: 2998158/3000000.0 - Recompensa: -0.5872092539537189\n",
            "Total de pasos: 2998159/3000000.0 - Recompensa: 0.9355989200513839\n",
            "0.9355989200513839\n",
            "Total de pasos: 2998160/3000000.0 - Recompensa: -0.5530622834376107\n",
            "Total de pasos: 2998161/3000000.0 - Recompensa: -0.8758265007314716\n",
            "Total de pasos: 2998162/3000000.0 - Recompensa: -0.3514259578548662\n",
            "Total de pasos: 2998163/3000000.0 - Recompensa: -2.3185768284849244\n",
            "Total de pasos: 2998164/3000000.0 - Recompensa: -1.424405346544768\n",
            "Total de pasos: 2998165/3000000.0 - Recompensa: 0.30545282261251233\n",
            "0.30545282261251233\n",
            "Total de pasos: 2998166/3000000.0 - Recompensa: -0.6239561209742466\n",
            "Total de pasos: 2998167/3000000.0 - Recompensa: -0.828457134309508\n",
            "Total de pasos: 2998168/3000000.0 - Recompensa: -1.9269274440011859\n",
            "Total de pasos: 2998169/3000000.0 - Recompensa: -1.0910747882012537\n",
            "Total de pasos: 2998170/3000000.0 - Recompensa: -0.37529250230778544\n",
            "Total de pasos: 2998171/3000000.0 - Recompensa: -4.715815146553044\n",
            "Total de pasos: 2998172/3000000.0 - Recompensa: -0.7175259113542806\n",
            "Total de pasos: 2998173/3000000.0 - Recompensa: -0.976852060388113\n",
            "Total de pasos: 2998174/3000000.0 - Recompensa: -0.17884756392330728\n",
            "Total de pasos: 2998175/3000000.0 - Recompensa: -1.98401371657142\n",
            "Total de pasos: 2998176/3000000.0 - Recompensa: -1.4745856472593024\n",
            "Total de pasos: 2998177/3000000.0 - Recompensa: -0.7646852968153615\n",
            "Total de pasos: 2998178/3000000.0 - Recompensa: -2.4840664062951308\n",
            "Total de pasos: 2998179/3000000.0 - Recompensa: -1.4917432322083348\n",
            "Total de pasos: 2998180/3000000.0 - Recompensa: 0.6206924353591918\n",
            "0.6206924353591918\n",
            "Total de pasos: 2998181/3000000.0 - Recompensa: 0.003927974528817962\n",
            "0.003927974528817962\n",
            "Total de pasos: 2998182/3000000.0 - Recompensa: -0.35108548854384375\n",
            "Total de pasos: 2998183/3000000.0 - Recompensa: -1.2306269882501977\n",
            "Total de pasos: 2998184/3000000.0 - Recompensa: 0.32687050712364946\n",
            "0.32687050712364946\n",
            "Total de pasos: 2998185/3000000.0 - Recompensa: -1.1547363384384786\n",
            "Total de pasos: 2998186/3000000.0 - Recompensa: -0.3995950921125065\n",
            "Total de pasos: 2998187/3000000.0 - Recompensa: -0.7668611056691348\n",
            "Total de pasos: 2998188/3000000.0 - Recompensa: -1.899977185808738\n",
            "Total de pasos: 2998189/3000000.0 - Recompensa: -0.7306251260732373\n",
            "Total de pasos: 2998190/3000000.0 - Recompensa: -0.38183689659009357\n",
            "Total de pasos: 2998191/3000000.0 - Recompensa: -1.0437530003264852\n",
            "Total de pasos: 2998192/3000000.0 - Recompensa: -1.3519280889790606\n",
            "Total de pasos: 2998193/3000000.0 - Recompensa: -0.7542262405777482\n",
            "Total de pasos: 2998194/3000000.0 - Recompensa: -0.371889045834607\n",
            "Total de pasos: 2998195/3000000.0 - Recompensa: -0.07431769732118304\n",
            "Total de pasos: 2998196/3000000.0 - Recompensa: -1.2739946013017431\n",
            "Total de pasos: 2998197/3000000.0 - Recompensa: -0.8214682451356665\n",
            "Total de pasos: 2998198/3000000.0 - Recompensa: 0.7552988880361011\n",
            "0.7552988880361011\n",
            "Total de pasos: 2998199/3000000.0 - Recompensa: -1.7938215590326878\n",
            "Total de pasos: 2998200/3000000.0 - Recompensa: -0.12532099157634172\n",
            "Total de pasos: 2998201/3000000.0 - Recompensa: -1.9560757575666086\n",
            "Total de pasos: 2998202/3000000.0 - Recompensa: -1.1701970267593735\n",
            "Total de pasos: 2998203/3000000.0 - Recompensa: -2.6980816861958443\n",
            "Total de pasos: 2998204/3000000.0 - Recompensa: -0.27690571292506394\n",
            "Total de pasos: 2998205/3000000.0 - Recompensa: -0.5067799380461417\n",
            "Total de pasos: 2998206/3000000.0 - Recompensa: -1.2629990308090335\n",
            "Total de pasos: 2998207/3000000.0 - Recompensa: -1.8271366941888922\n",
            "Total de pasos: 2998208/3000000.0 - Recompensa: -6.113767375240824\n",
            "Total de pasos: 2998209/3000000.0 - Recompensa: -0.27660439424872996\n",
            "Total de pasos: 2998210/3000000.0 - Recompensa: 0.43517569377746035\n",
            "0.43517569377746035\n",
            "Total de pasos: 2998211/3000000.0 - Recompensa: 0.06878541585678674\n",
            "0.06878541585678674\n",
            "Total de pasos: 2998212/3000000.0 - Recompensa: 0.7525839309173715\n",
            "0.7525839309173715\n",
            "Total de pasos: 2998213/3000000.0 - Recompensa: -1.2845188201767064\n",
            "Total de pasos: 2998214/3000000.0 - Recompensa: -0.8466660048444047\n",
            "Total de pasos: 2998215/3000000.0 - Recompensa: 0.017529622688219337\n",
            "0.017529622688219337\n",
            "Total de pasos: 2998216/3000000.0 - Recompensa: -0.2276736185578308\n",
            "Total de pasos: 2998217/3000000.0 - Recompensa: -0.5143341658177112\n",
            "Total de pasos: 2998218/3000000.0 - Recompensa: 0.14932891919211694\n",
            "0.14932891919211694\n",
            "Total de pasos: 2998219/3000000.0 - Recompensa: -0.623112786476945\n",
            "Total de pasos: 2998220/3000000.0 - Recompensa: 0.14290223194429882\n",
            "0.14290223194429882\n",
            "Total de pasos: 2998221/3000000.0 - Recompensa: 0.3467032506661187\n",
            "0.3467032506661187\n",
            "Total de pasos: 2998222/3000000.0 - Recompensa: -3.870262644328895\n",
            "Total de pasos: 2998223/3000000.0 - Recompensa: -1.2575189939860034\n",
            "Total de pasos: 2998224/3000000.0 - Recompensa: 0.18090629152957866\n",
            "0.18090629152957866\n",
            "Total de pasos: 2998225/3000000.0 - Recompensa: -0.15120990808826199\n",
            "Total de pasos: 2998226/3000000.0 - Recompensa: -0.2019668982190324\n",
            "Total de pasos: 2998227/3000000.0 - Recompensa: -1.0293499207752324\n",
            "Total de pasos: 2998228/3000000.0 - Recompensa: -1.984536064118462\n",
            "Total de pasos: 2998229/3000000.0 - Recompensa: -1.7179257977585753\n",
            "Total de pasos: 2998230/3000000.0 - Recompensa: -1.3408012075107858\n",
            "Total de pasos: 2998231/3000000.0 - Recompensa: -1.9626238428204685\n",
            "Total de pasos: 2998232/3000000.0 - Recompensa: -0.4736216005967554\n",
            "Total de pasos: 2998233/3000000.0 - Recompensa: -0.6711435151178468\n",
            "Total de pasos: 2998234/3000000.0 - Recompensa: -1.5958537579582721\n",
            "Total de pasos: 2998235/3000000.0 - Recompensa: -0.7620685874863531\n",
            "Total de pasos: 2998236/3000000.0 - Recompensa: -1.2661155786109053\n",
            "Total de pasos: 2998237/3000000.0 - Recompensa: -1.5122091990307112\n",
            "Total de pasos: 2998238/3000000.0 - Recompensa: -0.5883350134049181\n",
            "Total de pasos: 2998239/3000000.0 - Recompensa: -1.6130890820935144\n",
            "Total de pasos: 2998240/3000000.0 - Recompensa: -0.450861385718586\n",
            "Total de pasos: 2998241/3000000.0 - Recompensa: 0.5786499301696183\n",
            "0.5786499301696183\n",
            "Total de pasos: 2998242/3000000.0 - Recompensa: -1.7905171574298615\n",
            "Total de pasos: 2998243/3000000.0 - Recompensa: 0.025314399140047683\n",
            "0.025314399140047683\n",
            "Total de pasos: 2998244/3000000.0 - Recompensa: 0.2966469990712216\n",
            "0.2966469990712216\n",
            "Total de pasos: 2998245/3000000.0 - Recompensa: -1.0736796319324393\n",
            "Total de pasos: 2998246/3000000.0 - Recompensa: 0.8969748568621216\n",
            "0.8969748568621216\n",
            "Total de pasos: 2998247/3000000.0 - Recompensa: -2.5194346513689103\n",
            "Total de pasos: 2998248/3000000.0 - Recompensa: -1.4429927109235914\n",
            "Total de pasos: 2998249/3000000.0 - Recompensa: 0.6745700803759608\n",
            "0.6745700803759608\n",
            "Total de pasos: 2998250/3000000.0 - Recompensa: -1.2022700779544204\n",
            "Total de pasos: 2998251/3000000.0 - Recompensa: -1.7944922049051075\n",
            "Total de pasos: 2998252/3000000.0 - Recompensa: -1.5803489795798966\n",
            "Total de pasos: 2998253/3000000.0 - Recompensa: -0.8670036998766208\n",
            "Total de pasos: 2998254/3000000.0 - Recompensa: -0.9492191836143391\n",
            "Total de pasos: 2998255/3000000.0 - Recompensa: -1.6536107150442434\n",
            "Total de pasos: 2998256/3000000.0 - Recompensa: -1.3828396830166962\n",
            "Total de pasos: 2998257/3000000.0 - Recompensa: -2.111984507667037\n",
            "Total de pasos: 2998258/3000000.0 - Recompensa: 0.26226125366368763\n",
            "0.26226125366368763\n",
            "Total de pasos: 2998259/3000000.0 - Recompensa: -0.3233225272745649\n",
            "Total de pasos: 2998260/3000000.0 - Recompensa: 0.6278223091124115\n",
            "0.6278223091124115\n",
            "Total de pasos: 2998261/3000000.0 - Recompensa: 0.5531340146511705\n",
            "0.5531340146511705\n",
            "Total de pasos: 2998262/3000000.0 - Recompensa: 0.002104243662287286\n",
            "0.002104243662287286\n",
            "Total de pasos: 2998263/3000000.0 - Recompensa: 0.041733445855191315\n",
            "0.041733445855191315\n",
            "Total de pasos: 2998264/3000000.0 - Recompensa: -1.4711904063052401\n",
            "Total de pasos: 2998265/3000000.0 - Recompensa: -1.20285146981148\n",
            "Total de pasos: 2998266/3000000.0 - Recompensa: -1.0827228039325014\n",
            "Total de pasos: 2998267/3000000.0 - Recompensa: -1.7190597093457005\n",
            "Total de pasos: 2998268/3000000.0 - Recompensa: -2.2147097568121805\n",
            "Total de pasos: 2998269/3000000.0 - Recompensa: 0.8685280369346231\n",
            "0.8685280369346231\n",
            "Total de pasos: 2998270/3000000.0 - Recompensa: -2.469434639874106\n",
            "Total de pasos: 2998271/3000000.0 - Recompensa: -1.1812721092089233\n",
            "Total de pasos: 2998272/3000000.0 - Recompensa: -1.7788455011503492\n",
            "Total de pasos: 2998273/3000000.0 - Recompensa: -0.6429507175359059\n",
            "Total de pasos: 2998274/3000000.0 - Recompensa: -3.062837109938377\n",
            "Total de pasos: 2998275/3000000.0 - Recompensa: -1.3856646982936265\n",
            "Total de pasos: 2998276/3000000.0 - Recompensa: -5.269209007576401\n",
            "Total de pasos: 2998277/3000000.0 - Recompensa: 1.0741377199313165\n",
            "1.0741377199313165\n",
            "Total de pasos: 2998278/3000000.0 - Recompensa: 0.17550118004888193\n",
            "0.17550118004888193\n",
            "Total de pasos: 2998279/3000000.0 - Recompensa: -0.15145046144116986\n",
            "Total de pasos: 2998280/3000000.0 - Recompensa: -2.6994563568348093\n",
            "Total de pasos: 2998281/3000000.0 - Recompensa: -2.597287184922282\n",
            "Total de pasos: 2998282/3000000.0 - Recompensa: -0.29192700968902835\n",
            "Total de pasos: 2998283/3000000.0 - Recompensa: -1.003227243132888\n",
            "Total de pasos: 2998284/3000000.0 - Recompensa: -0.9677582348004651\n",
            "Total de pasos: 2998285/3000000.0 - Recompensa: -1.843034996526667\n",
            "Total de pasos: 2998286/3000000.0 - Recompensa: -1.031038181687051\n",
            "Total de pasos: 2998287/3000000.0 - Recompensa: -0.12022159434437035\n",
            "Total de pasos: 2998288/3000000.0 - Recompensa: -1.2039400340505062\n",
            "Total de pasos: 2998289/3000000.0 - Recompensa: -0.34202897474753946\n",
            "Total de pasos: 2998290/3000000.0 - Recompensa: 0.048189137708792934\n",
            "0.048189137708792934\n",
            "Total de pasos: 2998291/3000000.0 - Recompensa: -2.30936435079664\n",
            "Total de pasos: 2998292/3000000.0 - Recompensa: -0.2628585595353362\n",
            "Total de pasos: 2998293/3000000.0 - Recompensa: -0.3951503120153864\n",
            "Total de pasos: 2998294/3000000.0 - Recompensa: -1.181249643768543\n",
            "Total de pasos: 2998295/3000000.0 - Recompensa: -0.48070691260288206\n",
            "Total de pasos: 2998296/3000000.0 - Recompensa: -0.5942124491657401\n",
            "Total de pasos: 2998297/3000000.0 - Recompensa: -2.3378450107731257\n",
            "Total de pasos: 2998298/3000000.0 - Recompensa: -0.749993087217318\n",
            "Total de pasos: 2998299/3000000.0 - Recompensa: -1.283093798546199\n",
            "Total de pasos: 2998300/3000000.0 - Recompensa: -2.6777618037954403\n",
            "Total de pasos: 2998301/3000000.0 - Recompensa: -0.3594384222442513\n",
            "Total de pasos: 2998302/3000000.0 - Recompensa: -2.931293550320838\n",
            "Total de pasos: 2998303/3000000.0 - Recompensa: -0.8182375507986053\n",
            "Total de pasos: 2998304/3000000.0 - Recompensa: 0.3166812284920512\n",
            "0.3166812284920512\n",
            "Total de pasos: 2998305/3000000.0 - Recompensa: -2.0923363499186354\n",
            "Total de pasos: 2998306/3000000.0 - Recompensa: -1.1953307126899786\n",
            "Total de pasos: 2998307/3000000.0 - Recompensa: -1.2776680140829133\n",
            "Total de pasos: 2998308/3000000.0 - Recompensa: -0.9706788890017218\n",
            "Total de pasos: 2998309/3000000.0 - Recompensa: -0.9332255816631813\n",
            "Total de pasos: 2998310/3000000.0 - Recompensa: -0.3762279431598315\n",
            "Total de pasos: 2998311/3000000.0 - Recompensa: -0.486969944569039\n",
            "Total de pasos: 2998312/3000000.0 - Recompensa: -0.18838961585079553\n",
            "Total de pasos: 2998313/3000000.0 - Recompensa: -1.1082689448307466\n",
            "Total de pasos: 2998314/3000000.0 - Recompensa: -1.3132673079266992\n",
            "Total de pasos: 2998315/3000000.0 - Recompensa: -0.44826894709227966\n",
            "Total de pasos: 2998316/3000000.0 - Recompensa: 0.45095668184266036\n",
            "0.45095668184266036\n",
            "Total de pasos: 2998317/3000000.0 - Recompensa: -2.226898753280861\n",
            "Total de pasos: 2998318/3000000.0 - Recompensa: -1.2252148668078\n",
            "Total de pasos: 2998319/3000000.0 - Recompensa: -0.3345561892905991\n",
            "Total de pasos: 2998320/3000000.0 - Recompensa: -3.114243767011513\n",
            "Total de pasos: 2998321/3000000.0 - Recompensa: -1.4595954783556784\n",
            "Total de pasos: 2998322/3000000.0 - Recompensa: -1.4247352833159703\n",
            "Total de pasos: 2998323/3000000.0 - Recompensa: 0.13296955758678325\n",
            "0.13296955758678325\n",
            "Total de pasos: 2998324/3000000.0 - Recompensa: -0.3950101977276862\n",
            "Total de pasos: 2998325/3000000.0 - Recompensa: -1.5997520820663569\n",
            "Total de pasos: 2998326/3000000.0 - Recompensa: -2.1208143335865364\n",
            "Total de pasos: 2998327/3000000.0 - Recompensa: 0.428579714963265\n",
            "0.428579714963265\n",
            "Total de pasos: 2998328/3000000.0 - Recompensa: 0.28770439903840866\n",
            "0.28770439903840866\n",
            "Total de pasos: 2998329/3000000.0 - Recompensa: -2.0622633109940467\n",
            "Total de pasos: 2998330/3000000.0 - Recompensa: -0.17164129990771865\n",
            "Total de pasos: 2998331/3000000.0 - Recompensa: 0.2353351482844172\n",
            "0.2353351482844172\n",
            "Total de pasos: 2998332/3000000.0 - Recompensa: -1.0152311150343394\n",
            "Total de pasos: 2998333/3000000.0 - Recompensa: 0.1144796122355419\n",
            "0.1144796122355419\n",
            "Total de pasos: 2998334/3000000.0 - Recompensa: 0.7618621505960324\n",
            "0.7618621505960324\n",
            "Total de pasos: 2998335/3000000.0 - Recompensa: -2.935025061499754\n",
            "Total de pasos: 2998336/3000000.0 - Recompensa: -2.469354761165064\n",
            "Total de pasos: 2998337/3000000.0 - Recompensa: -0.70920805218463\n",
            "Total de pasos: 2998338/3000000.0 - Recompensa: 0.03396731758625901\n",
            "0.03396731758625901\n",
            "Total de pasos: 2998339/3000000.0 - Recompensa: 0.7830774923687934\n",
            "0.7830774923687934\n",
            "Total de pasos: 2998340/3000000.0 - Recompensa: -2.0462228757134318\n",
            "Total de pasos: 2998341/3000000.0 - Recompensa: 0.016709069616751338\n",
            "0.016709069616751338\n",
            "Total de pasos: 2998342/3000000.0 - Recompensa: -0.6156203210270664\n",
            "Total de pasos: 2998343/3000000.0 - Recompensa: -2.074210748197083\n",
            "Total de pasos: 2998344/3000000.0 - Recompensa: -0.04545761307216059\n",
            "Total de pasos: 2998345/3000000.0 - Recompensa: 0.6559209727464962\n",
            "0.6559209727464962\n",
            "Total de pasos: 2998346/3000000.0 - Recompensa: -1.0867379624086186\n",
            "Total de pasos: 2998347/3000000.0 - Recompensa: -1.1048929417761464\n",
            "Total de pasos: 2998348/3000000.0 - Recompensa: -3.5384203958288047\n",
            "Total de pasos: 2998349/3000000.0 - Recompensa: -0.23636291757542907\n",
            "Total de pasos: 2998350/3000000.0 - Recompensa: -1.1646359469549339\n",
            "Total de pasos: 2998351/3000000.0 - Recompensa: 0.4056020967960535\n",
            "0.4056020967960535\n",
            "Total de pasos: 2998352/3000000.0 - Recompensa: -1.1718777320905442\n",
            "Total de pasos: 2998353/3000000.0 - Recompensa: -0.5131593277853528\n",
            "Total de pasos: 2998354/3000000.0 - Recompensa: -1.199075273866212\n",
            "Total de pasos: 2998355/3000000.0 - Recompensa: -0.2715482379656645\n",
            "Total de pasos: 2998356/3000000.0 - Recompensa: -1.1059651206988796\n",
            "Total de pasos: 2998357/3000000.0 - Recompensa: -2.1988680381972667\n",
            "Total de pasos: 2998358/3000000.0 - Recompensa: -0.6977225437858737\n",
            "Total de pasos: 2998359/3000000.0 - Recompensa: -0.7640134767776756\n",
            "Total de pasos: 2998360/3000000.0 - Recompensa: -0.6523826019474324\n",
            "Total de pasos: 2998361/3000000.0 - Recompensa: -0.8762635802492105\n",
            "Total de pasos: 2998362/3000000.0 - Recompensa: -0.9145163978385094\n",
            "Total de pasos: 2998363/3000000.0 - Recompensa: 0.38956561607837\n",
            "0.38956561607837\n",
            "Total de pasos: 2998364/3000000.0 - Recompensa: 0.029163557537519536\n",
            "0.029163557537519536\n",
            "Total de pasos: 2998365/3000000.0 - Recompensa: -0.2618177450284847\n",
            "Total de pasos: 2998366/3000000.0 - Recompensa: -0.8982364996514204\n",
            "Total de pasos: 2998367/3000000.0 - Recompensa: -1.8389783233367518\n",
            "Total de pasos: 2998368/3000000.0 - Recompensa: -2.4846591245639407\n",
            "Total de pasos: 2998369/3000000.0 - Recompensa: -0.6122658994530596\n",
            "Total de pasos: 2998370/3000000.0 - Recompensa: 0.4716785863643604\n",
            "0.4716785863643604\n",
            "Total de pasos: 2998371/3000000.0 - Recompensa: -0.7008730212063365\n",
            "Total de pasos: 2998372/3000000.0 - Recompensa: -2.726325841644237\n",
            "Total de pasos: 2998373/3000000.0 - Recompensa: -2.7557686385556073\n",
            "Total de pasos: 2998374/3000000.0 - Recompensa: -0.7915778959183996\n",
            "Total de pasos: 2998375/3000000.0 - Recompensa: 0.29878625771714445\n",
            "0.29878625771714445\n",
            "Total de pasos: 2998376/3000000.0 - Recompensa: -2.965909337180552\n",
            "Total de pasos: 2998377/3000000.0 - Recompensa: 0.8423393780330216\n",
            "0.8423393780330216\n",
            "Total de pasos: 2998378/3000000.0 - Recompensa: -0.1981387721688906\n",
            "Total de pasos: 2998379/3000000.0 - Recompensa: -0.22118023576856807\n",
            "Total de pasos: 2998380/3000000.0 - Recompensa: -1.396224296974254\n",
            "Total de pasos: 2998381/3000000.0 - Recompensa: 0.28233145425407147\n",
            "0.28233145425407147\n",
            "Total de pasos: 2998382/3000000.0 - Recompensa: -0.042366493163691704\n",
            "Total de pasos: 2998383/3000000.0 - Recompensa: -1.572788915336122\n",
            "Total de pasos: 2998384/3000000.0 - Recompensa: -0.34668884022659424\n",
            "Total de pasos: 2998385/3000000.0 - Recompensa: -3.5866986388764364\n",
            "Total de pasos: 2998386/3000000.0 - Recompensa: -0.2443290357745001\n",
            "Total de pasos: 2998387/3000000.0 - Recompensa: 0.31229406471051246\n",
            "0.31229406471051246\n",
            "Total de pasos: 2998388/3000000.0 - Recompensa: -0.5980835689116673\n",
            "Total de pasos: 2998389/3000000.0 - Recompensa: -1.1933247482181881\n",
            "Total de pasos: 2998390/3000000.0 - Recompensa: 0.09159843518722871\n",
            "0.09159843518722871\n",
            "Total de pasos: 2998391/3000000.0 - Recompensa: -0.6764382385173432\n",
            "Total de pasos: 2998392/3000000.0 - Recompensa: -1.1605609450076688\n",
            "Total de pasos: 2998393/3000000.0 - Recompensa: -0.22523578241519476\n",
            "Total de pasos: 2998394/3000000.0 - Recompensa: -0.0779448734334102\n",
            "Total de pasos: 2998395/3000000.0 - Recompensa: 0.1282618900317029\n",
            "0.1282618900317029\n",
            "Total de pasos: 2998396/3000000.0 - Recompensa: -0.4483629874921252\n",
            "Total de pasos: 2998397/3000000.0 - Recompensa: 0.13888786040726217\n",
            "0.13888786040726217\n",
            "Total de pasos: 2998398/3000000.0 - Recompensa: -0.4309131793941415\n",
            "Total de pasos: 2998399/3000000.0 - Recompensa: -2.033053163186197\n",
            "Total de pasos: 2998400/3000000.0 - Recompensa: -1.0834403106749864\n",
            "Total de pasos: 2998401/3000000.0 - Recompensa: -0.17760891647726346\n",
            "Total de pasos: 2998402/3000000.0 - Recompensa: -0.7164207225569411\n",
            "Total de pasos: 2998403/3000000.0 - Recompensa: -1.022022163616134\n",
            "Total de pasos: 2998404/3000000.0 - Recompensa: -0.5321555734337035\n",
            "Total de pasos: 2998405/3000000.0 - Recompensa: -2.0341716292281395\n",
            "Total de pasos: 2998406/3000000.0 - Recompensa: -0.6960787844232865\n",
            "Total de pasos: 2998407/3000000.0 - Recompensa: -0.5325840502110804\n",
            "Total de pasos: 2998408/3000000.0 - Recompensa: -0.007797084943301336\n",
            "Total de pasos: 2998409/3000000.0 - Recompensa: -0.5174820386506757\n",
            "Total de pasos: 2998410/3000000.0 - Recompensa: -1.3384649750924515\n",
            "Total de pasos: 2998411/3000000.0 - Recompensa: -0.8872914753506647\n",
            "Total de pasos: 2998412/3000000.0 - Recompensa: -1.2827151297840327\n",
            "Total de pasos: 2998413/3000000.0 - Recompensa: -0.19332197515095434\n",
            "Total de pasos: 2998414/3000000.0 - Recompensa: -1.430723991362862\n",
            "Total de pasos: 2998415/3000000.0 - Recompensa: 0.1647845498070321\n",
            "0.1647845498070321\n",
            "Total de pasos: 2998416/3000000.0 - Recompensa: -0.9210762646825915\n",
            "Total de pasos: 2998417/3000000.0 - Recompensa: 0.37072023231683804\n",
            "0.37072023231683804\n",
            "Total de pasos: 2998418/3000000.0 - Recompensa: -0.036061628095076126\n",
            "Total de pasos: 2998419/3000000.0 - Recompensa: 0.23771073057220032\n",
            "0.23771073057220032\n",
            "Total de pasos: 2998420/3000000.0 - Recompensa: -0.7111173042039798\n",
            "Total de pasos: 2998421/3000000.0 - Recompensa: 0.15263764981008685\n",
            "0.15263764981008685\n",
            "Total de pasos: 2998422/3000000.0 - Recompensa: -1.0421463006273253\n",
            "Total de pasos: 2998423/3000000.0 - Recompensa: -1.318215475422631\n",
            "Total de pasos: 2998424/3000000.0 - Recompensa: -1.1128662573323254\n",
            "Total de pasos: 2998425/3000000.0 - Recompensa: -0.8248301607759079\n",
            "Total de pasos: 2998426/3000000.0 - Recompensa: -0.18672145228693365\n",
            "Total de pasos: 2998427/3000000.0 - Recompensa: 0.05162737643920362\n",
            "0.05162737643920362\n",
            "Total de pasos: 2998428/3000000.0 - Recompensa: 0.5394533979278474\n",
            "0.5394533979278474\n",
            "Total de pasos: 2998429/3000000.0 - Recompensa: -1.7101109295923227\n",
            "Total de pasos: 2998430/3000000.0 - Recompensa: -1.0039368715080792\n",
            "Total de pasos: 2998431/3000000.0 - Recompensa: -0.2741769950885343\n",
            "Total de pasos: 2998432/3000000.0 - Recompensa: -0.7099429775609581\n",
            "Total de pasos: 2998433/3000000.0 - Recompensa: -0.057541057565640236\n",
            "Total de pasos: 2998434/3000000.0 - Recompensa: -0.46503900264973447\n",
            "Total de pasos: 2998435/3000000.0 - Recompensa: -2.8965842481343764\n",
            "Total de pasos: 2998436/3000000.0 - Recompensa: -0.5651308080909406\n",
            "Total de pasos: 2998437/3000000.0 - Recompensa: -0.2626809319036745\n",
            "Total de pasos: 2998438/3000000.0 - Recompensa: 0.1160657234759534\n",
            "0.1160657234759534\n",
            "Total de pasos: 2998439/3000000.0 - Recompensa: 0.05367388137635007\n",
            "0.05367388137635007\n",
            "Total de pasos: 2998440/3000000.0 - Recompensa: 0.4607808738644992\n",
            "0.4607808738644992\n",
            "Total de pasos: 2998441/3000000.0 - Recompensa: -0.7638379066084878\n",
            "Total de pasos: 2998442/3000000.0 - Recompensa: -2.3512386723054224\n",
            "Total de pasos: 2998443/3000000.0 - Recompensa: -1.7316815893866258\n",
            "Total de pasos: 2998444/3000000.0 - Recompensa: 1.0035295828465363\n",
            "1.0035295828465363\n",
            "Total de pasos: 2998445/3000000.0 - Recompensa: 0.5146771435625555\n",
            "0.5146771435625555\n",
            "Total de pasos: 2998446/3000000.0 - Recompensa: -1.6241740372722708\n",
            "Total de pasos: 2998447/3000000.0 - Recompensa: -0.17287095666660784\n",
            "Total de pasos: 2998448/3000000.0 - Recompensa: 0.0049762318326568855\n",
            "0.0049762318326568855\n",
            "Total de pasos: 2998449/3000000.0 - Recompensa: -2.6642250933127087\n",
            "Total de pasos: 2998450/3000000.0 - Recompensa: -0.9507217449140887\n",
            "Total de pasos: 2998451/3000000.0 - Recompensa: -1.9763292408497892\n",
            "Total de pasos: 2998452/3000000.0 - Recompensa: -1.3362962297029073\n",
            "Total de pasos: 2998453/3000000.0 - Recompensa: -2.973328149449811\n",
            "Total de pasos: 2998454/3000000.0 - Recompensa: -1.0771542733825183\n",
            "Total de pasos: 2998455/3000000.0 - Recompensa: -1.485708984184545\n",
            "Total de pasos: 2998456/3000000.0 - Recompensa: 0.5383619743563862\n",
            "0.5383619743563862\n",
            "Total de pasos: 2998457/3000000.0 - Recompensa: -1.6771684231929518\n",
            "Total de pasos: 2998458/3000000.0 - Recompensa: 0.3887863439949738\n",
            "0.3887863439949738\n",
            "Total de pasos: 2998459/3000000.0 - Recompensa: -0.6975585925074576\n",
            "Total de pasos: 2998460/3000000.0 - Recompensa: 0.1632668262057567\n",
            "0.1632668262057567\n",
            "Total de pasos: 2998461/3000000.0 - Recompensa: 0.48758719527262134\n",
            "0.48758719527262134\n",
            "Total de pasos: 2998462/3000000.0 - Recompensa: -1.6581661885305055\n",
            "Total de pasos: 2998463/3000000.0 - Recompensa: -0.9678726209471111\n",
            "Total de pasos: 2998464/3000000.0 - Recompensa: -0.6200267882476268\n",
            "Total de pasos: 2998465/3000000.0 - Recompensa: 0.2588352317773854\n",
            "0.2588352317773854\n",
            "Total de pasos: 2998466/3000000.0 - Recompensa: -1.004672206015087\n",
            "Total de pasos: 2998467/3000000.0 - Recompensa: -1.0016850950336147\n",
            "Total de pasos: 2998468/3000000.0 - Recompensa: 0.00228039698192134\n",
            "0.00228039698192134\n",
            "Total de pasos: 2998469/3000000.0 - Recompensa: -2.0521993846359043\n",
            "Total de pasos: 2998470/3000000.0 - Recompensa: -1.2484166456152892\n",
            "Total de pasos: 2998471/3000000.0 - Recompensa: -1.699204136552258\n",
            "Total de pasos: 2998472/3000000.0 - Recompensa: -1.6829057842480644\n",
            "Total de pasos: 2998473/3000000.0 - Recompensa: -0.5005126161623135\n",
            "Total de pasos: 2998474/3000000.0 - Recompensa: 0.3967116630533356\n",
            "0.3967116630533356\n",
            "Total de pasos: 2998475/3000000.0 - Recompensa: -0.496280051860701\n",
            "Total de pasos: 2998476/3000000.0 - Recompensa: 0.4274784350301809\n",
            "0.4274784350301809\n",
            "Total de pasos: 2998477/3000000.0 - Recompensa: -1.7682831973425754\n",
            "Total de pasos: 2998478/3000000.0 - Recompensa: -0.2813352098539802\n",
            "Total de pasos: 2998479/3000000.0 - Recompensa: -3.8401374215170407\n",
            "Total de pasos: 2998480/3000000.0 - Recompensa: -2.800323453340531\n",
            "Total de pasos: 2998481/3000000.0 - Recompensa: -4.696124599569992\n",
            "Total de pasos: 2998482/3000000.0 - Recompensa: -0.5347679505445261\n",
            "Total de pasos: 2998483/3000000.0 - Recompensa: -0.6652282939945409\n",
            "Total de pasos: 2998484/3000000.0 - Recompensa: 0.08458489071887193\n",
            "0.08458489071887193\n",
            "Total de pasos: 2998485/3000000.0 - Recompensa: -0.7326195458924449\n",
            "Total de pasos: 2998486/3000000.0 - Recompensa: -0.18009348973450084\n",
            "Total de pasos: 2998487/3000000.0 - Recompensa: 0.5576828036664677\n",
            "0.5576828036664677\n",
            "Total de pasos: 2998488/3000000.0 - Recompensa: -0.5246848942682271\n",
            "Total de pasos: 2998489/3000000.0 - Recompensa: -1.220661906483969\n",
            "Total de pasos: 2998490/3000000.0 - Recompensa: -0.0987347411393838\n",
            "Total de pasos: 2998491/3000000.0 - Recompensa: -0.4924029249404044\n",
            "Total de pasos: 2998492/3000000.0 - Recompensa: 0.21388022781671018\n",
            "0.21388022781671018\n",
            "Total de pasos: 2998493/3000000.0 - Recompensa: -1.0086532634253367\n",
            "Total de pasos: 2998494/3000000.0 - Recompensa: 0.181745945660793\n",
            "0.181745945660793\n",
            "Total de pasos: 2998495/3000000.0 - Recompensa: -0.5113410243727035\n",
            "Total de pasos: 2998496/3000000.0 - Recompensa: 0.3599701219320301\n",
            "0.3599701219320301\n",
            "Total de pasos: 2998497/3000000.0 - Recompensa: -0.08879609681728257\n",
            "Total de pasos: 2998498/3000000.0 - Recompensa: -0.28273923697438386\n",
            "Total de pasos: 2998499/3000000.0 - Recompensa: -1.4791375217126272\n",
            "Total de pasos: 2998500/3000000.0 - Recompensa: -1.1062565898481802\n",
            "Total de pasos: 2998501/3000000.0 - Recompensa: -1.5144892298375179\n",
            "Total de pasos: 2998502/3000000.0 - Recompensa: -0.1779078010909995\n",
            "Total de pasos: 2998503/3000000.0 - Recompensa: -1.2450940812248528\n",
            "Total de pasos: 2998504/3000000.0 - Recompensa: -0.49317435622141914\n",
            "Total de pasos: 2998505/3000000.0 - Recompensa: 0.23447976300833234\n",
            "0.23447976300833234\n",
            "Total de pasos: 2998506/3000000.0 - Recompensa: -0.8192987604338453\n",
            "Total de pasos: 2998507/3000000.0 - Recompensa: 0.11435083983098066\n",
            "0.11435083983098066\n",
            "Total de pasos: 2998508/3000000.0 - Recompensa: -0.7007997005589603\n",
            "Total de pasos: 2998509/3000000.0 - Recompensa: -0.6963645812558636\n",
            "Total de pasos: 2998510/3000000.0 - Recompensa: -1.0580319020183417\n",
            "Total de pasos: 2998511/3000000.0 - Recompensa: -2.130680739072194\n",
            "Total de pasos: 2998512/3000000.0 - Recompensa: -0.3629471006920396\n",
            "Total de pasos: 2998513/3000000.0 - Recompensa: -2.3691571871593515\n",
            "Total de pasos: 2998514/3000000.0 - Recompensa: -0.4245356020412732\n",
            "Total de pasos: 2998515/3000000.0 - Recompensa: 0.26210805500966805\n",
            "0.26210805500966805\n",
            "Total de pasos: 2998516/3000000.0 - Recompensa: -1.3940524252831776\n",
            "Total de pasos: 2998517/3000000.0 - Recompensa: -0.7486996555144695\n",
            "Total de pasos: 2998518/3000000.0 - Recompensa: -1.1266649895601077\n",
            "Total de pasos: 2998519/3000000.0 - Recompensa: -1.2576660465748706\n",
            "Total de pasos: 2998520/3000000.0 - Recompensa: -2.6204180776684676\n",
            "Total de pasos: 2998521/3000000.0 - Recompensa: -0.17630307437246523\n",
            "Total de pasos: 2998522/3000000.0 - Recompensa: -0.2300422598839318\n",
            "Total de pasos: 2998523/3000000.0 - Recompensa: -1.3723364048104023\n",
            "Total de pasos: 2998524/3000000.0 - Recompensa: -0.15261245072530022\n",
            "Total de pasos: 2998525/3000000.0 - Recompensa: -0.5364582375553473\n",
            "Total de pasos: 2998526/3000000.0 - Recompensa: -0.5477941846848666\n",
            "Total de pasos: 2998527/3000000.0 - Recompensa: -0.761794384412295\n",
            "Total de pasos: 2998528/3000000.0 - Recompensa: 0.6586114909584906\n",
            "0.6586114909584906\n",
            "Total de pasos: 2998529/3000000.0 - Recompensa: -0.2279351676113656\n",
            "Total de pasos: 2998530/3000000.0 - Recompensa: -2.0997919947024943\n",
            "Total de pasos: 2998531/3000000.0 - Recompensa: -2.211653028014422\n",
            "Total de pasos: 2998532/3000000.0 - Recompensa: -0.4291396900065959\n",
            "Total de pasos: 2998533/3000000.0 - Recompensa: -0.6100446398873388\n",
            "Total de pasos: 2998534/3000000.0 - Recompensa: -1.0278564432114932\n",
            "Total de pasos: 2998535/3000000.0 - Recompensa: -3.647684790904923\n",
            "Total de pasos: 2998536/3000000.0 - Recompensa: -0.5451856176793626\n",
            "Total de pasos: 2998537/3000000.0 - Recompensa: 0.10584137447182002\n",
            "0.10584137447182002\n",
            "Total de pasos: 2998538/3000000.0 - Recompensa: -0.7465283478473632\n",
            "Total de pasos: 2998539/3000000.0 - Recompensa: 0.1135245153450472\n",
            "0.1135245153450472\n",
            "Total de pasos: 2998540/3000000.0 - Recompensa: -0.6624315544328516\n",
            "Total de pasos: 2998541/3000000.0 - Recompensa: -0.09315602309828314\n",
            "Total de pasos: 2998542/3000000.0 - Recompensa: -0.47126907869978907\n",
            "Total de pasos: 2998543/3000000.0 - Recompensa: -1.3906949359036531\n",
            "Total de pasos: 2998544/3000000.0 - Recompensa: -0.145389522756956\n",
            "Total de pasos: 2998545/3000000.0 - Recompensa: -0.6518894371706037\n",
            "Total de pasos: 2998546/3000000.0 - Recompensa: -1.346594204291534\n",
            "Total de pasos: 2998547/3000000.0 - Recompensa: -2.055079032517897\n",
            "Total de pasos: 2998548/3000000.0 - Recompensa: -0.2028800346914763\n",
            "Total de pasos: 2998549/3000000.0 - Recompensa: -0.16371472932985567\n",
            "Total de pasos: 2998550/3000000.0 - Recompensa: 0.061607100527620196\n",
            "0.061607100527620196\n",
            "Total de pasos: 2998551/3000000.0 - Recompensa: 0.23008267930705859\n",
            "0.23008267930705859\n",
            "Total de pasos: 2998552/3000000.0 - Recompensa: -0.5236929668560844\n",
            "Total de pasos: 2998553/3000000.0 - Recompensa: 0.5210692832069579\n",
            "0.5210692832069579\n",
            "Total de pasos: 2998554/3000000.0 - Recompensa: -1.2547781316834574\n",
            "Total de pasos: 2998555/3000000.0 - Recompensa: 0.30898175102613623\n",
            "0.30898175102613623\n",
            "Total de pasos: 2998556/3000000.0 - Recompensa: -0.2554065451732813\n",
            "Total de pasos: 2998557/3000000.0 - Recompensa: 0.6057773941125801\n",
            "0.6057773941125801\n",
            "Total de pasos: 2998558/3000000.0 - Recompensa: -1.207887070136249\n",
            "Total de pasos: 2998559/3000000.0 - Recompensa: -1.1936255188128244\n",
            "Total de pasos: 2998560/3000000.0 - Recompensa: 0.01886366908838405\n",
            "0.01886366908838405\n",
            "Total de pasos: 2998561/3000000.0 - Recompensa: -0.2355218044431287\n",
            "Total de pasos: 2998562/3000000.0 - Recompensa: 0.0018346606070821225\n",
            "0.0018346606070821225\n",
            "Total de pasos: 2998563/3000000.0 - Recompensa: -0.20286737233604493\n",
            "Total de pasos: 2998564/3000000.0 - Recompensa: 0.24257696449807864\n",
            "0.24257696449807864\n",
            "Total de pasos: 2998565/3000000.0 - Recompensa: -1.5575573537947716\n",
            "Total de pasos: 2998566/3000000.0 - Recompensa: -2.1393035245431506\n",
            "Total de pasos: 2998567/3000000.0 - Recompensa: -0.39642033396775994\n",
            "Total de pasos: 2998568/3000000.0 - Recompensa: -1.475956790465459\n",
            "Total de pasos: 2998569/3000000.0 - Recompensa: -0.4356166867220955\n",
            "Total de pasos: 2998570/3000000.0 - Recompensa: -2.8197782445020803\n",
            "Total de pasos: 2998571/3000000.0 - Recompensa: -0.2857190267731612\n",
            "Total de pasos: 2998572/3000000.0 - Recompensa: -1.841980998388086\n",
            "Total de pasos: 2998573/3000000.0 - Recompensa: -0.5897129813367211\n",
            "Total de pasos: 2998574/3000000.0 - Recompensa: 0.23757598726714532\n",
            "0.23757598726714532\n",
            "Total de pasos: 2998575/3000000.0 - Recompensa: -1.8500170685033557\n",
            "Total de pasos: 2998576/3000000.0 - Recompensa: -0.8885955577126418\n",
            "Total de pasos: 2998577/3000000.0 - Recompensa: 0.34809122065249165\n",
            "0.34809122065249165\n",
            "Total de pasos: 2998578/3000000.0 - Recompensa: -1.8645490857794567\n",
            "Total de pasos: 2998579/3000000.0 - Recompensa: -1.1337843377920447\n",
            "Total de pasos: 2998580/3000000.0 - Recompensa: -0.33564648779719697\n",
            "Total de pasos: 2998581/3000000.0 - Recompensa: -2.645435542255145\n",
            "Total de pasos: 2998582/3000000.0 - Recompensa: -0.41148375828121236\n",
            "Total de pasos: 2998583/3000000.0 - Recompensa: -1.027912292763521\n",
            "Total de pasos: 2998584/3000000.0 - Recompensa: -1.8599138635506036\n",
            "Total de pasos: 2998585/3000000.0 - Recompensa: -0.3354354661372539\n",
            "Total de pasos: 2998586/3000000.0 - Recompensa: -1.353518041130091\n",
            "Total de pasos: 2998587/3000000.0 - Recompensa: -1.7206448937032153\n",
            "Total de pasos: 2998588/3000000.0 - Recompensa: -0.556064328497498\n",
            "Total de pasos: 2998589/3000000.0 - Recompensa: -0.5238533671749596\n",
            "Total de pasos: 2998590/3000000.0 - Recompensa: -0.4438170138369538\n",
            "Total de pasos: 2998591/3000000.0 - Recompensa: -0.9603142175549166\n",
            "Total de pasos: 2998592/3000000.0 - Recompensa: -0.7475873284737531\n",
            "Total de pasos: 2998593/3000000.0 - Recompensa: -1.1409766462663888\n",
            "Total de pasos: 2998594/3000000.0 - Recompensa: -0.8997281505108677\n",
            "Total de pasos: 2998595/3000000.0 - Recompensa: -0.07293993551857891\n",
            "Total de pasos: 2998596/3000000.0 - Recompensa: -0.29326239805005533\n",
            "Total de pasos: 2998597/3000000.0 - Recompensa: -4.230187293907449\n",
            "Total de pasos: 2998598/3000000.0 - Recompensa: -1.7256809231472954\n",
            "Total de pasos: 2998599/3000000.0 - Recompensa: -1.2762577928000298\n",
            "Total de pasos: 2998600/3000000.0 - Recompensa: -0.21084525523853026\n",
            "Total de pasos: 2998601/3000000.0 - Recompensa: -0.46703552778245505\n",
            "Total de pasos: 2998602/3000000.0 - Recompensa: -0.3508823767398076\n",
            "Total de pasos: 2998603/3000000.0 - Recompensa: -1.9057854594127592\n",
            "Total de pasos: 2998604/3000000.0 - Recompensa: -0.6709141861142708\n",
            "Total de pasos: 2998605/3000000.0 - Recompensa: -3.1846110136225763\n",
            "Total de pasos: 2998606/3000000.0 - Recompensa: -1.7789611232646847\n",
            "Total de pasos: 2998607/3000000.0 - Recompensa: -0.48805105218144035\n",
            "Total de pasos: 2998608/3000000.0 - Recompensa: -0.5424460880545141\n",
            "Total de pasos: 2998609/3000000.0 - Recompensa: 0.09946644084758532\n",
            "0.09946644084758532\n",
            "Total de pasos: 2998610/3000000.0 - Recompensa: 0.1683296646935287\n",
            "0.1683296646935287\n",
            "Total de pasos: 2998611/3000000.0 - Recompensa: -4.268006331073959\n",
            "Total de pasos: 2998612/3000000.0 - Recompensa: -1.2278994960764864\n",
            "Total de pasos: 2998613/3000000.0 - Recompensa: -0.7126059043808401\n",
            "Total de pasos: 2998614/3000000.0 - Recompensa: -0.9649892958059394\n",
            "Total de pasos: 2998615/3000000.0 - Recompensa: -1.7224232961233086\n",
            "Total de pasos: 2998616/3000000.0 - Recompensa: -1.3393618201210904\n",
            "Total de pasos: 2998617/3000000.0 - Recompensa: -1.5699675779339122\n",
            "Total de pasos: 2998618/3000000.0 - Recompensa: -0.6382617773258986\n",
            "Total de pasos: 2998619/3000000.0 - Recompensa: -2.5151276210542175\n",
            "Total de pasos: 2998620/3000000.0 - Recompensa: 0.41423832434371155\n",
            "0.41423832434371155\n",
            "Total de pasos: 2998621/3000000.0 - Recompensa: -1.128689534045587\n",
            "Total de pasos: 2998622/3000000.0 - Recompensa: -0.25056195758420496\n",
            "Total de pasos: 2998623/3000000.0 - Recompensa: -0.6917240149546116\n",
            "Total de pasos: 2998624/3000000.0 - Recompensa: -1.0370771960286231\n",
            "Total de pasos: 2998625/3000000.0 - Recompensa: -1.6929779212840586\n",
            "Total de pasos: 2998626/3000000.0 - Recompensa: 0.30540499368437074\n",
            "0.30540499368437074\n",
            "Total de pasos: 2998627/3000000.0 - Recompensa: -0.8280312495477149\n",
            "Total de pasos: 2998628/3000000.0 - Recompensa: -2.222991673674651\n",
            "Total de pasos: 2998629/3000000.0 - Recompensa: -0.8474658035242867\n",
            "Total de pasos: 2998630/3000000.0 - Recompensa: -1.297464802615476\n",
            "Total de pasos: 2998631/3000000.0 - Recompensa: -1.9049216069727375\n",
            "Total de pasos: 2998632/3000000.0 - Recompensa: -4.814081187373234\n",
            "Total de pasos: 2998633/3000000.0 - Recompensa: -1.2945934201906057\n",
            "Total de pasos: 2998634/3000000.0 - Recompensa: -2.079591711669356\n",
            "Total de pasos: 2998635/3000000.0 - Recompensa: -0.25865840992546146\n",
            "Total de pasos: 2998636/3000000.0 - Recompensa: -0.11840950574779235\n",
            "Total de pasos: 2998637/3000000.0 - Recompensa: 0.2783668395321865\n",
            "0.2783668395321865\n",
            "Total de pasos: 2998638/3000000.0 - Recompensa: -0.1386183214340151\n",
            "Total de pasos: 2998639/3000000.0 - Recompensa: 0.16754385067366168\n",
            "0.16754385067366168\n",
            "Total de pasos: 2998640/3000000.0 - Recompensa: -1.4750674848779204\n",
            "Total de pasos: 2998641/3000000.0 - Recompensa: -6.113761607929629\n",
            "Total de pasos: 2998642/3000000.0 - Recompensa: 0.5171188181499908\n",
            "0.5171188181499908\n",
            "Total de pasos: 2998643/3000000.0 - Recompensa: -2.9983078806903247\n",
            "Total de pasos: 2998644/3000000.0 - Recompensa: -2.2970673165021704\n",
            "Total de pasos: 2998645/3000000.0 - Recompensa: -1.833492311185842\n",
            "Total de pasos: 2998646/3000000.0 - Recompensa: -0.029971914656213017\n",
            "Total de pasos: 2998647/3000000.0 - Recompensa: 0.27706819513390507\n",
            "0.27706819513390507\n",
            "Total de pasos: 2998648/3000000.0 - Recompensa: -0.007925167125086896\n",
            "Total de pasos: 2998649/3000000.0 - Recompensa: -1.1198229464109528\n",
            "Total de pasos: 2998650/3000000.0 - Recompensa: -1.3091883332257133\n",
            "Total de pasos: 2998651/3000000.0 - Recompensa: -1.9058515676262733\n",
            "Total de pasos: 2998652/3000000.0 - Recompensa: -1.643963055039554\n",
            "Total de pasos: 2998653/3000000.0 - Recompensa: 0.23833839868438353\n",
            "0.23833839868438353\n",
            "Total de pasos: 2998654/3000000.0 - Recompensa: -3.4197136320791968\n",
            "Total de pasos: 2998655/3000000.0 - Recompensa: 1.06925044433815\n",
            "1.06925044433815\n",
            "Total de pasos: 2998656/3000000.0 - Recompensa: -2.2499766591080723\n",
            "Total de pasos: 2998657/3000000.0 - Recompensa: 0.5494079991698289\n",
            "0.5494079991698289\n",
            "Total de pasos: 2998658/3000000.0 - Recompensa: -1.0342777054563128\n",
            "Total de pasos: 2998659/3000000.0 - Recompensa: -1.8364668033161062\n",
            "Total de pasos: 2998660/3000000.0 - Recompensa: 0.2484467642963005\n",
            "0.2484467642963005\n",
            "Total de pasos: 2998661/3000000.0 - Recompensa: 0.15151578866937715\n",
            "0.15151578866937715\n",
            "Total de pasos: 2998662/3000000.0 - Recompensa: -2.534959013887178\n",
            "Total de pasos: 2998663/3000000.0 - Recompensa: -1.5067593939038817\n",
            "Total de pasos: 2998664/3000000.0 - Recompensa: -1.329861049825215\n",
            "Total de pasos: 2998665/3000000.0 - Recompensa: 0.2876946437725875\n",
            "0.2876946437725875\n",
            "Total de pasos: 2998666/3000000.0 - Recompensa: -1.3120428574945797\n",
            "Total de pasos: 2998667/3000000.0 - Recompensa: -1.3631884149451114\n",
            "Total de pasos: 2998668/3000000.0 - Recompensa: -0.19807780139728096\n",
            "Total de pasos: 2998669/3000000.0 - Recompensa: -0.9857749835019772\n",
            "Total de pasos: 2998670/3000000.0 - Recompensa: -0.9041982771672388\n",
            "Total de pasos: 2998671/3000000.0 - Recompensa: -0.6937063560181381\n",
            "Total de pasos: 2998672/3000000.0 - Recompensa: -1.5805158506987445\n",
            "Total de pasos: 2998673/3000000.0 - Recompensa: -1.9366848513483779\n",
            "Total de pasos: 2998674/3000000.0 - Recompensa: -0.44934557931281416\n",
            "Total de pasos: 2998675/3000000.0 - Recompensa: 0.316206157611844\n",
            "0.316206157611844\n",
            "Total de pasos: 2998676/3000000.0 - Recompensa: 0.4333370192638763\n",
            "0.4333370192638763\n",
            "Total de pasos: 2998677/3000000.0 - Recompensa: -0.66358155590107\n",
            "Total de pasos: 2998678/3000000.0 - Recompensa: 0.6484175082429658\n",
            "0.6484175082429658\n",
            "Total de pasos: 2998679/3000000.0 - Recompensa: -0.9779508822418687\n",
            "Total de pasos: 2998680/3000000.0 - Recompensa: -3.550518865612231\n",
            "Total de pasos: 2998681/3000000.0 - Recompensa: -0.8722921130473402\n",
            "Total de pasos: 2998682/3000000.0 - Recompensa: -3.229488560780263\n",
            "Total de pasos: 2998683/3000000.0 - Recompensa: 0.5525808505305407\n",
            "0.5525808505305407\n",
            "Total de pasos: 2998684/3000000.0 - Recompensa: -2.345393314847282\n",
            "Total de pasos: 2998685/3000000.0 - Recompensa: -0.2452223053206904\n",
            "Total de pasos: 2998686/3000000.0 - Recompensa: -1.5803247569494672\n",
            "Total de pasos: 2998687/3000000.0 - Recompensa: -0.6223035171788307\n",
            "Total de pasos: 2998688/3000000.0 - Recompensa: 0.3158332760914652\n",
            "0.3158332760914652\n",
            "Total de pasos: 2998689/3000000.0 - Recompensa: -1.4156160771112105\n",
            "Total de pasos: 2998690/3000000.0 - Recompensa: -0.32679309795147216\n",
            "Total de pasos: 2998691/3000000.0 - Recompensa: -0.2806520342374322\n",
            "Total de pasos: 2998692/3000000.0 - Recompensa: -2.1166855107157656\n",
            "Total de pasos: 2998693/3000000.0 - Recompensa: -1.7131282376123123\n",
            "Total de pasos: 2998694/3000000.0 - Recompensa: 0.3955869263985802\n",
            "0.3955869263985802\n",
            "Total de pasos: 2998695/3000000.0 - Recompensa: -1.8874389979659743\n",
            "Total de pasos: 2998696/3000000.0 - Recompensa: 0.025391311606476424\n",
            "0.025391311606476424\n",
            "Total de pasos: 2998697/3000000.0 - Recompensa: -0.6698515422359368\n",
            "Total de pasos: 2998698/3000000.0 - Recompensa: -2.264068613722232\n",
            "Total de pasos: 2998699/3000000.0 - Recompensa: -1.0748501913233144\n",
            "Total de pasos: 2998700/3000000.0 - Recompensa: -1.599348584016256\n",
            "Total de pasos: 2998701/3000000.0 - Recompensa: -2.4141602800854502\n",
            "Total de pasos: 2998702/3000000.0 - Recompensa: -0.6080653465952055\n",
            "Total de pasos: 2998703/3000000.0 - Recompensa: -2.2673427151846286\n",
            "Total de pasos: 2998704/3000000.0 - Recompensa: -2.3602846915197198\n",
            "Total de pasos: 2998705/3000000.0 - Recompensa: 0.531602137167185\n",
            "0.531602137167185\n",
            "Total de pasos: 2998706/3000000.0 - Recompensa: 0.2753639365550546\n",
            "0.2753639365550546\n",
            "Total de pasos: 2998707/3000000.0 - Recompensa: -0.1565963521505042\n",
            "Total de pasos: 2998708/3000000.0 - Recompensa: -0.26467752818755563\n",
            "Total de pasos: 2998709/3000000.0 - Recompensa: -0.2728923788137969\n",
            "Total de pasos: 2998710/3000000.0 - Recompensa: -0.5832418489537979\n",
            "Total de pasos: 2998711/3000000.0 - Recompensa: 0.46814435092552964\n",
            "0.46814435092552964\n",
            "Total de pasos: 2998712/3000000.0 - Recompensa: -0.1266466644903435\n",
            "Total de pasos: 2998713/3000000.0 - Recompensa: -0.8541282943803481\n",
            "Total de pasos: 2998714/3000000.0 - Recompensa: -0.23351057952377535\n",
            "Total de pasos: 2998715/3000000.0 - Recompensa: -1.338878680240114\n",
            "Total de pasos: 2998716/3000000.0 - Recompensa: -1.7493009579333314\n",
            "Total de pasos: 2998717/3000000.0 - Recompensa: 0.11715895629289891\n",
            "0.11715895629289891\n",
            "Total de pasos: 2998718/3000000.0 - Recompensa: -0.7549968298399248\n",
            "Total de pasos: 2998719/3000000.0 - Recompensa: -0.004706980213593864\n",
            "Total de pasos: 2998720/3000000.0 - Recompensa: -0.9242923406136858\n",
            "Total de pasos: 2998721/3000000.0 - Recompensa: -0.013485031495872823\n",
            "Total de pasos: 2998722/3000000.0 - Recompensa: -0.3418356221733395\n",
            "Total de pasos: 2998723/3000000.0 - Recompensa: -0.832890746062492\n",
            "Total de pasos: 2998724/3000000.0 - Recompensa: -1.0477182695246108\n",
            "Total de pasos: 2998725/3000000.0 - Recompensa: -0.045981173134565456\n",
            "Total de pasos: 2998726/3000000.0 - Recompensa: -1.3969803447562876\n",
            "Total de pasos: 2998727/3000000.0 - Recompensa: -0.16472536250600728\n",
            "Total de pasos: 2998728/3000000.0 - Recompensa: -2.9535866546774714\n",
            "Total de pasos: 2998729/3000000.0 - Recompensa: 0.7827949687466613\n",
            "0.7827949687466613\n",
            "Total de pasos: 2998730/3000000.0 - Recompensa: 0.05606236580542617\n",
            "0.05606236580542617\n",
            "Total de pasos: 2998731/3000000.0 - Recompensa: -0.7881229951645685\n",
            "Total de pasos: 2998732/3000000.0 - Recompensa: -0.6838777705995687\n",
            "Total de pasos: 2998733/3000000.0 - Recompensa: -1.5389708409256124\n",
            "Total de pasos: 2998734/3000000.0 - Recompensa: -0.5718326101913827\n",
            "Total de pasos: 2998735/3000000.0 - Recompensa: -0.6131131630804336\n",
            "Total de pasos: 2998736/3000000.0 - Recompensa: -0.6774628964630451\n",
            "Total de pasos: 2998737/3000000.0 - Recompensa: -0.6466018199010743\n",
            "Total de pasos: 2998738/3000000.0 - Recompensa: -2.3121537078503853\n",
            "Total de pasos: 2998739/3000000.0 - Recompensa: -0.8797075161714168\n",
            "Total de pasos: 2998740/3000000.0 - Recompensa: -0.1471817945714256\n",
            "Total de pasos: 2998741/3000000.0 - Recompensa: -0.7510817359665587\n",
            "Total de pasos: 2998742/3000000.0 - Recompensa: 0.05728011291447452\n",
            "0.05728011291447452\n",
            "Total de pasos: 2998743/3000000.0 - Recompensa: 0.3364441247033543\n",
            "0.3364441247033543\n",
            "Total de pasos: 2998744/3000000.0 - Recompensa: -2.2072167363650887\n",
            "Total de pasos: 2998745/3000000.0 - Recompensa: 0.17255431201129454\n",
            "0.17255431201129454\n",
            "Total de pasos: 2998746/3000000.0 - Recompensa: -0.20457127749403387\n",
            "Total de pasos: 2998747/3000000.0 - Recompensa: 0.45725782021145245\n",
            "0.45725782021145245\n",
            "Total de pasos: 2998748/3000000.0 - Recompensa: 0.609456487557636\n",
            "0.609456487557636\n",
            "Total de pasos: 2998749/3000000.0 - Recompensa: -0.4348000059806071\n",
            "Total de pasos: 2998750/3000000.0 - Recompensa: -1.1901894149014758\n",
            "Total de pasos: 2998751/3000000.0 - Recompensa: 0.11265003123143086\n",
            "0.11265003123143086\n",
            "Total de pasos: 2998752/3000000.0 - Recompensa: -1.077763152135648\n",
            "Total de pasos: 2998753/3000000.0 - Recompensa: -0.4187600140659325\n",
            "Total de pasos: 2998754/3000000.0 - Recompensa: -0.02303962907903495\n",
            "Total de pasos: 2998755/3000000.0 - Recompensa: 0.01254768781353105\n",
            "0.01254768781353105\n",
            "Total de pasos: 2998756/3000000.0 - Recompensa: -1.9134739827941578\n",
            "Total de pasos: 2998757/3000000.0 - Recompensa: -1.2024793539000525\n",
            "Total de pasos: 2998758/3000000.0 - Recompensa: -1.9675311298445028\n",
            "Total de pasos: 2998759/3000000.0 - Recompensa: -1.2625749898042906\n",
            "Total de pasos: 2998760/3000000.0 - Recompensa: -2.9872781646027367\n",
            "Total de pasos: 2998761/3000000.0 - Recompensa: 0.16167434491506114\n",
            "0.16167434491506114\n",
            "Total de pasos: 2998762/3000000.0 - Recompensa: 0.05050888441174636\n",
            "0.05050888441174636\n",
            "Total de pasos: 2998763/3000000.0 - Recompensa: -0.45267792027138826\n",
            "Total de pasos: 2998764/3000000.0 - Recompensa: -2.500462904015011\n",
            "Total de pasos: 2998765/3000000.0 - Recompensa: -1.572165067116717\n",
            "Total de pasos: 2998766/3000000.0 - Recompensa: -0.3797205441264525\n",
            "Total de pasos: 2998767/3000000.0 - Recompensa: 0.5612689467285931\n",
            "0.5612689467285931\n",
            "Total de pasos: 2998768/3000000.0 - Recompensa: -0.8979984618725098\n",
            "Total de pasos: 2998769/3000000.0 - Recompensa: -0.35348221659078877\n",
            "Total de pasos: 2998770/3000000.0 - Recompensa: 0.5481820324282272\n",
            "0.5481820324282272\n",
            "Total de pasos: 2998771/3000000.0 - Recompensa: -0.6074766726289218\n",
            "Total de pasos: 2998772/3000000.0 - Recompensa: -2.214643386506769\n",
            "Total de pasos: 2998773/3000000.0 - Recompensa: -2.291458612018547\n",
            "Total de pasos: 2998774/3000000.0 - Recompensa: -1.7380176046084173\n",
            "Total de pasos: 2998775/3000000.0 - Recompensa: -1.7758717636286274\n",
            "Total de pasos: 2998776/3000000.0 - Recompensa: -1.1529971723803347\n",
            "Total de pasos: 2998777/3000000.0 - Recompensa: -1.806631390907678\n",
            "Total de pasos: 2998778/3000000.0 - Recompensa: -0.8505526464182263\n",
            "Total de pasos: 2998779/3000000.0 - Recompensa: -1.064018376655469\n",
            "Total de pasos: 2998780/3000000.0 - Recompensa: -1.1797923241159904\n",
            "Total de pasos: 2998781/3000000.0 - Recompensa: -0.3826211893479651\n",
            "Total de pasos: 2998782/3000000.0 - Recompensa: 0.8941321591968613\n",
            "0.8941321591968613\n",
            "Total de pasos: 2998783/3000000.0 - Recompensa: -1.5989331885380298\n",
            "Total de pasos: 2998784/3000000.0 - Recompensa: -2.693251802846118\n",
            "Total de pasos: 2998785/3000000.0 - Recompensa: -0.4200366541529091\n",
            "Total de pasos: 2998786/3000000.0 - Recompensa: -0.3972923065793017\n",
            "Total de pasos: 2998787/3000000.0 - Recompensa: 0.25912481731807824\n",
            "0.25912481731807824\n",
            "Total de pasos: 2998788/3000000.0 - Recompensa: -1.8588669372858155\n",
            "Total de pasos: 2998789/3000000.0 - Recompensa: 0.979875207583623\n",
            "0.979875207583623\n",
            "Total de pasos: 2998790/3000000.0 - Recompensa: -1.6306730512764582\n",
            "Total de pasos: 2998791/3000000.0 - Recompensa: -0.07182508779441701\n",
            "Total de pasos: 2998792/3000000.0 - Recompensa: -2.473657604366446\n",
            "Total de pasos: 2998793/3000000.0 - Recompensa: -0.7753716136541792\n",
            "Total de pasos: 2998794/3000000.0 - Recompensa: -0.6482075972747031\n",
            "Total de pasos: 2998795/3000000.0 - Recompensa: -2.8358255082830146\n",
            "Total de pasos: 2998796/3000000.0 - Recompensa: -1.1078191861848035\n",
            "Total de pasos: 2998797/3000000.0 - Recompensa: -0.4100415762119075\n",
            "Total de pasos: 2998798/3000000.0 - Recompensa: -1.722504071925968\n",
            "Total de pasos: 2998799/3000000.0 - Recompensa: -1.4083056087627017\n",
            "Total de pasos: 2998800/3000000.0 - Recompensa: 0.4351616907505935\n",
            "0.4351616907505935\n",
            "Total de pasos: 2998801/3000000.0 - Recompensa: -3.4493002980710705\n",
            "Total de pasos: 2998802/3000000.0 - Recompensa: -1.6067776670852467\n",
            "Total de pasos: 2998803/3000000.0 - Recompensa: -0.8646420809443093\n",
            "Total de pasos: 2998804/3000000.0 - Recompensa: -1.6303405824058346\n",
            "Total de pasos: 2998805/3000000.0 - Recompensa: -0.6186087062126256\n",
            "Total de pasos: 2998806/3000000.0 - Recompensa: -0.947874026805426\n",
            "Total de pasos: 2998807/3000000.0 - Recompensa: -0.9272128630589593\n",
            "Total de pasos: 2998808/3000000.0 - Recompensa: -0.4821359671272501\n",
            "Total de pasos: 2998809/3000000.0 - Recompensa: -0.7931937687332223\n",
            "Total de pasos: 2998810/3000000.0 - Recompensa: -0.9456978173527147\n",
            "Total de pasos: 2998811/3000000.0 - Recompensa: 0.17889429724698996\n",
            "0.17889429724698996\n",
            "Total de pasos: 2998812/3000000.0 - Recompensa: -1.084741138085071\n",
            "Total de pasos: 2998813/3000000.0 - Recompensa: -5.286255915900903\n",
            "Total de pasos: 2998814/3000000.0 - Recompensa: -0.8432516542916157\n",
            "Total de pasos: 2998815/3000000.0 - Recompensa: -2.182903850281687\n",
            "Total de pasos: 2998816/3000000.0 - Recompensa: -0.46416864488191695\n",
            "Total de pasos: 2998817/3000000.0 - Recompensa: -0.6606212234034394\n",
            "Total de pasos: 2998818/3000000.0 - Recompensa: -0.08842811857264801\n",
            "Total de pasos: 2998819/3000000.0 - Recompensa: -1.4570289750947674\n",
            "Total de pasos: 2998820/3000000.0 - Recompensa: 0.030776913238640125\n",
            "0.030776913238640125\n",
            "Total de pasos: 2998821/3000000.0 - Recompensa: -1.0099060840170573\n",
            "Total de pasos: 2998822/3000000.0 - Recompensa: -0.08331608895949488\n",
            "Total de pasos: 2998823/3000000.0 - Recompensa: -0.6467061643071766\n",
            "Total de pasos: 2998824/3000000.0 - Recompensa: -0.12913591291375665\n",
            "Total de pasos: 2998825/3000000.0 - Recompensa: -0.6514547813944626\n",
            "Total de pasos: 2998826/3000000.0 - Recompensa: -0.858417494947272\n",
            "Total de pasos: 2998827/3000000.0 - Recompensa: -1.1267220049092657\n",
            "Total de pasos: 2998828/3000000.0 - Recompensa: -0.9253580451711982\n",
            "Total de pasos: 2998829/3000000.0 - Recompensa: -0.14266733649529956\n",
            "Total de pasos: 2998830/3000000.0 - Recompensa: -0.7189891060590948\n",
            "Total de pasos: 2998831/3000000.0 - Recompensa: -1.1680345955736975\n",
            "Total de pasos: 2998832/3000000.0 - Recompensa: -3.390036141585944\n",
            "Total de pasos: 2998833/3000000.0 - Recompensa: 0.6501222842484871\n",
            "0.6501222842484871\n",
            "Total de pasos: 2998834/3000000.0 - Recompensa: 0.3990066550420811\n",
            "0.3990066550420811\n",
            "Total de pasos: 2998835/3000000.0 - Recompensa: -0.7838034029526336\n",
            "Total de pasos: 2998836/3000000.0 - Recompensa: -0.7674589242104094\n",
            "Total de pasos: 2998837/3000000.0 - Recompensa: -1.5029693581340655\n",
            "Total de pasos: 2998838/3000000.0 - Recompensa: -1.8496758777472944\n",
            "Total de pasos: 2998839/3000000.0 - Recompensa: -1.23144742702213\n",
            "Total de pasos: 2998840/3000000.0 - Recompensa: -3.014800907958793\n",
            "Total de pasos: 2998841/3000000.0 - Recompensa: -0.44548788255464783\n",
            "Total de pasos: 2998842/3000000.0 - Recompensa: -0.7719583136805549\n",
            "Total de pasos: 2998843/3000000.0 - Recompensa: -0.9383871490005701\n",
            "Total de pasos: 2998844/3000000.0 - Recompensa: 0.2697986028388397\n",
            "0.2697986028388397\n",
            "Total de pasos: 2998845/3000000.0 - Recompensa: -0.19039054274375458\n",
            "Total de pasos: 2998846/3000000.0 - Recompensa: -0.9140051048181554\n",
            "Total de pasos: 2998847/3000000.0 - Recompensa: -0.6542583428256864\n",
            "Total de pasos: 2998848/3000000.0 - Recompensa: -0.28947157572162824\n",
            "Total de pasos: 2998849/3000000.0 - Recompensa: 0.8445759319933018\n",
            "0.8445759319933018\n",
            "Total de pasos: 2998850/3000000.0 - Recompensa: 0.634940561132381\n",
            "0.634940561132381\n",
            "Total de pasos: 2998851/3000000.0 - Recompensa: -0.06972870332780304\n",
            "Total de pasos: 2998852/3000000.0 - Recompensa: -0.715599363700889\n",
            "Total de pasos: 2998853/3000000.0 - Recompensa: 0.5948496448463351\n",
            "0.5948496448463351\n",
            "Total de pasos: 2998854/3000000.0 - Recompensa: -0.021726194784546238\n",
            "Total de pasos: 2998855/3000000.0 - Recompensa: -2.7421267233129005\n",
            "Total de pasos: 2998856/3000000.0 - Recompensa: -1.455330647223393\n",
            "Total de pasos: 2998857/3000000.0 - Recompensa: -0.24745460708982484\n",
            "Total de pasos: 2998858/3000000.0 - Recompensa: -0.012610410027854624\n",
            "Total de pasos: 2998859/3000000.0 - Recompensa: -0.2859910330298273\n",
            "Total de pasos: 2998860/3000000.0 - Recompensa: 0.20273639238915403\n",
            "0.20273639238915403\n",
            "Total de pasos: 2998861/3000000.0 - Recompensa: -1.6546635116641317\n",
            "Total de pasos: 2998862/3000000.0 - Recompensa: 0.2864160337073055\n",
            "0.2864160337073055\n",
            "Total de pasos: 2998863/3000000.0 - Recompensa: -1.195387301666552\n",
            "Total de pasos: 2998864/3000000.0 - Recompensa: 0.4582721357297614\n",
            "0.4582721357297614\n",
            "Total de pasos: 2998865/3000000.0 - Recompensa: 0.5203614147431878\n",
            "0.5203614147431878\n",
            "Total de pasos: 2998866/3000000.0 - Recompensa: 0.4758189713646811\n",
            "0.4758189713646811\n",
            "Total de pasos: 2998867/3000000.0 - Recompensa: -3.1486209874379694\n",
            "Total de pasos: 2998868/3000000.0 - Recompensa: -0.7206711150981164\n",
            "Total de pasos: 2998869/3000000.0 - Recompensa: 0.4165018244495519\n",
            "0.4165018244495519\n",
            "Total de pasos: 2998870/3000000.0 - Recompensa: -1.2239645774483914\n",
            "Total de pasos: 2998871/3000000.0 - Recompensa: -2.011145725764474\n",
            "Total de pasos: 2998872/3000000.0 - Recompensa: -0.2508563420494346\n",
            "Total de pasos: 2998873/3000000.0 - Recompensa: -0.7680935801161256\n",
            "Total de pasos: 2998874/3000000.0 - Recompensa: -0.2852164125760657\n",
            "Total de pasos: 2998875/3000000.0 - Recompensa: 0.2281226128991841\n",
            "0.2281226128991841\n",
            "Total de pasos: 2998876/3000000.0 - Recompensa: 0.027683744924434345\n",
            "0.027683744924434345\n",
            "Total de pasos: 2998877/3000000.0 - Recompensa: 0.21998595845547206\n",
            "0.21998595845547206\n",
            "Total de pasos: 2998878/3000000.0 - Recompensa: -0.4152485514520329\n",
            "Total de pasos: 2998879/3000000.0 - Recompensa: -1.7172046409487063\n",
            "Total de pasos: 2998880/3000000.0 - Recompensa: -0.3893052779418092\n",
            "Total de pasos: 2998881/3000000.0 - Recompensa: -1.1944724284779673\n",
            "Total de pasos: 2998882/3000000.0 - Recompensa: -0.3495997821247128\n",
            "Total de pasos: 2998883/3000000.0 - Recompensa: 0.06375696306364462\n",
            "0.06375696306364462\n",
            "Total de pasos: 2998884/3000000.0 - Recompensa: -0.37065718980817175\n",
            "Total de pasos: 2998885/3000000.0 - Recompensa: -0.8270590948693756\n",
            "Total de pasos: 2998886/3000000.0 - Recompensa: -1.1851833997041303\n",
            "Total de pasos: 2998887/3000000.0 - Recompensa: -1.0615500637252202\n",
            "Total de pasos: 2998888/3000000.0 - Recompensa: 0.7458623837443255\n",
            "0.7458623837443255\n",
            "Total de pasos: 2998889/3000000.0 - Recompensa: -0.8609959204142565\n",
            "Total de pasos: 2998890/3000000.0 - Recompensa: -0.5728816932696285\n",
            "Total de pasos: 2998891/3000000.0 - Recompensa: 0.02433741542052248\n",
            "0.02433741542052248\n",
            "Total de pasos: 2998892/3000000.0 - Recompensa: -1.7068041759309476\n",
            "Total de pasos: 2998893/3000000.0 - Recompensa: -0.15347328783517927\n",
            "Total de pasos: 2998894/3000000.0 - Recompensa: -1.0917912803858065\n",
            "Total de pasos: 2998895/3000000.0 - Recompensa: -1.2999314994512843\n",
            "Total de pasos: 2998896/3000000.0 - Recompensa: -0.3050954863497915\n",
            "Total de pasos: 2998897/3000000.0 - Recompensa: 0.010888960397149317\n",
            "0.010888960397149317\n",
            "Total de pasos: 2998898/3000000.0 - Recompensa: -2.3231485852505407\n",
            "Total de pasos: 2998899/3000000.0 - Recompensa: 0.31688758085120183\n",
            "0.31688758085120183\n",
            "Total de pasos: 2998900/3000000.0 - Recompensa: 0.6636273105947874\n",
            "0.6636273105947874\n",
            "Total de pasos: 2998901/3000000.0 - Recompensa: -0.1851123654377454\n",
            "Total de pasos: 2998902/3000000.0 - Recompensa: -1.2997073999939652\n",
            "Total de pasos: 2998903/3000000.0 - Recompensa: -0.2209006979194495\n",
            "Total de pasos: 2998904/3000000.0 - Recompensa: -2.927189283558879\n",
            "Total de pasos: 2998905/3000000.0 - Recompensa: -0.9409645010031811\n",
            "Total de pasos: 2998906/3000000.0 - Recompensa: -0.013479357799800529\n",
            "Total de pasos: 2998907/3000000.0 - Recompensa: -1.0420404766577374\n",
            "Total de pasos: 2998908/3000000.0 - Recompensa: -0.786192996801056\n",
            "Total de pasos: 2998909/3000000.0 - Recompensa: -3.009643105852724\n",
            "Total de pasos: 2998910/3000000.0 - Recompensa: 0.4589345201682788\n",
            "0.4589345201682788\n",
            "Total de pasos: 2998911/3000000.0 - Recompensa: 0.840289071634184\n",
            "0.840289071634184\n",
            "Total de pasos: 2998912/3000000.0 - Recompensa: -0.5326611763604128\n",
            "Total de pasos: 2998913/3000000.0 - Recompensa: -0.587628086043612\n",
            "Total de pasos: 2998914/3000000.0 - Recompensa: -0.004624377929346141\n",
            "Total de pasos: 2998915/3000000.0 - Recompensa: -0.15916352478167664\n",
            "Total de pasos: 2998916/3000000.0 - Recompensa: -1.2065352173601769\n",
            "Total de pasos: 2998917/3000000.0 - Recompensa: -1.1867901185174656\n",
            "Total de pasos: 2998918/3000000.0 - Recompensa: -0.30725419579971225\n",
            "Total de pasos: 2998919/3000000.0 - Recompensa: -2.06429203788452\n",
            "Total de pasos: 2998920/3000000.0 - Recompensa: -4.253755557526071\n",
            "Total de pasos: 2998921/3000000.0 - Recompensa: -1.2123082670405227\n",
            "Total de pasos: 2998922/3000000.0 - Recompensa: -2.4003251997080133\n",
            "Total de pasos: 2998923/3000000.0 - Recompensa: 0.41847205663398024\n",
            "0.41847205663398024\n",
            "Total de pasos: 2998924/3000000.0 - Recompensa: -4.072350420944339\n",
            "Total de pasos: 2998925/3000000.0 - Recompensa: 0.9822328947204534\n",
            "0.9822328947204534\n",
            "Total de pasos: 2998926/3000000.0 - Recompensa: -3.5225638161296615\n",
            "Total de pasos: 2998927/3000000.0 - Recompensa: -1.9893931937825404\n",
            "Total de pasos: 2998928/3000000.0 - Recompensa: -1.3576710662336926\n",
            "Total de pasos: 2998929/3000000.0 - Recompensa: -3.9399253155311977\n",
            "Total de pasos: 2998930/3000000.0 - Recompensa: -1.2267964722892863\n",
            "Total de pasos: 2998931/3000000.0 - Recompensa: -2.0971479666864905\n",
            "Total de pasos: 2998932/3000000.0 - Recompensa: -0.42713871236961365\n",
            "Total de pasos: 2998933/3000000.0 - Recompensa: -1.2136647802936495\n",
            "Total de pasos: 2998934/3000000.0 - Recompensa: 0.6244532598848295\n",
            "0.6244532598848295\n",
            "Total de pasos: 2998935/3000000.0 - Recompensa: 0.14213169309169546\n",
            "0.14213169309169546\n",
            "Total de pasos: 2998936/3000000.0 - Recompensa: -0.17205539343597342\n",
            "Total de pasos: 2998937/3000000.0 - Recompensa: -0.9068813105138703\n",
            "Total de pasos: 2998938/3000000.0 - Recompensa: 0.5961949072647381\n",
            "0.5961949072647381\n",
            "Total de pasos: 2998939/3000000.0 - Recompensa: -0.09382151983036335\n",
            "Total de pasos: 2998940/3000000.0 - Recompensa: -2.297831997987058\n",
            "Total de pasos: 2998941/3000000.0 - Recompensa: -0.1489809546314727\n",
            "Total de pasos: 2998942/3000000.0 - Recompensa: -0.9461957206711731\n",
            "Total de pasos: 2998943/3000000.0 - Recompensa: -1.802916218957141\n",
            "Total de pasos: 2998944/3000000.0 - Recompensa: -1.0784917445969648\n",
            "Total de pasos: 2998945/3000000.0 - Recompensa: -1.8877827398119846\n",
            "Total de pasos: 2998946/3000000.0 - Recompensa: -0.2580095627267685\n",
            "Total de pasos: 2998947/3000000.0 - Recompensa: -0.03337397098374911\n",
            "Total de pasos: 2998948/3000000.0 - Recompensa: -1.1495072455163209\n",
            "Total de pasos: 2998949/3000000.0 - Recompensa: -2.7958458046095744\n",
            "Total de pasos: 2998950/3000000.0 - Recompensa: -0.40686629605991415\n",
            "Total de pasos: 2998951/3000000.0 - Recompensa: 0.3925439723406507\n",
            "0.3925439723406507\n",
            "Total de pasos: 2998952/3000000.0 - Recompensa: -2.0918382848883907\n",
            "Total de pasos: 2998953/3000000.0 - Recompensa: 0.6692380909477074\n",
            "0.6692380909477074\n",
            "Total de pasos: 2998954/3000000.0 - Recompensa: -0.5606323705187813\n",
            "Total de pasos: 2998955/3000000.0 - Recompensa: -4.490193612056285\n",
            "Total de pasos: 2998956/3000000.0 - Recompensa: -0.6308191289783338\n",
            "Total de pasos: 2998957/3000000.0 - Recompensa: -0.22465927480645426\n",
            "Total de pasos: 2998958/3000000.0 - Recompensa: -0.09486829762530063\n",
            "Total de pasos: 2998959/3000000.0 - Recompensa: 0.24313441117344098\n",
            "0.24313441117344098\n",
            "Total de pasos: 2998960/3000000.0 - Recompensa: -1.5467992121008036\n",
            "Total de pasos: 2998961/3000000.0 - Recompensa: -0.8250775353601444\n",
            "Total de pasos: 2998962/3000000.0 - Recompensa: 0.09016170700844078\n",
            "0.09016170700844078\n",
            "Total de pasos: 2998963/3000000.0 - Recompensa: -0.6010195491605177\n",
            "Total de pasos: 2998964/3000000.0 - Recompensa: -1.5501514193306272\n",
            "Total de pasos: 2998965/3000000.0 - Recompensa: -0.2620220919392791\n",
            "Total de pasos: 2998966/3000000.0 - Recompensa: -0.18084913824674534\n",
            "Total de pasos: 2998967/3000000.0 - Recompensa: 0.14263615890742248\n",
            "0.14263615890742248\n",
            "Total de pasos: 2998968/3000000.0 - Recompensa: -1.1501968721961848\n",
            "Total de pasos: 2998969/3000000.0 - Recompensa: -0.46539326065991415\n",
            "Total de pasos: 2998970/3000000.0 - Recompensa: -1.6108105834232973\n",
            "Total de pasos: 2998971/3000000.0 - Recompensa: -1.0459097505836723\n",
            "Total de pasos: 2998972/3000000.0 - Recompensa: -0.6425995362478026\n",
            "Total de pasos: 2998973/3000000.0 - Recompensa: -0.34951286981996066\n",
            "Total de pasos: 2998974/3000000.0 - Recompensa: -1.2208860646110087\n",
            "Total de pasos: 2998975/3000000.0 - Recompensa: -0.9220909965881087\n",
            "Total de pasos: 2998976/3000000.0 - Recompensa: -0.0023347436434043023\n",
            "Total de pasos: 2998977/3000000.0 - Recompensa: -2.495418132123059\n",
            "Total de pasos: 2998978/3000000.0 - Recompensa: -0.0759123715738877\n",
            "Total de pasos: 2998979/3000000.0 - Recompensa: -2.247552714856397\n",
            "Total de pasos: 2998980/3000000.0 - Recompensa: -0.3022970944387574\n",
            "Total de pasos: 2998981/3000000.0 - Recompensa: -0.8830974980465502\n",
            "Total de pasos: 2998982/3000000.0 - Recompensa: -1.0279918199580325\n",
            "Total de pasos: 2998983/3000000.0 - Recompensa: -2.501117867600299\n",
            "Total de pasos: 2998984/3000000.0 - Recompensa: -0.553531493049383\n",
            "Total de pasos: 2998985/3000000.0 - Recompensa: 0.17425889846072415\n",
            "0.17425889846072415\n",
            "Total de pasos: 2998986/3000000.0 - Recompensa: -0.6445993352582511\n",
            "Total de pasos: 2998987/3000000.0 - Recompensa: 0.32011170292745794\n",
            "0.32011170292745794\n",
            "Total de pasos: 2998988/3000000.0 - Recompensa: -1.1342774105075732\n",
            "Total de pasos: 2998989/3000000.0 - Recompensa: -2.658606442523052\n",
            "Total de pasos: 2998990/3000000.0 - Recompensa: -0.6114740600119759\n",
            "Total de pasos: 2998991/3000000.0 - Recompensa: 0.060497076837885716\n",
            "0.060497076837885716\n",
            "Total de pasos: 2998992/3000000.0 - Recompensa: 0.18780650211666855\n",
            "0.18780650211666855\n",
            "Total de pasos: 2998993/3000000.0 - Recompensa: -0.5232243460766834\n",
            "Total de pasos: 2998994/3000000.0 - Recompensa: -1.764415760064449\n",
            "Total de pasos: 2998995/3000000.0 - Recompensa: -0.5513374308412662\n",
            "Total de pasos: 2998996/3000000.0 - Recompensa: -2.058434681190318\n",
            "Total de pasos: 2998997/3000000.0 - Recompensa: -5.49839275309996\n",
            "Total de pasos: 2998998/3000000.0 - Recompensa: -1.5021236111382323\n",
            "Total de pasos: 2998999/3000000.0 - Recompensa: -0.2356565109747936\n",
            "Total de pasos: 2999000/3000000.0 - Recompensa: -0.32720875731104765\n",
            "Total de pasos: 2999001/3000000.0 - Recompensa: -1.0550469767794184\n",
            "Total de pasos: 2999002/3000000.0 - Recompensa: -1.68257666965128\n",
            "Total de pasos: 2999003/3000000.0 - Recompensa: 0.0035232232101413685\n",
            "0.0035232232101413685\n",
            "Total de pasos: 2999004/3000000.0 - Recompensa: 0.6267215643990883\n",
            "0.6267215643990883\n",
            "Total de pasos: 2999005/3000000.0 - Recompensa: -1.367188516647914\n",
            "Total de pasos: 2999006/3000000.0 - Recompensa: -4.956559394878595\n",
            "Total de pasos: 2999007/3000000.0 - Recompensa: 0.08797156989366733\n",
            "0.08797156989366733\n",
            "Total de pasos: 2999008/3000000.0 - Recompensa: -1.9714232190999468\n",
            "Total de pasos: 2999009/3000000.0 - Recompensa: -0.8372017230651146\n",
            "Total de pasos: 2999010/3000000.0 - Recompensa: -0.0932453496546613\n",
            "Total de pasos: 2999011/3000000.0 - Recompensa: -0.4256797927191043\n",
            "Total de pasos: 2999012/3000000.0 - Recompensa: 0.663620461873706\n",
            "0.663620461873706\n",
            "Total de pasos: 2999013/3000000.0 - Recompensa: 0.21284586811361889\n",
            "0.21284586811361889\n",
            "Total de pasos: 2999014/3000000.0 - Recompensa: -4.027807646189009\n",
            "Total de pasos: 2999015/3000000.0 - Recompensa: -1.8782399883694372\n",
            "Total de pasos: 2999016/3000000.0 - Recompensa: -0.39706972579951694\n",
            "Total de pasos: 2999017/3000000.0 - Recompensa: -0.6027163631241276\n",
            "Total de pasos: 2999018/3000000.0 - Recompensa: -2.58240896793661\n",
            "Total de pasos: 2999019/3000000.0 - Recompensa: 0.34548215742707894\n",
            "0.34548215742707894\n",
            "Total de pasos: 2999020/3000000.0 - Recompensa: -0.6482178472748259\n",
            "Total de pasos: 2999021/3000000.0 - Recompensa: -1.0827909340070534\n",
            "Total de pasos: 2999022/3000000.0 - Recompensa: -0.6529999862547993\n",
            "Total de pasos: 2999023/3000000.0 - Recompensa: -0.40892030964234116\n",
            "Total de pasos: 2999024/3000000.0 - Recompensa: -0.9004201115756425\n",
            "Total de pasos: 2999025/3000000.0 - Recompensa: -1.7717962692242235\n",
            "Total de pasos: 2999026/3000000.0 - Recompensa: -0.0028356466992943974\n",
            "Total de pasos: 2999027/3000000.0 - Recompensa: -0.7288829896519478\n",
            "Total de pasos: 2999028/3000000.0 - Recompensa: -0.40340430021559726\n",
            "Total de pasos: 2999029/3000000.0 - Recompensa: -0.414811525457757\n",
            "Total de pasos: 2999030/3000000.0 - Recompensa: 0.29234267971379313\n",
            "0.29234267971379313\n",
            "Total de pasos: 2999031/3000000.0 - Recompensa: 0.579516630573777\n",
            "0.579516630573777\n",
            "Total de pasos: 2999032/3000000.0 - Recompensa: -2.322874572931978\n",
            "Total de pasos: 2999033/3000000.0 - Recompensa: -0.9293589305216411\n",
            "Total de pasos: 2999034/3000000.0 - Recompensa: 0.9937647460428107\n",
            "0.9937647460428107\n",
            "Total de pasos: 2999035/3000000.0 - Recompensa: 0.4111265446224309\n",
            "0.4111265446224309\n",
            "Total de pasos: 2999036/3000000.0 - Recompensa: 0.49853573140351437\n",
            "0.49853573140351437\n",
            "Total de pasos: 2999037/3000000.0 - Recompensa: -0.5643807619711038\n",
            "Total de pasos: 2999038/3000000.0 - Recompensa: 0.20798794127237036\n",
            "0.20798794127237036\n",
            "Total de pasos: 2999039/3000000.0 - Recompensa: -2.6680767206734237\n",
            "Total de pasos: 2999040/3000000.0 - Recompensa: 0.7832187711296387\n",
            "0.7832187711296387\n",
            "Total de pasos: 2999041/3000000.0 - Recompensa: -0.764310036263242\n",
            "Total de pasos: 2999042/3000000.0 - Recompensa: 0.4042067556277006\n",
            "0.4042067556277006\n",
            "Total de pasos: 2999043/3000000.0 - Recompensa: -0.26987532803499725\n",
            "Total de pasos: 2999044/3000000.0 - Recompensa: -0.25163423196569595\n",
            "Total de pasos: 2999045/3000000.0 - Recompensa: 0.19462220178746978\n",
            "0.19462220178746978\n",
            "Total de pasos: 2999046/3000000.0 - Recompensa: -1.3641280864289378\n",
            "Total de pasos: 2999047/3000000.0 - Recompensa: -0.3829904421942548\n",
            "Total de pasos: 2999048/3000000.0 - Recompensa: -2.249540097789074\n",
            "Total de pasos: 2999049/3000000.0 - Recompensa: 0.2870100947861977\n",
            "0.2870100947861977\n",
            "Total de pasos: 2999050/3000000.0 - Recompensa: -2.0698802861990617\n",
            "Total de pasos: 2999051/3000000.0 - Recompensa: -1.5986637325242992\n",
            "Total de pasos: 2999052/3000000.0 - Recompensa: -1.4353787879562436\n",
            "Total de pasos: 2999053/3000000.0 - Recompensa: -2.2748527105414316\n",
            "Total de pasos: 2999054/3000000.0 - Recompensa: -0.35289482268387423\n",
            "Total de pasos: 2999055/3000000.0 - Recompensa: -0.11930596366867521\n",
            "Total de pasos: 2999056/3000000.0 - Recompensa: -1.4518000639143385\n",
            "Total de pasos: 2999057/3000000.0 - Recompensa: -0.36156391168047347\n",
            "Total de pasos: 2999058/3000000.0 - Recompensa: -1.012121757219692\n",
            "Total de pasos: 2999059/3000000.0 - Recompensa: -0.7996348592819822\n",
            "Total de pasos: 2999060/3000000.0 - Recompensa: -1.718713132635177\n",
            "Total de pasos: 2999061/3000000.0 - Recompensa: -0.9152700021025194\n",
            "Total de pasos: 2999062/3000000.0 - Recompensa: -1.741584084367935\n",
            "Total de pasos: 2999063/3000000.0 - Recompensa: -0.7160686337677585\n",
            "Total de pasos: 2999064/3000000.0 - Recompensa: -0.7832474573626582\n",
            "Total de pasos: 2999065/3000000.0 - Recompensa: -1.7979330341817412\n",
            "Total de pasos: 2999066/3000000.0 - Recompensa: -1.7657917895806976\n",
            "Total de pasos: 2999067/3000000.0 - Recompensa: -0.6659467085188909\n",
            "Total de pasos: 2999068/3000000.0 - Recompensa: -2.203121008937373\n",
            "Total de pasos: 2999069/3000000.0 - Recompensa: -0.39107220061918735\n",
            "Total de pasos: 2999070/3000000.0 - Recompensa: -0.7036280014621273\n",
            "Total de pasos: 2999071/3000000.0 - Recompensa: -1.5174998325841593\n",
            "Total de pasos: 2999072/3000000.0 - Recompensa: 0.03659117348316862\n",
            "0.03659117348316862\n",
            "Total de pasos: 2999073/3000000.0 - Recompensa: -1.7214753556545672\n",
            "Total de pasos: 2999074/3000000.0 - Recompensa: -0.1134914671641103\n",
            "Total de pasos: 2999075/3000000.0 - Recompensa: -0.6809469187648365\n",
            "Total de pasos: 2999076/3000000.0 - Recompensa: -0.7882993635539814\n",
            "Total de pasos: 2999077/3000000.0 - Recompensa: -1.784306763775757\n",
            "Total de pasos: 2999078/3000000.0 - Recompensa: -0.7634165858926922\n",
            "Total de pasos: 2999079/3000000.0 - Recompensa: -0.03692351578058908\n",
            "Total de pasos: 2999080/3000000.0 - Recompensa: -2.774656435882607\n",
            "Total de pasos: 2999081/3000000.0 - Recompensa: 0.07924033596563693\n",
            "0.07924033596563693\n",
            "Total de pasos: 2999082/3000000.0 - Recompensa: -1.198903207732234\n",
            "Total de pasos: 2999083/3000000.0 - Recompensa: -0.5446316991616416\n",
            "Total de pasos: 2999084/3000000.0 - Recompensa: -0.9786889623482475\n",
            "Total de pasos: 2999085/3000000.0 - Recompensa: -0.3247713761157643\n",
            "Total de pasos: 2999086/3000000.0 - Recompensa: -1.506886125627002\n",
            "Total de pasos: 2999087/3000000.0 - Recompensa: -0.47443920463381445\n",
            "Total de pasos: 2999088/3000000.0 - Recompensa: -0.8907489707916304\n",
            "Total de pasos: 2999089/3000000.0 - Recompensa: -1.977049308573291\n",
            "Total de pasos: 2999090/3000000.0 - Recompensa: -1.8871175893419916\n",
            "Total de pasos: 2999091/3000000.0 - Recompensa: -1.6304635905356246\n",
            "Total de pasos: 2999092/3000000.0 - Recompensa: -1.6951005262152716\n",
            "Total de pasos: 2999093/3000000.0 - Recompensa: -0.11999100670446589\n",
            "Total de pasos: 2999094/3000000.0 - Recompensa: -1.683004091234356\n",
            "Total de pasos: 2999095/3000000.0 - Recompensa: -0.12291362199604486\n",
            "Total de pasos: 2999096/3000000.0 - Recompensa: 0.7224002722921113\n",
            "0.7224002722921113\n",
            "Total de pasos: 2999097/3000000.0 - Recompensa: -2.1401059711552226\n",
            "Total de pasos: 2999098/3000000.0 - Recompensa: -1.043296312855208\n",
            "Total de pasos: 2999099/3000000.0 - Recompensa: 0.37736669646113014\n",
            "0.37736669646113014\n",
            "Total de pasos: 2999100/3000000.0 - Recompensa: 0.06030681096932056\n",
            "0.06030681096932056\n",
            "Total de pasos: 2999101/3000000.0 - Recompensa: -1.525501126754008\n",
            "Total de pasos: 2999102/3000000.0 - Recompensa: -0.28738234618617914\n",
            "Total de pasos: 2999103/3000000.0 - Recompensa: -2.0665381469783233\n",
            "Total de pasos: 2999104/3000000.0 - Recompensa: -1.6984040394833908\n",
            "Total de pasos: 2999105/3000000.0 - Recompensa: 0.5123689008399259\n",
            "0.5123689008399259\n",
            "Total de pasos: 2999106/3000000.0 - Recompensa: -1.7131840723696752\n",
            "Total de pasos: 2999107/3000000.0 - Recompensa: -0.9482865960922069\n",
            "Total de pasos: 2999108/3000000.0 - Recompensa: -1.6525458339618744\n",
            "Total de pasos: 2999109/3000000.0 - Recompensa: 0.11155538807212756\n",
            "0.11155538807212756\n",
            "Total de pasos: 2999110/3000000.0 - Recompensa: 0.42632298355482984\n",
            "0.42632298355482984\n",
            "Total de pasos: 2999111/3000000.0 - Recompensa: 0.6038153032393112\n",
            "0.6038153032393112\n",
            "Total de pasos: 2999112/3000000.0 - Recompensa: -0.2521053843622572\n",
            "Total de pasos: 2999113/3000000.0 - Recompensa: -1.434075527616311\n",
            "Total de pasos: 2999114/3000000.0 - Recompensa: -1.0904526208244754\n",
            "Total de pasos: 2999115/3000000.0 - Recompensa: -2.305864331651766\n",
            "Total de pasos: 2999116/3000000.0 - Recompensa: -2.1802687945384993\n",
            "Total de pasos: 2999117/3000000.0 - Recompensa: -0.9936730247213766\n",
            "Total de pasos: 2999118/3000000.0 - Recompensa: 0.4737011065057805\n",
            "0.4737011065057805\n",
            "Total de pasos: 2999119/3000000.0 - Recompensa: 0.6536850871927822\n",
            "0.6536850871927822\n",
            "Total de pasos: 2999120/3000000.0 - Recompensa: -0.9966085498491626\n",
            "Total de pasos: 2999121/3000000.0 - Recompensa: -0.6669602084514138\n",
            "Total de pasos: 2999122/3000000.0 - Recompensa: -1.1223127091129974\n",
            "Total de pasos: 2999123/3000000.0 - Recompensa: -0.30644955788902883\n",
            "Total de pasos: 2999124/3000000.0 - Recompensa: -0.945878277694969\n",
            "Total de pasos: 2999125/3000000.0 - Recompensa: -1.630759966949772\n",
            "Total de pasos: 2999126/3000000.0 - Recompensa: -4.6237793186727645\n",
            "Total de pasos: 2999127/3000000.0 - Recompensa: -0.2337220275838451\n",
            "Total de pasos: 2999128/3000000.0 - Recompensa: 0.013849454464774424\n",
            "0.013849454464774424\n",
            "Total de pasos: 2999129/3000000.0 - Recompensa: -0.5137736591000913\n",
            "Total de pasos: 2999130/3000000.0 - Recompensa: 0.2899960535385593\n",
            "0.2899960535385593\n",
            "Total de pasos: 2999131/3000000.0 - Recompensa: -0.524416738163165\n",
            "Total de pasos: 2999132/3000000.0 - Recompensa: -2.579950323531679\n",
            "Total de pasos: 2999133/3000000.0 - Recompensa: -0.10219872966809512\n",
            "Total de pasos: 2999134/3000000.0 - Recompensa: -1.0677368307530362\n",
            "Total de pasos: 2999135/3000000.0 - Recompensa: -1.0750367717366118\n",
            "Total de pasos: 2999136/3000000.0 - Recompensa: -0.589889268773255\n",
            "Total de pasos: 2999137/3000000.0 - Recompensa: -0.204069671087787\n",
            "Total de pasos: 2999138/3000000.0 - Recompensa: -0.2024832057688104\n",
            "Total de pasos: 2999139/3000000.0 - Recompensa: -0.9660115703218601\n",
            "Total de pasos: 2999140/3000000.0 - Recompensa: 0.7725920270491408\n",
            "0.7725920270491408\n",
            "Total de pasos: 2999141/3000000.0 - Recompensa: 0.13960854407169507\n",
            "0.13960854407169507\n",
            "Total de pasos: 2999142/3000000.0 - Recompensa: -1.2760794734149739\n",
            "Total de pasos: 2999143/3000000.0 - Recompensa: -1.158747226472864\n",
            "Total de pasos: 2999144/3000000.0 - Recompensa: 0.9758895914658297\n",
            "0.9758895914658297\n",
            "Total de pasos: 2999145/3000000.0 - Recompensa: -0.022241846337288484\n",
            "Total de pasos: 2999146/3000000.0 - Recompensa: 0.031762004397088706\n",
            "0.031762004397088706\n",
            "Total de pasos: 2999147/3000000.0 - Recompensa: -3.0893880081482985\n",
            "Total de pasos: 2999148/3000000.0 - Recompensa: -0.9065543450419947\n",
            "Total de pasos: 2999149/3000000.0 - Recompensa: -2.143307539478633\n",
            "Total de pasos: 2999150/3000000.0 - Recompensa: -2.1516008370620203\n",
            "Total de pasos: 2999151/3000000.0 - Recompensa: -2.9917985587182114\n",
            "Total de pasos: 2999152/3000000.0 - Recompensa: -1.4347649515696395\n",
            "Total de pasos: 2999153/3000000.0 - Recompensa: -1.4143687862526777\n",
            "Total de pasos: 2999154/3000000.0 - Recompensa: -2.13379357148618\n",
            "Total de pasos: 2999155/3000000.0 - Recompensa: 0.3442227030616578\n",
            "0.3442227030616578\n",
            "Total de pasos: 2999156/3000000.0 - Recompensa: 0.30634330289045114\n",
            "0.30634330289045114\n",
            "Total de pasos: 2999157/3000000.0 - Recompensa: 0.050738195935576685\n",
            "0.050738195935576685\n",
            "Total de pasos: 2999158/3000000.0 - Recompensa: -1.5555040005830192\n",
            "Total de pasos: 2999159/3000000.0 - Recompensa: -1.794524662455078\n",
            "Total de pasos: 2999160/3000000.0 - Recompensa: -1.5403587437261383\n",
            "Total de pasos: 2999161/3000000.0 - Recompensa: -2.1015439906548186\n",
            "Total de pasos: 2999162/3000000.0 - Recompensa: -0.2029660212898529\n",
            "Total de pasos: 2999163/3000000.0 - Recompensa: -0.23661149819389485\n",
            "Total de pasos: 2999164/3000000.0 - Recompensa: 1.072767512570498\n",
            "1.072767512570498\n",
            "Total de pasos: 2999165/3000000.0 - Recompensa: -0.44002441295048544\n",
            "Total de pasos: 2999166/3000000.0 - Recompensa: -1.4633694646434552\n",
            "Total de pasos: 2999167/3000000.0 - Recompensa: -1.619190163431548\n",
            "Total de pasos: 2999168/3000000.0 - Recompensa: -0.9891664764006023\n",
            "Total de pasos: 2999169/3000000.0 - Recompensa: -0.4090386405395366\n",
            "Total de pasos: 2999170/3000000.0 - Recompensa: -1.3512195039615822\n",
            "Total de pasos: 2999171/3000000.0 - Recompensa: -1.8354469797703967\n",
            "Total de pasos: 2999172/3000000.0 - Recompensa: -0.7425183951403963\n",
            "Total de pasos: 2999173/3000000.0 - Recompensa: -0.779620354235618\n",
            "Total de pasos: 2999174/3000000.0 - Recompensa: -2.085848501203726\n",
            "Total de pasos: 2999175/3000000.0 - Recompensa: -2.779041540250762\n",
            "Total de pasos: 2999176/3000000.0 - Recompensa: 0.16962658585818086\n",
            "0.16962658585818086\n",
            "Total de pasos: 2999177/3000000.0 - Recompensa: -1.8215492653111633\n",
            "Total de pasos: 2999178/3000000.0 - Recompensa: 0.4621212260809612\n",
            "0.4621212260809612\n",
            "Total de pasos: 2999179/3000000.0 - Recompensa: -0.7808867078415805\n",
            "Total de pasos: 2999180/3000000.0 - Recompensa: -0.40051028596767\n",
            "Total de pasos: 2999181/3000000.0 - Recompensa: -0.7229052511519185\n",
            "Total de pasos: 2999182/3000000.0 - Recompensa: -1.8905524111393508\n",
            "Total de pasos: 2999183/3000000.0 - Recompensa: -0.9449246603554025\n",
            "Total de pasos: 2999184/3000000.0 - Recompensa: -1.8981050753737567\n",
            "Total de pasos: 2999185/3000000.0 - Recompensa: -0.6973133783003885\n",
            "Total de pasos: 2999186/3000000.0 - Recompensa: 0.4910571301608986\n",
            "0.4910571301608986\n",
            "Total de pasos: 2999187/3000000.0 - Recompensa: -0.013907652004122861\n",
            "Total de pasos: 2999188/3000000.0 - Recompensa: -0.9730611738813792\n",
            "Total de pasos: 2999189/3000000.0 - Recompensa: -2.9325748575719697\n",
            "Total de pasos: 2999190/3000000.0 - Recompensa: -1.3488096780405825\n",
            "Total de pasos: 2999191/3000000.0 - Recompensa: 0.7371987978391319\n",
            "0.7371987978391319\n",
            "Total de pasos: 2999192/3000000.0 - Recompensa: -0.13890817700314623\n",
            "Total de pasos: 2999193/3000000.0 - Recompensa: 0.23263335827157858\n",
            "0.23263335827157858\n",
            "Total de pasos: 2999194/3000000.0 - Recompensa: -0.3404450712243808\n",
            "Total de pasos: 2999195/3000000.0 - Recompensa: 0.9894913356570773\n",
            "0.9894913356570773\n",
            "Total de pasos: 2999196/3000000.0 - Recompensa: -0.5516601384212473\n",
            "Total de pasos: 2999197/3000000.0 - Recompensa: -1.5904442068770077\n",
            "Total de pasos: 2999198/3000000.0 - Recompensa: -3.5478126934328023\n",
            "Total de pasos: 2999199/3000000.0 - Recompensa: 0.4428057872955449\n",
            "0.4428057872955449\n",
            "Total de pasos: 2999200/3000000.0 - Recompensa: -1.4750556726621948\n",
            "Total de pasos: 2999201/3000000.0 - Recompensa: -0.039306999617068794\n",
            "Total de pasos: 2999202/3000000.0 - Recompensa: -1.0892998488826724\n",
            "Total de pasos: 2999203/3000000.0 - Recompensa: -0.5734204867095614\n",
            "Total de pasos: 2999204/3000000.0 - Recompensa: 0.25010116741585725\n",
            "0.25010116741585725\n",
            "Total de pasos: 2999205/3000000.0 - Recompensa: -0.3063713174918233\n",
            "Total de pasos: 2999206/3000000.0 - Recompensa: -0.8831901040837272\n",
            "Total de pasos: 2999207/3000000.0 - Recompensa: -0.1035006984047886\n",
            "Total de pasos: 2999208/3000000.0 - Recompensa: -1.7795560134853394\n",
            "Total de pasos: 2999209/3000000.0 - Recompensa: -0.6275873315716954\n",
            "Total de pasos: 2999210/3000000.0 - Recompensa: 0.5772817802588133\n",
            "0.5772817802588133\n",
            "Total de pasos: 2999211/3000000.0 - Recompensa: -0.6316485825034246\n",
            "Total de pasos: 2999212/3000000.0 - Recompensa: -1.0814693092785381\n",
            "Total de pasos: 2999213/3000000.0 - Recompensa: -1.668755911128716\n",
            "Total de pasos: 2999214/3000000.0 - Recompensa: -0.6849645701160878\n",
            "Total de pasos: 2999215/3000000.0 - Recompensa: 0.3860249701474614\n",
            "0.3860249701474614\n",
            "Total de pasos: 2999216/3000000.0 - Recompensa: -1.0551310533871894\n",
            "Total de pasos: 2999217/3000000.0 - Recompensa: -0.7195601404218122\n",
            "Total de pasos: 2999218/3000000.0 - Recompensa: -1.332536549009815\n",
            "Total de pasos: 2999219/3000000.0 - Recompensa: -1.0729927435735784\n",
            "Total de pasos: 2999220/3000000.0 - Recompensa: -4.210155395951117\n",
            "Total de pasos: 2999221/3000000.0 - Recompensa: -1.5400289952300268\n",
            "Total de pasos: 2999222/3000000.0 - Recompensa: -0.18607262764850355\n",
            "Total de pasos: 2999223/3000000.0 - Recompensa: -0.9982094152057754\n",
            "Total de pasos: 2999224/3000000.0 - Recompensa: -0.3792554399257469\n",
            "Total de pasos: 2999225/3000000.0 - Recompensa: 0.01595300964809193\n",
            "0.01595300964809193\n",
            "Total de pasos: 2999226/3000000.0 - Recompensa: -0.21670489773603202\n",
            "Total de pasos: 2999227/3000000.0 - Recompensa: -2.1903969088355657\n",
            "Total de pasos: 2999228/3000000.0 - Recompensa: -1.7233206318598524\n",
            "Total de pasos: 2999229/3000000.0 - Recompensa: -0.12758128739423685\n",
            "Total de pasos: 2999230/3000000.0 - Recompensa: -0.3932848864386765\n",
            "Total de pasos: 2999231/3000000.0 - Recompensa: -0.24339606030618147\n",
            "Total de pasos: 2999232/3000000.0 - Recompensa: -0.18325827791694033\n",
            "Total de pasos: 2999233/3000000.0 - Recompensa: -2.2902694035606257\n",
            "Total de pasos: 2999234/3000000.0 - Recompensa: -1.1827152394395477\n",
            "Total de pasos: 2999235/3000000.0 - Recompensa: -0.5548181705941987\n",
            "Total de pasos: 2999236/3000000.0 - Recompensa: 0.7315506122734141\n",
            "0.7315506122734141\n",
            "Total de pasos: 2999237/3000000.0 - Recompensa: -3.6298982186880338\n",
            "Total de pasos: 2999238/3000000.0 - Recompensa: -2.0153478999739125\n",
            "Total de pasos: 2999239/3000000.0 - Recompensa: -0.6105469041465594\n",
            "Total de pasos: 2999240/3000000.0 - Recompensa: 0.8151784032868232\n",
            "0.8151784032868232\n",
            "Total de pasos: 2999241/3000000.0 - Recompensa: 0.1949288018711258\n",
            "0.1949288018711258\n",
            "Total de pasos: 2999242/3000000.0 - Recompensa: 0.07330645347725512\n",
            "0.07330645347725512\n",
            "Total de pasos: 2999243/3000000.0 - Recompensa: 0.25386036551818847\n",
            "0.25386036551818847\n",
            "Total de pasos: 2999244/3000000.0 - Recompensa: -0.7945082450735409\n",
            "Total de pasos: 2999245/3000000.0 - Recompensa: 0.03307101964994716\n",
            "0.03307101964994716\n",
            "Total de pasos: 2999246/3000000.0 - Recompensa: 0.3589777269120697\n",
            "0.3589777269120697\n",
            "Total de pasos: 2999247/3000000.0 - Recompensa: 0.22696652600507936\n",
            "0.22696652600507936\n",
            "Total de pasos: 2999248/3000000.0 - Recompensa: 0.9299030204156876\n",
            "0.9299030204156876\n",
            "Total de pasos: 2999249/3000000.0 - Recompensa: -0.6964971197999671\n",
            "Total de pasos: 2999250/3000000.0 - Recompensa: -0.44104145955986135\n",
            "Total de pasos: 2999251/3000000.0 - Recompensa: 0.05516068753763709\n",
            "0.05516068753763709\n",
            "Total de pasos: 2999252/3000000.0 - Recompensa: 0.6000051614260566\n",
            "0.6000051614260566\n",
            "Total de pasos: 2999253/3000000.0 - Recompensa: -0.23760513388925997\n",
            "Total de pasos: 2999254/3000000.0 - Recompensa: 0.38676780924735116\n",
            "0.38676780924735116\n",
            "Total de pasos: 2999255/3000000.0 - Recompensa: -0.9235590257358883\n",
            "Total de pasos: 2999256/3000000.0 - Recompensa: -0.9225328362099846\n",
            "Total de pasos: 2999257/3000000.0 - Recompensa: 0.6184031116151598\n",
            "0.6184031116151598\n",
            "Total de pasos: 2999258/3000000.0 - Recompensa: -1.027845693861239\n",
            "Total de pasos: 2999259/3000000.0 - Recompensa: -1.4707032983838695\n",
            "Total de pasos: 2999260/3000000.0 - Recompensa: -2.1045755532132717\n",
            "Total de pasos: 2999261/3000000.0 - Recompensa: -1.158203777383197\n",
            "Total de pasos: 2999262/3000000.0 - Recompensa: -0.45441050190451326\n",
            "Total de pasos: 2999263/3000000.0 - Recompensa: -3.6927289743343144\n",
            "Total de pasos: 2999264/3000000.0 - Recompensa: -2.9793284731325076\n",
            "Total de pasos: 2999265/3000000.0 - Recompensa: -0.3372800646092363\n",
            "Total de pasos: 2999266/3000000.0 - Recompensa: -1.8610546281775986\n",
            "Total de pasos: 2999267/3000000.0 - Recompensa: -0.772716398905433\n",
            "Total de pasos: 2999268/3000000.0 - Recompensa: -1.0003169194149482\n",
            "Total de pasos: 2999269/3000000.0 - Recompensa: -1.178343809733076\n",
            "Total de pasos: 2999270/3000000.0 - Recompensa: -1.2578544088611185\n",
            "Total de pasos: 2999271/3000000.0 - Recompensa: -1.4463720568585017\n",
            "Total de pasos: 2999272/3000000.0 - Recompensa: 0.08714742918329885\n",
            "0.08714742918329885\n",
            "Total de pasos: 2999273/3000000.0 - Recompensa: 0.09975695098462206\n",
            "0.09975695098462206\n",
            "Total de pasos: 2999274/3000000.0 - Recompensa: -1.337402227720241\n",
            "Total de pasos: 2999275/3000000.0 - Recompensa: -1.1760194296618571\n",
            "Total de pasos: 2999276/3000000.0 - Recompensa: 0.000826905611800155\n",
            "0.000826905611800155\n",
            "Total de pasos: 2999277/3000000.0 - Recompensa: -0.3351627597920043\n",
            "Total de pasos: 2999278/3000000.0 - Recompensa: 0.8529717473559173\n",
            "0.8529717473559173\n",
            "Total de pasos: 2999279/3000000.0 - Recompensa: -0.8581165248048576\n",
            "Total de pasos: 2999280/3000000.0 - Recompensa: 0.4253594474818848\n",
            "0.4253594474818848\n",
            "Total de pasos: 2999281/3000000.0 - Recompensa: -1.2453188241060886\n",
            "Total de pasos: 2999282/3000000.0 - Recompensa: -1.0684665400741449\n",
            "Total de pasos: 2999283/3000000.0 - Recompensa: 0.004891102724508656\n",
            "0.004891102724508656\n",
            "Total de pasos: 2999284/3000000.0 - Recompensa: 0.025136255850214118\n",
            "0.025136255850214118\n",
            "Total de pasos: 2999285/3000000.0 - Recompensa: -3.827939482680857\n",
            "Total de pasos: 2999286/3000000.0 - Recompensa: 0.08045990921656263\n",
            "0.08045990921656263\n",
            "Total de pasos: 2999287/3000000.0 - Recompensa: -1.1732400593896122\n",
            "Total de pasos: 2999288/3000000.0 - Recompensa: -0.7103121593184414\n",
            "Total de pasos: 2999289/3000000.0 - Recompensa: -1.1178735896632717\n",
            "Total de pasos: 2999290/3000000.0 - Recompensa: -1.0383309996844279\n",
            "Total de pasos: 2999291/3000000.0 - Recompensa: -0.39024542093737297\n",
            "Total de pasos: 2999292/3000000.0 - Recompensa: -0.6948437392982035\n",
            "Total de pasos: 2999293/3000000.0 - Recompensa: -1.7517689503897131\n",
            "Total de pasos: 2999294/3000000.0 - Recompensa: -0.24363679890151327\n",
            "Total de pasos: 2999295/3000000.0 - Recompensa: 0.884702768676223\n",
            "0.884702768676223\n",
            "Total de pasos: 2999296/3000000.0 - Recompensa: 0.22928499271151032\n",
            "0.22928499271151032\n",
            "Total de pasos: 2999297/3000000.0 - Recompensa: -0.95632673223968\n",
            "Total de pasos: 2999298/3000000.0 - Recompensa: -0.47724853277008783\n",
            "Total de pasos: 2999299/3000000.0 - Recompensa: -0.38148708735221454\n",
            "Total de pasos: 2999300/3000000.0 - Recompensa: -2.8257118566039794\n",
            "Total de pasos: 2999301/3000000.0 - Recompensa: 0.05000949731959259\n",
            "0.05000949731959259\n",
            "Total de pasos: 2999302/3000000.0 - Recompensa: 0.04806803352626371\n",
            "0.04806803352626371\n",
            "Total de pasos: 2999303/3000000.0 - Recompensa: 0.33694436288739266\n",
            "0.33694436288739266\n",
            "Total de pasos: 2999304/3000000.0 - Recompensa: -1.6255891836375453\n",
            "Total de pasos: 2999305/3000000.0 - Recompensa: -0.10952552191386783\n",
            "Total de pasos: 2999306/3000000.0 - Recompensa: -0.5680505147387105\n",
            "Total de pasos: 2999307/3000000.0 - Recompensa: -1.0641841699586896\n",
            "Total de pasos: 2999308/3000000.0 - Recompensa: -1.0486000217149072\n",
            "Total de pasos: 2999309/3000000.0 - Recompensa: -2.3170158994532857\n",
            "Total de pasos: 2999310/3000000.0 - Recompensa: -1.3002088293586966\n",
            "Total de pasos: 2999311/3000000.0 - Recompensa: -0.4873195177816897\n",
            "Total de pasos: 2999312/3000000.0 - Recompensa: -0.9407713541305991\n",
            "Total de pasos: 2999313/3000000.0 - Recompensa: -0.863938826842983\n",
            "Total de pasos: 2999314/3000000.0 - Recompensa: -2.354908010585353\n",
            "Total de pasos: 2999315/3000000.0 - Recompensa: -0.8497341311635032\n",
            "Total de pasos: 2999316/3000000.0 - Recompensa: -0.9815527612205963\n",
            "Total de pasos: 2999317/3000000.0 - Recompensa: -1.7916109989906306\n",
            "Total de pasos: 2999318/3000000.0 - Recompensa: -2.0108710888588193\n",
            "Total de pasos: 2999319/3000000.0 - Recompensa: -0.49648924558892416\n",
            "Total de pasos: 2999320/3000000.0 - Recompensa: -1.0125231885696517\n",
            "Total de pasos: 2999321/3000000.0 - Recompensa: -0.4244499811120165\n",
            "Total de pasos: 2999322/3000000.0 - Recompensa: -1.2182615360571276\n",
            "Total de pasos: 2999323/3000000.0 - Recompensa: 0.3282960111910735\n",
            "0.3282960111910735\n",
            "Total de pasos: 2999324/3000000.0 - Recompensa: -0.13376051687949522\n",
            "Total de pasos: 2999325/3000000.0 - Recompensa: -1.0629221821068953\n",
            "Total de pasos: 2999326/3000000.0 - Recompensa: -1.026498872076252\n",
            "Total de pasos: 2999327/3000000.0 - Recompensa: -3.3364248349976324\n",
            "Total de pasos: 2999328/3000000.0 - Recompensa: -0.6387915550913122\n",
            "Total de pasos: 2999329/3000000.0 - Recompensa: -0.23683888518441476\n",
            "Total de pasos: 2999330/3000000.0 - Recompensa: -0.8301515363437295\n",
            "Total de pasos: 2999331/3000000.0 - Recompensa: -0.4157870329791755\n",
            "Total de pasos: 2999332/3000000.0 - Recompensa: -0.3657082913755317\n",
            "Total de pasos: 2999333/3000000.0 - Recompensa: -0.6690781512327016\n",
            "Total de pasos: 2999334/3000000.0 - Recompensa: 0.24407242234073853\n",
            "0.24407242234073853\n",
            "Total de pasos: 2999335/3000000.0 - Recompensa: -0.5677394314041881\n",
            "Total de pasos: 2999336/3000000.0 - Recompensa: -1.280656174967915\n",
            "Total de pasos: 2999337/3000000.0 - Recompensa: -1.055848454740529\n",
            "Total de pasos: 2999338/3000000.0 - Recompensa: -2.5186852155097426\n",
            "Total de pasos: 2999339/3000000.0 - Recompensa: -0.58028551740307\n",
            "Total de pasos: 2999340/3000000.0 - Recompensa: -1.504815816945287\n",
            "Total de pasos: 2999341/3000000.0 - Recompensa: -2.6474387037432168\n",
            "Total de pasos: 2999342/3000000.0 - Recompensa: -2.6508704974292887\n",
            "Total de pasos: 2999343/3000000.0 - Recompensa: -0.39812813629522453\n",
            "Total de pasos: 2999344/3000000.0 - Recompensa: -1.4097213587346231\n",
            "Total de pasos: 2999345/3000000.0 - Recompensa: -0.20823115661340125\n",
            "Total de pasos: 2999346/3000000.0 - Recompensa: 0.19606528084885153\n",
            "0.19606528084885153\n",
            "Total de pasos: 2999347/3000000.0 - Recompensa: -2.1393056530922068\n",
            "Total de pasos: 2999348/3000000.0 - Recompensa: -0.806169846809511\n",
            "Total de pasos: 2999349/3000000.0 - Recompensa: -1.6865945483730247\n",
            "Total de pasos: 2999350/3000000.0 - Recompensa: -1.278009894868355\n",
            "Total de pasos: 2999351/3000000.0 - Recompensa: -0.5715690572674407\n",
            "Total de pasos: 2999352/3000000.0 - Recompensa: -1.8157812718451203\n",
            "Total de pasos: 2999353/3000000.0 - Recompensa: -0.6384748321481692\n",
            "Total de pasos: 2999354/3000000.0 - Recompensa: -2.4384711595965207\n",
            "Total de pasos: 2999355/3000000.0 - Recompensa: -0.2665161688255438\n",
            "Total de pasos: 2999356/3000000.0 - Recompensa: -0.5431699879608547\n",
            "Total de pasos: 2999357/3000000.0 - Recompensa: 0.2639529627475915\n",
            "0.2639529627475915\n",
            "Total de pasos: 2999358/3000000.0 - Recompensa: 0.48723630602432316\n",
            "0.48723630602432316\n",
            "Total de pasos: 2999359/3000000.0 - Recompensa: -0.546396993807313\n",
            "Total de pasos: 2999360/3000000.0 - Recompensa: -0.6178765480907228\n",
            "Total de pasos: 2999361/3000000.0 - Recompensa: -0.7896658872623046\n",
            "Total de pasos: 2999362/3000000.0 - Recompensa: -1.6654961013247274\n",
            "Total de pasos: 2999363/3000000.0 - Recompensa: 0.09323612040229351\n",
            "0.09323612040229351\n",
            "Total de pasos: 2999364/3000000.0 - Recompensa: -0.12280354276213729\n",
            "Total de pasos: 2999365/3000000.0 - Recompensa: -0.8646155566472846\n",
            "Total de pasos: 2999366/3000000.0 - Recompensa: -0.03308001718811676\n",
            "Total de pasos: 2999367/3000000.0 - Recompensa: 0.967162132857548\n",
            "0.967162132857548\n",
            "Total de pasos: 2999368/3000000.0 - Recompensa: -0.03186257083526289\n",
            "Total de pasos: 2999369/3000000.0 - Recompensa: 0.37574756972380186\n",
            "0.37574756972380186\n",
            "Total de pasos: 2999370/3000000.0 - Recompensa: -0.4861444336869519\n",
            "Total de pasos: 2999371/3000000.0 - Recompensa: -0.4254209534998553\n",
            "Total de pasos: 2999372/3000000.0 - Recompensa: -0.3180150018618163\n",
            "Total de pasos: 2999373/3000000.0 - Recompensa: -0.8013011221992467\n",
            "Total de pasos: 2999374/3000000.0 - Recompensa: 1.0917014699512444\n",
            "1.0917014699512444\n",
            "Total de pasos: 2999375/3000000.0 - Recompensa: 0.12533712431247118\n",
            "0.12533712431247118\n",
            "Total de pasos: 2999376/3000000.0 - Recompensa: 0.7570293550002776\n",
            "0.7570293550002776\n",
            "Total de pasos: 2999377/3000000.0 - Recompensa: -0.27295278855422805\n",
            "Total de pasos: 2999378/3000000.0 - Recompensa: -1.2949464689946486\n",
            "Total de pasos: 2999379/3000000.0 - Recompensa: 0.47168747723980936\n",
            "0.47168747723980936\n",
            "Total de pasos: 2999380/3000000.0 - Recompensa: -6.120404690835267\n",
            "Total de pasos: 2999381/3000000.0 - Recompensa: -0.39302905626836704\n",
            "Total de pasos: 2999382/3000000.0 - Recompensa: -0.017389926686237678\n",
            "Total de pasos: 2999383/3000000.0 - Recompensa: -1.2975270620652548\n",
            "Total de pasos: 2999384/3000000.0 - Recompensa: -0.39722274028161575\n",
            "Total de pasos: 2999385/3000000.0 - Recompensa: -1.7462090550795342\n",
            "Total de pasos: 2999386/3000000.0 - Recompensa: -2.023550512693175\n",
            "Total de pasos: 2999387/3000000.0 - Recompensa: -0.5635746845488406\n",
            "Total de pasos: 2999388/3000000.0 - Recompensa: -1.3074133904516256\n",
            "Total de pasos: 2999389/3000000.0 - Recompensa: -0.6724800793927009\n",
            "Total de pasos: 2999390/3000000.0 - Recompensa: -0.2286200986719739\n",
            "Total de pasos: 2999391/3000000.0 - Recompensa: -0.5716330446141099\n",
            "Total de pasos: 2999392/3000000.0 - Recompensa: -1.6790645441122019\n",
            "Total de pasos: 2999393/3000000.0 - Recompensa: -0.9812751072808189\n",
            "Total de pasos: 2999394/3000000.0 - Recompensa: -0.11171467080802394\n",
            "Total de pasos: 2999395/3000000.0 - Recompensa: -2.954731158884595\n",
            "Total de pasos: 2999396/3000000.0 - Recompensa: 0.015260613211737384\n",
            "0.015260613211737384\n",
            "Total de pasos: 2999397/3000000.0 - Recompensa: -1.0789596570496327\n",
            "Total de pasos: 2999398/3000000.0 - Recompensa: 0.09074376779691526\n",
            "0.09074376779691526\n",
            "Total de pasos: 2999399/3000000.0 - Recompensa: -0.1661000369788755\n",
            "Total de pasos: 2999400/3000000.0 - Recompensa: 0.5006683374663548\n",
            "0.5006683374663548\n",
            "Total de pasos: 2999401/3000000.0 - Recompensa: -1.1942896757142731\n",
            "Total de pasos: 2999402/3000000.0 - Recompensa: -0.25780659355969765\n",
            "Total de pasos: 2999403/3000000.0 - Recompensa: -2.582659012295921\n",
            "Total de pasos: 2999404/3000000.0 - Recompensa: -0.09043188081415501\n",
            "Total de pasos: 2999405/3000000.0 - Recompensa: -1.626287296710614\n",
            "Total de pasos: 2999406/3000000.0 - Recompensa: -0.7962606812589649\n",
            "Total de pasos: 2999407/3000000.0 - Recompensa: -0.7400675518806279\n",
            "Total de pasos: 2999408/3000000.0 - Recompensa: -1.1538622145749458\n",
            "Total de pasos: 2999409/3000000.0 - Recompensa: 0.24600306714893966\n",
            "0.24600306714893966\n",
            "Total de pasos: 2999410/3000000.0 - Recompensa: -0.6930138664479272\n",
            "Total de pasos: 2999411/3000000.0 - Recompensa: -0.02599179511561195\n",
            "Total de pasos: 2999412/3000000.0 - Recompensa: -1.0950679978718907\n",
            "Total de pasos: 2999413/3000000.0 - Recompensa: -0.5015499757894528\n",
            "Total de pasos: 2999414/3000000.0 - Recompensa: -0.3892628733404913\n",
            "Total de pasos: 2999415/3000000.0 - Recompensa: -2.8057306254693093\n",
            "Total de pasos: 2999416/3000000.0 - Recompensa: -1.1980283782652739\n",
            "Total de pasos: 2999417/3000000.0 - Recompensa: -0.1378651438980958\n",
            "Total de pasos: 2999418/3000000.0 - Recompensa: -2.22121445557151\n",
            "Total de pasos: 2999419/3000000.0 - Recompensa: -1.8022833580026116\n",
            "Total de pasos: 2999420/3000000.0 - Recompensa: 0.11200970305108768\n",
            "0.11200970305108768\n",
            "Total de pasos: 2999421/3000000.0 - Recompensa: 0.08136739065164317\n",
            "0.08136739065164317\n",
            "Total de pasos: 2999422/3000000.0 - Recompensa: -2.9750278905501726\n",
            "Total de pasos: 2999423/3000000.0 - Recompensa: -3.037001762809838\n",
            "Total de pasos: 2999424/3000000.0 - Recompensa: 0.40994488648690874\n",
            "0.40994488648690874\n",
            "Total de pasos: 2999425/3000000.0 - Recompensa: -0.30841099202875133\n",
            "Total de pasos: 2999426/3000000.0 - Recompensa: -0.4172695612382382\n",
            "Total de pasos: 2999427/3000000.0 - Recompensa: -0.5658462218124021\n",
            "Total de pasos: 2999428/3000000.0 - Recompensa: 0.07908025619187473\n",
            "0.07908025619187473\n",
            "Total de pasos: 2999429/3000000.0 - Recompensa: -2.972269308946988\n",
            "Total de pasos: 2999430/3000000.0 - Recompensa: -0.826254027364964\n",
            "Total de pasos: 2999431/3000000.0 - Recompensa: -2.7037170588903767\n",
            "Total de pasos: 2999432/3000000.0 - Recompensa: 0.1675168798465056\n",
            "0.1675168798465056\n",
            "Total de pasos: 2999433/3000000.0 - Recompensa: -0.16269260205602923\n",
            "Total de pasos: 2999434/3000000.0 - Recompensa: -1.692542559465758\n",
            "Total de pasos: 2999435/3000000.0 - Recompensa: -0.2766083307120846\n",
            "Total de pasos: 2999436/3000000.0 - Recompensa: -0.8627094225209915\n",
            "Total de pasos: 2999437/3000000.0 - Recompensa: 0.23076659451571802\n",
            "0.23076659451571802\n",
            "Total de pasos: 2999438/3000000.0 - Recompensa: -1.829261316975539\n",
            "Total de pasos: 2999439/3000000.0 - Recompensa: -0.771485411204983\n",
            "Total de pasos: 2999440/3000000.0 - Recompensa: -0.34876056511017406\n",
            "Total de pasos: 2999441/3000000.0 - Recompensa: -0.9046899255074525\n",
            "Total de pasos: 2999442/3000000.0 - Recompensa: -3.00805421190239\n",
            "Total de pasos: 2999443/3000000.0 - Recompensa: -0.1301499091189017\n",
            "Total de pasos: 2999444/3000000.0 - Recompensa: -0.7077312316166726\n",
            "Total de pasos: 2999445/3000000.0 - Recompensa: -0.19305312251042875\n",
            "Total de pasos: 2999446/3000000.0 - Recompensa: -1.3807180850229341\n",
            "Total de pasos: 2999447/3000000.0 - Recompensa: 0.6277751871902091\n",
            "0.6277751871902091\n",
            "Total de pasos: 2999448/3000000.0 - Recompensa: -0.7214765507471419\n",
            "Total de pasos: 2999449/3000000.0 - Recompensa: -1.8993838138688923\n",
            "Total de pasos: 2999450/3000000.0 - Recompensa: -2.3756007092810596\n",
            "Total de pasos: 2999451/3000000.0 - Recompensa: -1.6822487961471035\n",
            "Total de pasos: 2999452/3000000.0 - Recompensa: -0.1706269442571359\n",
            "Total de pasos: 2999453/3000000.0 - Recompensa: -0.28436925685222236\n",
            "Total de pasos: 2999454/3000000.0 - Recompensa: -1.2448054537738305\n",
            "Total de pasos: 2999455/3000000.0 - Recompensa: -0.2810932219344794\n",
            "Total de pasos: 2999456/3000000.0 - Recompensa: -1.254488879573584\n",
            "Total de pasos: 2999457/3000000.0 - Recompensa: -0.6112661920076315\n",
            "Total de pasos: 2999458/3000000.0 - Recompensa: 0.1949248180135394\n",
            "0.1949248180135394\n",
            "Total de pasos: 2999459/3000000.0 - Recompensa: -0.26014406662628514\n",
            "Total de pasos: 2999460/3000000.0 - Recompensa: -0.7964136788641708\n",
            "Total de pasos: 2999461/3000000.0 - Recompensa: -0.6849417613812755\n",
            "Total de pasos: 2999462/3000000.0 - Recompensa: 0.3559473566263473\n",
            "0.3559473566263473\n",
            "Total de pasos: 2999463/3000000.0 - Recompensa: 0.565476898670066\n",
            "0.565476898670066\n",
            "Total de pasos: 2999464/3000000.0 - Recompensa: -0.10164130517925135\n",
            "Total de pasos: 2999465/3000000.0 - Recompensa: -2.264990469019881\n",
            "Total de pasos: 2999466/3000000.0 - Recompensa: 0.2970207355207434\n",
            "0.2970207355207434\n",
            "Total de pasos: 2999467/3000000.0 - Recompensa: -0.6087967069719242\n",
            "Total de pasos: 2999468/3000000.0 - Recompensa: 0.05656889737106549\n",
            "0.05656889737106549\n",
            "Total de pasos: 2999469/3000000.0 - Recompensa: -0.699970659752338\n",
            "Total de pasos: 2999470/3000000.0 - Recompensa: -1.2415069349858676\n",
            "Total de pasos: 2999471/3000000.0 - Recompensa: -1.674648805680993\n",
            "Total de pasos: 2999472/3000000.0 - Recompensa: -0.8401222223837885\n",
            "Total de pasos: 2999473/3000000.0 - Recompensa: -0.4647315530491628\n",
            "Total de pasos: 2999474/3000000.0 - Recompensa: -1.0975710585021632\n",
            "Total de pasos: 2999475/3000000.0 - Recompensa: -2.4902124736618783\n",
            "Total de pasos: 2999476/3000000.0 - Recompensa: -0.7769106196750297\n",
            "Total de pasos: 2999477/3000000.0 - Recompensa: -0.5664848906232935\n",
            "Total de pasos: 2999478/3000000.0 - Recompensa: -0.23493205844261258\n",
            "Total de pasos: 2999479/3000000.0 - Recompensa: -0.583179552362272\n",
            "Total de pasos: 2999480/3000000.0 - Recompensa: -0.1619672199070087\n",
            "Total de pasos: 2999481/3000000.0 - Recompensa: -0.02140988997564844\n",
            "Total de pasos: 2999482/3000000.0 - Recompensa: -1.0270060014564208\n",
            "Total de pasos: 2999483/3000000.0 - Recompensa: -0.2794011059804154\n",
            "Total de pasos: 2999484/3000000.0 - Recompensa: -1.2985433951178942\n",
            "Total de pasos: 2999485/3000000.0 - Recompensa: -0.5307004164268772\n",
            "Total de pasos: 2999486/3000000.0 - Recompensa: -0.7401381529417177\n",
            "Total de pasos: 2999487/3000000.0 - Recompensa: 0.8958402954708625\n",
            "0.8958402954708625\n",
            "Total de pasos: 2999488/3000000.0 - Recompensa: -0.15204486045520144\n",
            "Total de pasos: 2999489/3000000.0 - Recompensa: -1.161613288707356\n",
            "Total de pasos: 2999490/3000000.0 - Recompensa: -0.2515332202035346\n",
            "Total de pasos: 2999491/3000000.0 - Recompensa: -0.6088185335054213\n",
            "Total de pasos: 2999492/3000000.0 - Recompensa: -1.4907284214400613\n",
            "Total de pasos: 2999493/3000000.0 - Recompensa: -3.412871684420116\n",
            "Total de pasos: 2999494/3000000.0 - Recompensa: -0.6239011236151207\n",
            "Total de pasos: 2999495/3000000.0 - Recompensa: -0.30359114004993415\n",
            "Total de pasos: 2999496/3000000.0 - Recompensa: -1.0480297328595056\n",
            "Total de pasos: 2999497/3000000.0 - Recompensa: 0.02135646503410865\n",
            "0.02135646503410865\n",
            "Total de pasos: 2999498/3000000.0 - Recompensa: -1.2986435871126614\n",
            "Total de pasos: 2999499/3000000.0 - Recompensa: -1.1849078659452816\n",
            "Total de pasos: 2999500/3000000.0 - Recompensa: 1.177889669388957\n",
            "1.177889669388957\n",
            "Total de pasos: 2999501/3000000.0 - Recompensa: -4.680180522142557\n",
            "Total de pasos: 2999502/3000000.0 - Recompensa: -1.2105677195208682\n",
            "Total de pasos: 2999503/3000000.0 - Recompensa: -1.4688917507608965\n",
            "Total de pasos: 2999504/3000000.0 - Recompensa: -2.5618999929964335\n",
            "Total de pasos: 2999505/3000000.0 - Recompensa: -1.227052296319091\n",
            "Total de pasos: 2999506/3000000.0 - Recompensa: -0.7902455281681113\n",
            "Total de pasos: 2999507/3000000.0 - Recompensa: -0.618566621870402\n",
            "Total de pasos: 2999508/3000000.0 - Recompensa: -0.36865440115434095\n",
            "Total de pasos: 2999509/3000000.0 - Recompensa: 0.5632676611850203\n",
            "0.5632676611850203\n",
            "Total de pasos: 2999510/3000000.0 - Recompensa: -1.8712457040693429\n",
            "Total de pasos: 2999511/3000000.0 - Recompensa: 0.5411063767295233\n",
            "0.5411063767295233\n",
            "Total de pasos: 2999512/3000000.0 - Recompensa: -0.2944425801164593\n",
            "Total de pasos: 2999513/3000000.0 - Recompensa: -0.2781123565388051\n",
            "Total de pasos: 2999514/3000000.0 - Recompensa: -0.7519002162908727\n",
            "Total de pasos: 2999515/3000000.0 - Recompensa: 0.14451591411721232\n",
            "0.14451591411721232\n",
            "Total de pasos: 2999516/3000000.0 - Recompensa: -0.7549278335428643\n",
            "Total de pasos: 2999517/3000000.0 - Recompensa: -0.693284040002719\n",
            "Total de pasos: 2999518/3000000.0 - Recompensa: -1.452563317141151\n",
            "Total de pasos: 2999519/3000000.0 - Recompensa: -0.35826242032113625\n",
            "Total de pasos: 2999520/3000000.0 - Recompensa: -1.1172841888666203\n",
            "Total de pasos: 2999521/3000000.0 - Recompensa: 0.16539286882570442\n",
            "0.16539286882570442\n",
            "Total de pasos: 2999522/3000000.0 - Recompensa: -0.6116031294297655\n",
            "Total de pasos: 2999523/3000000.0 - Recompensa: -1.065902484162775\n",
            "Total de pasos: 2999524/3000000.0 - Recompensa: -0.20342483488876711\n",
            "Total de pasos: 2999525/3000000.0 - Recompensa: 0.38268579996351737\n",
            "0.38268579996351737\n",
            "Total de pasos: 2999526/3000000.0 - Recompensa: -1.8384567014916853\n",
            "Total de pasos: 2999527/3000000.0 - Recompensa: -2.2713257792036954\n",
            "Total de pasos: 2999528/3000000.0 - Recompensa: -0.5295313192920158\n",
            "Total de pasos: 2999529/3000000.0 - Recompensa: -1.6635459994027881\n",
            "Total de pasos: 2999530/3000000.0 - Recompensa: -1.0471865270451914\n",
            "Total de pasos: 2999531/3000000.0 - Recompensa: -1.756927063681526\n",
            "Total de pasos: 2999532/3000000.0 - Recompensa: -1.9517577177870171\n",
            "Total de pasos: 2999533/3000000.0 - Recompensa: 0.5704773556257118\n",
            "0.5704773556257118\n",
            "Total de pasos: 2999534/3000000.0 - Recompensa: -0.45126051630180286\n",
            "Total de pasos: 2999535/3000000.0 - Recompensa: -0.4993988500766273\n",
            "Total de pasos: 2999536/3000000.0 - Recompensa: 0.7485814855869606\n",
            "0.7485814855869606\n",
            "Total de pasos: 2999537/3000000.0 - Recompensa: 0.6068127994894404\n",
            "0.6068127994894404\n",
            "Total de pasos: 2999538/3000000.0 - Recompensa: 0.353082151159413\n",
            "0.353082151159413\n",
            "Total de pasos: 2999539/3000000.0 - Recompensa: -2.0922188117721348\n",
            "Total de pasos: 2999540/3000000.0 - Recompensa: 0.39210577687456566\n",
            "0.39210577687456566\n",
            "Total de pasos: 2999541/3000000.0 - Recompensa: -1.019808464692445\n",
            "Total de pasos: 2999542/3000000.0 - Recompensa: -1.9575533439967057\n",
            "Total de pasos: 2999543/3000000.0 - Recompensa: 0.3881841261867994\n",
            "0.3881841261867994\n",
            "Total de pasos: 2999544/3000000.0 - Recompensa: 0.08945917264676204\n",
            "0.08945917264676204\n",
            "Total de pasos: 2999545/3000000.0 - Recompensa: 0.04691086619018758\n",
            "0.04691086619018758\n",
            "Total de pasos: 2999546/3000000.0 - Recompensa: -0.6304013857453439\n",
            "Total de pasos: 2999547/3000000.0 - Recompensa: -4.373176196657321\n",
            "Total de pasos: 2999548/3000000.0 - Recompensa: -1.87966726436873\n",
            "Total de pasos: 2999549/3000000.0 - Recompensa: -1.1117185104213956\n",
            "Total de pasos: 2999550/3000000.0 - Recompensa: -1.3305285825952875\n",
            "Total de pasos: 2999551/3000000.0 - Recompensa: 0.2157626113511772\n",
            "0.2157626113511772\n",
            "Total de pasos: 2999552/3000000.0 - Recompensa: 0.3860720383230175\n",
            "0.3860720383230175\n",
            "Total de pasos: 2999553/3000000.0 - Recompensa: -0.6074265162053385\n",
            "Total de pasos: 2999554/3000000.0 - Recompensa: -0.5681397458892617\n",
            "Total de pasos: 2999555/3000000.0 - Recompensa: -0.1871755966734197\n",
            "Total de pasos: 2999556/3000000.0 - Recompensa: -1.6914891493917148\n",
            "Total de pasos: 2999557/3000000.0 - Recompensa: -1.5854335337658199\n",
            "Total de pasos: 2999558/3000000.0 - Recompensa: -0.4016825657744806\n",
            "Total de pasos: 2999559/3000000.0 - Recompensa: -1.1383989514812993\n",
            "Total de pasos: 2999560/3000000.0 - Recompensa: -1.5685555887321891\n",
            "Total de pasos: 2999561/3000000.0 - Recompensa: -1.5003249058376888\n",
            "Total de pasos: 2999562/3000000.0 - Recompensa: -1.068232898521355\n",
            "Total de pasos: 2999563/3000000.0 - Recompensa: -1.156955500739968\n",
            "Total de pasos: 2999564/3000000.0 - Recompensa: -0.5506808798084346\n",
            "Total de pasos: 2999565/3000000.0 - Recompensa: -1.0282438250643728\n",
            "Total de pasos: 2999566/3000000.0 - Recompensa: -0.9666308205050121\n",
            "Total de pasos: 2999567/3000000.0 - Recompensa: 0.6118983228356532\n",
            "0.6118983228356532\n",
            "Total de pasos: 2999568/3000000.0 - Recompensa: -1.0161388905463835\n",
            "Total de pasos: 2999569/3000000.0 - Recompensa: -0.2121607334712862\n",
            "Total de pasos: 2999570/3000000.0 - Recompensa: -0.6735144285051355\n",
            "Total de pasos: 2999571/3000000.0 - Recompensa: -0.6723232268185189\n",
            "Total de pasos: 2999572/3000000.0 - Recompensa: 0.07293149206579191\n",
            "0.07293149206579191\n",
            "Total de pasos: 2999573/3000000.0 - Recompensa: -0.5695077031478657\n",
            "Total de pasos: 2999574/3000000.0 - Recompensa: -2.0555791154679706\n",
            "Total de pasos: 2999575/3000000.0 - Recompensa: -2.3250728442156072\n",
            "Total de pasos: 2999576/3000000.0 - Recompensa: -1.4418505460748154\n",
            "Total de pasos: 2999577/3000000.0 - Recompensa: -0.446725680955874\n",
            "Total de pasos: 2999578/3000000.0 - Recompensa: -0.88735543944991\n",
            "Total de pasos: 2999579/3000000.0 - Recompensa: -0.8471048263871619\n",
            "Total de pasos: 2999580/3000000.0 - Recompensa: -1.5509677192726983\n",
            "Total de pasos: 2999581/3000000.0 - Recompensa: -1.398907383784362\n",
            "Total de pasos: 2999582/3000000.0 - Recompensa: -1.7203057512986801\n",
            "Total de pasos: 2999583/3000000.0 - Recompensa: -0.8410080518539969\n",
            "Total de pasos: 2999584/3000000.0 - Recompensa: -1.4853121789596233\n",
            "Total de pasos: 2999585/3000000.0 - Recompensa: -0.6520847060323149\n",
            "Total de pasos: 2999586/3000000.0 - Recompensa: -3.2190972691980493\n",
            "Total de pasos: 2999587/3000000.0 - Recompensa: -2.6984734965743327\n",
            "Total de pasos: 2999588/3000000.0 - Recompensa: -0.9772063684553394\n",
            "Total de pasos: 2999589/3000000.0 - Recompensa: -0.22821313895574608\n",
            "Total de pasos: 2999590/3000000.0 - Recompensa: -0.10670510739921873\n",
            "Total de pasos: 2999591/3000000.0 - Recompensa: -0.6809455539058502\n",
            "Total de pasos: 2999592/3000000.0 - Recompensa: -0.7468564771941643\n",
            "Total de pasos: 2999593/3000000.0 - Recompensa: -1.016364246194012\n",
            "Total de pasos: 2999594/3000000.0 - Recompensa: -0.28653740900975666\n",
            "Total de pasos: 2999595/3000000.0 - Recompensa: -2.405694762800202\n",
            "Total de pasos: 2999596/3000000.0 - Recompensa: -1.0035288407295206\n",
            "Total de pasos: 2999597/3000000.0 - Recompensa: -0.9447464880300117\n",
            "Total de pasos: 2999598/3000000.0 - Recompensa: 0.1452703639612864\n",
            "0.1452703639612864\n",
            "Total de pasos: 2999599/3000000.0 - Recompensa: -3.2477181988657575\n",
            "Total de pasos: 2999600/3000000.0 - Recompensa: -1.2406681967048194\n",
            "Total de pasos: 2999601/3000000.0 - Recompensa: -0.04667606721941722\n",
            "Total de pasos: 2999602/3000000.0 - Recompensa: -1.2325219821079478\n",
            "Total de pasos: 2999603/3000000.0 - Recompensa: -1.7452972925516241\n",
            "Total de pasos: 2999604/3000000.0 - Recompensa: -3.222434442946805\n",
            "Total de pasos: 2999605/3000000.0 - Recompensa: -1.3462176652076574\n",
            "Total de pasos: 2999606/3000000.0 - Recompensa: -0.5031902140507116\n",
            "Total de pasos: 2999607/3000000.0 - Recompensa: -1.2802950919358027\n",
            "Total de pasos: 2999608/3000000.0 - Recompensa: -2.4863329612735017\n",
            "Total de pasos: 2999609/3000000.0 - Recompensa: -0.8659885999704192\n",
            "Total de pasos: 2999610/3000000.0 - Recompensa: -0.5347447353626478\n",
            "Total de pasos: 2999611/3000000.0 - Recompensa: -1.8895314759333193\n",
            "Total de pasos: 2999612/3000000.0 - Recompensa: -0.6797134247646611\n",
            "Total de pasos: 2999613/3000000.0 - Recompensa: -0.5357328596818468\n",
            "Total de pasos: 2999614/3000000.0 - Recompensa: -0.9509500407575591\n",
            "Total de pasos: 2999615/3000000.0 - Recompensa: -0.19336763558940434\n",
            "Total de pasos: 2999616/3000000.0 - Recompensa: -0.6782121135383161\n",
            "Total de pasos: 2999617/3000000.0 - Recompensa: -0.9765065204455795\n",
            "Total de pasos: 2999618/3000000.0 - Recompensa: -0.37653494200908844\n",
            "Total de pasos: 2999619/3000000.0 - Recompensa: -0.02221848354065195\n",
            "Total de pasos: 2999620/3000000.0 - Recompensa: -1.6366769780452177\n",
            "Total de pasos: 2999621/3000000.0 - Recompensa: -0.6097110134744674\n",
            "Total de pasos: 2999622/3000000.0 - Recompensa: 0.848163950176161\n",
            "0.848163950176161\n",
            "Total de pasos: 2999623/3000000.0 - Recompensa: -0.6556250137632603\n",
            "Total de pasos: 2999624/3000000.0 - Recompensa: -0.9079359079192718\n",
            "Total de pasos: 2999625/3000000.0 - Recompensa: -1.8804619703707623\n",
            "Total de pasos: 2999626/3000000.0 - Recompensa: -2.0295814279663693\n",
            "Total de pasos: 2999627/3000000.0 - Recompensa: 0.5963062765823305\n",
            "0.5963062765823305\n",
            "Total de pasos: 2999628/3000000.0 - Recompensa: -0.4295697847464143\n",
            "Total de pasos: 2999629/3000000.0 - Recompensa: -1.4574032262013092\n",
            "Total de pasos: 2999630/3000000.0 - Recompensa: -2.107889435403556\n",
            "Total de pasos: 2999631/3000000.0 - Recompensa: -0.36242488364787373\n",
            "Total de pasos: 2999632/3000000.0 - Recompensa: -1.2864777294839274\n",
            "Total de pasos: 2999633/3000000.0 - Recompensa: -2.3845671174943948\n",
            "Total de pasos: 2999634/3000000.0 - Recompensa: -1.1102927681635546\n",
            "Total de pasos: 2999635/3000000.0 - Recompensa: 0.14819477778137666\n",
            "0.14819477778137666\n",
            "Total de pasos: 2999636/3000000.0 - Recompensa: -1.0939852753413746\n",
            "Total de pasos: 2999637/3000000.0 - Recompensa: -0.734300366445307\n",
            "Total de pasos: 2999638/3000000.0 - Recompensa: -0.4381797357393088\n",
            "Total de pasos: 2999639/3000000.0 - Recompensa: -1.781227123559322\n",
            "Total de pasos: 2999640/3000000.0 - Recompensa: -2.0849041610204457\n",
            "Total de pasos: 2999641/3000000.0 - Recompensa: 0.25498407444141996\n",
            "0.25498407444141996\n",
            "Total de pasos: 2999642/3000000.0 - Recompensa: -1.76846812584945\n",
            "Total de pasos: 2999643/3000000.0 - Recompensa: 0.6559005385917116\n",
            "0.6559005385917116\n",
            "Total de pasos: 2999644/3000000.0 - Recompensa: 0.3613020817462703\n",
            "0.3613020817462703\n",
            "Total de pasos: 2999645/3000000.0 - Recompensa: -1.1918296778396305\n",
            "Total de pasos: 2999646/3000000.0 - Recompensa: -0.5728448741975607\n",
            "Total de pasos: 2999647/3000000.0 - Recompensa: -1.469717062980534\n",
            "Total de pasos: 2999648/3000000.0 - Recompensa: -0.8700720431476683\n",
            "Total de pasos: 2999649/3000000.0 - Recompensa: -1.2480849129852167\n",
            "Total de pasos: 2999650/3000000.0 - Recompensa: 0.19192448213933327\n",
            "0.19192448213933327\n",
            "Total de pasos: 2999651/3000000.0 - Recompensa: -0.5695160128129444\n",
            "Total de pasos: 2999652/3000000.0 - Recompensa: 0.26142558361065815\n",
            "0.26142558361065815\n",
            "Total de pasos: 2999653/3000000.0 - Recompensa: -0.39268263549712606\n",
            "Total de pasos: 2999654/3000000.0 - Recompensa: -0.5804513363687707\n",
            "Total de pasos: 2999655/3000000.0 - Recompensa: -3.005412830092799\n",
            "Total de pasos: 2999656/3000000.0 - Recompensa: -1.335251393662578\n",
            "Total de pasos: 2999657/3000000.0 - Recompensa: -2.100121347612877\n",
            "Total de pasos: 2999658/3000000.0 - Recompensa: -1.6045543458105993\n",
            "Total de pasos: 2999659/3000000.0 - Recompensa: -0.5390691108317809\n",
            "Total de pasos: 2999660/3000000.0 - Recompensa: -2.7171773226408766\n",
            "Total de pasos: 2999661/3000000.0 - Recompensa: -0.8989625700704574\n",
            "Total de pasos: 2999662/3000000.0 - Recompensa: -0.24572324868118206\n",
            "Total de pasos: 2999663/3000000.0 - Recompensa: -0.7488291005571333\n",
            "Total de pasos: 2999664/3000000.0 - Recompensa: -1.0200763889391078\n",
            "Total de pasos: 2999665/3000000.0 - Recompensa: 0.4257665641389613\n",
            "0.4257665641389613\n",
            "Total de pasos: 2999666/3000000.0 - Recompensa: -1.907420794029862\n",
            "Total de pasos: 2999667/3000000.0 - Recompensa: 0.8446241489494017\n",
            "0.8446241489494017\n",
            "Total de pasos: 2999668/3000000.0 - Recompensa: -1.5867383006583227\n",
            "Total de pasos: 2999669/3000000.0 - Recompensa: -1.5450554966475667\n",
            "Total de pasos: 2999670/3000000.0 - Recompensa: -1.6586546562647466\n",
            "Total de pasos: 2999671/3000000.0 - Recompensa: -1.25232690951869\n",
            "Total de pasos: 2999672/3000000.0 - Recompensa: -0.8338814905928882\n",
            "Total de pasos: 2999673/3000000.0 - Recompensa: -0.9256001050157849\n",
            "Total de pasos: 2999674/3000000.0 - Recompensa: 0.10874250019591777\n",
            "0.10874250019591777\n",
            "Total de pasos: 2999675/3000000.0 - Recompensa: -0.8548800497522663\n",
            "Total de pasos: 2999676/3000000.0 - Recompensa: 1.109585619142477\n",
            "1.109585619142477\n",
            "Total de pasos: 2999677/3000000.0 - Recompensa: -0.8337834200703393\n",
            "Total de pasos: 2999678/3000000.0 - Recompensa: -1.7118922808460884\n",
            "Total de pasos: 2999679/3000000.0 - Recompensa: -0.20666347099324903\n",
            "Total de pasos: 2999680/3000000.0 - Recompensa: -2.109311478000933\n",
            "Total de pasos: 2999681/3000000.0 - Recompensa: 0.47788442244987694\n",
            "0.47788442244987694\n",
            "Total de pasos: 2999682/3000000.0 - Recompensa: 0.41084111140975876\n",
            "0.41084111140975876\n",
            "Total de pasos: 2999683/3000000.0 - Recompensa: -0.8994496470363673\n",
            "Total de pasos: 2999684/3000000.0 - Recompensa: 0.18797035359263092\n",
            "0.18797035359263092\n",
            "Total de pasos: 2999685/3000000.0 - Recompensa: -2.1270840299485285\n",
            "Total de pasos: 2999686/3000000.0 - Recompensa: -1.0262213642519908\n",
            "Total de pasos: 2999687/3000000.0 - Recompensa: -0.23827880146318794\n",
            "Total de pasos: 2999688/3000000.0 - Recompensa: 1.000134500881051\n",
            "1.000134500881051\n",
            "Total de pasos: 2999689/3000000.0 - Recompensa: -2.1503882031188533\n",
            "Total de pasos: 2999690/3000000.0 - Recompensa: -0.2374378268654853\n",
            "Total de pasos: 2999691/3000000.0 - Recompensa: -0.7350427421485113\n",
            "Total de pasos: 2999692/3000000.0 - Recompensa: -2.352671310289229\n",
            "Total de pasos: 2999693/3000000.0 - Recompensa: -0.5081219032020414\n",
            "Total de pasos: 2999694/3000000.0 - Recompensa: -1.8619670462478037\n",
            "Total de pasos: 2999695/3000000.0 - Recompensa: -0.9083320047980792\n",
            "Total de pasos: 2999696/3000000.0 - Recompensa: 0.12036172592132782\n",
            "0.12036172592132782\n",
            "Total de pasos: 2999697/3000000.0 - Recompensa: -2.285784758948841\n",
            "Total de pasos: 2999698/3000000.0 - Recompensa: -0.5130043561091518\n",
            "Total de pasos: 2999699/3000000.0 - Recompensa: -1.0872069283482824\n",
            "Total de pasos: 2999700/3000000.0 - Recompensa: -0.8442005346182722\n",
            "Total de pasos: 2999701/3000000.0 - Recompensa: -2.8157104180568067\n",
            "Total de pasos: 2999702/3000000.0 - Recompensa: -0.3898199053916719\n",
            "Total de pasos: 2999703/3000000.0 - Recompensa: -0.2646282577777404\n",
            "Total de pasos: 2999704/3000000.0 - Recompensa: -0.37638511688861953\n",
            "Total de pasos: 2999705/3000000.0 - Recompensa: -1.2161860977207586\n",
            "Total de pasos: 2999706/3000000.0 - Recompensa: -1.02555740349583\n",
            "Total de pasos: 2999707/3000000.0 - Recompensa: -1.7966658538508582\n",
            "Total de pasos: 2999708/3000000.0 - Recompensa: -0.11438088166453181\n",
            "Total de pasos: 2999709/3000000.0 - Recompensa: -1.8629223870507148\n",
            "Total de pasos: 2999710/3000000.0 - Recompensa: -0.8394250874259119\n",
            "Total de pasos: 2999711/3000000.0 - Recompensa: 0.11711819824475084\n",
            "0.11711819824475084\n",
            "Total de pasos: 2999712/3000000.0 - Recompensa: 0.2741153544717185\n",
            "0.2741153544717185\n",
            "Total de pasos: 2999713/3000000.0 - Recompensa: -1.848139029111485\n",
            "Total de pasos: 2999714/3000000.0 - Recompensa: -1.612503683252572\n",
            "Total de pasos: 2999715/3000000.0 - Recompensa: -1.7679479199221424\n",
            "Total de pasos: 2999716/3000000.0 - Recompensa: -0.6250181184429364\n",
            "Total de pasos: 2999717/3000000.0 - Recompensa: -0.5918239492172249\n",
            "Total de pasos: 2999718/3000000.0 - Recompensa: -0.596682466433\n",
            "Total de pasos: 2999719/3000000.0 - Recompensa: -2.4639605828299125\n",
            "Total de pasos: 2999720/3000000.0 - Recompensa: -1.4158761344858404\n",
            "Total de pasos: 2999721/3000000.0 - Recompensa: -0.8995326071541835\n",
            "Total de pasos: 2999722/3000000.0 - Recompensa: 0.784140750851104\n",
            "0.784140750851104\n",
            "Total de pasos: 2999723/3000000.0 - Recompensa: -0.4603668022706187\n",
            "Total de pasos: 2999724/3000000.0 - Recompensa: 0.41443620542620085\n",
            "0.41443620542620085\n",
            "Total de pasos: 2999725/3000000.0 - Recompensa: 0.39200947409267023\n",
            "0.39200947409267023\n",
            "Total de pasos: 2999726/3000000.0 - Recompensa: -3.028936127936\n",
            "Total de pasos: 2999727/3000000.0 - Recompensa: -1.1237828907307736\n",
            "Total de pasos: 2999728/3000000.0 - Recompensa: -4.11043862472376\n",
            "Total de pasos: 2999729/3000000.0 - Recompensa: -0.23593431971818202\n",
            "Total de pasos: 2999730/3000000.0 - Recompensa: -1.4818674985088367\n",
            "Total de pasos: 2999731/3000000.0 - Recompensa: 0.6957255835624193\n",
            "0.6957255835624193\n",
            "Total de pasos: 2999732/3000000.0 - Recompensa: -0.2929874644261544\n",
            "Total de pasos: 2999733/3000000.0 - Recompensa: -0.8492474316301273\n",
            "Total de pasos: 2999734/3000000.0 - Recompensa: 0.4065718622330071\n",
            "0.4065718622330071\n",
            "Total de pasos: 2999735/3000000.0 - Recompensa: 0.03401453850756403\n",
            "0.03401453850756403\n",
            "Total de pasos: 2999736/3000000.0 - Recompensa: -0.7282407834259417\n",
            "Total de pasos: 2999737/3000000.0 - Recompensa: -0.2891969880704889\n",
            "Total de pasos: 2999738/3000000.0 - Recompensa: -0.32192780277228505\n",
            "Total de pasos: 2999739/3000000.0 - Recompensa: -1.8552117111700936\n",
            "Total de pasos: 2999740/3000000.0 - Recompensa: -0.1960029367468173\n",
            "Total de pasos: 2999741/3000000.0 - Recompensa: -0.2909096298107688\n",
            "Total de pasos: 2999742/3000000.0 - Recompensa: -0.9287291562995919\n",
            "Total de pasos: 2999743/3000000.0 - Recompensa: -2.6720831558310167\n",
            "Total de pasos: 2999744/3000000.0 - Recompensa: -0.4677663595338915\n",
            "Total de pasos: 2999745/3000000.0 - Recompensa: -3.139462231045241\n",
            "Total de pasos: 2999746/3000000.0 - Recompensa: 0.2596237835564245\n",
            "0.2596237835564245\n",
            "Total de pasos: 2999747/3000000.0 - Recompensa: 0.4074115390159833\n",
            "0.4074115390159833\n",
            "Total de pasos: 2999748/3000000.0 - Recompensa: -1.2403004563510642\n",
            "Total de pasos: 2999749/3000000.0 - Recompensa: -0.3998093091735807\n",
            "Total de pasos: 2999750/3000000.0 - Recompensa: 0.3651376260051933\n",
            "0.3651376260051933\n",
            "Total de pasos: 2999751/3000000.0 - Recompensa: -1.947022023683504\n",
            "Total de pasos: 2999752/3000000.0 - Recompensa: -2.6295527990494802\n",
            "Total de pasos: 2999753/3000000.0 - Recompensa: -3.9609347022495456\n",
            "Total de pasos: 2999754/3000000.0 - Recompensa: -3.190158164233689\n",
            "Total de pasos: 2999755/3000000.0 - Recompensa: -1.1352581767989958\n",
            "Total de pasos: 2999756/3000000.0 - Recompensa: -1.328241085983228\n",
            "Total de pasos: 2999757/3000000.0 - Recompensa: -1.4683198971297848\n",
            "Total de pasos: 2999758/3000000.0 - Recompensa: -0.5322922375421956\n",
            "Total de pasos: 2999759/3000000.0 - Recompensa: -0.6445094534071262\n",
            "Total de pasos: 2999760/3000000.0 - Recompensa: -1.6844738439139586\n",
            "Total de pasos: 2999761/3000000.0 - Recompensa: 0.11242536212061432\n",
            "0.11242536212061432\n",
            "Total de pasos: 2999762/3000000.0 - Recompensa: -0.867296165218501\n",
            "Total de pasos: 2999763/3000000.0 - Recompensa: -1.186007177678562\n",
            "Total de pasos: 2999764/3000000.0 - Recompensa: -0.3768712915577499\n",
            "Total de pasos: 2999765/3000000.0 - Recompensa: -0.052060572350735024\n",
            "Total de pasos: 2999766/3000000.0 - Recompensa: 0.28147115113301185\n",
            "0.28147115113301185\n",
            "Total de pasos: 2999767/3000000.0 - Recompensa: 0.18639463121335947\n",
            "0.18639463121335947\n",
            "Total de pasos: 2999768/3000000.0 - Recompensa: -0.5548927588759225\n",
            "Total de pasos: 2999769/3000000.0 - Recompensa: -1.028525544070078\n",
            "Total de pasos: 2999770/3000000.0 - Recompensa: -0.7301224336251412\n",
            "Total de pasos: 2999771/3000000.0 - Recompensa: -1.2294256683182787\n",
            "Total de pasos: 2999772/3000000.0 - Recompensa: -1.8187590807650762\n",
            "Total de pasos: 2999773/3000000.0 - Recompensa: 0.529434243354262\n",
            "0.529434243354262\n",
            "Total de pasos: 2999774/3000000.0 - Recompensa: -0.11164385331935583\n",
            "Total de pasos: 2999775/3000000.0 - Recompensa: -1.7675944760162963\n",
            "Total de pasos: 2999776/3000000.0 - Recompensa: -0.37207414340901523\n",
            "Total de pasos: 2999777/3000000.0 - Recompensa: 0.48051674870560757\n",
            "0.48051674870560757\n",
            "Total de pasos: 2999778/3000000.0 - Recompensa: -0.544109556633759\n",
            "Total de pasos: 2999779/3000000.0 - Recompensa: -2.167567081833802\n",
            "Total de pasos: 2999780/3000000.0 - Recompensa: -0.39080513262958966\n",
            "Total de pasos: 2999781/3000000.0 - Recompensa: 0.2943619781433551\n",
            "0.2943619781433551\n",
            "Total de pasos: 2999782/3000000.0 - Recompensa: -1.4235369205166102\n",
            "Total de pasos: 2999783/3000000.0 - Recompensa: 0.1893762647665757\n",
            "0.1893762647665757\n",
            "Total de pasos: 2999784/3000000.0 - Recompensa: -0.4462674849132088\n",
            "Total de pasos: 2999785/3000000.0 - Recompensa: -1.1112662474005226\n",
            "Total de pasos: 2999786/3000000.0 - Recompensa: -1.8793723335912538\n",
            "Total de pasos: 2999787/3000000.0 - Recompensa: -0.49735921203326927\n",
            "Total de pasos: 2999788/3000000.0 - Recompensa: -0.9092107703346863\n",
            "Total de pasos: 2999789/3000000.0 - Recompensa: -1.8413020838005267\n",
            "Total de pasos: 2999790/3000000.0 - Recompensa: -1.7515398144747047\n",
            "Total de pasos: 2999791/3000000.0 - Recompensa: -0.12947612024214467\n",
            "Total de pasos: 2999792/3000000.0 - Recompensa: -3.067615576584473\n",
            "Total de pasos: 2999793/3000000.0 - Recompensa: 0.30845194013443245\n",
            "0.30845194013443245\n",
            "Total de pasos: 2999794/3000000.0 - Recompensa: -0.14826506112142385\n",
            "Total de pasos: 2999795/3000000.0 - Recompensa: -0.171149353925604\n",
            "Total de pasos: 2999796/3000000.0 - Recompensa: 0.5103032747784514\n",
            "0.5103032747784514\n",
            "Total de pasos: 2999797/3000000.0 - Recompensa: 0.03731191561775202\n",
            "0.03731191561775202\n",
            "Total de pasos: 2999798/3000000.0 - Recompensa: 0.11046366420765324\n",
            "0.11046366420765324\n",
            "Total de pasos: 2999799/3000000.0 - Recompensa: -0.6846824297757201\n",
            "Total de pasos: 2999800/3000000.0 - Recompensa: -0.15969564213303605\n",
            "Total de pasos: 2999801/3000000.0 - Recompensa: 0.9299104733320912\n",
            "0.9299104733320912\n",
            "Total de pasos: 2999802/3000000.0 - Recompensa: -0.48066238093977925\n",
            "Total de pasos: 2999803/3000000.0 - Recompensa: -0.8077220648476117\n",
            "Total de pasos: 2999804/3000000.0 - Recompensa: 0.0998192336480844\n",
            "0.0998192336480844\n",
            "Total de pasos: 2999805/3000000.0 - Recompensa: -0.732224550361967\n",
            "Total de pasos: 2999806/3000000.0 - Recompensa: 0.2022921799942312\n",
            "0.2022921799942312\n",
            "Total de pasos: 2999807/3000000.0 - Recompensa: -1.5438674134619315\n",
            "Total de pasos: 2999808/3000000.0 - Recompensa: -0.40673176798370647\n",
            "Total de pasos: 2999809/3000000.0 - Recompensa: 0.41729071517205923\n",
            "0.41729071517205923\n",
            "Total de pasos: 2999810/3000000.0 - Recompensa: -1.6705210525153296\n",
            "Total de pasos: 2999811/3000000.0 - Recompensa: 0.11368226823216337\n",
            "0.11368226823216337\n",
            "Total de pasos: 2999812/3000000.0 - Recompensa: -2.851933668069259\n",
            "Total de pasos: 2999813/3000000.0 - Recompensa: -0.4739550669723365\n",
            "Total de pasos: 2999814/3000000.0 - Recompensa: -1.1083071349635307\n",
            "Total de pasos: 2999815/3000000.0 - Recompensa: -1.264229623371419\n",
            "Total de pasos: 2999816/3000000.0 - Recompensa: 0.43345567066042084\n",
            "0.43345567066042084\n",
            "Total de pasos: 2999817/3000000.0 - Recompensa: -0.8393399689478105\n",
            "Total de pasos: 2999818/3000000.0 - Recompensa: -1.1734413601080493\n",
            "Total de pasos: 2999819/3000000.0 - Recompensa: -0.8028597736298677\n",
            "Total de pasos: 2999820/3000000.0 - Recompensa: 0.0981215961930994\n",
            "0.0981215961930994\n",
            "Total de pasos: 2999821/3000000.0 - Recompensa: 0.22591727153650595\n",
            "0.22591727153650595\n",
            "Total de pasos: 2999822/3000000.0 - Recompensa: -0.5236088197143184\n",
            "Total de pasos: 2999823/3000000.0 - Recompensa: -0.5092941098648704\n",
            "Total de pasos: 2999824/3000000.0 - Recompensa: -1.0846116670297503\n",
            "Total de pasos: 2999825/3000000.0 - Recompensa: -0.5529582370588643\n",
            "Total de pasos: 2999826/3000000.0 - Recompensa: -0.7626721351150911\n",
            "Total de pasos: 2999827/3000000.0 - Recompensa: -0.5883913190874985\n",
            "Total de pasos: 2999828/3000000.0 - Recompensa: -0.5545234396674907\n",
            "Total de pasos: 2999829/3000000.0 - Recompensa: -2.4157773819300967\n",
            "Total de pasos: 2999830/3000000.0 - Recompensa: -0.4820522612767844\n",
            "Total de pasos: 2999831/3000000.0 - Recompensa: 0.10861345238586079\n",
            "0.10861345238586079\n",
            "Total de pasos: 2999832/3000000.0 - Recompensa: -1.0313529401410186\n",
            "Total de pasos: 2999833/3000000.0 - Recompensa: -0.8187255524453276\n",
            "Total de pasos: 2999834/3000000.0 - Recompensa: -1.5588844755293345\n",
            "Total de pasos: 2999835/3000000.0 - Recompensa: -0.772587502136738\n",
            "Total de pasos: 2999836/3000000.0 - Recompensa: 0.3268723586355514\n",
            "0.3268723586355514\n",
            "Total de pasos: 2999837/3000000.0 - Recompensa: -1.12760523822211\n",
            "Total de pasos: 2999838/3000000.0 - Recompensa: -0.13293328327815015\n",
            "Total de pasos: 2999839/3000000.0 - Recompensa: -0.4476318102355994\n",
            "Total de pasos: 2999840/3000000.0 - Recompensa: -1.862714331913522\n",
            "Total de pasos: 2999841/3000000.0 - Recompensa: -0.21128257720516458\n",
            "Total de pasos: 2999842/3000000.0 - Recompensa: 0.14825889730955905\n",
            "0.14825889730955905\n",
            "Total de pasos: 2999843/3000000.0 - Recompensa: -0.9609354613607882\n",
            "Total de pasos: 2999844/3000000.0 - Recompensa: -1.4974879798351317\n",
            "Total de pasos: 2999845/3000000.0 - Recompensa: -0.2805973542250982\n",
            "Total de pasos: 2999846/3000000.0 - Recompensa: -1.0120427478780623\n",
            "Total de pasos: 2999847/3000000.0 - Recompensa: -0.1871788701891049\n",
            "Total de pasos: 2999848/3000000.0 - Recompensa: -2.4666167432491717\n",
            "Total de pasos: 2999849/3000000.0 - Recompensa: -0.7463387086807892\n",
            "Total de pasos: 2999850/3000000.0 - Recompensa: -0.4270289913785084\n",
            "Total de pasos: 2999851/3000000.0 - Recompensa: -1.480060112191464\n",
            "Total de pasos: 2999852/3000000.0 - Recompensa: -0.08168273885407912\n",
            "Total de pasos: 2999853/3000000.0 - Recompensa: -4.328895357609796\n",
            "Total de pasos: 2999854/3000000.0 - Recompensa: -1.1007323534388354\n",
            "Total de pasos: 2999855/3000000.0 - Recompensa: -0.3169991325297755\n",
            "Total de pasos: 2999856/3000000.0 - Recompensa: -0.5326547167437815\n",
            "Total de pasos: 2999857/3000000.0 - Recompensa: -1.105251959203391\n",
            "Total de pasos: 2999858/3000000.0 - Recompensa: -0.1261053914304874\n",
            "Total de pasos: 2999859/3000000.0 - Recompensa: 0.3988651018671773\n",
            "0.3988651018671773\n",
            "Total de pasos: 2999860/3000000.0 - Recompensa: -1.5687476437529768\n",
            "Total de pasos: 2999861/3000000.0 - Recompensa: -0.057954507007231204\n",
            "Total de pasos: 2999862/3000000.0 - Recompensa: 0.5783498118657355\n",
            "0.5783498118657355\n",
            "Total de pasos: 2999863/3000000.0 - Recompensa: -0.5243032132477466\n",
            "Total de pasos: 2999864/3000000.0 - Recompensa: -0.22666346690312872\n",
            "Total de pasos: 2999865/3000000.0 - Recompensa: 0.9975681758794193\n",
            "0.9975681758794193\n",
            "Total de pasos: 2999866/3000000.0 - Recompensa: 0.15762669281532923\n",
            "0.15762669281532923\n",
            "Total de pasos: 2999867/3000000.0 - Recompensa: -1.4771746069164366\n",
            "Total de pasos: 2999868/3000000.0 - Recompensa: -2.261561209144878\n",
            "Total de pasos: 2999869/3000000.0 - Recompensa: -2.0248604698876043\n",
            "Total de pasos: 2999870/3000000.0 - Recompensa: -1.5904294499090912\n",
            "Total de pasos: 2999871/3000000.0 - Recompensa: -0.23910542664097179\n",
            "Total de pasos: 2999872/3000000.0 - Recompensa: 0.7113771281936675\n",
            "0.7113771281936675\n",
            "Total de pasos: 2999873/3000000.0 - Recompensa: -0.3231565659414771\n",
            "Total de pasos: 2999874/3000000.0 - Recompensa: -0.7162566485465576\n",
            "Total de pasos: 2999875/3000000.0 - Recompensa: 0.2828703485323204\n",
            "0.2828703485323204\n",
            "Total de pasos: 2999876/3000000.0 - Recompensa: -2.00711135935612\n",
            "Total de pasos: 2999877/3000000.0 - Recompensa: -0.20839390333470575\n",
            "Total de pasos: 2999878/3000000.0 - Recompensa: -0.1359281089168797\n",
            "Total de pasos: 2999879/3000000.0 - Recompensa: -0.4396351536380701\n",
            "Total de pasos: 2999880/3000000.0 - Recompensa: -1.1037730264782075\n",
            "Total de pasos: 2999881/3000000.0 - Recompensa: -0.5550246438754315\n",
            "Total de pasos: 2999882/3000000.0 - Recompensa: -2.2202529541573104\n",
            "Total de pasos: 2999883/3000000.0 - Recompensa: -0.0026346692833017493\n",
            "Total de pasos: 2999884/3000000.0 - Recompensa: 0.13622486921640692\n",
            "0.13622486921640692\n",
            "Total de pasos: 2999885/3000000.0 - Recompensa: 0.35682032753572035\n",
            "0.35682032753572035\n",
            "Total de pasos: 2999886/3000000.0 - Recompensa: -1.3515526055862597\n",
            "Total de pasos: 2999887/3000000.0 - Recompensa: 0.43044208959328467\n",
            "0.43044208959328467\n",
            "Total de pasos: 2999888/3000000.0 - Recompensa: -0.8507101733096525\n",
            "Total de pasos: 2999889/3000000.0 - Recompensa: -1.1215869786228683\n",
            "Total de pasos: 2999890/3000000.0 - Recompensa: -2.741470761753813\n",
            "Total de pasos: 2999891/3000000.0 - Recompensa: -0.6069103385080863\n",
            "Total de pasos: 2999892/3000000.0 - Recompensa: -0.10043535739329684\n",
            "Total de pasos: 2999893/3000000.0 - Recompensa: -3.400753063979433\n",
            "Total de pasos: 2999894/3000000.0 - Recompensa: -2.9335625214462926\n",
            "Total de pasos: 2999895/3000000.0 - Recompensa: -0.027695755259423832\n",
            "Total de pasos: 2999896/3000000.0 - Recompensa: -1.3589005989616352\n",
            "Total de pasos: 2999897/3000000.0 - Recompensa: -2.017372139373693\n",
            "Total de pasos: 2999898/3000000.0 - Recompensa: -0.8077809283466484\n",
            "Total de pasos: 2999899/3000000.0 - Recompensa: -1.1682613181750323\n",
            "Total de pasos: 2999900/3000000.0 - Recompensa: -2.9904435537631904\n",
            "Total de pasos: 2999901/3000000.0 - Recompensa: -1.4617565148120093\n",
            "Total de pasos: 2999902/3000000.0 - Recompensa: -2.0133606139942906\n",
            "Total de pasos: 2999903/3000000.0 - Recompensa: -1.9480403444511318\n",
            "Total de pasos: 2999904/3000000.0 - Recompensa: 0.7889865326661267\n",
            "0.7889865326661267\n",
            "Total de pasos: 2999905/3000000.0 - Recompensa: -1.5077889719327755\n",
            "Total de pasos: 2999906/3000000.0 - Recompensa: -1.6116067147091304\n",
            "Total de pasos: 2999907/3000000.0 - Recompensa: -1.2304599739482989\n",
            "Total de pasos: 2999908/3000000.0 - Recompensa: -0.22870973868834135\n",
            "Total de pasos: 2999909/3000000.0 - Recompensa: -1.7693080265845968\n",
            "Total de pasos: 2999910/3000000.0 - Recompensa: -1.0350821425227992\n",
            "Total de pasos: 2999911/3000000.0 - Recompensa: -0.33697348136141103\n",
            "Total de pasos: 2999912/3000000.0 - Recompensa: 0.1123523517081903\n",
            "0.1123523517081903\n",
            "Total de pasos: 2999913/3000000.0 - Recompensa: -0.8487036836195607\n",
            "Total de pasos: 2999914/3000000.0 - Recompensa: -0.9912777583845738\n",
            "Total de pasos: 2999915/3000000.0 - Recompensa: -0.2818558318509087\n",
            "Total de pasos: 2999916/3000000.0 - Recompensa: -1.5823775462949556\n",
            "Total de pasos: 2999917/3000000.0 - Recompensa: -0.8413306453103939\n",
            "Total de pasos: 2999918/3000000.0 - Recompensa: 0.4492253838790481\n",
            "0.4492253838790481\n",
            "Total de pasos: 2999919/3000000.0 - Recompensa: -0.7269737236786161\n",
            "Total de pasos: 2999920/3000000.0 - Recompensa: 0.057440229400759435\n",
            "0.057440229400759435\n",
            "Total de pasos: 2999921/3000000.0 - Recompensa: -1.9586213617007981\n",
            "Total de pasos: 2999922/3000000.0 - Recompensa: -0.599196525298494\n",
            "Total de pasos: 2999923/3000000.0 - Recompensa: -0.3523350721825035\n",
            "Total de pasos: 2999924/3000000.0 - Recompensa: -0.2066713990419225\n",
            "Total de pasos: 2999925/3000000.0 - Recompensa: -3.255115637889253\n",
            "Total de pasos: 2999926/3000000.0 - Recompensa: -0.734125730654442\n",
            "Total de pasos: 2999927/3000000.0 - Recompensa: -0.7291865084414906\n",
            "Total de pasos: 2999928/3000000.0 - Recompensa: -2.3601345331349344\n",
            "Total de pasos: 2999929/3000000.0 - Recompensa: -0.4130861682914884\n",
            "Total de pasos: 2999930/3000000.0 - Recompensa: -1.2399558907964192\n",
            "Total de pasos: 2999931/3000000.0 - Recompensa: -1.5797679855927418\n",
            "Total de pasos: 2999932/3000000.0 - Recompensa: -0.03630672463407994\n",
            "Total de pasos: 2999933/3000000.0 - Recompensa: 0.3422787442416581\n",
            "0.3422787442416581\n",
            "Total de pasos: 2999934/3000000.0 - Recompensa: -1.7200233360761206\n",
            "Total de pasos: 2999935/3000000.0 - Recompensa: -0.5693988391918995\n",
            "Total de pasos: 2999936/3000000.0 - Recompensa: -0.13575278109484362\n",
            "Total de pasos: 2999937/3000000.0 - Recompensa: 0.26410596231089406\n",
            "0.26410596231089406\n",
            "Total de pasos: 2999938/3000000.0 - Recompensa: 0.37899032321368453\n",
            "0.37899032321368453\n",
            "Total de pasos: 2999939/3000000.0 - Recompensa: -2.972907765423384\n",
            "Total de pasos: 2999940/3000000.0 - Recompensa: -0.6859327219207854\n",
            "Total de pasos: 2999941/3000000.0 - Recompensa: -0.15898326311565497\n",
            "Total de pasos: 2999942/3000000.0 - Recompensa: -0.9916620137889172\n",
            "Total de pasos: 2999943/3000000.0 - Recompensa: -3.8106306938825987\n",
            "Total de pasos: 2999944/3000000.0 - Recompensa: -0.2681589012519242\n",
            "Total de pasos: 2999945/3000000.0 - Recompensa: -0.7861228642205246\n",
            "Total de pasos: 2999946/3000000.0 - Recompensa: -4.08829592982616\n",
            "Total de pasos: 2999947/3000000.0 - Recompensa: -1.642865357079988\n",
            "Total de pasos: 2999948/3000000.0 - Recompensa: -0.6276389168245653\n",
            "Total de pasos: 2999949/3000000.0 - Recompensa: -0.37298710806828106\n",
            "Total de pasos: 2999950/3000000.0 - Recompensa: -1.226413844830324\n",
            "Total de pasos: 2999951/3000000.0 - Recompensa: -0.030056391221698814\n",
            "Total de pasos: 2999952/3000000.0 - Recompensa: -0.9830209550591678\n",
            "Total de pasos: 2999953/3000000.0 - Recompensa: -0.8966753039266087\n",
            "Total de pasos: 2999954/3000000.0 - Recompensa: 0.09470385584669239\n",
            "0.09470385584669239\n",
            "Total de pasos: 2999955/3000000.0 - Recompensa: -2.3688342450953184\n",
            "Total de pasos: 2999956/3000000.0 - Recompensa: 0.35640394006439324\n",
            "0.35640394006439324\n",
            "Total de pasos: 2999957/3000000.0 - Recompensa: -1.4764340459020227\n",
            "Total de pasos: 2999958/3000000.0 - Recompensa: -0.6768624392444011\n",
            "Total de pasos: 2999959/3000000.0 - Recompensa: -1.1367008224691422\n",
            "Total de pasos: 2999960/3000000.0 - Recompensa: -1.5811425114728928\n",
            "Total de pasos: 2999961/3000000.0 - Recompensa: -1.3410877700340826\n",
            "Total de pasos: 2999962/3000000.0 - Recompensa: -1.838469551347853\n",
            "Total de pasos: 2999963/3000000.0 - Recompensa: -0.9948821059747439\n",
            "Total de pasos: 2999964/3000000.0 - Recompensa: -2.1827688029873564\n",
            "Total de pasos: 2999965/3000000.0 - Recompensa: 1.0554589317607834\n",
            "1.0554589317607834\n",
            "Total de pasos: 2999966/3000000.0 - Recompensa: -1.4935036927730772\n",
            "Total de pasos: 2999967/3000000.0 - Recompensa: -0.6614297748695391\n",
            "Total de pasos: 2999968/3000000.0 - Recompensa: -0.6293188655148174\n",
            "Total de pasos: 2999969/3000000.0 - Recompensa: -2.343698013979631\n",
            "Total de pasos: 2999970/3000000.0 - Recompensa: -0.6731689975673241\n",
            "Total de pasos: 2999971/3000000.0 - Recompensa: -0.6584077362073615\n",
            "Total de pasos: 2999972/3000000.0 - Recompensa: -1.6981991471855173\n",
            "Total de pasos: 2999973/3000000.0 - Recompensa: 0.5204025604473845\n",
            "0.5204025604473845\n",
            "Total de pasos: 2999974/3000000.0 - Recompensa: 0.22974596598224445\n",
            "0.22974596598224445\n",
            "Total de pasos: 2999975/3000000.0 - Recompensa: -0.18616958673461195\n",
            "Total de pasos: 2999976/3000000.0 - Recompensa: -1.1751318174033867\n",
            "Total de pasos: 2999977/3000000.0 - Recompensa: -0.11845359499708322\n",
            "Total de pasos: 2999978/3000000.0 - Recompensa: -1.099863530631418\n",
            "Total de pasos: 2999979/3000000.0 - Recompensa: -1.1269536499596517\n",
            "Total de pasos: 2999980/3000000.0 - Recompensa: -0.5298454114839769\n",
            "Total de pasos: 2999981/3000000.0 - Recompensa: -0.5027205788107695\n",
            "Total de pasos: 2999982/3000000.0 - Recompensa: -0.27875080579407185\n",
            "Total de pasos: 2999983/3000000.0 - Recompensa: -0.2330605444956671\n",
            "Total de pasos: 2999984/3000000.0 - Recompensa: -0.4262095825520181\n",
            "Total de pasos: 2999985/3000000.0 - Recompensa: -2.3771444018106496\n",
            "Total de pasos: 2999986/3000000.0 - Recompensa: -3.2029313222821734\n",
            "Total de pasos: 2999987/3000000.0 - Recompensa: -1.5428924119695722\n",
            "Total de pasos: 2999988/3000000.0 - Recompensa: 0.3188074509073186\n",
            "0.3188074509073186\n",
            "Total de pasos: 2999989/3000000.0 - Recompensa: -1.7791997708590883\n",
            "Total de pasos: 2999990/3000000.0 - Recompensa: -0.6449864648955568\n",
            "Total de pasos: 2999991/3000000.0 - Recompensa: -0.6875985547069615\n",
            "Total de pasos: 2999992/3000000.0 - Recompensa: -0.16983967063019906\n",
            "Total de pasos: 2999993/3000000.0 - Recompensa: -0.3973367980863912\n",
            "Total de pasos: 2999994/3000000.0 - Recompensa: -0.92110807908425\n",
            "Total de pasos: 2999995/3000000.0 - Recompensa: -1.2775742637791776\n",
            "Total de pasos: 2999996/3000000.0 - Recompensa: -1.3518371165135405\n",
            "Total de pasos: 2999997/3000000.0 - Recompensa: -0.13908572013443182\n",
            "Total de pasos: 2999998/3000000.0 - Recompensa: -0.6695363931283168\n",
            "Total de pasos: 2999999/3000000.0 - Recompensa: -1.016790863038035\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "max_steps = max_timesteps  # Número máximo de pasos\n",
        "positive_rewards = []\n",
        "\n",
        "total_steps       = 0\n",
        "episodeo          = 0\n",
        "# Nos creamos la memoria de repetición de experiencias\n",
        "max_cap = int(2e4)\n",
        "replay_buff_pos =  ReplayBufferPos(max_capacity = max_cap)# Notar que la máxima capacidad de la memoria por defecto es: max_capacity = 1e4\n",
        "\n",
        "max_iter = 3 * max_steps\n",
        "while  total_steps < max_iter:\n",
        "    obs = env.reset()  # Reiniciar el entorno y obtener el estado inicial\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = env.action_space.sample()  # Tomar una acción aleatoria\n",
        "        next_obs, reward, done, _ = env.step(action)  # Realizar la acción y observar el resultado\n",
        "\n",
        "        # Almacenar la transición (estado inicial, estado final, acción, recompensa)\n",
        "        transition = (obs, next_obs, action, reward, done)\n",
        "\n",
        "        print(f'Total de pasos: {total_steps}/{max_iter} - Recompensa: {reward}')\n",
        "\n",
        "        # Verificar si la recompensa es positiva y almacenarla en la lista\n",
        "        if reward > 0:\n",
        "            print (reward)\n",
        "\n",
        "            positive_rewards.append (reward)\n",
        "            replay_buff_pos.add (transition)\n",
        "\n",
        "        obs = next_obs\n",
        "        total_steps += 1\n",
        "        if total_steps >= max_steps:\n",
        "            break\n",
        "\n",
        "    # Verificar si todas las transiciones tienen recompensas positivas\n",
        "    if len (positive_rewards) == max_start_steps:\n",
        "        print(\"Todas las transiciones tienen recompensas positivas. Deteniendo el entrenamiento.\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "WEijUywoeK3t",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEijUywoeK3t",
        "outputId": "d21e3201-0f85-4ec5-c160-277d5db52820"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "495982"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len (positive_rewards)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IdCsA3m6DHKb",
      "metadata": {
        "id": "IdCsA3m6DHKb"
      },
      "source": [
        "#Step 3.2: Etapa de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fc8e914c-0170-4af2-8cce-4ad02252b0c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc8e914c-0170-4af2-8cce-4ad02252b0c8",
        "outputId": "b4f33df1-248a-40f6-f65a-4eae4a36d222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "Total Steps: 531888 Episode Num: 8780 Reward: 85.05656993944457 avg_loss_c: 4.2711172657953185 avg_loss_a: -50.238874730929524\n",
            "Número de pasos del episodio 8781 son episode_steps:99\n",
            "Total Steps: 531987 Episode Num: 8781 Reward: 153.1438238487227 avg_loss_c: 4.0886034724688285 avg_loss_a: -50.65918635358714\n",
            "Número de pasos del episodio 8782 son episode_steps:81\n",
            "Total Steps: 532068 Episode Num: 8782 Reward: 111.63149037126396 avg_loss_c: 4.299364416687577 avg_loss_a: -50.469676076630016\n",
            "Número de pasos del episodio 8783 son episode_steps:79\n",
            "Total Steps: 532147 Episode Num: 8783 Reward: 82.68822679807445 avg_loss_c: 4.403769613821296 avg_loss_a: -50.349261078653456\n",
            "Número de pasos del episodio 8784 son episode_steps:94\n",
            "Total Steps: 532241 Episode Num: 8784 Reward: 116.1131736190497 avg_loss_c: 3.888538619305225 avg_loss_a: -50.37811206249481\n",
            "Número de pasos del episodio 8785 son episode_steps:101\n",
            "Total Steps: 532342 Episode Num: 8785 Reward: 157.1405964292399 avg_loss_c: 4.141736403550252 avg_loss_a: -50.55307954844862\n",
            "Número de pasos del episodio 8786 son episode_steps:81\n",
            "Total Steps: 532423 Episode Num: 8786 Reward: 88.0579433243035 avg_loss_c: 3.8769017296072876 avg_loss_a: -50.282461943449796\n",
            "Número de pasos del episodio 8787 son episode_steps:67\n",
            "Total Steps: 532490 Episode Num: 8787 Reward: 97.03112422015091 avg_loss_c: 4.085872336999694 avg_loss_a: -51.22407531738281\n",
            "Número de pasos del episodio 8788 son episode_steps:118\n",
            "Total Steps: 532608 Episode Num: 8788 Reward: 185.1666342284228 avg_loss_c: 4.06579400119135 avg_loss_a: -51.0471648523363\n",
            "Número de pasos del episodio 8789 son episode_steps:101\n",
            "Total Steps: 532709 Episode Num: 8789 Reward: 150.4118113119701 avg_loss_c: 4.0685592098991465 avg_loss_a: -51.248134197575034\n",
            "Número de pasos del episodio 8790 son episode_steps:104\n",
            "Total Steps: 532813 Episode Num: 8790 Reward: 140.46204179583071 avg_loss_c: 4.492466564361866 avg_loss_a: -50.90150957841139\n",
            "Número de pasos del episodio 8791 son episode_steps:175\n",
            "Total Steps: 532988 Episode Num: 8791 Reward: 216.85391710954792 avg_loss_c: 4.441290309088571 avg_loss_a: -50.87492071969169\n",
            "Número de pasos del episodio 8792 son episode_steps:132\n",
            "Total Steps: 533120 Episode Num: 8792 Reward: 106.70160002038837 avg_loss_c: 4.32173840746735 avg_loss_a: -50.67648714238947\n",
            "Número de pasos del episodio 8793 son episode_steps:100\n",
            "Total Steps: 533220 Episode Num: 8793 Reward: 146.38658158223834 avg_loss_c: 4.161877326965332 avg_loss_a: -51.27612976074219\n",
            "Número de pasos del episodio 8794 son episode_steps:65\n",
            "Total Steps: 533285 Episode Num: 8794 Reward: 93.96730368866241 avg_loss_c: 4.540884901927067 avg_loss_a: -51.17549485426683\n",
            "Número de pasos del episodio 8795 son episode_steps:45\n",
            "Total Steps: 533330 Episode Num: 8795 Reward: 43.29526175610334 avg_loss_c: 4.1524238851335316 avg_loss_a: -50.66787855360243\n",
            "Número de pasos del episodio 8796 son episode_steps:88\n",
            "Total Steps: 533418 Episode Num: 8796 Reward: 125.77852988681713 avg_loss_c: 4.469110957600853 avg_loss_a: -51.13961609927091\n",
            "Número de pasos del episodio 8797 son episode_steps:75\n",
            "Total Steps: 533493 Episode Num: 8797 Reward: 108.45257328823202 avg_loss_c: 4.099450956980387 avg_loss_a: -51.711355946858724\n",
            "Número de pasos del episodio 8798 son episode_steps:122\n",
            "Total Steps: 533615 Episode Num: 8798 Reward: 186.87045920446727 avg_loss_c: 4.1499615770871525 avg_loss_a: -51.29870699272781\n",
            "Número de pasos del episodio 8799 son episode_steps:87\n",
            "Total Steps: 533702 Episode Num: 8799 Reward: 119.76826965366111 avg_loss_c: 4.01665778269713 avg_loss_a: -50.72597885131836\n",
            "Número de pasos del episodio 8800 son episode_steps:98\n",
            "Total Steps: 533800 Episode Num: 8800 Reward: 156.4357228737958 avg_loss_c: 4.162862347096813 avg_loss_a: -51.47713057848872\n",
            "Número de pasos del episodio 8801 son episode_steps:72\n",
            "Total Steps: 533872 Episode Num: 8801 Reward: 75.8932071804376 avg_loss_c: 4.3369007011254626 avg_loss_a: -51.47771633995904\n",
            "Número de pasos del episodio 8802 son episode_steps:24\n",
            "Total Steps: 533896 Episode Num: 8802 Reward: -2.024843510710647 avg_loss_c: 4.920936952034633 avg_loss_a: -51.106871922810875\n",
            "Número de pasos del episodio 8803 son episode_steps:117\n",
            "Total Steps: 534013 Episode Num: 8803 Reward: 188.87677541669314 avg_loss_c: 4.555606183842716 avg_loss_a: -51.48105324639214\n",
            "Número de pasos del episodio 8804 son episode_steps:88\n",
            "Total Steps: 534101 Episode Num: 8804 Reward: 151.94123143135306 avg_loss_c: 4.298634049567309 avg_loss_a: -50.359966711564496\n",
            "Número de pasos del episodio 8805 son episode_steps:128\n",
            "Total Steps: 534229 Episode Num: 8805 Reward: 134.5713491660789 avg_loss_c: 4.482822921127081 avg_loss_a: -50.52817493677139\n",
            "Número de pasos del episodio 8806 son episode_steps:112\n",
            "Total Steps: 534341 Episode Num: 8806 Reward: 115.05837359916967 avg_loss_c: 4.717693558761051 avg_loss_a: -51.20046935762678\n",
            "Número de pasos del episodio 8807 son episode_steps:97\n",
            "Total Steps: 534438 Episode Num: 8807 Reward: 140.388566534449 avg_loss_c: 4.49042434299115 avg_loss_a: -51.59494761830753\n",
            "Número de pasos del episodio 8808 son episode_steps:112\n",
            "Total Steps: 534550 Episode Num: 8808 Reward: 140.50693085236466 avg_loss_c: 4.485238741551127 avg_loss_a: -51.417090960911345\n",
            "Número de pasos del episodio 8809 son episode_steps:46\n",
            "Total Steps: 534596 Episode Num: 8809 Reward: 20.536647107280658 avg_loss_c: 4.27035317213639 avg_loss_a: -50.9274666827658\n",
            "Número de pasos del episodio 8810 son episode_steps:60\n",
            "Total Steps: 534656 Episode Num: 8810 Reward: 89.98258311919085 avg_loss_c: 4.406564939022064 avg_loss_a: -51.30943336486816\n",
            "Número de pasos del episodio 8811 son episode_steps:85\n",
            "Total Steps: 534741 Episode Num: 8811 Reward: 115.14507977130803 avg_loss_c: 4.495144092335421 avg_loss_a: -50.86924662870519\n",
            "Número de pasos del episodio 8812 son episode_steps:84\n",
            "Total Steps: 534825 Episode Num: 8812 Reward: 121.5318869961134 avg_loss_c: 4.713589949267251 avg_loss_a: -51.41150465465727\n",
            "Número de pasos del episodio 8813 son episode_steps:72\n",
            "Total Steps: 534897 Episode Num: 8813 Reward: 108.3435441197433 avg_loss_c: 4.359714931911892 avg_loss_a: -51.35243437025282\n",
            "Número de pasos del episodio 8814 son episode_steps:93\n",
            "Total Steps: 534990 Episode Num: 8814 Reward: 128.2629892983385 avg_loss_c: 4.242763509032547 avg_loss_a: -51.15887258386099\n",
            "Número de pasos del episodio 8815 son episode_steps:101\n",
            "Total Steps: 535091 Episode Num: 8815 Reward: 130.94573939903765 avg_loss_c: 4.405765181720847 avg_loss_a: -51.33682972369808\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 143.017934\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 8816 son episode_steps:70\n",
            "Total Steps: 535161 Episode Num: 8816 Reward: 116.43745696475435 avg_loss_c: 4.147328870637076 avg_loss_a: -51.816084943498886\n",
            "Número de pasos del episodio 8817 son episode_steps:96\n",
            "Total Steps: 535257 Episode Num: 8817 Reward: 155.13930384277182 avg_loss_c: 4.278660876055558 avg_loss_a: -51.71099344889323\n",
            "Número de pasos del episodio 8818 son episode_steps:61\n",
            "Total Steps: 535318 Episode Num: 8818 Reward: 90.81659583547449 avg_loss_c: 4.3476778874631785 avg_loss_a: -51.25065594032163\n",
            "Número de pasos del episodio 8819 son episode_steps:52\n",
            "Total Steps: 535370 Episode Num: 8819 Reward: 40.99613137239455 avg_loss_c: 4.837026797808134 avg_loss_a: -51.26137572068434\n",
            "Número de pasos del episodio 8820 son episode_steps:51\n",
            "Total Steps: 535421 Episode Num: 8820 Reward: 75.72861761439253 avg_loss_c: 4.846882544311822 avg_loss_a: -51.74945576985677\n",
            "Número de pasos del episodio 8821 son episode_steps:79\n",
            "Total Steps: 535500 Episode Num: 8821 Reward: 117.94844242555405 avg_loss_c: 4.423591483997393 avg_loss_a: -51.27824266651009\n",
            "Número de pasos del episodio 8822 son episode_steps:32\n",
            "Total Steps: 535532 Episode Num: 8822 Reward: -1.3085363009742763 avg_loss_c: 4.493598975241184 avg_loss_a: -52.113463401794434\n",
            "Número de pasos del episodio 8823 son episode_steps:146\n",
            "Total Steps: 535678 Episode Num: 8823 Reward: 209.8406442489564 avg_loss_c: 4.512740371978446 avg_loss_a: -51.10207920858305\n",
            "Número de pasos del episodio 8824 son episode_steps:55\n",
            "Total Steps: 535733 Episode Num: 8824 Reward: 49.32039391872705 avg_loss_c: 4.4871765916997735 avg_loss_a: -51.168583540482956\n",
            "Número de pasos del episodio 8825 son episode_steps:108\n",
            "Total Steps: 535841 Episode Num: 8825 Reward: 131.31163947819914 avg_loss_c: 4.52016004147353 avg_loss_a: -50.95760875278049\n",
            "Número de pasos del episodio 8826 son episode_steps:67\n",
            "Total Steps: 535908 Episode Num: 8826 Reward: 108.19556724304384 avg_loss_c: 4.463013777092321 avg_loss_a: -50.836869937270436\n",
            "Número de pasos del episodio 8827 son episode_steps:121\n",
            "Total Steps: 536029 Episode Num: 8827 Reward: 190.83466323447675 avg_loss_c: 4.758386142982924 avg_loss_a: -51.20641869158784\n",
            "Número de pasos del episodio 8828 son episode_steps:75\n",
            "Total Steps: 536104 Episode Num: 8828 Reward: 99.7794957703899 avg_loss_c: 4.947356332143148 avg_loss_a: -51.28974512736003\n",
            "Número de pasos del episodio 8829 son episode_steps:100\n",
            "Total Steps: 536204 Episode Num: 8829 Reward: 111.01298903060932 avg_loss_c: 4.401452105045319 avg_loss_a: -50.833187408447266\n",
            "Número de pasos del episodio 8830 son episode_steps:64\n",
            "Total Steps: 536268 Episode Num: 8830 Reward: 70.78756614882909 avg_loss_c: 4.405827850103378 avg_loss_a: -50.93385028839111\n",
            "Número de pasos del episodio 8831 son episode_steps:132\n",
            "Total Steps: 536400 Episode Num: 8831 Reward: 200.6059887695822 avg_loss_c: 4.706695999159957 avg_loss_a: -50.75638534083511\n",
            "Número de pasos del episodio 8832 son episode_steps:49\n",
            "Total Steps: 536449 Episode Num: 8832 Reward: 22.11026022392947 avg_loss_c: 4.639639781445873 avg_loss_a: -51.593353582888234\n",
            "Número de pasos del episodio 8833 son episode_steps:98\n",
            "Total Steps: 536547 Episode Num: 8833 Reward: 129.03245643556602 avg_loss_c: 4.5472666827999815 avg_loss_a: -50.807875341298626\n",
            "Número de pasos del episodio 8834 son episode_steps:100\n",
            "Total Steps: 536647 Episode Num: 8834 Reward: 88.95888464040216 avg_loss_c: 5.0002141237258915 avg_loss_a: -50.261655731201174\n",
            "Número de pasos del episodio 8835 son episode_steps:109\n",
            "Total Steps: 536756 Episode Num: 8835 Reward: 171.1739174000827 avg_loss_c: 4.792343526805213 avg_loss_a: -50.74294851460588\n",
            "Número de pasos del episodio 8836 son episode_steps:74\n",
            "Total Steps: 536830 Episode Num: 8836 Reward: 53.36442194194944 avg_loss_c: 4.655732257946117 avg_loss_a: -51.542482118348815\n",
            "Número de pasos del episodio 8837 son episode_steps:73\n",
            "Total Steps: 536903 Episode Num: 8837 Reward: 115.39919025251822 avg_loss_c: 4.414375889791201 avg_loss_a: -50.52665261046527\n",
            "Número de pasos del episodio 8838 son episode_steps:42\n",
            "Total Steps: 536945 Episode Num: 8838 Reward: 18.73778035602109 avg_loss_c: 5.006483492397127 avg_loss_a: -50.49044436500186\n",
            "Número de pasos del episodio 8839 son episode_steps:87\n",
            "Total Steps: 537032 Episode Num: 8839 Reward: 105.64295684778214 avg_loss_c: 4.704488491189891 avg_loss_a: -51.198754760040636\n",
            "Número de pasos del episodio 8840 son episode_steps:77\n",
            "Total Steps: 537109 Episode Num: 8840 Reward: 114.04137448195316 avg_loss_c: 4.668016730964958 avg_loss_a: -50.76006946316013\n",
            "Número de pasos del episodio 8841 son episode_steps:72\n",
            "Total Steps: 537181 Episode Num: 8841 Reward: 122.5932592376163 avg_loss_c: 4.576257924238841 avg_loss_a: -50.86324670579698\n",
            "Número de pasos del episodio 8842 son episode_steps:85\n",
            "Total Steps: 537266 Episode Num: 8842 Reward: 122.7975546505647 avg_loss_c: 4.750958748424755 avg_loss_a: -50.756081031350526\n",
            "Número de pasos del episodio 8843 son episode_steps:85\n",
            "Total Steps: 537351 Episode Num: 8843 Reward: 99.39533829463987 avg_loss_c: 4.623103613011978 avg_loss_a: -51.07211160098805\n",
            "Número de pasos del episodio 8844 son episode_steps:142\n",
            "Total Steps: 537493 Episode Num: 8844 Reward: 228.30932844594045 avg_loss_c: 4.960842725256799 avg_loss_a: -51.25144695228254\n",
            "Número de pasos del episodio 8845 son episode_steps:100\n",
            "Total Steps: 537593 Episode Num: 8845 Reward: 155.15228822063943 avg_loss_c: 4.415230338573456 avg_loss_a: -50.69084197998047\n",
            "Número de pasos del episodio 8846 son episode_steps:107\n",
            "Total Steps: 537700 Episode Num: 8846 Reward: 121.18820978132432 avg_loss_c: 4.718495057007977 avg_loss_a: -51.17356790560428\n",
            "Número de pasos del episodio 8847 son episode_steps:92\n",
            "Total Steps: 537792 Episode Num: 8847 Reward: 107.04685285093372 avg_loss_c: 4.5017990651338 avg_loss_a: -51.8268055293871\n",
            "Número de pasos del episodio 8848 son episode_steps:100\n",
            "Total Steps: 537892 Episode Num: 8848 Reward: 116.00521972259948 avg_loss_c: 4.472196147441864 avg_loss_a: -51.35708282470703\n",
            "Número de pasos del episodio 8849 son episode_steps:51\n",
            "Total Steps: 537943 Episode Num: 8849 Reward: 40.21047004484912 avg_loss_c: 4.690573753095141 avg_loss_a: -50.89605338900697\n",
            "Número de pasos del episodio 8850 son episode_steps:67\n",
            "Total Steps: 538010 Episode Num: 8850 Reward: 102.59316068678933 avg_loss_c: 4.8503924234589535 avg_loss_a: -51.302595736375494\n",
            "Número de pasos del episodio 8851 son episode_steps:86\n",
            "Total Steps: 538096 Episode Num: 8851 Reward: 144.46951228045157 avg_loss_c: 4.787882009217905 avg_loss_a: -50.9131500776424\n",
            "Número de pasos del episodio 8852 son episode_steps:77\n",
            "Total Steps: 538173 Episode Num: 8852 Reward: 129.80578507430374 avg_loss_c: 4.850337551785754 avg_loss_a: -51.035608663187396\n",
            "Número de pasos del episodio 8853 son episode_steps:64\n",
            "Total Steps: 538237 Episode Num: 8853 Reward: 100.66377797584718 avg_loss_c: 4.479133505374193 avg_loss_a: -51.19770431518555\n",
            "Número de pasos del episodio 8854 son episode_steps:96\n",
            "Total Steps: 538333 Episode Num: 8854 Reward: 163.21293411703434 avg_loss_c: 4.497567971547444 avg_loss_a: -51.41404914855957\n",
            "Número de pasos del episodio 8855 son episode_steps:45\n",
            "Total Steps: 538378 Episode Num: 8855 Reward: 49.458364941330274 avg_loss_c: 4.865284909142388 avg_loss_a: -50.568436008029515\n",
            "Número de pasos del episodio 8856 son episode_steps:83\n",
            "Total Steps: 538461 Episode Num: 8856 Reward: 125.6568201683112 avg_loss_c: 4.386278666645648 avg_loss_a: -51.08462717446936\n",
            "Número de pasos del episodio 8857 son episode_steps:71\n",
            "Total Steps: 538532 Episode Num: 8857 Reward: 117.10792274868435 avg_loss_c: 4.3578183113689155 avg_loss_a: -50.91549354875591\n",
            "Número de pasos del episodio 8858 son episode_steps:92\n",
            "Total Steps: 538624 Episode Num: 8858 Reward: 148.82045704280767 avg_loss_c: 4.66669251607812 avg_loss_a: -51.417620036913\n",
            "Número de pasos del episodio 8859 son episode_steps:109\n",
            "Total Steps: 538733 Episode Num: 8859 Reward: 177.4348274776238 avg_loss_c: 4.437479819726507 avg_loss_a: -51.228754586036054\n",
            "Número de pasos del episodio 8860 son episode_steps:63\n",
            "Total Steps: 538796 Episode Num: 8860 Reward: 105.63465926539193 avg_loss_c: 4.439355948614696 avg_loss_a: -51.34005567762587\n",
            "Número de pasos del episodio 8861 son episode_steps:84\n",
            "Total Steps: 538880 Episode Num: 8861 Reward: 132.75156498858544 avg_loss_c: 4.248084071136656 avg_loss_a: -51.21183486211868\n",
            "Número de pasos del episodio 8862 son episode_steps:75\n",
            "Total Steps: 538955 Episode Num: 8862 Reward: 46.42203205634544 avg_loss_c: 4.903706607818603 avg_loss_a: -51.111312052408856\n",
            "Número de pasos del episodio 8863 son episode_steps:139\n",
            "Total Steps: 539094 Episode Num: 8863 Reward: 219.76061207377268 avg_loss_c: 4.4735360317093 avg_loss_a: -50.958357063128794\n",
            "Número de pasos del episodio 8864 son episode_steps:68\n",
            "Total Steps: 539162 Episode Num: 8864 Reward: 97.49459012076677 avg_loss_c: 4.190026318325716 avg_loss_a: -51.30375435773064\n",
            "Número de pasos del episodio 8865 son episode_steps:27\n",
            "Total Steps: 539189 Episode Num: 8865 Reward: 2.0649039736038985 avg_loss_c: 5.355890795036599 avg_loss_a: -52.00489397402163\n",
            "Número de pasos del episodio 8866 son episode_steps:138\n",
            "Total Steps: 539327 Episode Num: 8866 Reward: 180.51876433470903 avg_loss_c: 4.3845316119816 avg_loss_a: -51.67679032035496\n",
            "Número de pasos del episodio 8867 son episode_steps:75\n",
            "Total Steps: 539402 Episode Num: 8867 Reward: 119.62296861172649 avg_loss_c: 4.3564021841684974 avg_loss_a: -50.89522735595703\n",
            "Número de pasos del episodio 8868 son episode_steps:60\n",
            "Total Steps: 539462 Episode Num: 8868 Reward: 87.13693697842746 avg_loss_c: 4.239047348499298 avg_loss_a: -50.85705362955729\n",
            "Número de pasos del episodio 8869 son episode_steps:55\n",
            "Total Steps: 539517 Episode Num: 8869 Reward: 84.17240431401343 avg_loss_c: 4.275352928855202 avg_loss_a: -50.65459837480025\n",
            "Número de pasos del episodio 8870 son episode_steps:92\n",
            "Total Steps: 539609 Episode Num: 8870 Reward: 142.72104439960532 avg_loss_c: 4.460574199324069 avg_loss_a: -50.24095833819845\n",
            "Número de pasos del episodio 8871 son episode_steps:146\n",
            "Total Steps: 539755 Episode Num: 8871 Reward: 113.72867598085104 avg_loss_c: 4.565939537466389 avg_loss_a: -51.2481404134672\n",
            "Número de pasos del episodio 8872 son episode_steps:56\n",
            "Total Steps: 539811 Episode Num: 8872 Reward: 77.81530244887423 avg_loss_c: 5.012774071523121 avg_loss_a: -50.20502526419504\n",
            "Número de pasos del episodio 8873 son episode_steps:61\n",
            "Total Steps: 539872 Episode Num: 8873 Reward: 89.79797122412326 avg_loss_c: 4.641631407815902 avg_loss_a: -51.37886172435323\n",
            "Número de pasos del episodio 8874 son episode_steps:101\n",
            "Total Steps: 539973 Episode Num: 8874 Reward: 147.02317879996875 avg_loss_c: 4.41813602305875 avg_loss_a: -51.019893079701035\n",
            "Número de pasos del episodio 8875 son episode_steps:76\n",
            "Total Steps: 540049 Episode Num: 8875 Reward: 109.79791579876378 avg_loss_c: 4.380031708039735 avg_loss_a: -50.42047801770662\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 95.353140\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 8876 son episode_steps:89\n",
            "Total Steps: 540138 Episode Num: 8876 Reward: 94.6761186896247 avg_loss_c: 4.804894374997429 avg_loss_a: -50.64421317282687\n",
            "Número de pasos del episodio 8877 son episode_steps:59\n",
            "Total Steps: 540197 Episode Num: 8877 Reward: 96.3254424877484 avg_loss_c: 4.3821238703646905 avg_loss_a: -50.16149818291098\n",
            "Número de pasos del episodio 8878 son episode_steps:26\n",
            "Total Steps: 540223 Episode Num: 8878 Reward: -13.439312686923195 avg_loss_c: 4.742464496539189 avg_loss_a: -49.98308856670673\n",
            "Número de pasos del episodio 8879 son episode_steps:75\n",
            "Total Steps: 540298 Episode Num: 8879 Reward: 120.55981634838078 avg_loss_c: 4.87498340288798 avg_loss_a: -50.8151601155599\n",
            "Número de pasos del episodio 8880 son episode_steps:81\n",
            "Total Steps: 540379 Episode Num: 8880 Reward: 122.39290104314834 avg_loss_c: 5.137295098952305 avg_loss_a: -50.40460916213048\n",
            "Número de pasos del episodio 8881 son episode_steps:77\n",
            "Total Steps: 540456 Episode Num: 8881 Reward: 129.7216401431769 avg_loss_c: 4.864697366565853 avg_loss_a: -50.83849963894138\n",
            "Número de pasos del episodio 8882 son episode_steps:85\n",
            "Total Steps: 540541 Episode Num: 8882 Reward: 143.13031948164942 avg_loss_c: 4.442184106041403 avg_loss_a: -51.072130584716795\n",
            "Número de pasos del episodio 8883 son episode_steps:76\n",
            "Total Steps: 540617 Episode Num: 8883 Reward: 123.5576986135232 avg_loss_c: 4.542680708985579 avg_loss_a: -50.320310492264596\n",
            "Número de pasos del episodio 8884 son episode_steps:90\n",
            "Total Steps: 540707 Episode Num: 8884 Reward: 29.153011771225508 avg_loss_c: 4.500150635507372 avg_loss_a: -50.141882239447696\n",
            "Número de pasos del episodio 8885 son episode_steps:64\n",
            "Total Steps: 540771 Episode Num: 8885 Reward: 104.61196110290055 avg_loss_c: 4.297975178807974 avg_loss_a: -50.49003195762634\n",
            "Número de pasos del episodio 8886 son episode_steps:72\n",
            "Total Steps: 540843 Episode Num: 8886 Reward: 116.1327502162241 avg_loss_c: 4.517366240421931 avg_loss_a: -51.42631488376193\n",
            "Número de pasos del episodio 8887 son episode_steps:85\n",
            "Total Steps: 540928 Episode Num: 8887 Reward: 147.38798508592902 avg_loss_c: 4.5937692838556625 avg_loss_a: -50.60688709932215\n",
            "Número de pasos del episodio 8888 son episode_steps:70\n",
            "Total Steps: 540998 Episode Num: 8888 Reward: 99.58851514206388 avg_loss_c: 4.1247957944869995 avg_loss_a: -50.69416689191546\n",
            "Número de pasos del episodio 8889 son episode_steps:142\n",
            "Total Steps: 541140 Episode Num: 8889 Reward: 236.3903837620984 avg_loss_c: 4.553176399687646 avg_loss_a: -50.60440117204693\n",
            "Número de pasos del episodio 8890 son episode_steps:66\n",
            "Total Steps: 541206 Episode Num: 8890 Reward: 119.7811134000699 avg_loss_c: 4.379880937662992 avg_loss_a: -51.22466220277728\n",
            "Número de pasos del episodio 8891 son episode_steps:71\n",
            "Total Steps: 541277 Episode Num: 8891 Reward: 121.50963554332516 avg_loss_c: 4.447511400974972 avg_loss_a: -50.88930962790906\n",
            "Número de pasos del episodio 8892 son episode_steps:66\n",
            "Total Steps: 541343 Episode Num: 8892 Reward: 100.35392759257508 avg_loss_c: 3.9906973044077554 avg_loss_a: -50.9261975143895\n",
            "Número de pasos del episodio 8893 son episode_steps:56\n",
            "Total Steps: 541399 Episode Num: 8893 Reward: 52.10670363936057 avg_loss_c: 4.3587009991918295 avg_loss_a: -50.945068086896626\n",
            "Número de pasos del episodio 8894 son episode_steps:93\n",
            "Total Steps: 541492 Episode Num: 8894 Reward: 163.47927660278467 avg_loss_c: 4.5320634201008785 avg_loss_a: -51.12942049580236\n",
            "Número de pasos del episodio 8895 son episode_steps:63\n",
            "Total Steps: 541555 Episode Num: 8895 Reward: 101.53029508680483 avg_loss_c: 4.57796741667248 avg_loss_a: -51.77038816421751\n",
            "Número de pasos del episodio 8896 son episode_steps:66\n",
            "Total Steps: 541621 Episode Num: 8896 Reward: 97.86491394199146 avg_loss_c: 4.208288225260648 avg_loss_a: -51.45046395966501\n",
            "Número de pasos del episodio 8897 son episode_steps:43\n",
            "Total Steps: 541664 Episode Num: 8897 Reward: 32.498770273276 avg_loss_c: 4.2367652848709465 avg_loss_a: -51.487685891084894\n",
            "Número de pasos del episodio 8898 son episode_steps:87\n",
            "Total Steps: 541751 Episode Num: 8898 Reward: 136.95839450839412 avg_loss_c: 4.486422182499678 avg_loss_a: -50.4050135119208\n",
            "Número de pasos del episodio 8899 son episode_steps:86\n",
            "Total Steps: 541837 Episode Num: 8899 Reward: 154.93255747131346 avg_loss_c: 4.110501990761867 avg_loss_a: -51.01087658904319\n",
            "Número de pasos del episodio 8900 son episode_steps:80\n",
            "Total Steps: 541917 Episode Num: 8900 Reward: 111.5466119204306 avg_loss_c: 4.232494416832924 avg_loss_a: -50.6631519317627\n",
            "Número de pasos del episodio 8901 son episode_steps:251\n",
            "Total Steps: 542168 Episode Num: 8901 Reward: 299.42918492269854 avg_loss_c: 4.547286082073986 avg_loss_a: -50.72711999292868\n",
            "Número de pasos del episodio 8902 son episode_steps:19\n",
            "Total Steps: 542187 Episode Num: 8902 Reward: -18.590942698296544 avg_loss_c: 4.0375058525486995 avg_loss_a: -51.13252318532843\n",
            "Número de pasos del episodio 8903 son episode_steps:76\n",
            "Total Steps: 542263 Episode Num: 8903 Reward: 111.91023803893415 avg_loss_c: 4.301009849498146 avg_loss_a: -50.59796544125206\n",
            "Número de pasos del episodio 8904 son episode_steps:77\n",
            "Total Steps: 542340 Episode Num: 8904 Reward: 113.90300806734633 avg_loss_c: 4.157526245364895 avg_loss_a: -51.10686274937221\n",
            "Número de pasos del episodio 8905 son episode_steps:69\n",
            "Total Steps: 542409 Episode Num: 8905 Reward: 78.82188229655405 avg_loss_c: 4.444280012794163 avg_loss_a: -51.096349356830984\n",
            "Número de pasos del episodio 8906 son episode_steps:65\n",
            "Total Steps: 542474 Episode Num: 8906 Reward: 104.01899086723257 avg_loss_c: 4.23205520923321 avg_loss_a: -51.07316759549654\n",
            "Número de pasos del episodio 8907 son episode_steps:63\n",
            "Total Steps: 542537 Episode Num: 8907 Reward: 94.5339798876521 avg_loss_c: 4.168073434678335 avg_loss_a: -50.14669133746435\n",
            "Número de pasos del episodio 8908 son episode_steps:99\n",
            "Total Steps: 542636 Episode Num: 8908 Reward: 120.75980627785827 avg_loss_c: 4.611572145211576 avg_loss_a: -51.4109070903123\n",
            "Número de pasos del episodio 8909 son episode_steps:100\n",
            "Total Steps: 542736 Episode Num: 8909 Reward: 151.80399012076415 avg_loss_c: 4.33392107963562 avg_loss_a: -51.06325805664063\n",
            "Número de pasos del episodio 8910 son episode_steps:108\n",
            "Total Steps: 542844 Episode Num: 8910 Reward: 186.363606749512 avg_loss_c: 3.87107182652862 avg_loss_a: -50.84091652764214\n",
            "Número de pasos del episodio 8911 son episode_steps:164\n",
            "Total Steps: 543008 Episode Num: 8911 Reward: 262.3232642916815 avg_loss_c: 4.2993080615997314 avg_loss_a: -51.190357999103824\n",
            "Número de pasos del episodio 8912 son episode_steps:96\n",
            "Total Steps: 543104 Episode Num: 8912 Reward: 139.2670328973871 avg_loss_c: 4.221153529981772 avg_loss_a: -50.455708742141724\n",
            "Número de pasos del episodio 8913 son episode_steps:111\n",
            "Total Steps: 543215 Episode Num: 8913 Reward: 167.15397067820527 avg_loss_c: 4.017731584944166 avg_loss_a: -51.25008419827298\n",
            "Número de pasos del episodio 8914 son episode_steps:49\n",
            "Total Steps: 543264 Episode Num: 8914 Reward: 59.44881021822945 avg_loss_c: 3.9307264357197043 avg_loss_a: -51.09571293422154\n",
            "Número de pasos del episodio 8915 son episode_steps:107\n",
            "Total Steps: 543371 Episode Num: 8915 Reward: 137.0022258876769 avg_loss_c: 4.069230228941017 avg_loss_a: -51.28055486946462\n",
            "Número de pasos del episodio 8916 son episode_steps:74\n",
            "Total Steps: 543445 Episode Num: 8916 Reward: 121.48704274627185 avg_loss_c: 4.366054399593456 avg_loss_a: -51.179471505654824\n",
            "Número de pasos del episodio 8917 son episode_steps:131\n",
            "Total Steps: 543576 Episode Num: 8917 Reward: 232.71893781931374 avg_loss_c: 4.266638986936963 avg_loss_a: -51.013987854236866\n",
            "Número de pasos del episodio 8918 son episode_steps:87\n",
            "Total Steps: 543663 Episode Num: 8918 Reward: 141.8705454834135 avg_loss_c: 4.162275201972874 avg_loss_a: -50.53964505250426\n",
            "Número de pasos del episodio 8919 son episode_steps:140\n",
            "Total Steps: 543803 Episode Num: 8919 Reward: 214.40514232896604 avg_loss_c: 4.359805236543928 avg_loss_a: -51.234624426705494\n",
            "Número de pasos del episodio 8920 son episode_steps:99\n",
            "Total Steps: 543902 Episode Num: 8920 Reward: 140.84152289876792 avg_loss_c: 3.9960944315399787 avg_loss_a: -51.63170612219608\n",
            "Número de pasos del episodio 8921 son episode_steps:112\n",
            "Total Steps: 544014 Episode Num: 8921 Reward: 108.6909831535226 avg_loss_c: 4.688613221049309 avg_loss_a: -51.086515699114116\n",
            "Número de pasos del episodio 8922 son episode_steps:115\n",
            "Total Steps: 544129 Episode Num: 8922 Reward: 166.66438807211804 avg_loss_c: 3.8730362581170126 avg_loss_a: -51.87824564394744\n",
            "Número de pasos del episodio 8923 son episode_steps:196\n",
            "Total Steps: 544325 Episode Num: 8923 Reward: 319.5765133083509 avg_loss_c: 4.0121394991874695 avg_loss_a: -51.74022355371592\n",
            "Número de pasos del episodio 8924 son episode_steps:125\n",
            "Total Steps: 544450 Episode Num: 8924 Reward: 136.19632404576774 avg_loss_c: 4.128930707931518 avg_loss_a: -51.09233316040039\n",
            "Número de pasos del episodio 8925 son episode_steps:93\n",
            "Total Steps: 544543 Episode Num: 8925 Reward: 136.79447637999698 avg_loss_c: 4.089054733194331 avg_loss_a: -51.45049093102896\n",
            "Número de pasos del episodio 8926 son episode_steps:93\n",
            "Total Steps: 544636 Episode Num: 8926 Reward: 131.82677460069425 avg_loss_c: 4.046668583346952 avg_loss_a: -51.33922527682397\n",
            "Número de pasos del episodio 8927 son episode_steps:112\n",
            "Total Steps: 544748 Episode Num: 8927 Reward: 151.84953977755308 avg_loss_c: 4.043230054633958 avg_loss_a: -51.194896357400076\n",
            "Número de pasos del episodio 8928 son episode_steps:75\n",
            "Total Steps: 544823 Episode Num: 8928 Reward: 67.35486611094858 avg_loss_c: 4.156823701858521 avg_loss_a: -50.973163248697915\n",
            "Número de pasos del episodio 8929 son episode_steps:35\n",
            "Total Steps: 544858 Episode Num: 8929 Reward: -11.083097858828886 avg_loss_c: 3.954345178604126 avg_loss_a: -51.38723275320871\n",
            "Número de pasos del episodio 8930 son episode_steps:91\n",
            "Total Steps: 544949 Episode Num: 8930 Reward: 145.10438205740806 avg_loss_c: 4.3624389564598 avg_loss_a: -51.29160920866243\n",
            "Número de pasos del episodio 8931 son episode_steps:107\n",
            "Total Steps: 545056 Episode Num: 8931 Reward: 156.01580138368053 avg_loss_c: 3.8835566311239083 avg_loss_a: -51.263154823089316\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 124.992795\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 8932 son episode_steps:140\n",
            "Total Steps: 545196 Episode Num: 8932 Reward: 202.65329217318592 avg_loss_c: 4.064295056888035 avg_loss_a: -51.45221786499023\n",
            "Número de pasos del episodio 8933 son episode_steps:87\n",
            "Total Steps: 545283 Episode Num: 8933 Reward: 142.79338673057455 avg_loss_c: 4.137224641339532 avg_loss_a: -51.780895583931056\n",
            "Número de pasos del episodio 8934 son episode_steps:85\n",
            "Total Steps: 545368 Episode Num: 8934 Reward: 127.6850025010886 avg_loss_c: 3.88134768149432 avg_loss_a: -51.333901753145106\n",
            "Número de pasos del episodio 8935 son episode_steps:24\n",
            "Total Steps: 545392 Episode Num: 8935 Reward: -29.49675137995595 avg_loss_c: 4.2655918796857195 avg_loss_a: -51.360728899637856\n",
            "Número de pasos del episodio 8936 son episode_steps:83\n",
            "Total Steps: 545475 Episode Num: 8936 Reward: 118.12763866896228 avg_loss_c: 4.804763305618103 avg_loss_a: -51.530388659741504\n",
            "Número de pasos del episodio 8937 son episode_steps:136\n",
            "Total Steps: 545611 Episode Num: 8937 Reward: 206.04531963252788 avg_loss_c: 4.085934328682282 avg_loss_a: -51.07287193747128\n",
            "Número de pasos del episodio 8938 son episode_steps:41\n",
            "Total Steps: 545652 Episode Num: 8938 Reward: 15.499852417783956 avg_loss_c: 3.854895039302547 avg_loss_a: -50.44031580483041\n",
            "Número de pasos del episodio 8939 son episode_steps:78\n",
            "Total Steps: 545730 Episode Num: 8939 Reward: 121.2385399428732 avg_loss_c: 4.036137452492347 avg_loss_a: -51.15490233592498\n",
            "Número de pasos del episodio 8940 son episode_steps:49\n",
            "Total Steps: 545779 Episode Num: 8940 Reward: 33.23789323593067 avg_loss_c: 4.22515284771822 avg_loss_a: -51.1052624449438\n",
            "Número de pasos del episodio 8941 son episode_steps:44\n",
            "Total Steps: 545823 Episode Num: 8941 Reward: 50.606423312101334 avg_loss_c: 4.728489989584142 avg_loss_a: -51.86093815890226\n",
            "Número de pasos del episodio 8942 son episode_steps:72\n",
            "Total Steps: 545895 Episode Num: 8942 Reward: 75.69693146314991 avg_loss_c: 4.507679386271371 avg_loss_a: -51.21942530737983\n",
            "Número de pasos del episodio 8943 son episode_steps:116\n",
            "Total Steps: 546011 Episode Num: 8943 Reward: 171.14604530448628 avg_loss_c: 4.020008420122081 avg_loss_a: -50.922484628085435\n",
            "Número de pasos del episodio 8944 son episode_steps:88\n",
            "Total Steps: 546099 Episode Num: 8944 Reward: 109.10969916510119 avg_loss_c: 4.2265923185781995 avg_loss_a: -51.50342655181885\n",
            "Número de pasos del episodio 8945 son episode_steps:103\n",
            "Total Steps: 546202 Episode Num: 8945 Reward: 79.88011908539366 avg_loss_c: 4.44362856577901 avg_loss_a: -51.2190327690643\n",
            "Número de pasos del episodio 8946 son episode_steps:83\n",
            "Total Steps: 546285 Episode Num: 8946 Reward: 135.63081459493102 avg_loss_c: 4.203080995973334 avg_loss_a: -51.198539136404015\n",
            "Número de pasos del episodio 8947 son episode_steps:106\n",
            "Total Steps: 546391 Episode Num: 8947 Reward: 148.71564782780183 avg_loss_c: 4.949287839655606 avg_loss_a: -50.999108800348246\n",
            "Número de pasos del episodio 8948 son episode_steps:105\n",
            "Total Steps: 546496 Episode Num: 8948 Reward: 138.58749237548153 avg_loss_c: 4.1821681522187735 avg_loss_a: -51.150228663853234\n",
            "Número de pasos del episodio 8949 son episode_steps:135\n",
            "Total Steps: 546631 Episode Num: 8949 Reward: 184.29556532246204 avg_loss_c: 4.353110869725545 avg_loss_a: -50.76938318323206\n",
            "Número de pasos del episodio 8950 son episode_steps:69\n",
            "Total Steps: 546700 Episode Num: 8950 Reward: 75.65920994275396 avg_loss_c: 5.154810801796291 avg_loss_a: -51.1874518463577\n",
            "Número de pasos del episodio 8951 son episode_steps:116\n",
            "Total Steps: 546816 Episode Num: 8951 Reward: 70.92529650855253 avg_loss_c: 4.68628671045961 avg_loss_a: -50.443180676164296\n",
            "Número de pasos del episodio 8952 son episode_steps:77\n",
            "Total Steps: 546893 Episode Num: 8952 Reward: 83.86586343054364 avg_loss_c: 4.608168834215634 avg_loss_a: -50.88387372896269\n",
            "Número de pasos del episodio 8953 son episode_steps:61\n",
            "Total Steps: 546954 Episode Num: 8953 Reward: 91.67690185025255 avg_loss_c: 4.426210794292513 avg_loss_a: -51.21345901489258\n",
            "Número de pasos del episodio 8954 son episode_steps:86\n",
            "Total Steps: 547040 Episode Num: 8954 Reward: 20.084762182778146 avg_loss_c: 5.015732615493064 avg_loss_a: -50.785415294558504\n",
            "Número de pasos del episodio 8955 son episode_steps:76\n",
            "Total Steps: 547116 Episode Num: 8955 Reward: 113.21930178188919 avg_loss_c: 4.631293011339087 avg_loss_a: -51.166163193552116\n",
            "Número de pasos del episodio 8956 son episode_steps:92\n",
            "Total Steps: 547208 Episode Num: 8956 Reward: 128.72712492142566 avg_loss_c: 4.582946645176929 avg_loss_a: -50.601713926895805\n",
            "Número de pasos del episodio 8957 son episode_steps:25\n",
            "Total Steps: 547233 Episode Num: 8957 Reward: -12.146166562466174 avg_loss_c: 4.511409721374512 avg_loss_a: -50.26038116455078\n",
            "Número de pasos del episodio 8958 son episode_steps:99\n",
            "Total Steps: 547332 Episode Num: 8958 Reward: 136.0393010054246 avg_loss_c: 4.691102815396858 avg_loss_a: -50.59533887920958\n",
            "Número de pasos del episodio 8959 son episode_steps:117\n",
            "Total Steps: 547449 Episode Num: 8959 Reward: 151.21621406211838 avg_loss_c: 4.532574337771815 avg_loss_a: -50.21830315875192\n",
            "Número de pasos del episodio 8960 son episode_steps:122\n",
            "Total Steps: 547571 Episode Num: 8960 Reward: 52.50787561775237 avg_loss_c: 5.106219188111727 avg_loss_a: -50.418295313100344\n",
            "Número de pasos del episodio 8961 son episode_steps:115\n",
            "Total Steps: 547686 Episode Num: 8961 Reward: 205.07563778665698 avg_loss_c: 4.493035422200742 avg_loss_a: -50.13829352337381\n",
            "Número de pasos del episodio 8962 son episode_steps:73\n",
            "Total Steps: 547759 Episode Num: 8962 Reward: 95.65396101725088 avg_loss_c: 4.5267399827094925 avg_loss_a: -49.93477301401635\n",
            "Número de pasos del episodio 8963 son episode_steps:78\n",
            "Total Steps: 547837 Episode Num: 8963 Reward: 99.44185536840463 avg_loss_c: 4.713361801245274 avg_loss_a: -49.76290472959861\n",
            "Número de pasos del episodio 8964 son episode_steps:92\n",
            "Total Steps: 547929 Episode Num: 8964 Reward: 116.03271124437907 avg_loss_c: 4.861521731252256 avg_loss_a: -50.348881928817086\n",
            "Número de pasos del episodio 8965 son episode_steps:36\n",
            "Total Steps: 547965 Episode Num: 8965 Reward: 3.3523113644570177 avg_loss_c: 5.023144112692939 avg_loss_a: -50.851686265733505\n",
            "Número de pasos del episodio 8966 son episode_steps:78\n",
            "Total Steps: 548043 Episode Num: 8966 Reward: 113.29221439083418 avg_loss_c: 4.402185715161837 avg_loss_a: -50.05526567116762\n",
            "Número de pasos del episodio 8967 son episode_steps:136\n",
            "Total Steps: 548179 Episode Num: 8967 Reward: 203.67873520558092 avg_loss_c: 4.445837935980628 avg_loss_a: -50.57439114065731\n",
            "Número de pasos del episodio 8968 son episode_steps:140\n",
            "Total Steps: 548319 Episode Num: 8968 Reward: 130.56680909243843 avg_loss_c: 4.433184267793383 avg_loss_a: -49.340859113420755\n",
            "Número de pasos del episodio 8969 son episode_steps:121\n",
            "Total Steps: 548440 Episode Num: 8969 Reward: 58.35515249238849 avg_loss_c: 4.755534847905813 avg_loss_a: -50.56353422432892\n",
            "Número de pasos del episodio 8970 son episode_steps:81\n",
            "Total Steps: 548521 Episode Num: 8970 Reward: 110.56661599473466 avg_loss_c: 4.588745064205593 avg_loss_a: -49.69832813592605\n",
            "Número de pasos del episodio 8971 son episode_steps:67\n",
            "Total Steps: 548588 Episode Num: 8971 Reward: 110.25395375775314 avg_loss_c: 4.592042278887621 avg_loss_a: -49.77734107401834\n",
            "Número de pasos del episodio 8972 son episode_steps:77\n",
            "Total Steps: 548665 Episode Num: 8972 Reward: 100.59841097815605 avg_loss_c: 4.683120758502515 avg_loss_a: -49.84917355822278\n",
            "Número de pasos del episodio 8973 son episode_steps:87\n",
            "Total Steps: 548752 Episode Num: 8973 Reward: 99.83196416818815 avg_loss_c: 4.409694866202344 avg_loss_a: -49.97712624210051\n",
            "Número de pasos del episodio 8974 son episode_steps:149\n",
            "Total Steps: 548901 Episode Num: 8974 Reward: 185.35119018340438 avg_loss_c: 4.390089622279942 avg_loss_a: -49.74704860200818\n",
            "Número de pasos del episodio 8975 son episode_steps:79\n",
            "Total Steps: 548980 Episode Num: 8975 Reward: 113.32873181333535 avg_loss_c: 4.508285157288177 avg_loss_a: -50.038107570213604\n",
            "Número de pasos del episodio 8976 son episode_steps:83\n",
            "Total Steps: 549063 Episode Num: 8976 Reward: 102.64961923839552 avg_loss_c: 4.740425342536835 avg_loss_a: -49.94641692379871\n",
            "Número de pasos del episodio 8977 son episode_steps:84\n",
            "Total Steps: 549147 Episode Num: 8977 Reward: 114.25070859409118 avg_loss_c: 4.422256540684473 avg_loss_a: -49.44932056608654\n",
            "Número de pasos del episodio 8978 son episode_steps:128\n",
            "Total Steps: 549275 Episode Num: 8978 Reward: 85.11667653199808 avg_loss_c: 4.7163999024778605 avg_loss_a: -50.224718272686005\n",
            "Número de pasos del episodio 8979 son episode_steps:94\n",
            "Total Steps: 549369 Episode Num: 8979 Reward: 74.6101459848387 avg_loss_c: 4.635824974547041 avg_loss_a: -49.86098512690118\n",
            "Número de pasos del episodio 8980 son episode_steps:81\n",
            "Total Steps: 549450 Episode Num: 8980 Reward: 16.384755943570514 avg_loss_c: 5.00470221189805 avg_loss_a: -50.5742512455693\n",
            "Número de pasos del episodio 8981 son episode_steps:104\n",
            "Total Steps: 549554 Episode Num: 8981 Reward: 75.23790750670045 avg_loss_c: 5.016107293275686 avg_loss_a: -49.10620931478647\n",
            "Número de pasos del episodio 8982 son episode_steps:146\n",
            "Total Steps: 549700 Episode Num: 8982 Reward: 210.30261192689161 avg_loss_c: 5.137748532099266 avg_loss_a: -49.730174757029914\n",
            "Número de pasos del episodio 8983 son episode_steps:205\n",
            "Total Steps: 549905 Episode Num: 8983 Reward: 301.6208498176481 avg_loss_c: 4.785718796892864 avg_loss_a: -49.96959911439477\n",
            "Número de pasos del episodio 8984 son episode_steps:83\n",
            "Total Steps: 549988 Episode Num: 8984 Reward: 113.7274709615658 avg_loss_c: 5.0406431146414885 avg_loss_a: -50.22281256066748\n",
            "Número de pasos del episodio 8985 son episode_steps:151\n",
            "Total Steps: 550139 Episode Num: 8985 Reward: 208.9296175149261 avg_loss_c: 4.661576381582298 avg_loss_a: -50.0464264067593\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 117.568643\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 8986 son episode_steps:95\n",
            "Total Steps: 550234 Episode Num: 8986 Reward: 110.7575330543274 avg_loss_c: 4.870860272959659 avg_loss_a: -49.216216278076175\n",
            "Número de pasos del episodio 8987 son episode_steps:108\n",
            "Total Steps: 550342 Episode Num: 8987 Reward: 42.27167127878806 avg_loss_c: 4.7068987908186735 avg_loss_a: -49.65949793215151\n",
            "Número de pasos del episodio 8988 son episode_steps:89\n",
            "Total Steps: 550431 Episode Num: 8988 Reward: 94.51730950315739 avg_loss_c: 4.920070559790965 avg_loss_a: -50.066777690073074\n",
            "Número de pasos del episodio 8989 son episode_steps:66\n",
            "Total Steps: 550497 Episode Num: 8989 Reward: 87.16806341501139 avg_loss_c: 4.999299356431672 avg_loss_a: -49.51790850090258\n",
            "Número de pasos del episodio 8990 son episode_steps:66\n",
            "Total Steps: 550563 Episode Num: 8990 Reward: 23.362659434982653 avg_loss_c: 5.118108695203608 avg_loss_a: -49.48567662094579\n",
            "Número de pasos del episodio 8991 son episode_steps:104\n",
            "Total Steps: 550667 Episode Num: 8991 Reward: 71.89871077622936 avg_loss_c: 4.8613876310678625 avg_loss_a: -49.47179889678955\n",
            "Número de pasos del episodio 8992 son episode_steps:88\n",
            "Total Steps: 550755 Episode Num: 8992 Reward: 136.61540761217722 avg_loss_c: 5.429127116094936 avg_loss_a: -49.39695444974032\n",
            "Número de pasos del episodio 8993 son episode_steps:106\n",
            "Total Steps: 550861 Episode Num: 8993 Reward: 151.0700494342482 avg_loss_c: 5.013225272016705 avg_loss_a: -49.740913103211604\n",
            "Número de pasos del episodio 8994 son episode_steps:119\n",
            "Total Steps: 550980 Episode Num: 8994 Reward: 144.77394538311316 avg_loss_c: 4.845165437009154 avg_loss_a: -49.026019665373475\n",
            "Número de pasos del episodio 8995 son episode_steps:234\n",
            "Total Steps: 551214 Episode Num: 8995 Reward: 351.45739968457355 avg_loss_c: 4.931601363369542 avg_loss_a: -49.44889003395016\n",
            "Número de pasos del episodio 8996 son episode_steps:124\n",
            "Total Steps: 551338 Episode Num: 8996 Reward: 197.30104722350526 avg_loss_c: 4.678762828150103 avg_loss_a: -49.1915541618101\n",
            "Número de pasos del episodio 8997 son episode_steps:122\n",
            "Total Steps: 551460 Episode Num: 8997 Reward: 171.88553590791 avg_loss_c: 4.44583622744826 avg_loss_a: -49.23592764432313\n",
            "Número de pasos del episodio 8998 son episode_steps:97\n",
            "Total Steps: 551557 Episode Num: 8998 Reward: 150.54736367960064 avg_loss_c: 4.851347942942197 avg_loss_a: -49.17141145529206\n",
            "Número de pasos del episodio 8999 son episode_steps:95\n",
            "Total Steps: 551652 Episode Num: 8999 Reward: 138.60484032855356 avg_loss_c: 4.664666918704384 avg_loss_a: -49.26317989951686\n",
            "Número de pasos del episodio 9000 son episode_steps:124\n",
            "Total Steps: 551776 Episode Num: 9000 Reward: 139.58986232154504 avg_loss_c: 4.715853321936823 avg_loss_a: -49.1229069002213\n",
            "Número de pasos del episodio 9001 son episode_steps:82\n",
            "Total Steps: 551858 Episode Num: 9001 Reward: 129.48695928938002 avg_loss_c: 4.366786980047459 avg_loss_a: -49.64138356650748\n",
            "Número de pasos del episodio 9002 son episode_steps:109\n",
            "Total Steps: 551967 Episode Num: 9002 Reward: 57.77260635941964 avg_loss_c: 4.933990296967533 avg_loss_a: -48.64605698891736\n",
            "Número de pasos del episodio 9003 son episode_steps:92\n",
            "Total Steps: 552059 Episode Num: 9003 Reward: 70.85544592958927 avg_loss_c: 4.609271430450937 avg_loss_a: -49.168983210688054\n",
            "Número de pasos del episodio 9004 son episode_steps:19\n",
            "Total Steps: 552078 Episode Num: 9004 Reward: -23.85516208076308 avg_loss_c: 4.760136064730193 avg_loss_a: -48.5889314350329\n",
            "Número de pasos del episodio 9005 son episode_steps:123\n",
            "Total Steps: 552201 Episode Num: 9005 Reward: 187.1633939981488 avg_loss_c: 4.807551159122126 avg_loss_a: -48.70443220061015\n",
            "Número de pasos del episodio 9006 son episode_steps:140\n",
            "Total Steps: 552341 Episode Num: 9006 Reward: 211.92924750132934 avg_loss_c: 4.474985379832131 avg_loss_a: -49.33384497506278\n",
            "Número de pasos del episodio 9007 son episode_steps:108\n",
            "Total Steps: 552449 Episode Num: 9007 Reward: 160.9661768791691 avg_loss_c: 4.386203156577216 avg_loss_a: -49.56483487729673\n",
            "Número de pasos del episodio 9008 son episode_steps:120\n",
            "Total Steps: 552569 Episode Num: 9008 Reward: 149.12814018966014 avg_loss_c: 4.533914985259374 avg_loss_a: -48.87946065266927\n",
            "Número de pasos del episodio 9009 son episode_steps:64\n",
            "Total Steps: 552633 Episode Num: 9009 Reward: 69.36526256985543 avg_loss_c: 4.22828559204936 avg_loss_a: -48.72281551361084\n",
            "Número de pasos del episodio 9010 son episode_steps:92\n",
            "Total Steps: 552725 Episode Num: 9010 Reward: 142.9995053713947 avg_loss_c: 4.6413627811100175 avg_loss_a: -49.2621139028798\n",
            "Número de pasos del episodio 9011 son episode_steps:151\n",
            "Total Steps: 552876 Episode Num: 9011 Reward: 131.86860780084652 avg_loss_c: 4.709243793361234 avg_loss_a: -48.801411963456516\n",
            "Número de pasos del episodio 9012 son episode_steps:76\n",
            "Total Steps: 552952 Episode Num: 9012 Reward: 109.17703259445894 avg_loss_c: 4.797021138040643 avg_loss_a: -49.0387578261526\n",
            "Número de pasos del episodio 9013 son episode_steps:176\n",
            "Total Steps: 553128 Episode Num: 9013 Reward: 262.2297956853493 avg_loss_c: 4.777500200000676 avg_loss_a: -49.36093529787931\n",
            "Número de pasos del episodio 9014 son episode_steps:107\n",
            "Total Steps: 553235 Episode Num: 9014 Reward: 158.91511635011548 avg_loss_c: 4.573606056587718 avg_loss_a: -48.64102222763489\n",
            "Número de pasos del episodio 9015 son episode_steps:61\n",
            "Total Steps: 553296 Episode Num: 9015 Reward: 80.94598416779431 avg_loss_c: 4.673750881288872 avg_loss_a: -49.135736871938235\n",
            "Número de pasos del episodio 9016 son episode_steps:102\n",
            "Total Steps: 553398 Episode Num: 9016 Reward: 135.58507104095378 avg_loss_c: 4.605338758113337 avg_loss_a: -49.83564676022997\n",
            "Número de pasos del episodio 9017 son episode_steps:117\n",
            "Total Steps: 553515 Episode Num: 9017 Reward: 150.9967948044221 avg_loss_c: 4.64278692058009 avg_loss_a: -49.11540140657343\n",
            "Número de pasos del episodio 9018 son episode_steps:86\n",
            "Total Steps: 553601 Episode Num: 9018 Reward: 44.546742749351374 avg_loss_c: 4.52985338277595 avg_loss_a: -49.44040103291356\n",
            "Número de pasos del episodio 9019 son episode_steps:60\n",
            "Total Steps: 553661 Episode Num: 9019 Reward: 75.33781728605638 avg_loss_c: 4.375954639911652 avg_loss_a: -48.63886032104492\n",
            "Número de pasos del episodio 9020 son episode_steps:48\n",
            "Total Steps: 553709 Episode Num: 9020 Reward: 4.96075730476391 avg_loss_c: 4.881364057461421 avg_loss_a: -49.37570492426554\n",
            "Número de pasos del episodio 9021 son episode_steps:64\n",
            "Total Steps: 553773 Episode Num: 9021 Reward: 82.45247122809086 avg_loss_c: 4.658556193113327 avg_loss_a: -48.61393690109253\n",
            "Número de pasos del episodio 9022 son episode_steps:74\n",
            "Total Steps: 553847 Episode Num: 9022 Reward: 119.58100177324874 avg_loss_c: 4.801528344283232 avg_loss_a: -49.09998857652819\n",
            "Número de pasos del episodio 9023 son episode_steps:141\n",
            "Total Steps: 553988 Episode Num: 9023 Reward: 242.4204675593512 avg_loss_c: 4.539698320077666 avg_loss_a: -49.47269331478903\n",
            "Número de pasos del episodio 9024 son episode_steps:106\n",
            "Total Steps: 554094 Episode Num: 9024 Reward: 128.38711625109394 avg_loss_c: 4.4982312535339934 avg_loss_a: -49.08500268324366\n",
            "Número de pasos del episodio 9025 son episode_steps:137\n",
            "Total Steps: 554231 Episode Num: 9025 Reward: 182.83345067895286 avg_loss_c: 4.424231917318637 avg_loss_a: -49.12079450509844\n",
            "Número de pasos del episodio 9026 son episode_steps:115\n",
            "Total Steps: 554346 Episode Num: 9026 Reward: 163.87231666547927 avg_loss_c: 4.459647672072701 avg_loss_a: -48.788379967730975\n",
            "Número de pasos del episodio 9027 son episode_steps:167\n",
            "Total Steps: 554513 Episode Num: 9027 Reward: 246.16579548598773 avg_loss_c: 4.4769405704772405 avg_loss_a: -48.97915784184804\n",
            "Número de pasos del episodio 9028 son episode_steps:89\n",
            "Total Steps: 554602 Episode Num: 9028 Reward: 119.95826806094509 avg_loss_c: 4.3722269936893765 avg_loss_a: -49.31657851144169\n",
            "Número de pasos del episodio 9029 son episode_steps:126\n",
            "Total Steps: 554728 Episode Num: 9029 Reward: 179.50731497456533 avg_loss_c: 4.121797953333173 avg_loss_a: -48.88396992759099\n",
            "Número de pasos del episodio 9030 son episode_steps:55\n",
            "Total Steps: 554783 Episode Num: 9030 Reward: 22.09419743759532 avg_loss_c: 4.4492095340381965 avg_loss_a: -48.91509364734996\n",
            "Número de pasos del episodio 9031 son episode_steps:48\n",
            "Total Steps: 554831 Episode Num: 9031 Reward: 32.7889913117412 avg_loss_c: 4.502942234277725 avg_loss_a: -49.07147836685181\n",
            "Número de pasos del episodio 9032 son episode_steps:110\n",
            "Total Steps: 554941 Episode Num: 9032 Reward: 163.29272153254266 avg_loss_c: 4.366195121678439 avg_loss_a: -49.3987116726962\n",
            "Número de pasos del episodio 9033 son episode_steps:107\n",
            "Total Steps: 555048 Episode Num: 9033 Reward: 166.26615668836394 avg_loss_c: 4.215262330581095 avg_loss_a: -49.13714207444236\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 166.389644\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9034 son episode_steps:45\n",
            "Total Steps: 555093 Episode Num: 9034 Reward: 31.801279515281706 avg_loss_c: 4.300493399302165 avg_loss_a: -48.576329464382596\n",
            "Número de pasos del episodio 9035 son episode_steps:101\n",
            "Total Steps: 555194 Episode Num: 9035 Reward: 152.31631028187047 avg_loss_c: 4.419131290794599 avg_loss_a: -49.001521119976985\n",
            "Número de pasos del episodio 9036 son episode_steps:202\n",
            "Total Steps: 555396 Episode Num: 9036 Reward: 332.05925523963765 avg_loss_c: 4.4345031398357735 avg_loss_a: -49.008180070631575\n",
            "Número de pasos del episodio 9037 son episode_steps:55\n",
            "Total Steps: 555451 Episode Num: 9037 Reward: 80.90247360298827 avg_loss_c: 4.22133654681119 avg_loss_a: -49.043425195867364\n",
            "Número de pasos del episodio 9038 son episode_steps:58\n",
            "Total Steps: 555509 Episode Num: 9038 Reward: 88.51765156475994 avg_loss_c: 4.295441898806342 avg_loss_a: -49.57764829438308\n",
            "Número de pasos del episodio 9039 son episode_steps:100\n",
            "Total Steps: 555609 Episode Num: 9039 Reward: 134.21159897553937 avg_loss_c: 4.093631846904755 avg_loss_a: -49.40192481994629\n",
            "Número de pasos del episodio 9040 son episode_steps:145\n",
            "Total Steps: 555754 Episode Num: 9040 Reward: 225.90767923753486 avg_loss_c: 4.193576041583357 avg_loss_a: -49.04318326752761\n",
            "Número de pasos del episodio 9041 son episode_steps:74\n",
            "Total Steps: 555828 Episode Num: 9041 Reward: 122.97205347031286 avg_loss_c: 4.249166160016446 avg_loss_a: -49.28894661568307\n",
            "Número de pasos del episodio 9042 son episode_steps:70\n",
            "Total Steps: 555898 Episode Num: 9042 Reward: 106.87234410252827 avg_loss_c: 4.1938234806060795 avg_loss_a: -48.98855547223772\n",
            "Número de pasos del episodio 9043 son episode_steps:116\n",
            "Total Steps: 556014 Episode Num: 9043 Reward: 178.31143592049648 avg_loss_c: 4.1864263127590045 avg_loss_a: -49.728595602101294\n",
            "Número de pasos del episodio 9044 son episode_steps:108\n",
            "Total Steps: 556122 Episode Num: 9044 Reward: 168.74082849502213 avg_loss_c: 4.4247584232577575 avg_loss_a: -49.377705326786746\n",
            "Número de pasos del episodio 9045 son episode_steps:96\n",
            "Total Steps: 556218 Episode Num: 9045 Reward: 102.01612579386132 avg_loss_c: 3.98481705536445 avg_loss_a: -49.70280400911967\n",
            "Número de pasos del episodio 9046 son episode_steps:139\n",
            "Total Steps: 556357 Episode Num: 9046 Reward: 94.99969254789913 avg_loss_c: 4.234792654462855 avg_loss_a: -49.10350752905976\n",
            "Número de pasos del episodio 9047 son episode_steps:113\n",
            "Total Steps: 556470 Episode Num: 9047 Reward: 178.2735320600971 avg_loss_c: 4.308181053769272 avg_loss_a: -49.7042437528087\n",
            "Número de pasos del episodio 9048 son episode_steps:136\n",
            "Total Steps: 556606 Episode Num: 9048 Reward: 158.47035743510105 avg_loss_c: 4.275057070395526 avg_loss_a: -49.66397195703843\n",
            "Número de pasos del episodio 9049 son episode_steps:45\n",
            "Total Steps: 556651 Episode Num: 9049 Reward: 33.737239217148726 avg_loss_c: 4.638347752888998 avg_loss_a: -49.161976962619356\n",
            "Número de pasos del episodio 9050 son episode_steps:140\n",
            "Total Steps: 556791 Episode Num: 9050 Reward: 239.77578434499384 avg_loss_c: 4.051017088549478 avg_loss_a: -49.860045187813895\n",
            "Número de pasos del episodio 9051 son episode_steps:55\n",
            "Total Steps: 556846 Episode Num: 9051 Reward: 52.09564675198679 avg_loss_c: 4.352817713130604 avg_loss_a: -49.45558742176403\n",
            "Número de pasos del episodio 9052 son episode_steps:98\n",
            "Total Steps: 556944 Episode Num: 9052 Reward: 155.4882871557812 avg_loss_c: 4.245239780873669 avg_loss_a: -49.75583633111448\n",
            "Número de pasos del episodio 9053 son episode_steps:105\n",
            "Total Steps: 557049 Episode Num: 9053 Reward: 184.1667111931577 avg_loss_c: 4.373726617722284 avg_loss_a: -49.96576875959124\n",
            "Número de pasos del episodio 9054 son episode_steps:41\n",
            "Total Steps: 557090 Episode Num: 9054 Reward: 24.936535439564352 avg_loss_c: 4.196769941143874 avg_loss_a: -48.888820462110566\n",
            "Número de pasos del episodio 9055 son episode_steps:84\n",
            "Total Steps: 557174 Episode Num: 9055 Reward: 130.49828745085634 avg_loss_c: 3.8423952346756343 avg_loss_a: -49.181969869704474\n",
            "Número de pasos del episodio 9056 son episode_steps:83\n",
            "Total Steps: 557257 Episode Num: 9056 Reward: 131.16503187833072 avg_loss_c: 3.859989582774151 avg_loss_a: -49.53729946642037\n",
            "Número de pasos del episodio 9057 son episode_steps:95\n",
            "Total Steps: 557352 Episode Num: 9057 Reward: 150.10150727317637 avg_loss_c: 4.486710731606735 avg_loss_a: -49.407856549714744\n",
            "Número de pasos del episodio 9058 son episode_steps:83\n",
            "Total Steps: 557435 Episode Num: 9058 Reward: 131.60730273063402 avg_loss_c: 4.109590027705733 avg_loss_a: -50.090082191559205\n",
            "Número de pasos del episodio 9059 son episode_steps:85\n",
            "Total Steps: 557520 Episode Num: 9059 Reward: 118.9870090417539 avg_loss_c: 3.9915385975557216 avg_loss_a: -49.965539820054\n",
            "Número de pasos del episodio 9060 son episode_steps:112\n",
            "Total Steps: 557632 Episode Num: 9060 Reward: 167.32637086794972 avg_loss_c: 4.258162010993276 avg_loss_a: -49.63272687367031\n",
            "Número de pasos del episodio 9061 son episode_steps:90\n",
            "Total Steps: 557722 Episode Num: 9061 Reward: 159.79549668967147 avg_loss_c: 4.110009251700507 avg_loss_a: -49.98922882080078\n",
            "Número de pasos del episodio 9062 son episode_steps:96\n",
            "Total Steps: 557818 Episode Num: 9062 Reward: 164.81801838161212 avg_loss_c: 3.9396668995420137 avg_loss_a: -49.971857150395714\n",
            "Número de pasos del episodio 9063 son episode_steps:19\n",
            "Total Steps: 557837 Episode Num: 9063 Reward: -20.906622215640994 avg_loss_c: 3.943206322820563 avg_loss_a: -48.506009553608145\n",
            "Número de pasos del episodio 9064 son episode_steps:101\n",
            "Total Steps: 557938 Episode Num: 9064 Reward: 150.3970135242337 avg_loss_c: 4.053752844876582 avg_loss_a: -50.02783373086759\n",
            "Número de pasos del episodio 9065 son episode_steps:86\n",
            "Total Steps: 558024 Episode Num: 9065 Reward: 140.1133023225944 avg_loss_c: 4.202910254167956 avg_loss_a: -49.830371235692226\n",
            "Número de pasos del episodio 9066 son episode_steps:119\n",
            "Total Steps: 558143 Episode Num: 9066 Reward: 179.69521833255604 avg_loss_c: 4.646627390084147 avg_loss_a: -50.16628380783466\n",
            "Número de pasos del episodio 9067 son episode_steps:69\n",
            "Total Steps: 558212 Episode Num: 9067 Reward: 119.48036463472799 avg_loss_c: 4.162289488142815 avg_loss_a: -49.55274217025094\n",
            "Número de pasos del episodio 9068 son episode_steps:99\n",
            "Total Steps: 558311 Episode Num: 9068 Reward: 155.1132208041872 avg_loss_c: 4.101096882964626 avg_loss_a: -49.72596729162967\n",
            "Número de pasos del episodio 9069 son episode_steps:56\n",
            "Total Steps: 558367 Episode Num: 9069 Reward: 34.373812731828345 avg_loss_c: 3.9929104362215315 avg_loss_a: -50.086880275181365\n",
            "Número de pasos del episodio 9070 son episode_steps:109\n",
            "Total Steps: 558476 Episode Num: 9070 Reward: 57.68613401886442 avg_loss_c: 4.6486817565533 avg_loss_a: -50.16741299410479\n",
            "Número de pasos del episodio 9071 son episode_steps:67\n",
            "Total Steps: 558543 Episode Num: 9071 Reward: 95.40478277635074 avg_loss_c: 4.449697362842844 avg_loss_a: -49.45086852116371\n",
            "Número de pasos del episodio 9072 son episode_steps:68\n",
            "Total Steps: 558611 Episode Num: 9072 Reward: 78.73104497311974 avg_loss_c: 4.458569936892566 avg_loss_a: -50.088898939244885\n",
            "Número de pasos del episodio 9073 son episode_steps:133\n",
            "Total Steps: 558744 Episode Num: 9073 Reward: 238.00990549351604 avg_loss_c: 4.281426110662016 avg_loss_a: -49.16533592052029\n",
            "Número de pasos del episodio 9074 son episode_steps:112\n",
            "Total Steps: 558856 Episode Num: 9074 Reward: 177.9206014146685 avg_loss_c: 4.175960132053921 avg_loss_a: -49.96910006659372\n",
            "Número de pasos del episodio 9075 son episode_steps:48\n",
            "Total Steps: 558904 Episode Num: 9075 Reward: 68.68846939840678 avg_loss_c: 4.0871608058611555 avg_loss_a: -49.601714769999184\n",
            "Número de pasos del episodio 9076 son episode_steps:101\n",
            "Total Steps: 559005 Episode Num: 9076 Reward: 166.65134110927775 avg_loss_c: 4.221480308192791 avg_loss_a: -50.159888541344365\n",
            "Número de pasos del episodio 9077 son episode_steps:66\n",
            "Total Steps: 559071 Episode Num: 9077 Reward: 86.56129102394597 avg_loss_c: 4.2571998617865825 avg_loss_a: -49.45870925440933\n",
            "Número de pasos del episodio 9078 son episode_steps:87\n",
            "Total Steps: 559158 Episode Num: 9078 Reward: 139.2866336812567 avg_loss_c: 3.9902472167179504 avg_loss_a: -49.75560742959209\n",
            "Número de pasos del episodio 9079 son episode_steps:125\n",
            "Total Steps: 559283 Episode Num: 9079 Reward: 204.26250476448573 avg_loss_c: 4.016239530563355 avg_loss_a: -49.915933227539064\n",
            "Número de pasos del episodio 9080 son episode_steps:76\n",
            "Total Steps: 559359 Episode Num: 9080 Reward: 110.72013395865073 avg_loss_c: 3.9882151766827234 avg_loss_a: -50.09719627781918\n",
            "Número de pasos del episodio 9081 son episode_steps:108\n",
            "Total Steps: 559467 Episode Num: 9081 Reward: 118.9443799634647 avg_loss_c: 4.0597795799926475 avg_loss_a: -49.719397368254484\n",
            "Número de pasos del episodio 9082 son episode_steps:75\n",
            "Total Steps: 559542 Episode Num: 9082 Reward: 98.98510066883074 avg_loss_c: 3.8379235235850016 avg_loss_a: -49.87777460734049\n",
            "Número de pasos del episodio 9083 son episode_steps:51\n",
            "Total Steps: 559593 Episode Num: 9083 Reward: 50.4281328404428 avg_loss_c: 4.044649367238961 avg_loss_a: -49.74918208402746\n",
            "Número de pasos del episodio 9084 son episode_steps:143\n",
            "Total Steps: 559736 Episode Num: 9084 Reward: 238.48270267249362 avg_loss_c: 3.8885280435735528 avg_loss_a: -49.71595102590281\n",
            "Número de pasos del episodio 9085 son episode_steps:91\n",
            "Total Steps: 559827 Episode Num: 9085 Reward: 147.07399308832106 avg_loss_c: 3.938649837787335 avg_loss_a: -49.58128843202696\n",
            "Número de pasos del episodio 9086 son episode_steps:133\n",
            "Total Steps: 559960 Episode Num: 9086 Reward: 172.06940313932415 avg_loss_c: 3.8562282996070114 avg_loss_a: -49.613539961047636\n",
            "Número de pasos del episodio 9087 son episode_steps:86\n",
            "Total Steps: 560046 Episode Num: 9087 Reward: 120.86177178784008 avg_loss_c: 3.932066277016041 avg_loss_a: -50.21002694063409\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 140.490741\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9088 son episode_steps:65\n",
            "Total Steps: 560111 Episode Num: 9088 Reward: 98.36415420580174 avg_loss_c: 3.7746957742250884 avg_loss_a: -50.42868881225586\n",
            "Número de pasos del episodio 9089 son episode_steps:72\n",
            "Total Steps: 560183 Episode Num: 9089 Reward: 108.34855685463458 avg_loss_c: 3.960958252350489 avg_loss_a: -50.333448304070366\n",
            "Número de pasos del episodio 9090 son episode_steps:84\n",
            "Total Steps: 560267 Episode Num: 9090 Reward: 134.88051968644194 avg_loss_c: 3.825479317279089 avg_loss_a: -49.519401277814595\n",
            "Número de pasos del episodio 9091 son episode_steps:105\n",
            "Total Steps: 560372 Episode Num: 9091 Reward: 172.02667427226115 avg_loss_c: 3.7846608457111177 avg_loss_a: -49.59411559331985\n",
            "Número de pasos del episodio 9092 son episode_steps:117\n",
            "Total Steps: 560489 Episode Num: 9092 Reward: 201.39098802805975 avg_loss_c: 3.7141667940677743 avg_loss_a: -50.14204194810655\n",
            "Número de pasos del episodio 9093 son episode_steps:116\n",
            "Total Steps: 560605 Episode Num: 9093 Reward: 186.84580314837783 avg_loss_c: 3.8156969773358314 avg_loss_a: -49.87224585434486\n",
            "Número de pasos del episodio 9094 son episode_steps:55\n",
            "Total Steps: 560660 Episode Num: 9094 Reward: -16.503208760837765 avg_loss_c: 4.191761276938698 avg_loss_a: -49.559067604758525\n",
            "Número de pasos del episodio 9095 son episode_steps:44\n",
            "Total Steps: 560704 Episode Num: 9095 Reward: 49.19400924423444 avg_loss_c: 4.072498868812215 avg_loss_a: -50.42397464405406\n",
            "Número de pasos del episodio 9096 son episode_steps:115\n",
            "Total Steps: 560819 Episode Num: 9096 Reward: 177.09110313264162 avg_loss_c: 4.054124653857687 avg_loss_a: -50.03054650348166\n",
            "Número de pasos del episodio 9097 son episode_steps:77\n",
            "Total Steps: 560896 Episode Num: 9097 Reward: 121.62901528100969 avg_loss_c: 4.010030737170926 avg_loss_a: -50.1256671756893\n",
            "Número de pasos del episodio 9098 son episode_steps:42\n",
            "Total Steps: 560938 Episode Num: 9098 Reward: 36.4415939332954 avg_loss_c: 3.8607423986707414 avg_loss_a: -49.99750191824777\n",
            "Número de pasos del episodio 9099 son episode_steps:65\n",
            "Total Steps: 561003 Episode Num: 9099 Reward: 102.48454533298633 avg_loss_c: 3.9170117451594426 avg_loss_a: -49.41672598031851\n",
            "Número de pasos del episodio 9100 son episode_steps:86\n",
            "Total Steps: 561089 Episode Num: 9100 Reward: 121.69256857726967 avg_loss_c: 4.07692816922831 avg_loss_a: -50.068100774010944\n",
            "Número de pasos del episodio 9101 son episode_steps:90\n",
            "Total Steps: 561179 Episode Num: 9101 Reward: 162.1485114905668 avg_loss_c: 3.81527451939053 avg_loss_a: -49.493560791015625\n",
            "Número de pasos del episodio 9102 son episode_steps:141\n",
            "Total Steps: 561320 Episode Num: 9102 Reward: 226.4926684298011 avg_loss_c: 3.811053632844424 avg_loss_a: -49.7106116004024\n",
            "Número de pasos del episodio 9103 son episode_steps:68\n",
            "Total Steps: 561388 Episode Num: 9103 Reward: 104.59833714803815 avg_loss_c: 3.9353099815985737 avg_loss_a: -49.91857450148638\n",
            "Número de pasos del episodio 9104 son episode_steps:106\n",
            "Total Steps: 561494 Episode Num: 9104 Reward: 137.09401396497142 avg_loss_c: 3.9975907645135558 avg_loss_a: -49.93104589210366\n",
            "Número de pasos del episodio 9105 son episode_steps:96\n",
            "Total Steps: 561590 Episode Num: 9105 Reward: 78.41034273472675 avg_loss_c: 4.763884502152602 avg_loss_a: -49.4519153436025\n",
            "Número de pasos del episodio 9106 son episode_steps:53\n",
            "Total Steps: 561643 Episode Num: 9106 Reward: 55.093414340105085 avg_loss_c: 4.83816958823294 avg_loss_a: -50.22349742673478\n",
            "Número de pasos del episodio 9107 son episode_steps:118\n",
            "Total Steps: 561761 Episode Num: 9107 Reward: 166.03867953436435 avg_loss_c: 4.474154330916324 avg_loss_a: -49.52244154073424\n",
            "Número de pasos del episodio 9108 son episode_steps:105\n",
            "Total Steps: 561866 Episode Num: 9108 Reward: 171.6382842862577 avg_loss_c: 4.2079676787058515 avg_loss_a: -49.844458807082404\n",
            "Número de pasos del episodio 9109 son episode_steps:91\n",
            "Total Steps: 561957 Episode Num: 9109 Reward: 136.06488141618004 avg_loss_c: 4.876555023612557 avg_loss_a: -50.337083334451194\n",
            "Número de pasos del episodio 9110 son episode_steps:97\n",
            "Total Steps: 562054 Episode Num: 9110 Reward: 130.5197189309086 avg_loss_c: 4.309472954150328 avg_loss_a: -50.20621506209226\n",
            "Número de pasos del episodio 9111 son episode_steps:129\n",
            "Total Steps: 562183 Episode Num: 9111 Reward: 111.97010001280243 avg_loss_c: 4.306668076404305 avg_loss_a: -49.239947622136555\n",
            "Número de pasos del episodio 9112 son episode_steps:129\n",
            "Total Steps: 562312 Episode Num: 9112 Reward: 223.7924777322282 avg_loss_c: 4.149600675863813 avg_loss_a: -49.87665371562159\n",
            "Número de pasos del episodio 9113 son episode_steps:113\n",
            "Total Steps: 562425 Episode Num: 9113 Reward: 60.94811973340275 avg_loss_c: 4.442917644450095 avg_loss_a: -50.09040207989448\n",
            "Número de pasos del episodio 9114 son episode_steps:38\n",
            "Total Steps: 562463 Episode Num: 9114 Reward: 1.2147064625041692 avg_loss_c: 4.024667143821716 avg_loss_a: -50.2776850650185\n",
            "Número de pasos del episodio 9115 son episode_steps:97\n",
            "Total Steps: 562560 Episode Num: 9115 Reward: 152.1686447205889 avg_loss_c: 4.293097542733261 avg_loss_a: -49.273447017079775\n",
            "Número de pasos del episodio 9116 son episode_steps:47\n",
            "Total Steps: 562607 Episode Num: 9116 Reward: 48.94316103367911 avg_loss_c: 4.860593192120816 avg_loss_a: -49.64193206137799\n",
            "Número de pasos del episodio 9117 son episode_steps:107\n",
            "Total Steps: 562714 Episode Num: 9117 Reward: 171.67093995517772 avg_loss_c: 4.31969854319207 avg_loss_a: -49.68649324078426\n",
            "Número de pasos del episodio 9118 son episode_steps:134\n",
            "Total Steps: 562848 Episode Num: 9118 Reward: 196.54325341873755 avg_loss_c: 4.321853959738319 avg_loss_a: -49.484729083616344\n",
            "Número de pasos del episodio 9119 son episode_steps:103\n",
            "Total Steps: 562951 Episode Num: 9119 Reward: 160.10568762892396 avg_loss_c: 4.497419204526735 avg_loss_a: -49.48984164636112\n",
            "Número de pasos del episodio 9120 son episode_steps:41\n",
            "Total Steps: 562992 Episode Num: 9120 Reward: 26.95192484735782 avg_loss_c: 4.401032668788258 avg_loss_a: -50.1085743787812\n",
            "Número de pasos del episodio 9121 son episode_steps:87\n",
            "Total Steps: 563079 Episode Num: 9121 Reward: 145.79733918397548 avg_loss_c: 4.351255526487854 avg_loss_a: -49.40439781101271\n",
            "Número de pasos del episodio 9122 son episode_steps:94\n",
            "Total Steps: 563173 Episode Num: 9122 Reward: 148.54402164224405 avg_loss_c: 5.097944657853309 avg_loss_a: -49.360551144214384\n",
            "Número de pasos del episodio 9123 son episode_steps:85\n",
            "Total Steps: 563258 Episode Num: 9123 Reward: 121.8228412833314 avg_loss_c: 4.15593204498291 avg_loss_a: -49.12528834623449\n",
            "Número de pasos del episodio 9124 son episode_steps:82\n",
            "Total Steps: 563340 Episode Num: 9124 Reward: 129.11422851971324 avg_loss_c: 4.529479041332152 avg_loss_a: -49.21006291087081\n",
            "Número de pasos del episodio 9125 son episode_steps:107\n",
            "Total Steps: 563447 Episode Num: 9125 Reward: 175.41293449933184 avg_loss_c: 4.269769472496532 avg_loss_a: -49.04004776143582\n",
            "Número de pasos del episodio 9126 son episode_steps:110\n",
            "Total Steps: 563557 Episode Num: 9126 Reward: 189.088682891235 avg_loss_c: 3.9948650923642246 avg_loss_a: -49.53625994595615\n",
            "Número de pasos del episodio 9127 son episode_steps:27\n",
            "Total Steps: 563584 Episode Num: 9127 Reward: -12.089647821347938 avg_loss_c: 4.293306209422924 avg_loss_a: -48.88658650716146\n",
            "Número de pasos del episodio 9128 son episode_steps:104\n",
            "Total Steps: 563688 Episode Num: 9128 Reward: 153.25917935826834 avg_loss_c: 4.311859009357599 avg_loss_a: -49.26390897310697\n",
            "Número de pasos del episodio 9129 son episode_steps:103\n",
            "Total Steps: 563791 Episode Num: 9129 Reward: 156.2846247121654 avg_loss_c: 4.399896404118214 avg_loss_a: -49.25959940789973\n",
            "Número de pasos del episodio 9130 son episode_steps:94\n",
            "Total Steps: 563885 Episode Num: 9130 Reward: 155.99609058046894 avg_loss_c: 4.435165372300656 avg_loss_a: -49.74225251218106\n",
            "Número de pasos del episodio 9131 son episode_steps:97\n",
            "Total Steps: 563982 Episode Num: 9131 Reward: 148.72394322640025 avg_loss_c: 5.022863139811251 avg_loss_a: -49.52211175505648\n",
            "Número de pasos del episodio 9132 son episode_steps:124\n",
            "Total Steps: 564106 Episode Num: 9132 Reward: 206.28603192932138 avg_loss_c: 4.458359093435349 avg_loss_a: -49.28490780245873\n",
            "Número de pasos del episodio 9133 son episode_steps:111\n",
            "Total Steps: 564217 Episode Num: 9133 Reward: 180.8296620438859 avg_loss_c: 4.336762118983913 avg_loss_a: -49.67752930924699\n",
            "Número de pasos del episodio 9134 son episode_steps:55\n",
            "Total Steps: 564272 Episode Num: 9134 Reward: 82.38025028543498 avg_loss_c: 4.319725743207065 avg_loss_a: -49.34767858331854\n",
            "Número de pasos del episodio 9135 son episode_steps:76\n",
            "Total Steps: 564348 Episode Num: 9135 Reward: -14.072285736841296 avg_loss_c: 4.419107035586708 avg_loss_a: -48.44915801600406\n",
            "Número de pasos del episodio 9136 son episode_steps:91\n",
            "Total Steps: 564439 Episode Num: 9136 Reward: 142.455407852312 avg_loss_c: 4.94404477077526 avg_loss_a: -48.791594704428874\n",
            "Número de pasos del episodio 9137 son episode_steps:45\n",
            "Total Steps: 564484 Episode Num: 9137 Reward: 18.95021263940564 avg_loss_c: 4.47819554011027 avg_loss_a: -48.877090793185765\n",
            "Número de pasos del episodio 9138 son episode_steps:87\n",
            "Total Steps: 564571 Episode Num: 9138 Reward: 69.24845317930148 avg_loss_c: 4.3929712580538345 avg_loss_a: -49.10902378476899\n",
            "Número de pasos del episodio 9139 son episode_steps:103\n",
            "Total Steps: 564674 Episode Num: 9139 Reward: 175.63721566933353 avg_loss_c: 4.476003003351897 avg_loss_a: -49.2917752312225\n",
            "Número de pasos del episodio 9140 son episode_steps:84\n",
            "Total Steps: 564758 Episode Num: 9140 Reward: 132.41219412206894 avg_loss_c: 4.960604088647025 avg_loss_a: -49.34432683672224\n",
            "Número de pasos del episodio 9141 son episode_steps:80\n",
            "Total Steps: 564838 Episode Num: 9141 Reward: 112.63234670591369 avg_loss_c: 4.846737796068192 avg_loss_a: -49.205334186553955\n",
            "Número de pasos del episodio 9142 son episode_steps:81\n",
            "Total Steps: 564919 Episode Num: 9142 Reward: 125.9212344669578 avg_loss_c: 4.106716609295503 avg_loss_a: -49.349859214123384\n",
            "Número de pasos del episodio 9143 son episode_steps:67\n",
            "Total Steps: 564986 Episode Num: 9143 Reward: 95.51715827148145 avg_loss_c: 4.493809301461747 avg_loss_a: -49.46087703420155\n",
            "Número de pasos del episodio 9144 son episode_steps:103\n",
            "Total Steps: 565089 Episode Num: 9144 Reward: 175.80177025259707 avg_loss_c: 4.2782286625463986 avg_loss_a: -48.78889328299217\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 190.697290\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9145 son episode_steps:51\n",
            "Total Steps: 565140 Episode Num: 9145 Reward: 39.7036017026888 avg_loss_c: 4.354915717068841 avg_loss_a: -49.373600080901504\n",
            "Número de pasos del episodio 9146 son episode_steps:97\n",
            "Total Steps: 565237 Episode Num: 9146 Reward: 135.07070692003396 avg_loss_c: 4.1983688270922785 avg_loss_a: -49.51594720427523\n",
            "Número de pasos del episodio 9147 son episode_steps:136\n",
            "Total Steps: 565373 Episode Num: 9147 Reward: 205.61678890397692 avg_loss_c: 4.387273825266782 avg_loss_a: -49.398044249590704\n",
            "Número de pasos del episodio 9148 son episode_steps:45\n",
            "Total Steps: 565418 Episode Num: 9148 Reward: 24.722175640082302 avg_loss_c: 4.791417704688178 avg_loss_a: -49.1304800245497\n",
            "Número de pasos del episodio 9149 son episode_steps:88\n",
            "Total Steps: 565506 Episode Num: 9149 Reward: 138.1036287870294 avg_loss_c: 4.373064249753952 avg_loss_a: -49.006680488586426\n",
            "Número de pasos del episodio 9150 son episode_steps:154\n",
            "Total Steps: 565660 Episode Num: 9150 Reward: 254.1492854553203 avg_loss_c: 4.227130433181664 avg_loss_a: -49.355680540010525\n",
            "Número de pasos del episodio 9151 son episode_steps:101\n",
            "Total Steps: 565761 Episode Num: 9151 Reward: 168.335707055987 avg_loss_c: 4.027020577156898 avg_loss_a: -49.14276878432472\n",
            "Número de pasos del episodio 9152 son episode_steps:76\n",
            "Total Steps: 565837 Episode Num: 9152 Reward: 109.49334426194078 avg_loss_c: 4.520761668682098 avg_loss_a: -49.19457837154991\n",
            "Número de pasos del episodio 9153 son episode_steps:73\n",
            "Total Steps: 565910 Episode Num: 9153 Reward: 113.67296841151399 avg_loss_c: 4.6515489963636005 avg_loss_a: -49.4722454123301\n",
            "Número de pasos del episodio 9154 son episode_steps:60\n",
            "Total Steps: 565970 Episode Num: 9154 Reward: 75.70320776572594 avg_loss_c: 4.633943017323812 avg_loss_a: -50.138708623250324\n",
            "Número de pasos del episodio 9155 son episode_steps:86\n",
            "Total Steps: 566056 Episode Num: 9155 Reward: 116.981664169129 avg_loss_c: 4.19967054489047 avg_loss_a: -49.047373660775115\n",
            "Número de pasos del episodio 9156 son episode_steps:107\n",
            "Total Steps: 566163 Episode Num: 9156 Reward: 175.11361549919843 avg_loss_c: 4.255288438262227 avg_loss_a: -49.36171258944217\n",
            "Número de pasos del episodio 9157 son episode_steps:79\n",
            "Total Steps: 566242 Episode Num: 9157 Reward: 104.77492100332917 avg_loss_c: 4.615811203099504 avg_loss_a: -49.76360519022881\n",
            "Número de pasos del episodio 9158 son episode_steps:61\n",
            "Total Steps: 566303 Episode Num: 9158 Reward: 88.25949153990544 avg_loss_c: 4.086555555218556 avg_loss_a: -49.788853817298765\n",
            "Número de pasos del episodio 9159 son episode_steps:41\n",
            "Total Steps: 566344 Episode Num: 9159 Reward: 9.194997923573533 avg_loss_c: 4.846022611711083 avg_loss_a: -49.431897047089365\n",
            "Número de pasos del episodio 9160 son episode_steps:162\n",
            "Total Steps: 566506 Episode Num: 9160 Reward: 266.6364505789233 avg_loss_c: 4.250064621736974 avg_loss_a: -49.86144256591797\n",
            "Número de pasos del episodio 9161 son episode_steps:139\n",
            "Total Steps: 566645 Episode Num: 9161 Reward: 228.32869133054723 avg_loss_c: 4.5039546626934905 avg_loss_a: -49.1191747926122\n",
            "Número de pasos del episodio 9162 son episode_steps:55\n",
            "Total Steps: 566700 Episode Num: 9162 Reward: 28.252470481297824 avg_loss_c: 3.944380456751043 avg_loss_a: -49.60021459406072\n",
            "Número de pasos del episodio 9163 son episode_steps:188\n",
            "Total Steps: 566888 Episode Num: 9163 Reward: 290.70242190240015 avg_loss_c: 4.6046354694569365 avg_loss_a: -49.59079778955338\n",
            "Número de pasos del episodio 9164 son episode_steps:75\n",
            "Total Steps: 566963 Episode Num: 9164 Reward: 114.63770987599777 avg_loss_c: 4.0981580289204915 avg_loss_a: -49.80651911417643\n",
            "Número de pasos del episodio 9165 son episode_steps:111\n",
            "Total Steps: 567074 Episode Num: 9165 Reward: 175.25419167205737 avg_loss_c: 4.591866413752238 avg_loss_a: -50.28318989384282\n",
            "Número de pasos del episodio 9166 son episode_steps:69\n",
            "Total Steps: 567143 Episode Num: 9166 Reward: 102.47590746443558 avg_loss_c: 4.2519523268160615 avg_loss_a: -50.37128857598788\n",
            "Número de pasos del episodio 9167 son episode_steps:86\n",
            "Total Steps: 567229 Episode Num: 9167 Reward: 99.82582278075905 avg_loss_c: 4.077869420827821 avg_loss_a: -49.61916511003361\n",
            "Número de pasos del episodio 9168 son episode_steps:92\n",
            "Total Steps: 567321 Episode Num: 9168 Reward: 144.4110327731174 avg_loss_c: 3.921240290869837 avg_loss_a: -50.26440777985946\n",
            "Número de pasos del episodio 9169 son episode_steps:123\n",
            "Total Steps: 567444 Episode Num: 9169 Reward: 184.9546816992714 avg_loss_c: 4.2088519247566785 avg_loss_a: -49.57803797528027\n",
            "Número de pasos del episodio 9170 son episode_steps:124\n",
            "Total Steps: 567568 Episode Num: 9170 Reward: 210.36029416537463 avg_loss_c: 4.0987383454076705 avg_loss_a: -49.64969665773453\n",
            "Número de pasos del episodio 9171 son episode_steps:73\n",
            "Total Steps: 567641 Episode Num: 9171 Reward: 81.93711219771933 avg_loss_c: 3.9229398916845453 avg_loss_a: -50.03216030173106\n",
            "Número de pasos del episodio 9172 son episode_steps:78\n",
            "Total Steps: 567719 Episode Num: 9172 Reward: 84.55364173969703 avg_loss_c: 4.027447446798667 avg_loss_a: -49.99985220493414\n",
            "Número de pasos del episodio 9173 son episode_steps:105\n",
            "Total Steps: 567824 Episode Num: 9173 Reward: 163.16298878457908 avg_loss_c: 4.3163505031949 avg_loss_a: -50.04916981288365\n",
            "Número de pasos del episodio 9174 son episode_steps:79\n",
            "Total Steps: 567903 Episode Num: 9174 Reward: 113.51954079370348 avg_loss_c: 4.492718452139746 avg_loss_a: -50.084784254243104\n",
            "Número de pasos del episodio 9175 son episode_steps:177\n",
            "Total Steps: 568080 Episode Num: 9175 Reward: 241.5837739608438 avg_loss_c: 4.0516779692159535 avg_loss_a: -49.94544743683379\n",
            "Número de pasos del episodio 9176 son episode_steps:134\n",
            "Total Steps: 568214 Episode Num: 9176 Reward: 165.3544445629204 avg_loss_c: 4.209013090204837 avg_loss_a: -49.9421098054345\n",
            "Número de pasos del episodio 9177 son episode_steps:141\n",
            "Total Steps: 568355 Episode Num: 9177 Reward: 199.96970378088562 avg_loss_c: 4.080624847547383 avg_loss_a: -50.13515101764219\n",
            "Número de pasos del episodio 9178 son episode_steps:138\n",
            "Total Steps: 568493 Episode Num: 9178 Reward: 215.09114625283593 avg_loss_c: 4.520063446915668 avg_loss_a: -50.126359082650445\n",
            "Número de pasos del episodio 9179 son episode_steps:82\n",
            "Total Steps: 568575 Episode Num: 9179 Reward: 126.91214144517438 avg_loss_c: 4.139160923841523 avg_loss_a: -50.40377714575791\n",
            "Número de pasos del episodio 9180 son episode_steps:84\n",
            "Total Steps: 568659 Episode Num: 9180 Reward: 128.74184385041363 avg_loss_c: 3.971961980774289 avg_loss_a: -50.92389442807152\n",
            "Número de pasos del episodio 9181 son episode_steps:92\n",
            "Total Steps: 568751 Episode Num: 9181 Reward: 128.57737524616812 avg_loss_c: 3.9703670714212502 avg_loss_a: -50.46818550773289\n",
            "Número de pasos del episodio 9182 son episode_steps:150\n",
            "Total Steps: 568901 Episode Num: 9182 Reward: 232.21166068290222 avg_loss_c: 3.5411886835098265 avg_loss_a: -50.75470555623372\n",
            "Número de pasos del episodio 9183 son episode_steps:112\n",
            "Total Steps: 569013 Episode Num: 9183 Reward: 162.52873675477764 avg_loss_c: 4.562930611627443 avg_loss_a: -50.89459187643869\n",
            "Número de pasos del episodio 9184 son episode_steps:141\n",
            "Total Steps: 569154 Episode Num: 9184 Reward: 222.83962506413218 avg_loss_c: 3.850149303463334 avg_loss_a: -50.68908585893347\n",
            "Número de pasos del episodio 9185 son episode_steps:83\n",
            "Total Steps: 569237 Episode Num: 9185 Reward: 136.37413010833006 avg_loss_c: 3.9815988540649414 avg_loss_a: -50.68119830395802\n",
            "Número de pasos del episodio 9186 son episode_steps:105\n",
            "Total Steps: 569342 Episode Num: 9186 Reward: 138.34759837055873 avg_loss_c: 4.133920051938012 avg_loss_a: -51.30527641659691\n",
            "Número de pasos del episodio 9187 son episode_steps:56\n",
            "Total Steps: 569398 Episode Num: 9187 Reward: 72.1020042264758 avg_loss_c: 3.579725844519479 avg_loss_a: -51.26734719957624\n",
            "Número de pasos del episodio 9188 son episode_steps:34\n",
            "Total Steps: 569432 Episode Num: 9188 Reward: -10.256174758141144 avg_loss_c: 3.5601204142850986 avg_loss_a: -50.83015105303596\n",
            "Número de pasos del episodio 9189 son episode_steps:90\n",
            "Total Steps: 569522 Episode Num: 9189 Reward: 129.86342736543017 avg_loss_c: 4.87511510848999 avg_loss_a: -50.87862531873915\n",
            "Número de pasos del episodio 9190 son episode_steps:132\n",
            "Total Steps: 569654 Episode Num: 9190 Reward: 134.18672494974587 avg_loss_c: 5.084889608802217 avg_loss_a: -50.37710993217699\n",
            "Número de pasos del episodio 9191 son episode_steps:70\n",
            "Total Steps: 569724 Episode Num: 9191 Reward: 100.64904577636719 avg_loss_c: 3.82290506703513 avg_loss_a: -50.970931897844586\n",
            "Número de pasos del episodio 9192 son episode_steps:113\n",
            "Total Steps: 569837 Episode Num: 9192 Reward: 165.63467196275332 avg_loss_c: 4.4038293446059775 avg_loss_a: -50.88096642283212\n",
            "Número de pasos del episodio 9193 son episode_steps:118\n",
            "Total Steps: 569955 Episode Num: 9193 Reward: 185.6279921585619 avg_loss_c: 3.8851984537253945 avg_loss_a: -50.90132082922984\n",
            "Número de pasos del episodio 9194 son episode_steps:116\n",
            "Total Steps: 570071 Episode Num: 9194 Reward: 161.7688084431673 avg_loss_c: 4.046699685269389 avg_loss_a: -50.741848978503\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 98.174856\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9195 son episode_steps:101\n",
            "Total Steps: 570172 Episode Num: 9195 Reward: 152.38312738350183 avg_loss_c: 4.243398656939516 avg_loss_a: -51.00447414889194\n",
            "Número de pasos del episodio 9196 son episode_steps:49\n",
            "Total Steps: 570221 Episode Num: 9196 Reward: 25.950185584858417 avg_loss_c: 3.9486418743522798 avg_loss_a: -50.774320174236685\n",
            "Número de pasos del episodio 9197 son episode_steps:22\n",
            "Total Steps: 570243 Episode Num: 9197 Reward: -19.78501583086479 avg_loss_c: 3.5433977950703013 avg_loss_a: -51.84836786443537\n",
            "Número de pasos del episodio 9198 son episode_steps:85\n",
            "Total Steps: 570328 Episode Num: 9198 Reward: 25.21653581351239 avg_loss_c: 4.20494355874903 avg_loss_a: -50.81291512882008\n",
            "Número de pasos del episodio 9199 son episode_steps:136\n",
            "Total Steps: 570464 Episode Num: 9199 Reward: 215.01109453426665 avg_loss_c: 4.217472847770242 avg_loss_a: -50.69103650485768\n",
            "Número de pasos del episodio 9200 son episode_steps:87\n",
            "Total Steps: 570551 Episode Num: 9200 Reward: 115.54368008529106 avg_loss_c: 4.690361294253119 avg_loss_a: -50.460178506785425\n",
            "Número de pasos del episodio 9201 son episode_steps:77\n",
            "Total Steps: 570628 Episode Num: 9201 Reward: 117.66265672750446 avg_loss_c: 3.951652495892017 avg_loss_a: -50.71461377825056\n",
            "Número de pasos del episodio 9202 son episode_steps:192\n",
            "Total Steps: 570820 Episode Num: 9202 Reward: 333.9007005132959 avg_loss_c: 4.405769733091195 avg_loss_a: -50.91701094309489\n",
            "Número de pasos del episodio 9203 son episode_steps:169\n",
            "Total Steps: 570989 Episode Num: 9203 Reward: 266.77722381405846 avg_loss_c: 4.344116292761628 avg_loss_a: -51.29454078900038\n",
            "Número de pasos del episodio 9204 son episode_steps:112\n",
            "Total Steps: 571101 Episode Num: 9204 Reward: 170.21250903708497 avg_loss_c: 3.756734243461064 avg_loss_a: -50.774383885519846\n",
            "Número de pasos del episodio 9205 son episode_steps:166\n",
            "Total Steps: 571267 Episode Num: 9205 Reward: 228.39938866193557 avg_loss_c: 4.123470264745046 avg_loss_a: -50.818593726100694\n",
            "Número de pasos del episodio 9206 son episode_steps:75\n",
            "Total Steps: 571342 Episode Num: 9206 Reward: 104.29874794671677 avg_loss_c: 4.1854026317596436 avg_loss_a: -50.86488026936849\n",
            "Número de pasos del episodio 9207 son episode_steps:77\n",
            "Total Steps: 571419 Episode Num: 9207 Reward: 87.61269203971924 avg_loss_c: 4.043685420767053 avg_loss_a: -51.55594327852324\n",
            "Número de pasos del episodio 9208 son episode_steps:100\n",
            "Total Steps: 571519 Episode Num: 9208 Reward: 156.70465552641426 avg_loss_c: 3.949029486179352 avg_loss_a: -51.42200828552246\n",
            "Número de pasos del episodio 9209 son episode_steps:150\n",
            "Total Steps: 571669 Episode Num: 9209 Reward: 223.78658700341109 avg_loss_c: 4.142125714619954 avg_loss_a: -50.7498540242513\n",
            "Número de pasos del episodio 9210 son episode_steps:42\n",
            "Total Steps: 571711 Episode Num: 9210 Reward: 19.13833662094231 avg_loss_c: 3.8403825759887695 avg_loss_a: -51.16569991338821\n",
            "Número de pasos del episodio 9211 son episode_steps:124\n",
            "Total Steps: 571835 Episode Num: 9211 Reward: 158.14195874333387 avg_loss_c: 3.931300053673406 avg_loss_a: -51.13551004471317\n",
            "Número de pasos del episodio 9212 son episode_steps:163\n",
            "Total Steps: 571998 Episode Num: 9212 Reward: 258.67296680455814 avg_loss_c: 3.812486674888002 avg_loss_a: -51.24349196264349\n",
            "Número de pasos del episodio 9213 son episode_steps:71\n",
            "Total Steps: 572069 Episode Num: 9213 Reward: 43.547242253279684 avg_loss_c: 4.273602851679628 avg_loss_a: -51.028592552937255\n",
            "Número de pasos del episodio 9214 son episode_steps:104\n",
            "Total Steps: 572173 Episode Num: 9214 Reward: 144.16928521012383 avg_loss_c: 3.710101128770755 avg_loss_a: -51.479916719289925\n",
            "Número de pasos del episodio 9215 son episode_steps:103\n",
            "Total Steps: 572276 Episode Num: 9215 Reward: 149.1563670749113 avg_loss_c: 3.5657946600497348 avg_loss_a: -50.682285271801994\n",
            "Número de pasos del episodio 9216 son episode_steps:95\n",
            "Total Steps: 572371 Episode Num: 9216 Reward: 146.1502472529248 avg_loss_c: 3.883695788132517 avg_loss_a: -50.94074401855469\n",
            "Número de pasos del episodio 9217 son episode_steps:96\n",
            "Total Steps: 572467 Episode Num: 9217 Reward: 84.99033602719372 avg_loss_c: 4.399121927718322 avg_loss_a: -51.405120611190796\n",
            "Número de pasos del episodio 9218 son episode_steps:95\n",
            "Total Steps: 572562 Episode Num: 9218 Reward: 156.42988839894463 avg_loss_c: 4.226539822628624 avg_loss_a: -51.14349879214638\n",
            "Número de pasos del episodio 9219 son episode_steps:73\n",
            "Total Steps: 572635 Episode Num: 9219 Reward: 110.36105754476222 avg_loss_c: 3.8262204307399386 avg_loss_a: -50.983237175092306\n",
            "Número de pasos del episodio 9220 son episode_steps:198\n",
            "Total Steps: 572833 Episode Num: 9220 Reward: 213.65866131686508 avg_loss_c: 4.330089805102108 avg_loss_a: -50.957836806172075\n",
            "Número de pasos del episodio 9221 son episode_steps:100\n",
            "Total Steps: 572933 Episode Num: 9221 Reward: 142.12593711795037 avg_loss_c: 4.099191706180573 avg_loss_a: -51.61380966186523\n",
            "Número de pasos del episodio 9222 son episode_steps:130\n",
            "Total Steps: 573063 Episode Num: 9222 Reward: 192.8369096439564 avg_loss_c: 4.100168655468868 avg_loss_a: -50.97995623075045\n",
            "Número de pasos del episodio 9223 son episode_steps:61\n",
            "Total Steps: 573124 Episode Num: 9223 Reward: 52.93020749789066 avg_loss_c: 3.7209746251340774 avg_loss_a: -50.82835644581279\n",
            "Número de pasos del episodio 9224 son episode_steps:143\n",
            "Total Steps: 573267 Episode Num: 9224 Reward: 220.24776027168062 avg_loss_c: 4.009815936321979 avg_loss_a: -51.049819839584245\n",
            "Número de pasos del episodio 9225 son episode_steps:73\n",
            "Total Steps: 573340 Episode Num: 9225 Reward: 102.63948537381498 avg_loss_c: 4.206824567219982 avg_loss_a: -50.80115378392886\n",
            "Número de pasos del episodio 9226 son episode_steps:101\n",
            "Total Steps: 573441 Episode Num: 9226 Reward: 132.44289246520475 avg_loss_c: 3.961429470836526 avg_loss_a: -51.27651426107577\n",
            "Número de pasos del episodio 9227 son episode_steps:133\n",
            "Total Steps: 573574 Episode Num: 9227 Reward: 206.17950281703708 avg_loss_c: 3.6775761152568616 avg_loss_a: -51.638371489101786\n",
            "Número de pasos del episodio 9228 son episode_steps:112\n",
            "Total Steps: 573686 Episode Num: 9228 Reward: 164.8563685637533 avg_loss_c: 3.794641524553299 avg_loss_a: -51.46780736105783\n",
            "Número de pasos del episodio 9229 son episode_steps:154\n",
            "Total Steps: 573840 Episode Num: 9229 Reward: 226.96879004399878 avg_loss_c: 3.8474564103337077 avg_loss_a: -51.69972461849064\n",
            "Número de pasos del episodio 9230 son episode_steps:114\n",
            "Total Steps: 573954 Episode Num: 9230 Reward: 186.35913608673474 avg_loss_c: 4.220769112570244 avg_loss_a: -51.59894849542986\n",
            "Número de pasos del episodio 9231 son episode_steps:43\n",
            "Total Steps: 573997 Episode Num: 9231 Reward: 44.0005068886993 avg_loss_c: 3.422804205916649 avg_loss_a: -51.9816288615382\n",
            "Número de pasos del episodio 9232 son episode_steps:159\n",
            "Total Steps: 574156 Episode Num: 9232 Reward: 251.88631805925343 avg_loss_c: 4.277991779195438 avg_loss_a: -51.31019577890072\n",
            "Número de pasos del episodio 9233 son episode_steps:152\n",
            "Total Steps: 574308 Episode Num: 9233 Reward: 240.23457733640703 avg_loss_c: 3.9709508826858118 avg_loss_a: -51.84538023095382\n",
            "Número de pasos del episodio 9234 son episode_steps:137\n",
            "Total Steps: 574445 Episode Num: 9234 Reward: 225.98422375088072 avg_loss_c: 3.764695665262041 avg_loss_a: -51.2173853129366\n",
            "Número de pasos del episodio 9235 son episode_steps:108\n",
            "Total Steps: 574553 Episode Num: 9235 Reward: 182.04295577178348 avg_loss_c: 3.674242878401721 avg_loss_a: -51.847573386298286\n",
            "Número de pasos del episodio 9236 son episode_steps:258\n",
            "Total Steps: 574811 Episode Num: 9236 Reward: 372.0562627642909 avg_loss_c: 3.7645183395045674 avg_loss_a: -52.40005809576937\n",
            "Número de pasos del episodio 9237 son episode_steps:136\n",
            "Total Steps: 574947 Episode Num: 9237 Reward: 197.10833828736995 avg_loss_c: 3.639800680034301 avg_loss_a: -52.125222879297596\n",
            "Número de pasos del episodio 9238 son episode_steps:182\n",
            "Total Steps: 575129 Episode Num: 9238 Reward: 288.22052821967293 avg_loss_c: 3.8321478484751106 avg_loss_a: -52.34806580595918\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 119.344686\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9239 son episode_steps:96\n",
            "Total Steps: 575225 Episode Num: 9239 Reward: 153.5766808376188 avg_loss_c: 3.4105062087376914 avg_loss_a: -51.73451940218607\n",
            "Número de pasos del episodio 9240 son episode_steps:185\n",
            "Total Steps: 575410 Episode Num: 9240 Reward: 277.06970508393255 avg_loss_c: 3.8115112407787426 avg_loss_a: -53.08209886293154\n",
            "Número de pasos del episodio 9241 son episode_steps:137\n",
            "Total Steps: 575547 Episode Num: 9241 Reward: 217.17815364356665 avg_loss_c: 3.9581094466856794 avg_loss_a: -52.696732931763584\n",
            "Número de pasos del episodio 9242 son episode_steps:115\n",
            "Total Steps: 575662 Episode Num: 9242 Reward: 159.91310585817774 avg_loss_c: 3.7936534549878993 avg_loss_a: -52.65815499347189\n",
            "Número de pasos del episodio 9243 son episode_steps:83\n",
            "Total Steps: 575745 Episode Num: 9243 Reward: 106.36734316950067 avg_loss_c: 4.024935144975961 avg_loss_a: -52.27278389988175\n",
            "Número de pasos del episodio 9244 son episode_steps:70\n",
            "Total Steps: 575815 Episode Num: 9244 Reward: 98.90068689782495 avg_loss_c: 4.219766991479056 avg_loss_a: -53.23224618094308\n",
            "Número de pasos del episodio 9245 son episode_steps:93\n",
            "Total Steps: 575908 Episode Num: 9245 Reward: 81.8210009085945 avg_loss_c: 4.459973858248803 avg_loss_a: -52.7645634887039\n",
            "Número de pasos del episodio 9246 son episode_steps:135\n",
            "Total Steps: 576043 Episode Num: 9246 Reward: 166.3539908259128 avg_loss_c: 4.1071917374928795 avg_loss_a: -52.66137966579861\n",
            "Número de pasos del episodio 9247 son episode_steps:60\n",
            "Total Steps: 576103 Episode Num: 9247 Reward: 66.96741289018831 avg_loss_c: 4.354726696014405 avg_loss_a: -52.84341303507487\n",
            "Número de pasos del episodio 9248 son episode_steps:143\n",
            "Total Steps: 576246 Episode Num: 9248 Reward: 222.77050022008677 avg_loss_c: 4.138155266955183 avg_loss_a: -52.71728427593525\n",
            "Número de pasos del episodio 9249 son episode_steps:142\n",
            "Total Steps: 576388 Episode Num: 9249 Reward: 72.80342217094427 avg_loss_c: 4.141460868674264 avg_loss_a: -52.31709902051469\n",
            "Número de pasos del episodio 9250 son episode_steps:87\n",
            "Total Steps: 576475 Episode Num: 9250 Reward: 66.56999837616208 avg_loss_c: 3.8981440889424293 avg_loss_a: -52.60223866605211\n",
            "Número de pasos del episodio 9251 son episode_steps:190\n",
            "Total Steps: 576665 Episode Num: 9251 Reward: 245.54380373350273 avg_loss_c: 4.085959646576329 avg_loss_a: -52.43706030594675\n",
            "Número de pasos del episodio 9252 son episode_steps:107\n",
            "Total Steps: 576772 Episode Num: 9252 Reward: 138.26474082288408 avg_loss_c: 4.295683658011606 avg_loss_a: -52.57810909948616\n",
            "Número de pasos del episodio 9253 son episode_steps:157\n",
            "Total Steps: 576929 Episode Num: 9253 Reward: 215.0187525845662 avg_loss_c: 4.509489720034751 avg_loss_a: -52.386298234295694\n",
            "Número de pasos del episodio 9254 son episode_steps:70\n",
            "Total Steps: 576999 Episode Num: 9254 Reward: 112.6218973831288 avg_loss_c: 4.243625017574855 avg_loss_a: -52.6062497820173\n",
            "Número de pasos del episodio 9255 son episode_steps:93\n",
            "Total Steps: 577092 Episode Num: 9255 Reward: 101.00792649277822 avg_loss_c: 4.552277021510626 avg_loss_a: -52.55469057636876\n",
            "Número de pasos del episodio 9256 son episode_steps:24\n",
            "Total Steps: 577116 Episode Num: 9256 Reward: -14.88889589128464 avg_loss_c: 4.566457619269689 avg_loss_a: -52.14965629577637\n",
            "Número de pasos del episodio 9257 son episode_steps:99\n",
            "Total Steps: 577215 Episode Num: 9257 Reward: 57.67329112955652 avg_loss_c: 4.431051593838316 avg_loss_a: -51.953214433458115\n",
            "Número de pasos del episodio 9258 son episode_steps:189\n",
            "Total Steps: 577404 Episode Num: 9258 Reward: 314.0065091753179 avg_loss_c: 4.392633467124253 avg_loss_a: -52.680664123050754\n",
            "Número de pasos del episodio 9259 son episode_steps:65\n",
            "Total Steps: 577469 Episode Num: 9259 Reward: 73.6708819800758 avg_loss_c: 4.177622072513287 avg_loss_a: -52.99176565317007\n",
            "Número de pasos del episodio 9260 son episode_steps:122\n",
            "Total Steps: 577591 Episode Num: 9260 Reward: 195.70149405784508 avg_loss_c: 4.68059262877605 avg_loss_a: -52.65160463677078\n",
            "Número de pasos del episodio 9261 son episode_steps:198\n",
            "Total Steps: 577789 Episode Num: 9261 Reward: 246.6936888256656 avg_loss_c: 4.426628241635332 avg_loss_a: -53.07319398359819\n",
            "Número de pasos del episodio 9262 son episode_steps:84\n",
            "Total Steps: 577873 Episode Num: 9262 Reward: 141.81384218713833 avg_loss_c: 4.313531929538364 avg_loss_a: -52.98026711600168\n",
            "Número de pasos del episodio 9263 son episode_steps:62\n",
            "Total Steps: 577935 Episode Num: 9263 Reward: 64.60590905314751 avg_loss_c: 4.204938492467327 avg_loss_a: -53.30091119581653\n",
            "Número de pasos del episodio 9264 son episode_steps:69\n",
            "Total Steps: 578004 Episode Num: 9264 Reward: 90.30205380889319 avg_loss_c: 4.185434939204782 avg_loss_a: -53.50209675664487\n",
            "Número de pasos del episodio 9265 son episode_steps:74\n",
            "Total Steps: 578078 Episode Num: 9265 Reward: 78.30890095283934 avg_loss_c: 4.134987154522458 avg_loss_a: -52.87323523856498\n",
            "Número de pasos del episodio 9266 son episode_steps:87\n",
            "Total Steps: 578165 Episode Num: 9266 Reward: 140.0241808326122 avg_loss_c: 4.746343546900256 avg_loss_a: -52.522011329387794\n",
            "Número de pasos del episodio 9267 son episode_steps:108\n",
            "Total Steps: 578273 Episode Num: 9267 Reward: 176.41055059628033 avg_loss_c: 4.742838693989648 avg_loss_a: -52.1557300708912\n",
            "Número de pasos del episodio 9268 son episode_steps:121\n",
            "Total Steps: 578394 Episode Num: 9268 Reward: 195.48676600190458 avg_loss_c: 4.275207328402306 avg_loss_a: -53.27722227868955\n",
            "Número de pasos del episodio 9269 son episode_steps:98\n",
            "Total Steps: 578492 Episode Num: 9269 Reward: 125.91378550168571 avg_loss_c: 4.143327542713711 avg_loss_a: -53.31526549981565\n",
            "Número de pasos del episodio 9270 son episode_steps:191\n",
            "Total Steps: 578683 Episode Num: 9270 Reward: 234.9289045488992 avg_loss_c: 4.347355903755308 avg_loss_a: -52.925264907757025\n",
            "Número de pasos del episodio 9271 son episode_steps:101\n",
            "Total Steps: 578784 Episode Num: 9271 Reward: 157.53254836158675 avg_loss_c: 4.016921270011675 avg_loss_a: -52.80378617390548\n",
            "Número de pasos del episodio 9272 son episode_steps:136\n",
            "Total Steps: 578920 Episode Num: 9272 Reward: 224.68527912005985 avg_loss_c: 3.9911961239926956 avg_loss_a: -53.18536068411434\n",
            "Número de pasos del episodio 9273 son episode_steps:115\n",
            "Total Steps: 579035 Episode Num: 9273 Reward: 189.04309778639293 avg_loss_c: 4.3118036435998 avg_loss_a: -53.84113215570864\n",
            "Número de pasos del episodio 9274 son episode_steps:87\n",
            "Total Steps: 579122 Episode Num: 9274 Reward: 144.2847977648785 avg_loss_c: 4.17348750158288 avg_loss_a: -52.923372641377064\n",
            "Número de pasos del episodio 9275 son episode_steps:94\n",
            "Total Steps: 579216 Episode Num: 9275 Reward: 90.54425457534266 avg_loss_c: 3.9559457885458116 avg_loss_a: -53.41566629612699\n",
            "Número de pasos del episodio 9276 son episode_steps:85\n",
            "Total Steps: 579301 Episode Num: 9276 Reward: 74.56979657891878 avg_loss_c: 4.399833311754114 avg_loss_a: -53.540570337632126\n",
            "Número de pasos del episodio 9277 son episode_steps:188\n",
            "Total Steps: 579489 Episode Num: 9277 Reward: 338.9840995207189 avg_loss_c: 4.130678800826377 avg_loss_a: -53.279266803822615\n",
            "Número de pasos del episodio 9278 son episode_steps:101\n",
            "Total Steps: 579590 Episode Num: 9278 Reward: -7.2532011933171034 avg_loss_c: 4.63106914085917 avg_loss_a: -53.01558341602288\n",
            "Número de pasos del episodio 9279 son episode_steps:20\n",
            "Total Steps: 579610 Episode Num: 9279 Reward: -16.02628606277488 avg_loss_c: 4.535415542125702 avg_loss_a: -53.663702392578124\n",
            "Número de pasos del episodio 9280 son episode_steps:52\n",
            "Total Steps: 579662 Episode Num: 9280 Reward: 45.41690531796211 avg_loss_c: 4.188552916049957 avg_loss_a: -53.49757957458496\n",
            "Número de pasos del episodio 9281 son episode_steps:110\n",
            "Total Steps: 579772 Episode Num: 9281 Reward: 170.9885489892347 avg_loss_c: 4.521050565893 avg_loss_a: -53.03738250732422\n",
            "Número de pasos del episodio 9282 son episode_steps:74\n",
            "Total Steps: 579846 Episode Num: 9282 Reward: 110.54956400511895 avg_loss_c: 4.166323120529587 avg_loss_a: -54.052213204873574\n",
            "Número de pasos del episodio 9283 son episode_steps:108\n",
            "Total Steps: 579954 Episode Num: 9283 Reward: 127.98820172987803 avg_loss_c: 4.38932384164245 avg_loss_a: -53.466886591028285\n",
            "Número de pasos del episodio 9284 son episode_steps:76\n",
            "Total Steps: 580030 Episode Num: 9284 Reward: 118.9416198930623 avg_loss_c: 4.480588881593001 avg_loss_a: -53.100906773617396\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 157.712005\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9285 son episode_steps:68\n",
            "Total Steps: 580098 Episode Num: 9285 Reward: 96.65276482990193 avg_loss_c: 5.095913150731255 avg_loss_a: -53.12066504534553\n",
            "Número de pasos del episodio 9286 son episode_steps:147\n",
            "Total Steps: 580245 Episode Num: 9286 Reward: 212.1532709426626 avg_loss_c: 4.615633002754782 avg_loss_a: -53.02575185347577\n",
            "Número de pasos del episodio 9287 son episode_steps:77\n",
            "Total Steps: 580322 Episode Num: 9287 Reward: 109.38742006263263 avg_loss_c: 4.634423311654624 avg_loss_a: -52.822834113975624\n",
            "Número de pasos del episodio 9288 son episode_steps:103\n",
            "Total Steps: 580425 Episode Num: 9288 Reward: 49.351629646988016 avg_loss_c: 4.601373197962936 avg_loss_a: -53.05185336511112\n",
            "Número de pasos del episodio 9289 son episode_steps:95\n",
            "Total Steps: 580520 Episode Num: 9289 Reward: 93.80890802487514 avg_loss_c: 4.718787803147968 avg_loss_a: -53.27608710841129\n",
            "Número de pasos del episodio 9290 son episode_steps:98\n",
            "Total Steps: 580618 Episode Num: 9290 Reward: 137.27871686445206 avg_loss_c: 4.696804795946393 avg_loss_a: -52.98085107608717\n",
            "Número de pasos del episodio 9291 son episode_steps:71\n",
            "Total Steps: 580689 Episode Num: 9291 Reward: 47.69784303832145 avg_loss_c: 4.987035875589076 avg_loss_a: -53.52525899108027\n",
            "Número de pasos del episodio 9292 son episode_steps:154\n",
            "Total Steps: 580843 Episode Num: 9292 Reward: 254.13194232912025 avg_loss_c: 4.8783250582682625 avg_loss_a: -53.26517541067941\n",
            "Número de pasos del episodio 9293 son episode_steps:163\n",
            "Total Steps: 581006 Episode Num: 9293 Reward: 276.531159310742 avg_loss_c: 4.500790116245761 avg_loss_a: -53.010750308358595\n",
            "Número de pasos del episodio 9294 son episode_steps:107\n",
            "Total Steps: 581113 Episode Num: 9294 Reward: 180.761375143361 avg_loss_c: 4.83482944853952 avg_loss_a: -53.53556135658906\n",
            "Número de pasos del episodio 9295 son episode_steps:116\n",
            "Total Steps: 581229 Episode Num: 9295 Reward: 181.53561745408547 avg_loss_c: 4.635546684265137 avg_loss_a: -52.97351521459119\n",
            "Número de pasos del episodio 9296 son episode_steps:102\n",
            "Total Steps: 581331 Episode Num: 9296 Reward: 156.38659799412233 avg_loss_c: 4.529329007747126 avg_loss_a: -53.325298010134226\n",
            "Número de pasos del episodio 9297 son episode_steps:87\n",
            "Total Steps: 581418 Episode Num: 9297 Reward: 116.17514009891565 avg_loss_c: 4.28030433325932 avg_loss_a: -53.292734299582996\n",
            "Número de pasos del episodio 9298 son episode_steps:129\n",
            "Total Steps: 581547 Episode Num: 9298 Reward: 162.163778423334 avg_loss_c: 4.623073749764021 avg_loss_a: -53.67238412901413\n",
            "Número de pasos del episodio 9299 son episode_steps:130\n",
            "Total Steps: 581677 Episode Num: 9299 Reward: 213.2214927142361 avg_loss_c: 4.369329006855304 avg_loss_a: -53.816490642841046\n",
            "Número de pasos del episodio 9300 son episode_steps:153\n",
            "Total Steps: 581830 Episode Num: 9300 Reward: 219.6839480788015 avg_loss_c: 4.33942974159141 avg_loss_a: -53.907828860812714\n",
            "Número de pasos del episodio 9301 son episode_steps:71\n",
            "Total Steps: 581901 Episode Num: 9301 Reward: 99.77975163845434 avg_loss_c: 4.1035544435742874 avg_loss_a: -53.74273880434708\n",
            "Número de pasos del episodio 9302 son episode_steps:19\n",
            "Total Steps: 581920 Episode Num: 9302 Reward: -24.152365298511445 avg_loss_c: 4.467280927457307 avg_loss_a: -53.32149063913446\n",
            "Número de pasos del episodio 9303 son episode_steps:129\n",
            "Total Steps: 582049 Episode Num: 9303 Reward: 216.0078976713794 avg_loss_c: 4.478092919948489 avg_loss_a: -53.8467297517052\n",
            "Número de pasos del episodio 9304 son episode_steps:116\n",
            "Total Steps: 582165 Episode Num: 9304 Reward: 171.96122480534927 avg_loss_c: 4.0690327142847 avg_loss_a: -53.996604919433594\n",
            "Número de pasos del episodio 9305 son episode_steps:69\n",
            "Total Steps: 582234 Episode Num: 9305 Reward: 74.85200726648544 avg_loss_c: 4.625122332918471 avg_loss_a: -53.07416667108951\n",
            "Número de pasos del episodio 9306 son episode_steps:119\n",
            "Total Steps: 582353 Episode Num: 9306 Reward: 121.95738617194912 avg_loss_c: 4.6746448729218555 avg_loss_a: -53.575407813577094\n",
            "Número de pasos del episodio 9307 son episode_steps:71\n",
            "Total Steps: 582424 Episode Num: 9307 Reward: 102.74439712795974 avg_loss_c: 4.416187205784757 avg_loss_a: -54.406605250398876\n",
            "Número de pasos del episodio 9308 son episode_steps:82\n",
            "Total Steps: 582506 Episode Num: 9308 Reward: 63.35510810161759 avg_loss_c: 4.6647738770740785 avg_loss_a: -53.78527134220774\n",
            "Número de pasos del episodio 9309 son episode_steps:92\n",
            "Total Steps: 582598 Episode Num: 9309 Reward: 119.51011714252525 avg_loss_c: 4.934339142364005 avg_loss_a: -53.90401400690494\n",
            "Número de pasos del episodio 9310 son episode_steps:110\n",
            "Total Steps: 582708 Episode Num: 9310 Reward: 152.83203883064252 avg_loss_c: 4.870286826653914 avg_loss_a: -53.97753975608132\n",
            "Número de pasos del episodio 9311 son episode_steps:129\n",
            "Total Steps: 582837 Episode Num: 9311 Reward: 201.72049972176453 avg_loss_c: 4.466783412667208 avg_loss_a: -53.14494143345559\n",
            "Número de pasos del episodio 9312 son episode_steps:93\n",
            "Total Steps: 582930 Episode Num: 9312 Reward: 139.140919965886 avg_loss_c: 4.235720939533685 avg_loss_a: -53.853211597729754\n",
            "Número de pasos del episodio 9313 son episode_steps:136\n",
            "Total Steps: 583066 Episode Num: 9313 Reward: 235.03063008942607 avg_loss_c: 4.433907035519095 avg_loss_a: -53.92399097891415\n",
            "Número de pasos del episodio 9314 son episode_steps:92\n",
            "Total Steps: 583158 Episode Num: 9314 Reward: 138.75424743199608 avg_loss_c: 4.163124843784001 avg_loss_a: -53.79759315822435\n",
            "Número de pasos del episodio 9315 son episode_steps:107\n",
            "Total Steps: 583265 Episode Num: 9315 Reward: 179.88993694423763 avg_loss_c: 4.244930365375269 avg_loss_a: -54.3688069281177\n",
            "Número de pasos del episodio 9316 son episode_steps:148\n",
            "Total Steps: 583413 Episode Num: 9316 Reward: 250.2056397098035 avg_loss_c: 4.00629251873171 avg_loss_a: -54.30053257297825\n",
            "Número de pasos del episodio 9317 son episode_steps:45\n",
            "Total Steps: 583458 Episode Num: 9317 Reward: 18.691078551196597 avg_loss_c: 4.088322358661228 avg_loss_a: -54.076475355360245\n",
            "Número de pasos del episodio 9318 son episode_steps:126\n",
            "Total Steps: 583584 Episode Num: 9318 Reward: 199.82543565646733 avg_loss_c: 4.3386131714260765 avg_loss_a: -53.763035486614896\n",
            "Número de pasos del episodio 9319 son episode_steps:133\n",
            "Total Steps: 583717 Episode Num: 9319 Reward: 197.38906098578207 avg_loss_c: 4.298653738839286 avg_loss_a: -54.312303069838904\n",
            "Número de pasos del episodio 9320 son episode_steps:70\n",
            "Total Steps: 583787 Episode Num: 9320 Reward: 48.623947997354755 avg_loss_c: 4.159208829062326 avg_loss_a: -54.02085298810687\n",
            "Número de pasos del episodio 9321 son episode_steps:60\n",
            "Total Steps: 583847 Episode Num: 9321 Reward: 66.04825017156122 avg_loss_c: 4.177599970499674 avg_loss_a: -54.31147422790527\n",
            "Número de pasos del episodio 9322 son episode_steps:105\n",
            "Total Steps: 583952 Episode Num: 9322 Reward: 154.29051906156053 avg_loss_c: 4.513846526827131 avg_loss_a: -53.374917965843565\n",
            "Número de pasos del episodio 9323 son episode_steps:75\n",
            "Total Steps: 584027 Episode Num: 9323 Reward: 122.79785859478879 avg_loss_c: 4.572393980026245 avg_loss_a: -53.77996119181315\n",
            "Número de pasos del episodio 9324 son episode_steps:86\n",
            "Total Steps: 584113 Episode Num: 9324 Reward: 123.91802504987741 avg_loss_c: 4.31777498611184 avg_loss_a: -53.57025998137718\n",
            "Número de pasos del episodio 9325 son episode_steps:43\n",
            "Total Steps: 584156 Episode Num: 9325 Reward: 29.30005077841996 avg_loss_c: 4.566169256387755 avg_loss_a: -54.20109833118527\n",
            "Número de pasos del episodio 9326 son episode_steps:106\n",
            "Total Steps: 584262 Episode Num: 9326 Reward: 165.25146513155576 avg_loss_c: 4.736285879926862 avg_loss_a: -53.57599776645876\n",
            "Número de pasos del episodio 9327 son episode_steps:99\n",
            "Total Steps: 584361 Episode Num: 9327 Reward: 112.92054739761282 avg_loss_c: 4.8119314005880645 avg_loss_a: -53.388688058564156\n",
            "Número de pasos del episodio 9328 son episode_steps:161\n",
            "Total Steps: 584522 Episode Num: 9328 Reward: 254.30789787070466 avg_loss_c: 4.570457959027024 avg_loss_a: -53.48612997398613\n",
            "Número de pasos del episodio 9329 son episode_steps:98\n",
            "Total Steps: 584620 Episode Num: 9329 Reward: 122.0311030515814 avg_loss_c: 4.51747046441448 avg_loss_a: -53.67461527610312\n",
            "Número de pasos del episodio 9330 son episode_steps:67\n",
            "Total Steps: 584687 Episode Num: 9330 Reward: 103.14702991502278 avg_loss_c: 4.005308290026081 avg_loss_a: -54.038414912437325\n",
            "Número de pasos del episodio 9331 son episode_steps:87\n",
            "Total Steps: 584774 Episode Num: 9331 Reward: 139.9388486764475 avg_loss_c: 4.336027416689642 avg_loss_a: -53.87381454993938\n",
            "Número de pasos del episodio 9332 son episode_steps:95\n",
            "Total Steps: 584869 Episode Num: 9332 Reward: 138.6979414935492 avg_loss_c: 4.455427209954513 avg_loss_a: -53.405358123779294\n",
            "Número de pasos del episodio 9333 son episode_steps:81\n",
            "Total Steps: 584950 Episode Num: 9333 Reward: 111.10613320860101 avg_loss_c: 4.218494903894118 avg_loss_a: -53.89645738954897\n",
            "Número de pasos del episodio 9334 son episode_steps:109\n",
            "Total Steps: 585059 Episode Num: 9334 Reward: 181.99622051601966 avg_loss_c: 4.402800360950855 avg_loss_a: -53.80664601457228\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 165.104605\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9335 son episode_steps:88\n",
            "Total Steps: 585147 Episode Num: 9335 Reward: 122.03202368601232 avg_loss_c: 4.128698340871117 avg_loss_a: -53.04121242869984\n",
            "Número de pasos del episodio 9336 son episode_steps:97\n",
            "Total Steps: 585244 Episode Num: 9336 Reward: 142.76198807499696 avg_loss_c: 4.676184646862069 avg_loss_a: -53.84422534274072\n",
            "Número de pasos del episodio 9337 son episode_steps:130\n",
            "Total Steps: 585374 Episode Num: 9337 Reward: 220.3056157213078 avg_loss_c: 4.481109446745652 avg_loss_a: -53.7079093346229\n",
            "Número de pasos del episodio 9338 son episode_steps:60\n",
            "Total Steps: 585434 Episode Num: 9338 Reward: 5.363592023673626 avg_loss_c: 4.465044967333475 avg_loss_a: -53.322774251302086\n",
            "Número de pasos del episodio 9339 son episode_steps:78\n",
            "Total Steps: 585512 Episode Num: 9339 Reward: 85.46774579261748 avg_loss_c: 5.20605070468707 avg_loss_a: -54.29715836353791\n",
            "Número de pasos del episodio 9340 son episode_steps:59\n",
            "Total Steps: 585571 Episode Num: 9340 Reward: 18.02164971453577 avg_loss_c: 4.521888688459235 avg_loss_a: -53.9311861587783\n",
            "Número de pasos del episodio 9341 son episode_steps:64\n",
            "Total Steps: 585635 Episode Num: 9341 Reward: 79.12661317004245 avg_loss_c: 4.792082663625479 avg_loss_a: -52.95355701446533\n",
            "Número de pasos del episodio 9342 son episode_steps:71\n",
            "Total Steps: 585706 Episode Num: 9342 Reward: 102.31125452971875 avg_loss_c: 4.832906262975343 avg_loss_a: -52.804357233181804\n",
            "Número de pasos del episodio 9343 son episode_steps:76\n",
            "Total Steps: 585782 Episode Num: 9343 Reward: 102.72759396718237 avg_loss_c: 4.2980720526293705 avg_loss_a: -53.55959641306024\n",
            "Número de pasos del episodio 9344 son episode_steps:104\n",
            "Total Steps: 585886 Episode Num: 9344 Reward: 158.09570586956306 avg_loss_c: 4.623029610285392 avg_loss_a: -53.487817177405724\n",
            "Número de pasos del episodio 9345 son episode_steps:59\n",
            "Total Steps: 585945 Episode Num: 9345 Reward: 90.22322505123768 avg_loss_c: 4.30488842624729 avg_loss_a: -53.452956312793795\n",
            "Número de pasos del episodio 9346 son episode_steps:92\n",
            "Total Steps: 586037 Episode Num: 9346 Reward: 147.98311855083278 avg_loss_c: 4.135116548641868 avg_loss_a: -54.067453384399414\n",
            "Número de pasos del episodio 9347 son episode_steps:175\n",
            "Total Steps: 586212 Episode Num: 9347 Reward: 266.9363857086081 avg_loss_c: 4.753773275102888 avg_loss_a: -53.66206974574498\n",
            "Número de pasos del episodio 9348 son episode_steps:94\n",
            "Total Steps: 586306 Episode Num: 9348 Reward: 13.322738017728545 avg_loss_c: 5.4747566238362735 avg_loss_a: -53.65088507469664\n",
            "Número de pasos del episodio 9349 son episode_steps:40\n",
            "Total Steps: 586346 Episode Num: 9349 Reward: 19.335750989838097 avg_loss_c: 4.92723423242569 avg_loss_a: -53.966263389587404\n",
            "Número de pasos del episodio 9350 son episode_steps:180\n",
            "Total Steps: 586526 Episode Num: 9350 Reward: 312.7920291720752 avg_loss_c: 4.8720784929063585 avg_loss_a: -53.5846847958035\n",
            "Número de pasos del episodio 9351 son episode_steps:74\n",
            "Total Steps: 586600 Episode Num: 9351 Reward: 113.15216109911044 avg_loss_c: 4.444733149296528 avg_loss_a: -52.91219597893792\n",
            "Número de pasos del episodio 9352 son episode_steps:70\n",
            "Total Steps: 586670 Episode Num: 9352 Reward: 60.27259241851625 avg_loss_c: 4.30142811025892 avg_loss_a: -53.48181119646345\n",
            "Número de pasos del episodio 9353 son episode_steps:66\n",
            "Total Steps: 586736 Episode Num: 9353 Reward: 27.977220001809947 avg_loss_c: 4.293691996372107 avg_loss_a: -53.79791317564069\n",
            "Número de pasos del episodio 9354 son episode_steps:125\n",
            "Total Steps: 586861 Episode Num: 9354 Reward: 204.69789502390654 avg_loss_c: 4.72443508720398 avg_loss_a: -53.457572692871096\n",
            "Número de pasos del episodio 9355 son episode_steps:94\n",
            "Total Steps: 586955 Episode Num: 9355 Reward: 150.3483620001884 avg_loss_c: 4.847458327070195 avg_loss_a: -53.442704302199346\n",
            "Número de pasos del episodio 9356 son episode_steps:145\n",
            "Total Steps: 587100 Episode Num: 9356 Reward: 234.73030771813185 avg_loss_c: 4.568137540488408 avg_loss_a: -53.713084937786235\n",
            "Número de pasos del episodio 9357 son episode_steps:86\n",
            "Total Steps: 587186 Episode Num: 9357 Reward: 101.04828070013649 avg_loss_c: 4.729555659515913 avg_loss_a: -53.07718764903934\n",
            "Número de pasos del episodio 9358 son episode_steps:82\n",
            "Total Steps: 587268 Episode Num: 9358 Reward: 93.45883577630471 avg_loss_c: 4.4328911682454555 avg_loss_a: -53.75976218246832\n",
            "Número de pasos del episodio 9359 son episode_steps:157\n",
            "Total Steps: 587425 Episode Num: 9359 Reward: 130.48806443741577 avg_loss_c: 4.920752065196918 avg_loss_a: -53.87732271328094\n",
            "Número de pasos del episodio 9360 son episode_steps:133\n",
            "Total Steps: 587558 Episode Num: 9360 Reward: 140.1926793861945 avg_loss_c: 4.592964387477789 avg_loss_a: -53.14992738307867\n",
            "Número de pasos del episodio 9361 son episode_steps:123\n",
            "Total Steps: 587681 Episode Num: 9361 Reward: 186.98924833932165 avg_loss_c: 4.383336553728677 avg_loss_a: -53.428014150479946\n",
            "Número de pasos del episodio 9362 son episode_steps:99\n",
            "Total Steps: 587780 Episode Num: 9362 Reward: 149.45398342347647 avg_loss_c: 4.5131354115226054 avg_loss_a: -53.26684100218493\n",
            "Número de pasos del episodio 9363 son episode_steps:97\n",
            "Total Steps: 587877 Episode Num: 9363 Reward: 83.58066944502154 avg_loss_c: 4.5171333956964235 avg_loss_a: -53.137979173168695\n",
            "Número de pasos del episodio 9364 son episode_steps:127\n",
            "Total Steps: 588004 Episode Num: 9364 Reward: 207.15097742863054 avg_loss_c: 5.001968378157128 avg_loss_a: -53.475055964912954\n",
            "Número de pasos del episodio 9365 son episode_steps:92\n",
            "Total Steps: 588096 Episode Num: 9365 Reward: 131.53455047293733 avg_loss_c: 4.680027259432751 avg_loss_a: -53.30882288062054\n",
            "Número de pasos del episodio 9366 son episode_steps:140\n",
            "Total Steps: 588236 Episode Num: 9366 Reward: 197.43593430213434 avg_loss_c: 4.533733991214207 avg_loss_a: -52.91294779096331\n",
            "Número de pasos del episodio 9367 son episode_steps:72\n",
            "Total Steps: 588308 Episode Num: 9367 Reward: 115.18874016793657 avg_loss_c: 4.810473326179716 avg_loss_a: -52.842878871493866\n",
            "Número de pasos del episodio 9368 son episode_steps:168\n",
            "Total Steps: 588476 Episode Num: 9368 Reward: 270.9452704911937 avg_loss_c: 4.439336678811482 avg_loss_a: -53.293567157927015\n",
            "Número de pasos del episodio 9369 son episode_steps:96\n",
            "Total Steps: 588572 Episode Num: 9369 Reward: 129.23940063024642 avg_loss_c: 4.398721533517043 avg_loss_a: -53.61093751589457\n",
            "Número de pasos del episodio 9370 son episode_steps:95\n",
            "Total Steps: 588667 Episode Num: 9370 Reward: 138.5683884550623 avg_loss_c: 4.647898546018099 avg_loss_a: -53.69263679102848\n",
            "Número de pasos del episodio 9371 son episode_steps:88\n",
            "Total Steps: 588755 Episode Num: 9371 Reward: 113.38557193907336 avg_loss_c: 4.826321184635162 avg_loss_a: -52.81311191212047\n",
            "Número de pasos del episodio 9372 son episode_steps:91\n",
            "Total Steps: 588846 Episode Num: 9372 Reward: 133.65925426006692 avg_loss_c: 4.415534580146874 avg_loss_a: -53.348998436561\n",
            "Número de pasos del episodio 9373 son episode_steps:117\n",
            "Total Steps: 588963 Episode Num: 9373 Reward: 192.779234348181 avg_loss_c: 4.956067339986817 avg_loss_a: -53.20491366916232\n",
            "Número de pasos del episodio 9374 son episode_steps:87\n",
            "Total Steps: 589050 Episode Num: 9374 Reward: 119.27881987376236 avg_loss_c: 4.380547093248915 avg_loss_a: -52.50639080179149\n",
            "Número de pasos del episodio 9375 son episode_steps:50\n",
            "Total Steps: 589100 Episode Num: 9375 Reward: -13.874522025437752 avg_loss_c: 4.470533828735352 avg_loss_a: -52.994617004394534\n",
            "Número de pasos del episodio 9376 son episode_steps:40\n",
            "Total Steps: 589140 Episode Num: 9376 Reward: 11.978378619579686 avg_loss_c: 4.837818992137909 avg_loss_a: -52.953309059143066\n",
            "Número de pasos del episodio 9377 son episode_steps:119\n",
            "Total Steps: 589259 Episode Num: 9377 Reward: 203.89120243138393 avg_loss_c: 4.65519927329376 avg_loss_a: -52.77198749830743\n",
            "Número de pasos del episodio 9378 son episode_steps:129\n",
            "Total Steps: 589388 Episode Num: 9378 Reward: 198.7716738290572 avg_loss_c: 4.745466710985169 avg_loss_a: -52.81907062382661\n",
            "Número de pasos del episodio 9379 son episode_steps:82\n",
            "Total Steps: 589470 Episode Num: 9379 Reward: 113.74383032560057 avg_loss_c: 4.522554333617047 avg_loss_a: -52.691441326606565\n",
            "Número de pasos del episodio 9380 son episode_steps:167\n",
            "Total Steps: 589637 Episode Num: 9380 Reward: 247.02085547699738 avg_loss_c: 4.818973678314757 avg_loss_a: -52.815527065071514\n",
            "Número de pasos del episodio 9381 son episode_steps:63\n",
            "Total Steps: 589700 Episode Num: 9381 Reward: 66.89932053104124 avg_loss_c: 5.3726609585777165 avg_loss_a: -52.854647015768386\n",
            "Número de pasos del episodio 9382 son episode_steps:100\n",
            "Total Steps: 589800 Episode Num: 9382 Reward: 146.01692556225885 avg_loss_c: 5.0721033406257625 avg_loss_a: -52.800082244873046\n",
            "Número de pasos del episodio 9383 son episode_steps:132\n",
            "Total Steps: 589932 Episode Num: 9383 Reward: 192.3415703070765 avg_loss_c: 4.547918630368782 avg_loss_a: -53.22599260734789\n",
            "Número de pasos del episodio 9384 son episode_steps:87\n",
            "Total Steps: 590019 Episode Num: 9384 Reward: 131.89010139370004 avg_loss_c: 4.60062095488625 avg_loss_a: -53.17602780221522\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 145.361312\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9385 son episode_steps:83\n",
            "Total Steps: 590102 Episode Num: 9385 Reward: 87.34487009712983 avg_loss_c: 4.613043405923499 avg_loss_a: -52.927074018731176\n",
            "Número de pasos del episodio 9386 son episode_steps:101\n",
            "Total Steps: 590203 Episode Num: 9386 Reward: 132.1002595188284 avg_loss_c: 4.781295719713268 avg_loss_a: -52.31937314024066\n",
            "Número de pasos del episodio 9387 son episode_steps:75\n",
            "Total Steps: 590278 Episode Num: 9387 Reward: 114.23325103274946 avg_loss_c: 4.458764022191366 avg_loss_a: -52.53620162963867\n",
            "Número de pasos del episodio 9388 son episode_steps:44\n",
            "Total Steps: 590322 Episode Num: 9388 Reward: 22.900355047213527 avg_loss_c: 4.516716892069036 avg_loss_a: -53.00693321228027\n",
            "Número de pasos del episodio 9389 son episode_steps:79\n",
            "Total Steps: 590401 Episode Num: 9389 Reward: 128.455137651301 avg_loss_c: 5.385197461405887 avg_loss_a: -52.492079722730416\n",
            "Número de pasos del episodio 9390 son episode_steps:73\n",
            "Total Steps: 590474 Episode Num: 9390 Reward: 76.80918559948816 avg_loss_c: 4.449136315959773 avg_loss_a: -53.15459896766976\n",
            "Número de pasos del episodio 9391 son episode_steps:87\n",
            "Total Steps: 590561 Episode Num: 9391 Reward: 35.624481079143 avg_loss_c: 5.466065201266058 avg_loss_a: -52.424027059270045\n",
            "Número de pasos del episodio 9392 son episode_steps:130\n",
            "Total Steps: 590691 Episode Num: 9392 Reward: 217.64383820295672 avg_loss_c: 4.933391328958365 avg_loss_a: -52.63529539841872\n",
            "Número de pasos del episodio 9393 son episode_steps:90\n",
            "Total Steps: 590781 Episode Num: 9393 Reward: 143.53032454771642 avg_loss_c: 4.868109938833449 avg_loss_a: -52.066977183024086\n",
            "Número de pasos del episodio 9394 son episode_steps:61\n",
            "Total Steps: 590842 Episode Num: 9394 Reward: 45.20454588648439 avg_loss_c: 5.350072012572992 avg_loss_a: -52.297277606901574\n",
            "Número de pasos del episodio 9395 son episode_steps:93\n",
            "Total Steps: 590935 Episode Num: 9395 Reward: 139.20353070723246 avg_loss_c: 4.648769537607829 avg_loss_a: -52.673101609753026\n",
            "Número de pasos del episodio 9396 son episode_steps:151\n",
            "Total Steps: 591086 Episode Num: 9396 Reward: 228.79497078965085 avg_loss_c: 4.6033360531788 avg_loss_a: -52.586064648154554\n",
            "Número de pasos del episodio 9397 son episode_steps:121\n",
            "Total Steps: 591207 Episode Num: 9397 Reward: 199.16006379087304 avg_loss_c: 4.858028796093523 avg_loss_a: -52.425793198514576\n",
            "Número de pasos del episodio 9398 son episode_steps:145\n",
            "Total Steps: 591352 Episode Num: 9398 Reward: 248.71816345279635 avg_loss_c: 4.554497894747504 avg_loss_a: -52.74141556312298\n",
            "Número de pasos del episodio 9399 son episode_steps:122\n",
            "Total Steps: 591474 Episode Num: 9399 Reward: 197.81940958041383 avg_loss_c: 4.700011954932917 avg_loss_a: -53.15846859040808\n",
            "Número de pasos del episodio 9400 son episode_steps:48\n",
            "Total Steps: 591522 Episode Num: 9400 Reward: 58.73177826871 avg_loss_c: 5.4897686292727785 avg_loss_a: -52.56516249974569\n",
            "Número de pasos del episodio 9401 son episode_steps:98\n",
            "Total Steps: 591620 Episode Num: 9401 Reward: 98.33974629256616 avg_loss_c: 4.6659175717100805 avg_loss_a: -52.47182721507792\n",
            "Número de pasos del episodio 9402 son episode_steps:61\n",
            "Total Steps: 591681 Episode Num: 9402 Reward: 83.1151007976176 avg_loss_c: 4.906409118996292 avg_loss_a: -52.29552903722544\n",
            "Número de pasos del episodio 9403 son episode_steps:49\n",
            "Total Steps: 591730 Episode Num: 9403 Reward: 25.807971395962223 avg_loss_c: 5.302631086232711 avg_loss_a: -51.388014812858735\n",
            "Número de pasos del episodio 9404 son episode_steps:103\n",
            "Total Steps: 591833 Episode Num: 9404 Reward: 173.15340475451842 avg_loss_c: 4.804224729537964 avg_loss_a: -52.17256157143602\n",
            "Número de pasos del episodio 9405 son episode_steps:136\n",
            "Total Steps: 591969 Episode Num: 9405 Reward: 216.0924604734169 avg_loss_c: 4.736012271221946 avg_loss_a: -52.3195904563455\n",
            "Número de pasos del episodio 9406 son episode_steps:104\n",
            "Total Steps: 592073 Episode Num: 9406 Reward: 159.7815004713813 avg_loss_c: 4.638196255152042 avg_loss_a: -52.35631737342248\n",
            "Número de pasos del episodio 9407 son episode_steps:84\n",
            "Total Steps: 592157 Episode Num: 9407 Reward: 119.67437165946612 avg_loss_c: 5.020849594048092 avg_loss_a: -52.84760039193289\n",
            "Número de pasos del episodio 9408 son episode_steps:118\n",
            "Total Steps: 592275 Episode Num: 9408 Reward: 152.23489300241573 avg_loss_c: 4.844920592792963 avg_loss_a: -52.03886976080426\n",
            "Número de pasos del episodio 9409 son episode_steps:90\n",
            "Total Steps: 592365 Episode Num: 9409 Reward: 141.27052231695734 avg_loss_c: 4.842095179027981 avg_loss_a: -51.450675031873914\n",
            "Número de pasos del episodio 9410 son episode_steps:135\n",
            "Total Steps: 592500 Episode Num: 9410 Reward: 217.13688920104366 avg_loss_c: 4.647844173290111 avg_loss_a: -52.78126576741536\n",
            "Número de pasos del episodio 9411 son episode_steps:50\n",
            "Total Steps: 592550 Episode Num: 9411 Reward: 20.056450112849685 avg_loss_c: 5.102699728012085 avg_loss_a: -52.665594329833986\n",
            "Número de pasos del episodio 9412 son episode_steps:139\n",
            "Total Steps: 592689 Episode Num: 9412 Reward: 234.8736939321355 avg_loss_c: 5.007667345966366 avg_loss_a: -52.57883071899414\n",
            "Número de pasos del episodio 9413 son episode_steps:102\n",
            "Total Steps: 592791 Episode Num: 9413 Reward: 155.97950576089784 avg_loss_c: 4.546685866281098 avg_loss_a: -52.80687825820025\n",
            "Número de pasos del episodio 9414 son episode_steps:128\n",
            "Total Steps: 592919 Episode Num: 9414 Reward: 224.08119740436777 avg_loss_c: 4.870204558596015 avg_loss_a: -52.266104221343994\n",
            "Número de pasos del episodio 9415 son episode_steps:113\n",
            "Total Steps: 593032 Episode Num: 9415 Reward: 168.6747798800469 avg_loss_c: 4.481952580730472 avg_loss_a: -52.24877828412351\n",
            "Número de pasos del episodio 9416 son episode_steps:148\n",
            "Total Steps: 593180 Episode Num: 9416 Reward: 247.11810682617102 avg_loss_c: 5.136765678186674 avg_loss_a: -52.36552449819204\n",
            "Número de pasos del episodio 9417 son episode_steps:107\n",
            "Total Steps: 593287 Episode Num: 9417 Reward: 167.0715367791657 avg_loss_c: 4.769583599589695 avg_loss_a: -52.707659070736895\n",
            "Número de pasos del episodio 9418 son episode_steps:154\n",
            "Total Steps: 593441 Episode Num: 9418 Reward: 256.7749500068176 avg_loss_c: 4.772657118834458 avg_loss_a: -52.13442468023919\n",
            "Número de pasos del episodio 9419 son episode_steps:93\n",
            "Total Steps: 593534 Episode Num: 9419 Reward: 124.8826743789673 avg_loss_c: 4.801514089748424 avg_loss_a: -51.715887008174775\n",
            "Número de pasos del episodio 9420 son episode_steps:158\n",
            "Total Steps: 593692 Episode Num: 9420 Reward: 225.23978925152986 avg_loss_c: 4.884314653239673 avg_loss_a: -52.900162370899054\n",
            "Número de pasos del episodio 9421 son episode_steps:125\n",
            "Total Steps: 593817 Episode Num: 9421 Reward: 197.34905152132114 avg_loss_c: 5.065796783447266 avg_loss_a: -52.220463439941405\n",
            "Número de pasos del episodio 9422 son episode_steps:259\n",
            "Total Steps: 594076 Episode Num: 9422 Reward: 378.7627001142782 avg_loss_c: 5.009498970849173 avg_loss_a: -52.53622966751629\n",
            "Número de pasos del episodio 9423 son episode_steps:118\n",
            "Total Steps: 594194 Episode Num: 9423 Reward: 196.94424930104546 avg_loss_c: 4.6739456694004895 avg_loss_a: -52.50532745102704\n",
            "Número de pasos del episodio 9424 son episode_steps:98\n",
            "Total Steps: 594292 Episode Num: 9424 Reward: 159.95254346775283 avg_loss_c: 4.89312341991736 avg_loss_a: -52.26770011746154\n",
            "Número de pasos del episodio 9425 son episode_steps:112\n",
            "Total Steps: 594404 Episode Num: 9425 Reward: 178.39384325684316 avg_loss_c: 4.733659441981997 avg_loss_a: -52.656404222760884\n",
            "Número de pasos del episodio 9426 son episode_steps:147\n",
            "Total Steps: 594551 Episode Num: 9426 Reward: 139.97362142096694 avg_loss_c: 4.6666515619576385 avg_loss_a: -52.821292539843085\n",
            "Número de pasos del episodio 9427 son episode_steps:135\n",
            "Total Steps: 594686 Episode Num: 9427 Reward: 211.72029932481502 avg_loss_c: 4.708450750068382 avg_loss_a: -52.69713230839482\n",
            "Número de pasos del episodio 9428 son episode_steps:116\n",
            "Total Steps: 594802 Episode Num: 9428 Reward: 177.27814141970165 avg_loss_c: 4.752524867140013 avg_loss_a: -52.60587619913036\n",
            "Número de pasos del episodio 9429 son episode_steps:135\n",
            "Total Steps: 594937 Episode Num: 9429 Reward: 207.39451910571503 avg_loss_c: 4.81004149472272 avg_loss_a: -52.27901243986907\n",
            "Número de pasos del episodio 9430 son episode_steps:144\n",
            "Total Steps: 595081 Episode Num: 9430 Reward: 187.7790038492395 avg_loss_c: 4.798781668146451 avg_loss_a: -52.083691385057236\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 179.591084\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9431 son episode_steps:197\n",
            "Total Steps: 595278 Episode Num: 9431 Reward: 326.84668370982484 avg_loss_c: 4.8287557248536706 avg_loss_a: -52.14807942191961\n",
            "Número de pasos del episodio 9432 son episode_steps:211\n",
            "Total Steps: 595489 Episode Num: 9432 Reward: 344.234552221722 avg_loss_c: 4.686566221770517 avg_loss_a: -52.18551022859546\n",
            "Número de pasos del episodio 9433 son episode_steps:64\n",
            "Total Steps: 595553 Episode Num: 9433 Reward: 82.47225139798854 avg_loss_c: 4.702588114887476 avg_loss_a: -52.70020854473114\n",
            "Número de pasos del episodio 9434 son episode_steps:125\n",
            "Total Steps: 595678 Episode Num: 9434 Reward: 134.34798478585242 avg_loss_c: 4.729317865371704 avg_loss_a: -51.98031921386719\n",
            "Número de pasos del episodio 9435 son episode_steps:116\n",
            "Total Steps: 595794 Episode Num: 9435 Reward: 187.55983163136506 avg_loss_c: 4.76916584475287 avg_loss_a: -52.20385867151721\n",
            "Número de pasos del episodio 9436 son episode_steps:75\n",
            "Total Steps: 595869 Episode Num: 9436 Reward: 119.54601381232861 avg_loss_c: 4.444592679341634 avg_loss_a: -52.02944468180338\n",
            "Número de pasos del episodio 9437 son episode_steps:149\n",
            "Total Steps: 596018 Episode Num: 9437 Reward: 227.2431724038494 avg_loss_c: 4.686378208582833 avg_loss_a: -52.66894751427158\n",
            "Número de pasos del episodio 9438 son episode_steps:184\n",
            "Total Steps: 596202 Episode Num: 9438 Reward: 328.16561501320075 avg_loss_c: 4.587785601615906 avg_loss_a: -52.77089861164922\n",
            "Número de pasos del episodio 9439 son episode_steps:93\n",
            "Total Steps: 596295 Episode Num: 9439 Reward: 62.45664655728289 avg_loss_c: 4.563265133929509 avg_loss_a: -52.374930597120716\n",
            "Número de pasos del episodio 9440 son episode_steps:90\n",
            "Total Steps: 596385 Episode Num: 9440 Reward: 134.21134798002404 avg_loss_c: 4.706495963202583 avg_loss_a: -52.6710816277398\n",
            "Número de pasos del episodio 9441 son episode_steps:83\n",
            "Total Steps: 596468 Episode Num: 9441 Reward: 122.81123595769013 avg_loss_c: 4.755447180874376 avg_loss_a: -53.28182339955525\n",
            "Número de pasos del episodio 9442 son episode_steps:119\n",
            "Total Steps: 596587 Episode Num: 9442 Reward: 189.29674330530386 avg_loss_c: 4.80981132363071 avg_loss_a: -51.81455336498613\n",
            "Número de pasos del episodio 9443 son episode_steps:157\n",
            "Total Steps: 596744 Episode Num: 9443 Reward: 270.2127161462872 avg_loss_c: 4.455367967581293 avg_loss_a: -52.10968471940156\n",
            "Número de pasos del episodio 9444 son episode_steps:79\n",
            "Total Steps: 596823 Episode Num: 9444 Reward: 119.04439608432054 avg_loss_c: 4.342641326445568 avg_loss_a: -52.94511273541028\n",
            "Número de pasos del episodio 9445 son episode_steps:79\n",
            "Total Steps: 596902 Episode Num: 9445 Reward: 37.234559861973 avg_loss_c: 4.58819122254094 avg_loss_a: -52.87905014617534\n",
            "Número de pasos del episodio 9446 son episode_steps:271\n",
            "Total Steps: 597173 Episode Num: 9446 Reward: 442.10668377110113 avg_loss_c: 4.557081792627313 avg_loss_a: -52.96350369330262\n",
            "Número de pasos del episodio 9447 son episode_steps:154\n",
            "Total Steps: 597327 Episode Num: 9447 Reward: 220.37517692618002 avg_loss_c: 4.847489038071075 avg_loss_a: -52.99486214773996\n",
            "Número de pasos del episodio 9448 son episode_steps:124\n",
            "Total Steps: 597451 Episode Num: 9448 Reward: 201.40532516506786 avg_loss_c: 4.9095376287737205 avg_loss_a: -52.638445577313824\n",
            "Número de pasos del episodio 9449 son episode_steps:88\n",
            "Total Steps: 597539 Episode Num: 9449 Reward: 136.15628769449427 avg_loss_c: 4.6906454048373485 avg_loss_a: -53.15005111694336\n",
            "Número de pasos del episodio 9450 son episode_steps:160\n",
            "Total Steps: 597699 Episode Num: 9450 Reward: 250.94681811561145 avg_loss_c: 4.688749970495701 avg_loss_a: -52.887100315093996\n",
            "Número de pasos del episodio 9451 son episode_steps:152\n",
            "Total Steps: 597851 Episode Num: 9451 Reward: 247.29891206449625 avg_loss_c: 4.525521027414422 avg_loss_a: -53.39263002496017\n",
            "Número de pasos del episodio 9452 son episode_steps:261\n",
            "Total Steps: 598112 Episode Num: 9452 Reward: 417.5267140918272 avg_loss_c: 4.610411060267482 avg_loss_a: -53.47141203021638\n",
            "Número de pasos del episodio 9453 son episode_steps:96\n",
            "Total Steps: 598208 Episode Num: 9453 Reward: 134.38398965178527 avg_loss_c: 4.513866499066353 avg_loss_a: -53.45729684829712\n",
            "Número de pasos del episodio 9454 son episode_steps:130\n",
            "Total Steps: 598338 Episode Num: 9454 Reward: 166.77960690075855 avg_loss_c: 4.52998313170213 avg_loss_a: -53.20404516366812\n",
            "Número de pasos del episodio 9455 son episode_steps:119\n",
            "Total Steps: 598457 Episode Num: 9455 Reward: 179.88027641077528 avg_loss_c: 4.4344499992723225 avg_loss_a: -53.73039954049246\n",
            "Número de pasos del episodio 9456 son episode_steps:167\n",
            "Total Steps: 598624 Episode Num: 9456 Reward: 259.86974646778395 avg_loss_c: 4.357707875931334 avg_loss_a: -53.16763006427331\n",
            "Número de pasos del episodio 9457 son episode_steps:156\n",
            "Total Steps: 598780 Episode Num: 9457 Reward: 249.3413598746551 avg_loss_c: 4.372526885607304 avg_loss_a: -53.56918085538424\n",
            "Número de pasos del episodio 9458 son episode_steps:52\n",
            "Total Steps: 598832 Episode Num: 9458 Reward: 34.903931064515 avg_loss_c: 4.922910309754885 avg_loss_a: -53.24454953120305\n",
            "Número de pasos del episodio 9459 son episode_steps:190\n",
            "Total Steps: 599022 Episode Num: 9459 Reward: 314.76329298442744 avg_loss_c: 4.460120109507912 avg_loss_a: -53.716039918598376\n",
            "Número de pasos del episodio 9460 son episode_steps:54\n",
            "Total Steps: 599076 Episode Num: 9460 Reward: 68.15875345464866 avg_loss_c: 4.6513711523126675 avg_loss_a: -53.205410427517364\n",
            "Número de pasos del episodio 9461 son episode_steps:119\n",
            "Total Steps: 599195 Episode Num: 9461 Reward: 195.16006999786623 avg_loss_c: 4.546076403946436 avg_loss_a: -53.54698671613421\n",
            "Número de pasos del episodio 9462 son episode_steps:138\n",
            "Total Steps: 599333 Episode Num: 9462 Reward: 199.18248418593575 avg_loss_c: 4.628963415173517 avg_loss_a: -53.946484275486156\n",
            "Número de pasos del episodio 9463 son episode_steps:175\n",
            "Total Steps: 599508 Episode Num: 9463 Reward: 226.59092318712678 avg_loss_c: 4.5829429490225655 avg_loss_a: -53.739625047956196\n",
            "Número de pasos del episodio 9464 son episode_steps:200\n",
            "Total Steps: 599708 Episode Num: 9464 Reward: 292.830258468329 avg_loss_c: 4.328473734855652 avg_loss_a: -54.10535312652588\n",
            "Número de pasos del episodio 9465 son episode_steps:118\n",
            "Total Steps: 599826 Episode Num: 9465 Reward: 180.47763058956056 avg_loss_c: 4.226412413483959 avg_loss_a: -54.347263271525755\n",
            "Número de pasos del episodio 9466 son episode_steps:51\n",
            "Total Steps: 599877 Episode Num: 9466 Reward: 35.84220904217914 avg_loss_c: 4.524346800411449 avg_loss_a: -53.27557560041839\n",
            "Número de pasos del episodio 9467 son episode_steps:88\n",
            "Total Steps: 599965 Episode Num: 9467 Reward: 130.3886407582467 avg_loss_c: 4.278831289573149 avg_loss_a: -54.53502585671165\n",
            "Número de pasos del episodio 9468 son episode_steps:101\n",
            "Total Steps: 600066 Episode Num: 9468 Reward: 154.17614993034093 avg_loss_c: 4.595098807079958 avg_loss_a: -55.12834798227443\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 213.558677\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9469 son episode_steps:184\n",
            "Total Steps: 600250 Episode Num: 9469 Reward: 252.29855626764265 avg_loss_c: 4.418619320444439 avg_loss_a: -54.13735111899998\n",
            "Número de pasos del episodio 9470 son episode_steps:133\n",
            "Total Steps: 600383 Episode Num: 9470 Reward: 225.95371360465927 avg_loss_c: 4.4538466302972095 avg_loss_a: -54.6670776596643\n",
            "Número de pasos del episodio 9471 son episode_steps:48\n",
            "Total Steps: 600431 Episode Num: 9471 Reward: 6.486882818207782 avg_loss_c: 4.509565015633901 avg_loss_a: -54.38827912012736\n",
            "Número de pasos del episodio 9472 son episode_steps:153\n",
            "Total Steps: 600584 Episode Num: 9472 Reward: 199.55801467945503 avg_loss_c: 4.453855941498202 avg_loss_a: -54.54161141588797\n",
            "Número de pasos del episodio 9473 son episode_steps:178\n",
            "Total Steps: 600762 Episode Num: 9473 Reward: 269.12495134795074 avg_loss_c: 4.890572026874242 avg_loss_a: -54.89340968614214\n",
            "Número de pasos del episodio 9474 son episode_steps:137\n",
            "Total Steps: 600899 Episode Num: 9474 Reward: 186.23102001372632 avg_loss_c: 4.7975487204363745 avg_loss_a: -54.45067679969063\n",
            "Número de pasos del episodio 9475 son episode_steps:134\n",
            "Total Steps: 601033 Episode Num: 9475 Reward: 221.01665350685124 avg_loss_c: 4.545703647741631 avg_loss_a: -54.71380068650886\n",
            "Número de pasos del episodio 9476 son episode_steps:132\n",
            "Total Steps: 601165 Episode Num: 9476 Reward: 101.41797120378145 avg_loss_c: 4.56605719797539 avg_loss_a: -54.508666067412406\n",
            "Número de pasos del episodio 9477 son episode_steps:141\n",
            "Total Steps: 601306 Episode Num: 9477 Reward: 208.6326107780707 avg_loss_c: 4.931262021369123 avg_loss_a: -54.691444938064464\n",
            "Número de pasos del episodio 9478 son episode_steps:19\n",
            "Total Steps: 601325 Episode Num: 9478 Reward: -22.808348575784848 avg_loss_c: 5.458447167747899 avg_loss_a: -54.86573209260639\n",
            "Número de pasos del episodio 9479 son episode_steps:126\n",
            "Total Steps: 601451 Episode Num: 9479 Reward: 172.70553290173555 avg_loss_c: 4.992606166809324 avg_loss_a: -54.74683585999504\n",
            "Número de pasos del episodio 9480 son episode_steps:285\n",
            "Total Steps: 601736 Episode Num: 9480 Reward: 453.1868414963998 avg_loss_c: 4.653995354970296 avg_loss_a: -54.24263301648592\n",
            "Número de pasos del episodio 9481 son episode_steps:178\n",
            "Total Steps: 601914 Episode Num: 9481 Reward: 218.50582753400306 avg_loss_c: 5.063897399420149 avg_loss_a: -54.96983003080561\n",
            "Número de pasos del episodio 9482 son episode_steps:147\n",
            "Total Steps: 602061 Episode Num: 9482 Reward: 210.40999096123807 avg_loss_c: 4.80228599561315 avg_loss_a: -54.67756987591179\n",
            "Número de pasos del episodio 9483 son episode_steps:170\n",
            "Total Steps: 602231 Episode Num: 9483 Reward: 231.72424620890405 avg_loss_c: 4.850158931227291 avg_loss_a: -54.61256978652057\n",
            "Número de pasos del episodio 9484 son episode_steps:88\n",
            "Total Steps: 602319 Episode Num: 9484 Reward: 113.61039289804049 avg_loss_c: 5.4643126563592395 avg_loss_a: -55.27554269270463\n",
            "Número de pasos del episodio 9485 son episode_steps:95\n",
            "Total Steps: 602414 Episode Num: 9485 Reward: 137.72876337274656 avg_loss_c: 5.3982811551345025 avg_loss_a: -54.83998071770919\n",
            "Número de pasos del episodio 9486 son episode_steps:205\n",
            "Total Steps: 602619 Episode Num: 9486 Reward: 334.2604639852877 avg_loss_c: 5.34676911423846 avg_loss_a: -55.13941985339653\n",
            "Número de pasos del episodio 9487 son episode_steps:193\n",
            "Total Steps: 602812 Episode Num: 9487 Reward: 298.57605457775406 avg_loss_c: 4.61076595252042 avg_loss_a: -55.085999207175455\n",
            "Número de pasos del episodio 9488 son episode_steps:131\n",
            "Total Steps: 602943 Episode Num: 9488 Reward: 208.90449472417842 avg_loss_c: 4.457673691611253 avg_loss_a: -55.15337371826172\n",
            "Número de pasos del episodio 9489 son episode_steps:176\n",
            "Total Steps: 603119 Episode Num: 9489 Reward: 266.6753164045854 avg_loss_c: 5.0607705482027745 avg_loss_a: -55.05704277211969\n",
            "Número de pasos del episodio 9490 son episode_steps:166\n",
            "Total Steps: 603285 Episode Num: 9490 Reward: 84.28434796140168 avg_loss_c: 4.650568802672696 avg_loss_a: -55.70750303153532\n",
            "Número de pasos del episodio 9491 son episode_steps:113\n",
            "Total Steps: 603398 Episode Num: 9491 Reward: 172.29295546741596 avg_loss_c: 4.688712691838762 avg_loss_a: -55.35514507462493\n",
            "Número de pasos del episodio 9492 son episode_steps:48\n",
            "Total Steps: 603446 Episode Num: 9492 Reward: 29.15022190787662 avg_loss_c: 5.873006701469421 avg_loss_a: -55.84071683883667\n",
            "Número de pasos del episodio 9493 son episode_steps:170\n",
            "Total Steps: 603616 Episode Num: 9493 Reward: 261.5402586703422 avg_loss_c: 4.933693591286154 avg_loss_a: -55.13403679342831\n",
            "Número de pasos del episodio 9494 son episode_steps:114\n",
            "Total Steps: 603730 Episode Num: 9494 Reward: 143.70920405143144 avg_loss_c: 4.339158334230122 avg_loss_a: -55.754850688733555\n",
            "Número de pasos del episodio 9495 son episode_steps:94\n",
            "Total Steps: 603824 Episode Num: 9495 Reward: 94.26587334590951 avg_loss_c: 4.794484952662853 avg_loss_a: -55.841475385300654\n",
            "Número de pasos del episodio 9496 son episode_steps:60\n",
            "Total Steps: 603884 Episode Num: 9496 Reward: 76.71992955167464 avg_loss_c: 4.290400699774424 avg_loss_a: -55.95202356974284\n",
            "Número de pasos del episodio 9497 son episode_steps:90\n",
            "Total Steps: 603974 Episode Num: 9497 Reward: 133.89326138606015 avg_loss_c: 4.540455595652262 avg_loss_a: -55.531683349609374\n",
            "Número de pasos del episodio 9498 son episode_steps:145\n",
            "Total Steps: 604119 Episode Num: 9498 Reward: 228.23936767430223 avg_loss_c: 4.552289305062129 avg_loss_a: -55.78605807074185\n",
            "Número de pasos del episodio 9499 son episode_steps:106\n",
            "Total Steps: 604225 Episode Num: 9499 Reward: 151.4435727265884 avg_loss_c: 4.661991504003417 avg_loss_a: -55.441814998410784\n",
            "Número de pasos del episodio 9500 son episode_steps:122\n",
            "Total Steps: 604347 Episode Num: 9500 Reward: 151.56855089525362 avg_loss_c: 4.7075714595982285 avg_loss_a: -55.58388556808722\n",
            "Número de pasos del episodio 9501 son episode_steps:147\n",
            "Total Steps: 604494 Episode Num: 9501 Reward: 223.629009561665 avg_loss_c: 4.601637524001452 avg_loss_a: -55.55708896870516\n",
            "Número de pasos del episodio 9502 son episode_steps:167\n",
            "Total Steps: 604661 Episode Num: 9502 Reward: 249.9422901753712 avg_loss_c: 4.680167515120821 avg_loss_a: -56.22828952994889\n",
            "Número de pasos del episodio 9503 son episode_steps:93\n",
            "Total Steps: 604754 Episode Num: 9503 Reward: 135.8372125595458 avg_loss_c: 4.828170209802607 avg_loss_a: -55.6859502894904\n",
            "Número de pasos del episodio 9504 son episode_steps:127\n",
            "Total Steps: 604881 Episode Num: 9504 Reward: 62.66615608843146 avg_loss_c: 4.516311745005329 avg_loss_a: -55.897847333292326\n",
            "Número de pasos del episodio 9505 son episode_steps:105\n",
            "Total Steps: 604986 Episode Num: 9505 Reward: 95.65248885263786 avg_loss_c: 4.897338687805902 avg_loss_a: -55.538948386056084\n",
            "Número de pasos del episodio 9506 son episode_steps:144\n",
            "Total Steps: 605130 Episode Num: 9506 Reward: 213.208482087942 avg_loss_c: 5.178064306577046 avg_loss_a: -55.748336897956\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 145.362722\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9507 son episode_steps:190\n",
            "Total Steps: 605320 Episode Num: 9507 Reward: 304.387313114858 avg_loss_c: 4.6369686302385835 avg_loss_a: -55.868687760202505\n",
            "Número de pasos del episodio 9508 son episode_steps:131\n",
            "Total Steps: 605451 Episode Num: 9508 Reward: 191.70916594635668 avg_loss_c: 4.316142651870961 avg_loss_a: -56.64232422923314\n",
            "Número de pasos del episodio 9509 son episode_steps:199\n",
            "Total Steps: 605650 Episode Num: 9509 Reward: 295.2806750587009 avg_loss_c: 4.341135510248155 avg_loss_a: -56.489309147973756\n",
            "Número de pasos del episodio 9510 son episode_steps:175\n",
            "Total Steps: 605825 Episode Num: 9510 Reward: 284.61035842902595 avg_loss_c: 4.444880841118949 avg_loss_a: -56.87414570399693\n",
            "Número de pasos del episodio 9511 son episode_steps:126\n",
            "Total Steps: 605951 Episode Num: 9511 Reward: 206.65798449232955 avg_loss_c: 4.376408488031418 avg_loss_a: -57.410433269682386\n",
            "Número de pasos del episodio 9512 son episode_steps:126\n",
            "Total Steps: 606077 Episode Num: 9512 Reward: 158.36314954086612 avg_loss_c: 4.254697803467039 avg_loss_a: -56.694064306834385\n",
            "Número de pasos del episodio 9513 son episode_steps:120\n",
            "Total Steps: 606197 Episode Num: 9513 Reward: 186.1567167711037 avg_loss_c: 4.205794095993042 avg_loss_a: -57.20868771870931\n",
            "Número de pasos del episodio 9514 son episode_steps:106\n",
            "Total Steps: 606303 Episode Num: 9514 Reward: 149.689344206519 avg_loss_c: 4.478934652400467 avg_loss_a: -56.922429858513595\n",
            "Número de pasos del episodio 9515 son episode_steps:180\n",
            "Total Steps: 606483 Episode Num: 9515 Reward: 282.8240027966963 avg_loss_c: 4.211582273907132 avg_loss_a: -56.580147722032336\n",
            "Número de pasos del episodio 9516 son episode_steps:107\n",
            "Total Steps: 606590 Episode Num: 9516 Reward: 160.9892871740002 avg_loss_c: 4.49332457390901 avg_loss_a: -56.31005813028211\n",
            "Número de pasos del episodio 9517 son episode_steps:126\n",
            "Total Steps: 606716 Episode Num: 9517 Reward: 191.3152857525503 avg_loss_c: 4.082877692722139 avg_loss_a: -56.88070612105112\n",
            "Número de pasos del episodio 9518 son episode_steps:100\n",
            "Total Steps: 606816 Episode Num: 9518 Reward: 145.7474710164097 avg_loss_c: 4.5838597917556765 avg_loss_a: -57.18962532043457\n",
            "Número de pasos del episodio 9519 son episode_steps:161\n",
            "Total Steps: 606977 Episode Num: 9519 Reward: 257.42283000377813 avg_loss_c: 4.2418360887847335 avg_loss_a: -57.210168494941286\n",
            "Número de pasos del episodio 9520 son episode_steps:186\n",
            "Total Steps: 607163 Episode Num: 9520 Reward: 286.9965409498198 avg_loss_c: 4.320405934446601 avg_loss_a: -57.5064326050461\n",
            "Número de pasos del episodio 9521 son episode_steps:74\n",
            "Total Steps: 607237 Episode Num: 9521 Reward: 76.23911386651147 avg_loss_c: 4.182499360393834 avg_loss_a: -57.31134342502903\n",
            "Número de pasos del episodio 9522 son episode_steps:126\n",
            "Total Steps: 607363 Episode Num: 9522 Reward: 186.01232119334114 avg_loss_c: 4.267594146350073 avg_loss_a: -57.16729760548425\n",
            "Número de pasos del episodio 9523 son episode_steps:143\n",
            "Total Steps: 607506 Episode Num: 9523 Reward: 223.01806565813868 avg_loss_c: 4.410172999321998 avg_loss_a: -57.57111433335951\n",
            "Número de pasos del episodio 9524 son episode_steps:120\n",
            "Total Steps: 607626 Episode Num: 9524 Reward: 170.04456717549064 avg_loss_c: 4.2358955403169 avg_loss_a: -57.1783873240153\n",
            "Número de pasos del episodio 9525 son episode_steps:101\n",
            "Total Steps: 607727 Episode Num: 9525 Reward: 150.60376718302524 avg_loss_c: 4.128174703900177 avg_loss_a: -57.75583335196618\n",
            "Número de pasos del episodio 9526 son episode_steps:106\n",
            "Total Steps: 607833 Episode Num: 9526 Reward: 143.87748025004817 avg_loss_c: 4.0613273787048625 avg_loss_a: -57.42051919901146\n",
            "Número de pasos del episodio 9527 son episode_steps:86\n",
            "Total Steps: 607919 Episode Num: 9527 Reward: 123.56801177767227 avg_loss_c: 4.327631556710531 avg_loss_a: -57.7812684524891\n",
            "Número de pasos del episodio 9528 son episode_steps:171\n",
            "Total Steps: 608090 Episode Num: 9528 Reward: 255.78075862663445 avg_loss_c: 4.1457869309430935 avg_loss_a: -57.582578870985245\n",
            "Número de pasos del episodio 9529 son episode_steps:165\n",
            "Total Steps: 608255 Episode Num: 9529 Reward: 238.9270128866716 avg_loss_c: 4.459735761989247 avg_loss_a: -57.30391140562115\n",
            "Número de pasos del episodio 9530 son episode_steps:137\n",
            "Total Steps: 608392 Episode Num: 9530 Reward: 216.57048296930012 avg_loss_c: 4.139538530015598 avg_loss_a: -57.00765373062914\n",
            "Número de pasos del episodio 9531 son episode_steps:112\n",
            "Total Steps: 608504 Episode Num: 9531 Reward: 145.67473581000976 avg_loss_c: 4.402441452656474 avg_loss_a: -57.47803708485195\n",
            "Número de pasos del episodio 9532 son episode_steps:138\n",
            "Total Steps: 608642 Episode Num: 9532 Reward: 209.22356523379136 avg_loss_c: 4.120373547941014 avg_loss_a: -57.5983635722727\n",
            "Número de pasos del episodio 9533 son episode_steps:23\n",
            "Total Steps: 608665 Episode Num: 9533 Reward: -22.534507639232455 avg_loss_c: 3.7286732300468115 avg_loss_a: -56.87351442419964\n",
            "Número de pasos del episodio 9534 son episode_steps:144\n",
            "Total Steps: 608809 Episode Num: 9534 Reward: 202.66340620490413 avg_loss_c: 4.530588848723306 avg_loss_a: -57.61264398362901\n",
            "Número de pasos del episodio 9535 son episode_steps:129\n",
            "Total Steps: 608938 Episode Num: 9535 Reward: 206.98251226967068 avg_loss_c: 4.201404626979384 avg_loss_a: -57.737767744433974\n",
            "Número de pasos del episodio 9536 son episode_steps:117\n",
            "Total Steps: 609055 Episode Num: 9536 Reward: 165.7565374702203 avg_loss_c: 4.313451261601896 avg_loss_a: -57.204059633434326\n",
            "Número de pasos del episodio 9537 son episode_steps:57\n",
            "Total Steps: 609112 Episode Num: 9537 Reward: 61.29459441614643 avg_loss_c: 4.081393007646527 avg_loss_a: -57.863886649148505\n",
            "Número de pasos del episodio 9538 son episode_steps:72\n",
            "Total Steps: 609184 Episode Num: 9538 Reward: 90.961779247414 avg_loss_c: 4.487925502989027 avg_loss_a: -58.091077168782554\n",
            "Número de pasos del episodio 9539 son episode_steps:82\n",
            "Total Steps: 609266 Episode Num: 9539 Reward: 132.2838767882751 avg_loss_c: 4.8033813703350905 avg_loss_a: -57.69306620155893\n",
            "Número de pasos del episodio 9540 son episode_steps:85\n",
            "Total Steps: 609351 Episode Num: 9540 Reward: 122.74856072128146 avg_loss_c: 4.028784662134507 avg_loss_a: -57.616982852711395\n",
            "Número de pasos del episodio 9541 son episode_steps:92\n",
            "Total Steps: 609443 Episode Num: 9541 Reward: 130.29948318933916 avg_loss_c: 4.809002827043119 avg_loss_a: -57.80571381942086\n",
            "Número de pasos del episodio 9542 son episode_steps:131\n",
            "Total Steps: 609574 Episode Num: 9542 Reward: 182.24075864769026 avg_loss_c: 4.409911213940337 avg_loss_a: -58.67938188742135\n",
            "Número de pasos del episodio 9543 son episode_steps:75\n",
            "Total Steps: 609649 Episode Num: 9543 Reward: 100.66216767326132 avg_loss_c: 4.114220596949259 avg_loss_a: -57.92616704305013\n",
            "Número de pasos del episodio 9544 son episode_steps:66\n",
            "Total Steps: 609715 Episode Num: 9544 Reward: 45.74826842076898 avg_loss_c: 5.016671614213423 avg_loss_a: -57.49242146809896\n",
            "Número de pasos del episodio 9545 son episode_steps:130\n",
            "Total Steps: 609845 Episode Num: 9545 Reward: 171.16866568030517 avg_loss_c: 4.567978644371033 avg_loss_a: -57.61801276573768\n",
            "Número de pasos del episodio 9546 son episode_steps:20\n",
            "Total Steps: 609865 Episode Num: 9546 Reward: -24.230950428624013 avg_loss_c: 3.7390313386917113 avg_loss_a: -59.33518943786621\n",
            "Número de pasos del episodio 9547 son episode_steps:60\n",
            "Total Steps: 609925 Episode Num: 9547 Reward: 77.3942230518912 avg_loss_c: 4.651823143164317 avg_loss_a: -58.13687019348144\n",
            "Número de pasos del episodio 9548 son episode_steps:30\n",
            "Total Steps: 609955 Episode Num: 9548 Reward: -14.411588188829619 avg_loss_c: 4.447523593902588 avg_loss_a: -57.30177510579427\n",
            "Número de pasos del episodio 9549 son episode_steps:100\n",
            "Total Steps: 610055 Episode Num: 9549 Reward: 139.70023148576573 avg_loss_c: 4.688878636360169 avg_loss_a: -57.35616729736328\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 163.771266\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9550 son episode_steps:63\n",
            "Total Steps: 610118 Episode Num: 9550 Reward: 32.156027333783314 avg_loss_c: 4.454854117499457 avg_loss_a: -57.04736655099051\n",
            "Número de pasos del episodio 9551 son episode_steps:115\n",
            "Total Steps: 610233 Episode Num: 9551 Reward: 175.3333295355903 avg_loss_c: 4.621567952114603 avg_loss_a: -57.762249225118886\n",
            "Número de pasos del episodio 9552 son episode_steps:128\n",
            "Total Steps: 610361 Episode Num: 9552 Reward: 173.01576705664172 avg_loss_c: 4.39869236946106 avg_loss_a: -57.3854216337204\n",
            "Número de pasos del episodio 9553 son episode_steps:175\n",
            "Total Steps: 610536 Episode Num: 9553 Reward: 244.4192212655672 avg_loss_c: 4.722874249049595 avg_loss_a: -58.06691739763532\n",
            "Número de pasos del episodio 9554 son episode_steps:42\n",
            "Total Steps: 610578 Episode Num: 9554 Reward: 9.045835618460544 avg_loss_c: 4.2460885899407526 avg_loss_a: -57.44249253045945\n",
            "Número de pasos del episodio 9555 son episode_steps:76\n",
            "Total Steps: 610654 Episode Num: 9555 Reward: 103.96278174788168 avg_loss_c: 4.648169749661496 avg_loss_a: -58.169119583932975\n",
            "Número de pasos del episodio 9556 son episode_steps:146\n",
            "Total Steps: 610800 Episode Num: 9556 Reward: 202.28719097588734 avg_loss_c: 4.806999402503445 avg_loss_a: -57.94939286741492\n",
            "Número de pasos del episodio 9557 son episode_steps:80\n",
            "Total Steps: 610880 Episode Num: 9557 Reward: 95.36677300284131 avg_loss_c: 4.404926863312721 avg_loss_a: -58.08193826675415\n",
            "Número de pasos del episodio 9558 son episode_steps:121\n",
            "Total Steps: 611001 Episode Num: 9558 Reward: 151.29376970176534 avg_loss_c: 4.9673507725896915 avg_loss_a: -57.93091056760677\n",
            "Número de pasos del episodio 9559 son episode_steps:128\n",
            "Total Steps: 611129 Episode Num: 9559 Reward: 188.91183480100645 avg_loss_c: 4.77830370888114 avg_loss_a: -58.34380519390106\n",
            "Número de pasos del episodio 9560 son episode_steps:113\n",
            "Total Steps: 611242 Episode Num: 9560 Reward: 149.07133621731788 avg_loss_c: 4.360934278606313 avg_loss_a: -57.92466688578108\n",
            "Número de pasos del episodio 9561 son episode_steps:89\n",
            "Total Steps: 611331 Episode Num: 9561 Reward: 111.56435715870842 avg_loss_c: 4.889305744278297 avg_loss_a: -57.45342550384864\n",
            "Número de pasos del episodio 9562 son episode_steps:69\n",
            "Total Steps: 611400 Episode Num: 9562 Reward: 94.03654297701512 avg_loss_c: 4.446629800658295 avg_loss_a: -57.93056676007699\n",
            "Número de pasos del episodio 9563 son episode_steps:114\n",
            "Total Steps: 611514 Episode Num: 9563 Reward: 123.949458933446 avg_loss_c: 4.862820880454883 avg_loss_a: -57.43076003225226\n",
            "Número de pasos del episodio 9564 son episode_steps:63\n",
            "Total Steps: 611577 Episode Num: 9564 Reward: 30.487247377345323 avg_loss_c: 5.352492975810217 avg_loss_a: -58.10119041563973\n",
            "Número de pasos del episodio 9565 son episode_steps:141\n",
            "Total Steps: 611718 Episode Num: 9565 Reward: 207.2766783076377 avg_loss_c: 4.685440305276965 avg_loss_a: -58.06129228307846\n",
            "Número de pasos del episodio 9566 son episode_steps:217\n",
            "Total Steps: 611935 Episode Num: 9566 Reward: 335.55471534716617 avg_loss_c: 4.436591308787122 avg_loss_a: -57.799009367068244\n",
            "Número de pasos del episodio 9567 son episode_steps:67\n",
            "Total Steps: 612002 Episode Num: 9567 Reward: -30.63211798799038 avg_loss_c: 4.617910217882982 avg_loss_a: -57.512541130407534\n",
            "Número de pasos del episodio 9568 son episode_steps:105\n",
            "Total Steps: 612107 Episode Num: 9568 Reward: 147.10196917665147 avg_loss_c: 5.287563987005324 avg_loss_a: -57.816315351213724\n",
            "Número de pasos del episodio 9569 son episode_steps:139\n",
            "Total Steps: 612246 Episode Num: 9569 Reward: 169.8757301766696 avg_loss_c: 4.727951351687205 avg_loss_a: -58.052024649201535\n",
            "Número de pasos del episodio 9570 son episode_steps:209\n",
            "Total Steps: 612455 Episode Num: 9570 Reward: 336.7795605687744 avg_loss_c: 4.621621159275183 avg_loss_a: -58.296322562477805\n",
            "Número de pasos del episodio 9571 son episode_steps:105\n",
            "Total Steps: 612560 Episode Num: 9571 Reward: 145.31996186058345 avg_loss_c: 4.468799883978708 avg_loss_a: -57.65968747820173\n",
            "Número de pasos del episodio 9572 son episode_steps:111\n",
            "Total Steps: 612671 Episode Num: 9572 Reward: 168.34476167826358 avg_loss_c: 5.0128408466373475 avg_loss_a: -58.193034953899215\n",
            "Número de pasos del episodio 9573 son episode_steps:125\n",
            "Total Steps: 612796 Episode Num: 9573 Reward: 201.02397080457717 avg_loss_c: 4.25260262298584 avg_loss_a: -58.496036041259764\n",
            "Número de pasos del episodio 9574 son episode_steps:101\n",
            "Total Steps: 612897 Episode Num: 9574 Reward: 154.01563719268697 avg_loss_c: 4.284794318794024 avg_loss_a: -58.00945825860052\n",
            "Número de pasos del episodio 9575 son episode_steps:60\n",
            "Total Steps: 612957 Episode Num: 9575 Reward: 31.243880587747995 avg_loss_c: 4.890049084027608 avg_loss_a: -58.03729502360026\n",
            "Número de pasos del episodio 9576 son episode_steps:69\n",
            "Total Steps: 613026 Episode Num: 9576 Reward: 59.692156791013296 avg_loss_c: 4.558590743852698 avg_loss_a: -58.9682658098746\n",
            "Número de pasos del episodio 9577 son episode_steps:80\n",
            "Total Steps: 613106 Episode Num: 9577 Reward: 84.36972474528898 avg_loss_c: 4.419500657916069 avg_loss_a: -57.59401922225952\n",
            "Número de pasos del episodio 9578 son episode_steps:89\n",
            "Total Steps: 613195 Episode Num: 9578 Reward: 117.70933013721299 avg_loss_c: 4.503892515482527 avg_loss_a: -58.13108289911506\n",
            "Número de pasos del episodio 9579 son episode_steps:96\n",
            "Total Steps: 613291 Episode Num: 9579 Reward: 132.37826135751848 avg_loss_c: 4.22974360237519 avg_loss_a: -58.58418130874634\n",
            "Número de pasos del episodio 9580 son episode_steps:151\n",
            "Total Steps: 613442 Episode Num: 9580 Reward: 226.1361997940831 avg_loss_c: 4.639159775727632 avg_loss_a: -58.61790681043208\n",
            "Número de pasos del episodio 9581 son episode_steps:62\n",
            "Total Steps: 613504 Episode Num: 9581 Reward: -32.28962444669247 avg_loss_c: 4.930706754807503 avg_loss_a: -57.5161973276446\n",
            "Número de pasos del episodio 9582 son episode_steps:123\n",
            "Total Steps: 613627 Episode Num: 9582 Reward: 146.81419866054426 avg_loss_c: 4.764035744395683 avg_loss_a: -57.50993282038991\n",
            "Número de pasos del episodio 9583 son episode_steps:257\n",
            "Total Steps: 613884 Episode Num: 9583 Reward: 434.95796911088553 avg_loss_c: 4.623135485073935 avg_loss_a: -57.655602941253306\n",
            "Número de pasos del episodio 9584 son episode_steps:47\n",
            "Total Steps: 613931 Episode Num: 9584 Reward: 8.125290311149314 avg_loss_c: 4.511344980686269 avg_loss_a: -57.44317432160073\n",
            "Número de pasos del episodio 9585 son episode_steps:98\n",
            "Total Steps: 614029 Episode Num: 9585 Reward: 152.6492544643036 avg_loss_c: 4.864284714873956 avg_loss_a: -57.304979051862446\n",
            "Número de pasos del episodio 9586 son episode_steps:121\n",
            "Total Steps: 614150 Episode Num: 9586 Reward: 201.67643211464812 avg_loss_c: 5.20306038462426 avg_loss_a: -57.88234089622813\n",
            "Número de pasos del episodio 9587 son episode_steps:63\n",
            "Total Steps: 614213 Episode Num: 9587 Reward: 23.76622141000591 avg_loss_c: 5.570608808880761 avg_loss_a: -58.05347648499504\n",
            "Número de pasos del episodio 9588 son episode_steps:182\n",
            "Total Steps: 614395 Episode Num: 9588 Reward: 314.0596592720963 avg_loss_c: 4.558067832674299 avg_loss_a: -57.23797599037925\n",
            "Número de pasos del episodio 9589 son episode_steps:107\n",
            "Total Steps: 614502 Episode Num: 9589 Reward: 158.71056595090744 avg_loss_c: 5.257949806819452 avg_loss_a: -57.49679415693907\n",
            "Número de pasos del episodio 9590 son episode_steps:156\n",
            "Total Steps: 614658 Episode Num: 9590 Reward: 239.57768424839375 avg_loss_c: 4.610861223477584 avg_loss_a: -57.504704450949646\n",
            "Número de pasos del episodio 9591 son episode_steps:166\n",
            "Total Steps: 614824 Episode Num: 9591 Reward: 237.9037452611214 avg_loss_c: 4.587029431239668 avg_loss_a: -57.666737935629236\n",
            "Número de pasos del episodio 9592 son episode_steps:107\n",
            "Total Steps: 614931 Episode Num: 9592 Reward: 160.23649688333936 avg_loss_c: 4.528807154325682 avg_loss_a: -57.912430950414354\n",
            "Número de pasos del episodio 9593 son episode_steps:69\n",
            "Total Steps: 615000 Episode Num: 9593 Reward: 76.23063095185921 avg_loss_c: 4.457184359647226 avg_loss_a: -56.94953901871391\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 141.116696\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9594 son episode_steps:133\n",
            "Total Steps: 615133 Episode Num: 9594 Reward: 215.52550652606925 avg_loss_c: 5.1003014736605765 avg_loss_a: -58.022951312531205\n",
            "Número de pasos del episodio 9595 son episode_steps:141\n",
            "Total Steps: 615274 Episode Num: 9595 Reward: 222.1768706278426 avg_loss_c: 4.8710010389909675 avg_loss_a: -57.28489630949413\n",
            "Número de pasos del episodio 9596 son episode_steps:73\n",
            "Total Steps: 615347 Episode Num: 9596 Reward: 73.32356719949111 avg_loss_c: 5.085938930511475 avg_loss_a: -57.121735193958024\n",
            "Número de pasos del episodio 9597 son episode_steps:111\n",
            "Total Steps: 615458 Episode Num: 9597 Reward: 144.96160691952193 avg_loss_c: 5.339045496674271 avg_loss_a: -57.3476150443962\n",
            "Número de pasos del episodio 9598 son episode_steps:96\n",
            "Total Steps: 615554 Episode Num: 9598 Reward: 137.32004537833305 avg_loss_c: 4.7589325979352 avg_loss_a: -57.68761936823527\n",
            "Número de pasos del episodio 9599 son episode_steps:143\n",
            "Total Steps: 615697 Episode Num: 9599 Reward: 214.32575680970538 avg_loss_c: 4.853602367681223 avg_loss_a: -57.36061891142305\n",
            "Número de pasos del episodio 9600 son episode_steps:173\n",
            "Total Steps: 615870 Episode Num: 9600 Reward: 259.4297883850374 avg_loss_c: 4.704759548165206 avg_loss_a: -57.6231637634983\n",
            "Número de pasos del episodio 9601 son episode_steps:81\n",
            "Total Steps: 615951 Episode Num: 9601 Reward: 110.88506249939644 avg_loss_c: 4.5746172416357345 avg_loss_a: -57.22614194140022\n",
            "Número de pasos del episodio 9602 son episode_steps:180\n",
            "Total Steps: 616131 Episode Num: 9602 Reward: 281.49771247784577 avg_loss_c: 4.732351281907824 avg_loss_a: -57.26905763414171\n",
            "Número de pasos del episodio 9603 son episode_steps:130\n",
            "Total Steps: 616261 Episode Num: 9603 Reward: 183.45952994059854 avg_loss_c: 4.901214262155386 avg_loss_a: -57.75110174325796\n",
            "Número de pasos del episodio 9604 son episode_steps:79\n",
            "Total Steps: 616340 Episode Num: 9604 Reward: 112.11011102286142 avg_loss_c: 4.805483259732211 avg_loss_a: -57.737186673321304\n",
            "Número de pasos del episodio 9605 son episode_steps:108\n",
            "Total Steps: 616448 Episode Num: 9605 Reward: 139.35546709673827 avg_loss_c: 4.681661656609288 avg_loss_a: -57.16678810119629\n",
            "Número de pasos del episodio 9606 son episode_steps:57\n",
            "Total Steps: 616505 Episode Num: 9606 Reward: 75.42023617026788 avg_loss_c: 5.142422881042748 avg_loss_a: -57.03162109642698\n",
            "Número de pasos del episodio 9607 son episode_steps:76\n",
            "Total Steps: 616581 Episode Num: 9607 Reward: 115.51073911601604 avg_loss_c: 4.54711314565257 avg_loss_a: -57.682402861745736\n",
            "Número de pasos del episodio 9608 son episode_steps:130\n",
            "Total Steps: 616711 Episode Num: 9608 Reward: 185.90558461612335 avg_loss_c: 4.347782270724957 avg_loss_a: -57.5698606637808\n",
            "Número de pasos del episodio 9609 son episode_steps:114\n",
            "Total Steps: 616825 Episode Num: 9609 Reward: 175.29936618027705 avg_loss_c: 4.760973227651496 avg_loss_a: -57.366154520135176\n",
            "Número de pasos del episodio 9610 son episode_steps:171\n",
            "Total Steps: 616996 Episode Num: 9610 Reward: 286.54972787765456 avg_loss_c: 4.738201646079794 avg_loss_a: -57.25339501364189\n",
            "Número de pasos del episodio 9611 son episode_steps:99\n",
            "Total Steps: 617095 Episode Num: 9611 Reward: 145.0824790947652 avg_loss_c: 4.440863286605989 avg_loss_a: -57.220461373377326\n",
            "Número de pasos del episodio 9612 son episode_steps:122\n",
            "Total Steps: 617217 Episode Num: 9612 Reward: 186.2710181992997 avg_loss_c: 4.328318818670804 avg_loss_a: -57.26101052956503\n",
            "Número de pasos del episodio 9613 son episode_steps:140\n",
            "Total Steps: 617357 Episode Num: 9613 Reward: 195.9876408726872 avg_loss_c: 4.423916103158678 avg_loss_a: -57.399459620884485\n",
            "Número de pasos del episodio 9614 son episode_steps:100\n",
            "Total Steps: 617457 Episode Num: 9614 Reward: 147.76093167931413 avg_loss_c: 4.632721126079559 avg_loss_a: -57.94460342407226\n",
            "Número de pasos del episodio 9615 son episode_steps:136\n",
            "Total Steps: 617593 Episode Num: 9615 Reward: 190.8674369009981 avg_loss_c: 4.354603150311639 avg_loss_a: -57.203801435582776\n",
            "Número de pasos del episodio 9616 son episode_steps:172\n",
            "Total Steps: 617765 Episode Num: 9616 Reward: 266.8205673649157 avg_loss_c: 4.359324421993522 avg_loss_a: -56.96738935071369\n",
            "Número de pasos del episodio 9617 son episode_steps:132\n",
            "Total Steps: 617897 Episode Num: 9617 Reward: 179.23212424500736 avg_loss_c: 4.471332187002355 avg_loss_a: -57.1458406159372\n",
            "Número de pasos del episodio 9618 son episode_steps:118\n",
            "Total Steps: 618015 Episode Num: 9618 Reward: 179.67135628583605 avg_loss_c: 4.457787960262622 avg_loss_a: -56.93643912622484\n",
            "Número de pasos del episodio 9619 son episode_steps:126\n",
            "Total Steps: 618141 Episode Num: 9619 Reward: 165.35828246374604 avg_loss_c: 4.614919724918547 avg_loss_a: -57.208435724652006\n",
            "Número de pasos del episodio 9620 son episode_steps:160\n",
            "Total Steps: 618301 Episode Num: 9620 Reward: 192.46657798460882 avg_loss_c: 4.886199790239334 avg_loss_a: -56.89001436233521\n",
            "Número de pasos del episodio 9621 son episode_steps:124\n",
            "Total Steps: 618425 Episode Num: 9621 Reward: 185.21048982088544 avg_loss_c: 4.5623224954451285 avg_loss_a: -57.161334007017075\n",
            "Número de pasos del episodio 9622 son episode_steps:87\n",
            "Total Steps: 618512 Episode Num: 9622 Reward: 133.40555044363862 avg_loss_c: 4.260551469079379 avg_loss_a: -56.700492902733814\n",
            "Número de pasos del episodio 9623 son episode_steps:82\n",
            "Total Steps: 618594 Episode Num: 9623 Reward: 126.3943543775607 avg_loss_c: 4.318417319437352 avg_loss_a: -57.34325018161681\n",
            "Número de pasos del episodio 9624 son episode_steps:113\n",
            "Total Steps: 618707 Episode Num: 9624 Reward: 175.254858935841 avg_loss_c: 4.241020107691267 avg_loss_a: -57.270665531664825\n",
            "Número de pasos del episodio 9625 son episode_steps:116\n",
            "Total Steps: 618823 Episode Num: 9625 Reward: 145.40194820394026 avg_loss_c: 4.363726944758974 avg_loss_a: -56.78643200315278\n",
            "Número de pasos del episodio 9626 son episode_steps:60\n",
            "Total Steps: 618883 Episode Num: 9626 Reward: 81.89046069550672 avg_loss_c: 4.408499141534169 avg_loss_a: -56.33100357055664\n",
            "Número de pasos del episodio 9627 son episode_steps:19\n",
            "Total Steps: 618902 Episode Num: 9627 Reward: -22.078330651751788 avg_loss_c: 4.4074255667234725 avg_loss_a: -56.35094150743986\n",
            "Número de pasos del episodio 9628 son episode_steps:66\n",
            "Total Steps: 618968 Episode Num: 9628 Reward: 69.8143272738937 avg_loss_c: 5.205777139374704 avg_loss_a: -56.543517026034266\n",
            "Número de pasos del episodio 9629 son episode_steps:98\n",
            "Total Steps: 619066 Episode Num: 9629 Reward: 129.78923632601402 avg_loss_c: 4.331818838508761 avg_loss_a: -56.64255835085499\n",
            "Número de pasos del episodio 9630 son episode_steps:99\n",
            "Total Steps: 619165 Episode Num: 9630 Reward: 141.56687997701394 avg_loss_c: 4.67691246186844 avg_loss_a: -57.55604591754952\n",
            "Número de pasos del episodio 9631 son episode_steps:129\n",
            "Total Steps: 619294 Episode Num: 9631 Reward: 176.71938264495694 avg_loss_c: 4.423726281454397 avg_loss_a: -56.58810599275338\n",
            "Número de pasos del episodio 9632 son episode_steps:103\n",
            "Total Steps: 619397 Episode Num: 9632 Reward: 141.2851246628323 avg_loss_c: 4.986645633734546 avg_loss_a: -56.58661851605165\n",
            "Número de pasos del episodio 9633 son episode_steps:52\n",
            "Total Steps: 619449 Episode Num: 9633 Reward: 68.41035161799091 avg_loss_c: 4.559119829764733 avg_loss_a: -56.54257319523738\n",
            "Número de pasos del episodio 9634 son episode_steps:132\n",
            "Total Steps: 619581 Episode Num: 9634 Reward: 207.29824378013572 avg_loss_c: 4.329514662424724 avg_loss_a: -56.53695285681522\n",
            "Número de pasos del episodio 9635 son episode_steps:93\n",
            "Total Steps: 619674 Episode Num: 9635 Reward: 131.48325933299512 avg_loss_c: 4.312498056760398 avg_loss_a: -56.79829841531733\n",
            "Número de pasos del episodio 9636 son episode_steps:59\n",
            "Total Steps: 619733 Episode Num: 9636 Reward: 38.78939510952555 avg_loss_c: 4.793682272151365 avg_loss_a: -56.7318000793457\n",
            "Número de pasos del episodio 9637 son episode_steps:158\n",
            "Total Steps: 619891 Episode Num: 9637 Reward: 206.06151770892728 avg_loss_c: 4.648816576486902 avg_loss_a: -57.23252419580387\n",
            "Número de pasos del episodio 9638 son episode_steps:97\n",
            "Total Steps: 619988 Episode Num: 9638 Reward: 84.49410061034982 avg_loss_c: 4.7806906650975804 avg_loss_a: -56.47141191148266\n",
            "Número de pasos del episodio 9639 son episode_steps:155\n",
            "Total Steps: 620143 Episode Num: 9639 Reward: 282.3692794132656 avg_loss_c: 4.989019344698998 avg_loss_a: -57.09321042952999\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 176.711446\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9640 son episode_steps:172\n",
            "Total Steps: 620315 Episode Num: 9640 Reward: 274.44783923483163 avg_loss_c: 4.614487704842589 avg_loss_a: -56.94521779792253\n",
            "Número de pasos del episodio 9641 son episode_steps:78\n",
            "Total Steps: 620393 Episode Num: 9641 Reward: 95.84355801078934 avg_loss_c: 4.534116625785828 avg_loss_a: -56.71987357506385\n",
            "Número de pasos del episodio 9642 son episode_steps:140\n",
            "Total Steps: 620533 Episode Num: 9642 Reward: 235.31059835434786 avg_loss_c: 4.410735452175141 avg_loss_a: -56.86295503888812\n",
            "Número de pasos del episodio 9643 son episode_steps:84\n",
            "Total Steps: 620617 Episode Num: 9643 Reward: 113.71500508666048 avg_loss_c: 4.525439333348047 avg_loss_a: -56.66493388584682\n",
            "Número de pasos del episodio 9644 son episode_steps:89\n",
            "Total Steps: 620706 Episode Num: 9644 Reward: 125.8977249258418 avg_loss_c: 4.394750437040008 avg_loss_a: -57.30859079253808\n",
            "Número de pasos del episodio 9645 son episode_steps:122\n",
            "Total Steps: 620828 Episode Num: 9645 Reward: 184.61064233589954 avg_loss_c: 4.503428975089651 avg_loss_a: -56.45717720907243\n",
            "Número de pasos del episodio 9646 son episode_steps:168\n",
            "Total Steps: 620996 Episode Num: 9646 Reward: 230.0992768722516 avg_loss_c: 4.655053548869633 avg_loss_a: -56.49482781546457\n",
            "Número de pasos del episodio 9647 son episode_steps:69\n",
            "Total Steps: 621065 Episode Num: 9647 Reward: 67.17568513840514 avg_loss_c: 4.370628920154295 avg_loss_a: -56.918754688207656\n",
            "Número de pasos del episodio 9648 son episode_steps:129\n",
            "Total Steps: 621194 Episode Num: 9648 Reward: 148.47506373569882 avg_loss_c: 5.003205160761988 avg_loss_a: -57.064194908437806\n",
            "Número de pasos del episodio 9649 son episode_steps:53\n",
            "Total Steps: 621247 Episode Num: 9649 Reward: 7.27209100524178 avg_loss_c: 4.814243096225667 avg_loss_a: -57.20078342365769\n",
            "Número de pasos del episodio 9650 son episode_steps:129\n",
            "Total Steps: 621376 Episode Num: 9650 Reward: 211.9120503183589 avg_loss_c: 4.447470679763676 avg_loss_a: -56.88499296912851\n",
            "Número de pasos del episodio 9651 son episode_steps:75\n",
            "Total Steps: 621451 Episode Num: 9651 Reward: 110.96132538980618 avg_loss_c: 5.015615094502767 avg_loss_a: -56.45728449503581\n",
            "Número de pasos del episodio 9652 son episode_steps:154\n",
            "Total Steps: 621605 Episode Num: 9652 Reward: 184.99977093725022 avg_loss_c: 4.706850068909781 avg_loss_a: -56.40860812694996\n",
            "Número de pasos del episodio 9653 son episode_steps:71\n",
            "Total Steps: 621676 Episode Num: 9653 Reward: 88.60743555904844 avg_loss_c: 4.501330815570455 avg_loss_a: -56.318375654623544\n",
            "Número de pasos del episodio 9654 son episode_steps:132\n",
            "Total Steps: 621808 Episode Num: 9654 Reward: 199.4198988166086 avg_loss_c: 4.660241022254482 avg_loss_a: -56.29213633681788\n",
            "Número de pasos del episodio 9655 son episode_steps:76\n",
            "Total Steps: 621884 Episode Num: 9655 Reward: 109.617086635414 avg_loss_c: 4.444195502682736 avg_loss_a: -56.80331541362562\n",
            "Número de pasos del episodio 9656 son episode_steps:171\n",
            "Total Steps: 622055 Episode Num: 9656 Reward: 273.98258012389545 avg_loss_c: 4.619258877826713 avg_loss_a: -56.72824346531204\n",
            "Número de pasos del episodio 9657 son episode_steps:89\n",
            "Total Steps: 622144 Episode Num: 9657 Reward: 127.0607306298232 avg_loss_c: 4.822139825713768 avg_loss_a: -56.492638620097985\n",
            "Número de pasos del episodio 9658 son episode_steps:89\n",
            "Total Steps: 622233 Episode Num: 9658 Reward: 119.33520819986086 avg_loss_c: 4.423724565613136 avg_loss_a: -56.992610759949415\n",
            "Número de pasos del episodio 9659 son episode_steps:51\n",
            "Total Steps: 622284 Episode Num: 9659 Reward: 22.145388044807536 avg_loss_c: 4.443492043252085 avg_loss_a: -56.511219697840076\n",
            "Número de pasos del episodio 9660 son episode_steps:113\n",
            "Total Steps: 622397 Episode Num: 9660 Reward: 132.44915537709326 avg_loss_c: 4.767534327718009 avg_loss_a: -56.6726202500605\n",
            "Número de pasos del episodio 9661 son episode_steps:91\n",
            "Total Steps: 622488 Episode Num: 9661 Reward: 141.97076030771345 avg_loss_c: 4.708053208969452 avg_loss_a: -56.104048341185184\n",
            "Número de pasos del episodio 9662 son episode_steps:76\n",
            "Total Steps: 622564 Episode Num: 9662 Reward: 117.71437130260725 avg_loss_c: 4.5607370483247855 avg_loss_a: -56.417329386660924\n",
            "Número de pasos del episodio 9663 son episode_steps:101\n",
            "Total Steps: 622665 Episode Num: 9663 Reward: 155.91972435013065 avg_loss_c: 4.909489870071411 avg_loss_a: -56.25222268435034\n",
            "Número de pasos del episodio 9664 son episode_steps:128\n",
            "Total Steps: 622793 Episode Num: 9664 Reward: 200.7950229768419 avg_loss_c: 4.718516701832414 avg_loss_a: -55.922389447689056\n",
            "Número de pasos del episodio 9665 son episode_steps:157\n",
            "Total Steps: 622950 Episode Num: 9665 Reward: 253.66379369220832 avg_loss_c: 4.7229811173335765 avg_loss_a: -55.96578770534248\n",
            "Número de pasos del episodio 9666 son episode_steps:74\n",
            "Total Steps: 623024 Episode Num: 9666 Reward: 70.24480263422609 avg_loss_c: 4.949061902793678 avg_loss_a: -56.11545707084037\n",
            "Número de pasos del episodio 9667 son episode_steps:68\n",
            "Total Steps: 623092 Episode Num: 9667 Reward: 103.74551776263799 avg_loss_c: 4.492836222929113 avg_loss_a: -55.62113559947294\n",
            "Número de pasos del episodio 9668 son episode_steps:99\n",
            "Total Steps: 623191 Episode Num: 9668 Reward: 166.56198435867398 avg_loss_c: 4.600480616694749 avg_loss_a: -56.24069167628433\n",
            "Número de pasos del episodio 9669 son episode_steps:126\n",
            "Total Steps: 623317 Episode Num: 9669 Reward: 186.7688654045994 avg_loss_c: 4.573151289470612 avg_loss_a: -56.221412537589906\n",
            "Número de pasos del episodio 9670 son episode_steps:93\n",
            "Total Steps: 623410 Episode Num: 9670 Reward: 136.86901216080645 avg_loss_c: 4.626023166923113 avg_loss_a: -56.061827464770246\n",
            "Número de pasos del episodio 9671 son episode_steps:48\n",
            "Total Steps: 623458 Episode Num: 9671 Reward: 21.576123774762475 avg_loss_c: 5.013905177513759 avg_loss_a: -56.78620831171671\n",
            "Número de pasos del episodio 9672 son episode_steps:138\n",
            "Total Steps: 623596 Episode Num: 9672 Reward: 209.37540843819966 avg_loss_c: 4.862794803536457 avg_loss_a: -55.99724916098774\n",
            "Número de pasos del episodio 9673 son episode_steps:19\n",
            "Total Steps: 623615 Episode Num: 9673 Reward: -25.766803378469668 avg_loss_c: 4.837428180794967 avg_loss_a: -57.36100989893863\n",
            "Número de pasos del episodio 9674 son episode_steps:167\n",
            "Total Steps: 623782 Episode Num: 9674 Reward: 229.04397906993628 avg_loss_c: 4.78076819174304 avg_loss_a: -56.14665512267701\n",
            "Número de pasos del episodio 9675 son episode_steps:265\n",
            "Total Steps: 624047 Episode Num: 9675 Reward: 397.06292892316407 avg_loss_c: 4.898438166672329 avg_loss_a: -56.44030711335956\n",
            "Número de pasos del episodio 9676 son episode_steps:64\n",
            "Total Steps: 624111 Episode Num: 9676 Reward: 94.06948500670575 avg_loss_c: 4.800575017929077 avg_loss_a: -56.047802448272705\n",
            "Número de pasos del episodio 9677 son episode_steps:129\n",
            "Total Steps: 624240 Episode Num: 9677 Reward: 198.98373281040674 avg_loss_c: 4.715989878011304 avg_loss_a: -56.33486503778502\n",
            "Número de pasos del episodio 9678 son episode_steps:148\n",
            "Total Steps: 624388 Episode Num: 9678 Reward: 244.13674896896282 avg_loss_c: 4.699100331680195 avg_loss_a: -56.54831912066486\n",
            "Número de pasos del episodio 9679 son episode_steps:81\n",
            "Total Steps: 624469 Episode Num: 9679 Reward: 119.85725891145447 avg_loss_c: 4.613359254083516 avg_loss_a: -57.12385818104685\n",
            "Número de pasos del episodio 9680 son episode_steps:119\n",
            "Total Steps: 624588 Episode Num: 9680 Reward: 157.8247296689573 avg_loss_c: 4.423012316727839 avg_loss_a: -56.37282735359769\n",
            "Número de pasos del episodio 9681 son episode_steps:118\n",
            "Total Steps: 624706 Episode Num: 9681 Reward: 161.63089110538937 avg_loss_c: 4.771584674463433 avg_loss_a: -56.30517448813228\n",
            "Número de pasos del episodio 9682 son episode_steps:116\n",
            "Total Steps: 624822 Episode Num: 9682 Reward: 188.2686237882577 avg_loss_c: 4.4203271310904935 avg_loss_a: -57.202877636613515\n",
            "Número de pasos del episodio 9683 son episode_steps:131\n",
            "Total Steps: 624953 Episode Num: 9683 Reward: 193.6561092134928 avg_loss_c: 4.759212883374163 avg_loss_a: -55.76892340274257\n",
            "Número de pasos del episodio 9684 son episode_steps:101\n",
            "Total Steps: 625054 Episode Num: 9684 Reward: 146.5704654012429 avg_loss_c: 5.227370434468336 avg_loss_a: -57.27720914028659\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 113.313146\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9685 son episode_steps:63\n",
            "Total Steps: 625117 Episode Num: 9685 Reward: 22.838004692187035 avg_loss_c: 4.446597008478074 avg_loss_a: -56.48415023561508\n",
            "Número de pasos del episodio 9686 son episode_steps:139\n",
            "Total Steps: 625256 Episode Num: 9686 Reward: 219.02593938315187 avg_loss_c: 4.640568988786327 avg_loss_a: -56.31682273809859\n",
            "Número de pasos del episodio 9687 son episode_steps:72\n",
            "Total Steps: 625328 Episode Num: 9687 Reward: 101.62282284725046 avg_loss_c: 4.52885060177909 avg_loss_a: -56.70964495340983\n",
            "Número de pasos del episodio 9688 son episode_steps:77\n",
            "Total Steps: 625405 Episode Num: 9688 Reward: 93.13327016715863 avg_loss_c: 4.808546750576465 avg_loss_a: -57.02761043201793\n",
            "Número de pasos del episodio 9689 son episode_steps:102\n",
            "Total Steps: 625507 Episode Num: 9689 Reward: 149.56778588019517 avg_loss_c: 4.496332327524821 avg_loss_a: -56.9552770876417\n",
            "Número de pasos del episodio 9690 son episode_steps:158\n",
            "Total Steps: 625665 Episode Num: 9690 Reward: 268.72958318133107 avg_loss_c: 4.485231515727466 avg_loss_a: -56.50245376780063\n",
            "Número de pasos del episodio 9691 son episode_steps:75\n",
            "Total Steps: 625740 Episode Num: 9691 Reward: 116.32791070218397 avg_loss_c: 4.756828314463298 avg_loss_a: -56.274405314127605\n",
            "Número de pasos del episodio 9692 son episode_steps:174\n",
            "Total Steps: 625914 Episode Num: 9692 Reward: 254.3527464226908 avg_loss_c: 4.6897003527345325 avg_loss_a: -56.27099451525458\n",
            "Número de pasos del episodio 9693 son episode_steps:71\n",
            "Total Steps: 625985 Episode Num: 9693 Reward: 100.6461677003628 avg_loss_c: 4.583530201038844 avg_loss_a: -56.89602054004938\n",
            "Número de pasos del episodio 9694 son episode_steps:20\n",
            "Total Steps: 626005 Episode Num: 9694 Reward: -24.741780733353718 avg_loss_c: 4.490811204910278 avg_loss_a: -55.79469528198242\n",
            "Número de pasos del episodio 9695 son episode_steps:60\n",
            "Total Steps: 626065 Episode Num: 9695 Reward: 90.52231769905994 avg_loss_c: 4.596353014310201 avg_loss_a: -57.028460311889646\n",
            "Número de pasos del episodio 9696 son episode_steps:159\n",
            "Total Steps: 626224 Episode Num: 9696 Reward: 218.2350063535018 avg_loss_c: 4.48696923555818 avg_loss_a: -56.59109609831804\n",
            "Número de pasos del episodio 9697 son episode_steps:107\n",
            "Total Steps: 626331 Episode Num: 9697 Reward: 158.78857288019586 avg_loss_c: 4.571663181358408 avg_loss_a: -56.871755225636136\n",
            "Número de pasos del episodio 9698 son episode_steps:86\n",
            "Total Steps: 626417 Episode Num: 9698 Reward: 90.01743554760017 avg_loss_c: 4.611968980279079 avg_loss_a: -56.609230218931685\n",
            "Número de pasos del episodio 9699 son episode_steps:112\n",
            "Total Steps: 626529 Episode Num: 9699 Reward: 145.8708599721984 avg_loss_c: 4.746851697564125 avg_loss_a: -56.69670193535941\n",
            "Número de pasos del episodio 9700 son episode_steps:75\n",
            "Total Steps: 626604 Episode Num: 9700 Reward: 69.04712135930374 avg_loss_c: 5.040134522120158 avg_loss_a: -56.7076047261556\n",
            "Número de pasos del episodio 9701 son episode_steps:129\n",
            "Total Steps: 626733 Episode Num: 9701 Reward: 192.9519814124155 avg_loss_c: 4.611319061397582 avg_loss_a: -56.326934903167015\n",
            "Número de pasos del episodio 9702 son episode_steps:72\n",
            "Total Steps: 626805 Episode Num: 9702 Reward: 98.92663384053184 avg_loss_c: 4.36837492717637 avg_loss_a: -56.0451480017768\n",
            "Número de pasos del episodio 9703 son episode_steps:156\n",
            "Total Steps: 626961 Episode Num: 9703 Reward: 188.3861298929182 avg_loss_c: 4.917899134831551 avg_loss_a: -56.24667739868164\n",
            "Número de pasos del episodio 9704 son episode_steps:17\n",
            "Total Steps: 626978 Episode Num: 9704 Reward: -27.206994988217353 avg_loss_c: 4.686763174393597 avg_loss_a: -55.64215536678539\n",
            "Número de pasos del episodio 9705 son episode_steps:112\n",
            "Total Steps: 627090 Episode Num: 9705 Reward: 160.91306951034676 avg_loss_c: 5.59234271304948 avg_loss_a: -56.39505890437535\n",
            "Número de pasos del episodio 9706 son episode_steps:143\n",
            "Total Steps: 627233 Episode Num: 9706 Reward: 228.022150238741 avg_loss_c: 5.652216417806132 avg_loss_a: -56.72396887932624\n",
            "Número de pasos del episodio 9707 son episode_steps:220\n",
            "Total Steps: 627453 Episode Num: 9707 Reward: 337.08445533782754 avg_loss_c: 5.001279032230377 avg_loss_a: -56.26325811906295\n",
            "Número de pasos del episodio 9708 son episode_steps:118\n",
            "Total Steps: 627571 Episode Num: 9708 Reward: 141.27171878849867 avg_loss_c: 4.885756197622267 avg_loss_a: -56.011822328729146\n",
            "Número de pasos del episodio 9709 son episode_steps:102\n",
            "Total Steps: 627673 Episode Num: 9709 Reward: 156.1088190436019 avg_loss_c: 4.529603780484667 avg_loss_a: -56.45603105133655\n",
            "Número de pasos del episodio 9710 son episode_steps:142\n",
            "Total Steps: 627815 Episode Num: 9710 Reward: 241.09637133278972 avg_loss_c: 4.855172038078308 avg_loss_a: -57.06002549722161\n",
            "Número de pasos del episodio 9711 son episode_steps:154\n",
            "Total Steps: 627969 Episode Num: 9711 Reward: 278.37137847641634 avg_loss_c: 4.397112775158573 avg_loss_a: -56.7964973449707\n",
            "Número de pasos del episodio 9712 son episode_steps:139\n",
            "Total Steps: 628108 Episode Num: 9712 Reward: 216.96282398851764 avg_loss_c: 4.592864165203177 avg_loss_a: -56.3983248154894\n",
            "Número de pasos del episodio 9713 son episode_steps:111\n",
            "Total Steps: 628219 Episode Num: 9713 Reward: 166.19599109037836 avg_loss_c: 4.703553146070188 avg_loss_a: -56.24167389053482\n",
            "Número de pasos del episodio 9714 son episode_steps:292\n",
            "Total Steps: 628511 Episode Num: 9714 Reward: 452.831857239145 avg_loss_c: 4.689166276422266 avg_loss_a: -56.6442335468449\n",
            "Número de pasos del episodio 9715 son episode_steps:73\n",
            "Total Steps: 628584 Episode Num: 9715 Reward: 99.63413197952087 avg_loss_c: 4.6152957040969635 avg_loss_a: -56.48844805155715\n",
            "Número de pasos del episodio 9716 son episode_steps:109\n",
            "Total Steps: 628693 Episode Num: 9716 Reward: 150.72623246702588 avg_loss_c: 4.798149587911204 avg_loss_a: -57.16985072564641\n",
            "Número de pasos del episodio 9717 son episode_steps:91\n",
            "Total Steps: 628784 Episode Num: 9717 Reward: 138.46172161757224 avg_loss_c: 4.449608860435067 avg_loss_a: -57.09289303454724\n",
            "Número de pasos del episodio 9718 son episode_steps:140\n",
            "Total Steps: 628924 Episode Num: 9718 Reward: 215.35081679991515 avg_loss_c: 4.6759091581617085 avg_loss_a: -56.79126194545201\n",
            "Número de pasos del episodio 9719 son episode_steps:100\n",
            "Total Steps: 629024 Episode Num: 9719 Reward: 150.1393869525962 avg_loss_c: 4.342944936752319 avg_loss_a: -57.272637939453126\n",
            "Número de pasos del episodio 9720 son episode_steps:70\n",
            "Total Steps: 629094 Episode Num: 9720 Reward: 66.3960364293997 avg_loss_c: 4.542725610733032 avg_loss_a: -56.825254276820594\n",
            "Número de pasos del episodio 9721 son episode_steps:84\n",
            "Total Steps: 629178 Episode Num: 9721 Reward: 107.90198361710324 avg_loss_c: 4.686498241765158 avg_loss_a: -56.8278869447254\n",
            "Número de pasos del episodio 9722 son episode_steps:104\n",
            "Total Steps: 629282 Episode Num: 9722 Reward: 168.16324270909325 avg_loss_c: 4.49915766945252 avg_loss_a: -57.05001104795016\n",
            "Número de pasos del episodio 9723 son episode_steps:65\n",
            "Total Steps: 629347 Episode Num: 9723 Reward: 96.87078120271572 avg_loss_c: 4.6855456462273235 avg_loss_a: -57.06403339092548\n",
            "Número de pasos del episodio 9724 son episode_steps:161\n",
            "Total Steps: 629508 Episode Num: 9724 Reward: 258.63929434955867 avg_loss_c: 4.591099959722957 avg_loss_a: -57.12270940460774\n",
            "Número de pasos del episodio 9725 son episode_steps:62\n",
            "Total Steps: 629570 Episode Num: 9725 Reward: 67.9754168344223 avg_loss_c: 4.90106979877718 avg_loss_a: -56.75227466706307\n",
            "Número de pasos del episodio 9726 son episode_steps:100\n",
            "Total Steps: 629670 Episode Num: 9726 Reward: 63.22600920421702 avg_loss_c: 4.732518911361694 avg_loss_a: -56.24537109375\n",
            "Número de pasos del episodio 9727 son episode_steps:109\n",
            "Total Steps: 629779 Episode Num: 9727 Reward: 123.2257321101478 avg_loss_c: 4.674973988751753 avg_loss_a: -56.482918205611206\n",
            "Número de pasos del episodio 9728 son episode_steps:107\n",
            "Total Steps: 629886 Episode Num: 9728 Reward: 164.09365247290347 avg_loss_c: 4.733614792333585 avg_loss_a: -57.17998148124909\n",
            "Número de pasos del episodio 9729 son episode_steps:251\n",
            "Total Steps: 630137 Episode Num: 9729 Reward: 437.4715399163134 avg_loss_c: 4.6092317265818314 avg_loss_a: -57.06298756694414\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 150.238162\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9730 son episode_steps:98\n",
            "Total Steps: 630235 Episode Num: 9730 Reward: 156.17745517225669 avg_loss_c: 4.760287844404882 avg_loss_a: -57.29068514765525\n",
            "Número de pasos del episodio 9731 son episode_steps:49\n",
            "Total Steps: 630284 Episode Num: 9731 Reward: 22.359964400435185 avg_loss_c: 4.3377373413163784 avg_loss_a: -58.13102605391522\n",
            "Número de pasos del episodio 9732 son episode_steps:71\n",
            "Total Steps: 630355 Episode Num: 9732 Reward: 94.55444133475969 avg_loss_c: 4.648407308148666 avg_loss_a: -56.81548228733976\n",
            "Número de pasos del episodio 9733 son episode_steps:103\n",
            "Total Steps: 630458 Episode Num: 9733 Reward: 153.01857579487313 avg_loss_c: 4.655569666797675 avg_loss_a: -57.00159080283156\n",
            "Número de pasos del episodio 9734 son episode_steps:80\n",
            "Total Steps: 630538 Episode Num: 9734 Reward: 97.16348166521124 avg_loss_c: 4.788710075616836 avg_loss_a: -57.288889503479005\n",
            "Número de pasos del episodio 9735 son episode_steps:77\n",
            "Total Steps: 630615 Episode Num: 9735 Reward: 121.34303181314469 avg_loss_c: 4.626190036922306 avg_loss_a: -56.95230548412769\n",
            "Número de pasos del episodio 9736 son episode_steps:149\n",
            "Total Steps: 630764 Episode Num: 9736 Reward: 227.15098095334452 avg_loss_c: 4.794663856493547 avg_loss_a: -57.27201036798874\n",
            "Número de pasos del episodio 9737 son episode_steps:68\n",
            "Total Steps: 630832 Episode Num: 9737 Reward: 95.1224633905793 avg_loss_c: 4.43564168845906 avg_loss_a: -57.71977996826172\n",
            "Número de pasos del episodio 9738 son episode_steps:116\n",
            "Total Steps: 630948 Episode Num: 9738 Reward: 170.0526587188335 avg_loss_c: 4.803810006585614 avg_loss_a: -57.34447972527866\n",
            "Número de pasos del episodio 9739 son episode_steps:93\n",
            "Total Steps: 631041 Episode Num: 9739 Reward: 103.36959771786395 avg_loss_c: 4.884462348876461 avg_loss_a: -57.188972924345286\n",
            "Número de pasos del episodio 9740 son episode_steps:82\n",
            "Total Steps: 631123 Episode Num: 9740 Reward: 130.32678725234678 avg_loss_c: 4.962693563321742 avg_loss_a: -58.00089729122999\n",
            "Número de pasos del episodio 9741 son episode_steps:124\n",
            "Total Steps: 631247 Episode Num: 9741 Reward: 148.7192854959574 avg_loss_c: 4.688454376113031 avg_loss_a: -57.55076894452495\n",
            "Número de pasos del episodio 9742 son episode_steps:111\n",
            "Total Steps: 631358 Episode Num: 9742 Reward: 155.05324013187703 avg_loss_c: 4.822280830091184 avg_loss_a: -57.15200407011015\n",
            "Número de pasos del episodio 9743 son episode_steps:120\n",
            "Total Steps: 631478 Episode Num: 9743 Reward: 165.9012198513524 avg_loss_c: 4.552582385142644 avg_loss_a: -57.22669849395752\n",
            "Número de pasos del episodio 9744 son episode_steps:75\n",
            "Total Steps: 631553 Episode Num: 9744 Reward: 14.263479547109844 avg_loss_c: 4.91420716603597 avg_loss_a: -57.40781285603841\n",
            "Número de pasos del episodio 9745 son episode_steps:135\n",
            "Total Steps: 631688 Episode Num: 9745 Reward: 190.19439185118884 avg_loss_c: 4.52561130700288 avg_loss_a: -57.39500828495732\n",
            "Número de pasos del episodio 9746 son episode_steps:58\n",
            "Total Steps: 631746 Episode Num: 9746 Reward: 64.38321193419961 avg_loss_c: 4.298067018903535 avg_loss_a: -58.00474916655442\n",
            "Número de pasos del episodio 9747 son episode_steps:103\n",
            "Total Steps: 631849 Episode Num: 9747 Reward: 157.36051935942558 avg_loss_c: 4.642135527527448 avg_loss_a: -57.92564903185205\n",
            "Número de pasos del episodio 9748 son episode_steps:89\n",
            "Total Steps: 631938 Episode Num: 9748 Reward: 138.0212750698124 avg_loss_c: 4.805111400197061 avg_loss_a: -57.14867002508613\n",
            "Número de pasos del episodio 9749 son episode_steps:141\n",
            "Total Steps: 632079 Episode Num: 9749 Reward: 204.3358754669908 avg_loss_c: 4.89441491187887 avg_loss_a: -57.42117463781479\n",
            "Número de pasos del episodio 9750 son episode_steps:162\n",
            "Total Steps: 632241 Episode Num: 9750 Reward: 258.8591505201305 avg_loss_c: 4.55487980813156 avg_loss_a: -57.884489412660955\n",
            "Número de pasos del episodio 9751 son episode_steps:85\n",
            "Total Steps: 632326 Episode Num: 9751 Reward: 102.79476261482367 avg_loss_c: 4.7590156695422 avg_loss_a: -57.02624327715706\n",
            "Número de pasos del episodio 9752 son episode_steps:21\n",
            "Total Steps: 632347 Episode Num: 9752 Reward: -16.365494278799297 avg_loss_c: 4.5414528506142755 avg_loss_a: -56.80420775640579\n",
            "Número de pasos del episodio 9753 son episode_steps:89\n",
            "Total Steps: 632436 Episode Num: 9753 Reward: 48.0177655934898 avg_loss_c: 4.5942279060235185 avg_loss_a: -56.94483926323023\n",
            "Número de pasos del episodio 9754 son episode_steps:173\n",
            "Total Steps: 632609 Episode Num: 9754 Reward: 273.8810078224752 avg_loss_c: 4.706765833617635 avg_loss_a: -57.79408687525402\n",
            "Número de pasos del episodio 9755 son episode_steps:43\n",
            "Total Steps: 632652 Episode Num: 9755 Reward: 18.35595375484817 avg_loss_c: 5.464408198068308 avg_loss_a: -56.71640440475109\n",
            "Número de pasos del episodio 9756 son episode_steps:47\n",
            "Total Steps: 632699 Episode Num: 9756 Reward: 28.995273822486794 avg_loss_c: 4.638923269637088 avg_loss_a: -56.82932817175033\n",
            "Número de pasos del episodio 9757 son episode_steps:116\n",
            "Total Steps: 632815 Episode Num: 9757 Reward: 179.86088851511792 avg_loss_c: 4.880337659654947 avg_loss_a: -56.85253840479358\n",
            "Número de pasos del episodio 9758 son episode_steps:225\n",
            "Total Steps: 633040 Episode Num: 9758 Reward: 338.72484827007634 avg_loss_c: 4.738878015942044 avg_loss_a: -57.1568608601888\n",
            "Número de pasos del episodio 9759 son episode_steps:127\n",
            "Total Steps: 633167 Episode Num: 9759 Reward: 159.28977420385115 avg_loss_c: 4.777452267999724 avg_loss_a: -57.340309623658186\n",
            "Número de pasos del episodio 9760 son episode_steps:125\n",
            "Total Steps: 633292 Episode Num: 9760 Reward: 177.4579889275493 avg_loss_c: 4.696294342041016 avg_loss_a: -57.05280215454101\n",
            "Número de pasos del episodio 9761 son episode_steps:134\n",
            "Total Steps: 633426 Episode Num: 9761 Reward: 206.76983442742102 avg_loss_c: 5.159302053166859 avg_loss_a: -57.139779959151994\n",
            "Número de pasos del episodio 9762 son episode_steps:122\n",
            "Total Steps: 633548 Episode Num: 9762 Reward: 188.0022068104922 avg_loss_c: 4.80437746986014 avg_loss_a: -57.76594393370581\n",
            "Número de pasos del episodio 9763 son episode_steps:142\n",
            "Total Steps: 633690 Episode Num: 9763 Reward: 198.80354316797465 avg_loss_c: 5.110744815477183 avg_loss_a: -57.749820870412904\n",
            "Número de pasos del episodio 9764 son episode_steps:54\n",
            "Total Steps: 633744 Episode Num: 9764 Reward: 61.8494476541995 avg_loss_c: 4.775169610977173 avg_loss_a: -56.574914579038264\n",
            "Número de pasos del episodio 9765 son episode_steps:107\n",
            "Total Steps: 633851 Episode Num: 9765 Reward: 145.4810887131834 avg_loss_c: 4.668066399119724 avg_loss_a: -56.90758275540075\n",
            "Número de pasos del episodio 9766 son episode_steps:79\n",
            "Total Steps: 633930 Episode Num: 9766 Reward: 75.16963534062147 avg_loss_c: 4.721964072577561 avg_loss_a: -57.6036309350895\n",
            "Número de pasos del episodio 9767 son episode_steps:124\n",
            "Total Steps: 634054 Episode Num: 9767 Reward: 194.88413277508872 avg_loss_c: 5.203553872723734 avg_loss_a: -57.02869083035377\n",
            "Número de pasos del episodio 9768 son episode_steps:113\n",
            "Total Steps: 634167 Episode Num: 9768 Reward: 184.88874188875045 avg_loss_c: 4.817121539495687 avg_loss_a: -57.33206048475957\n",
            "Número de pasos del episodio 9769 son episode_steps:157\n",
            "Total Steps: 634324 Episode Num: 9769 Reward: 243.46058520696047 avg_loss_c: 5.093898016935701 avg_loss_a: -57.53698817939515\n",
            "Número de pasos del episodio 9770 son episode_steps:78\n",
            "Total Steps: 634402 Episode Num: 9770 Reward: 108.4218957979134 avg_loss_c: 5.047396641511184 avg_loss_a: -57.02074940999349\n",
            "Número de pasos del episodio 9771 son episode_steps:61\n",
            "Total Steps: 634463 Episode Num: 9771 Reward: 79.38534415738607 avg_loss_c: 4.779787282474706 avg_loss_a: -57.09005030647653\n",
            "Número de pasos del episodio 9772 son episode_steps:160\n",
            "Total Steps: 634623 Episode Num: 9772 Reward: 237.27174062320125 avg_loss_c: 4.48192980736494 avg_loss_a: -57.08720502853394\n",
            "Número de pasos del episodio 9773 son episode_steps:191\n",
            "Total Steps: 634814 Episode Num: 9773 Reward: 249.40041628625053 avg_loss_c: 4.797206414307599 avg_loss_a: -56.93956800530718\n",
            "Número de pasos del episodio 9774 son episode_steps:124\n",
            "Total Steps: 634938 Episode Num: 9774 Reward: 172.10968746990312 avg_loss_c: 4.604366958141327 avg_loss_a: -57.576813790106\n",
            "Número de pasos del episodio 9775 son episode_steps:114\n",
            "Total Steps: 635052 Episode Num: 9775 Reward: 108.94338778833938 avg_loss_c: 4.503211809877763 avg_loss_a: -56.95299463104784\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 207.709189\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9776 son episode_steps:87\n",
            "Total Steps: 635139 Episode Num: 9776 Reward: 107.32903778490908 avg_loss_c: 4.518600768056409 avg_loss_a: -56.59134551300399\n",
            "Número de pasos del episodio 9777 son episode_steps:167\n",
            "Total Steps: 635306 Episode Num: 9777 Reward: 265.4443249362905 avg_loss_c: 4.71596363204682 avg_loss_a: -57.2479687536548\n",
            "Número de pasos del episodio 9778 son episode_steps:147\n",
            "Total Steps: 635453 Episode Num: 9778 Reward: 244.27843587818904 avg_loss_c: 4.747907413106386 avg_loss_a: -57.49974041893368\n",
            "Número de pasos del episodio 9779 son episode_steps:124\n",
            "Total Steps: 635577 Episode Num: 9779 Reward: 166.29667823002183 avg_loss_c: 4.839180459899287 avg_loss_a: -57.42230267678538\n",
            "Número de pasos del episodio 9780 son episode_steps:182\n",
            "Total Steps: 635759 Episode Num: 9780 Reward: 285.1803937696919 avg_loss_c: 4.727941515681508 avg_loss_a: -57.26037446745149\n",
            "Número de pasos del episodio 9781 son episode_steps:103\n",
            "Total Steps: 635862 Episode Num: 9781 Reward: 166.13456011553623 avg_loss_c: 4.337630764951983 avg_loss_a: -57.46234797505499\n",
            "Número de pasos del episodio 9782 son episode_steps:153\n",
            "Total Steps: 636015 Episode Num: 9782 Reward: 233.00171021998713 avg_loss_c: 4.683822059943006 avg_loss_a: -57.4457064360575\n",
            "Número de pasos del episodio 9783 son episode_steps:147\n",
            "Total Steps: 636162 Episode Num: 9783 Reward: 207.31404032055536 avg_loss_c: 4.68702346937997 avg_loss_a: -58.40330975071914\n",
            "Número de pasos del episodio 9784 son episode_steps:144\n",
            "Total Steps: 636306 Episode Num: 9784 Reward: 224.24414331041146 avg_loss_c: 4.669377618365818 avg_loss_a: -57.30584404203627\n",
            "Número de pasos del episodio 9785 son episode_steps:98\n",
            "Total Steps: 636404 Episode Num: 9785 Reward: 97.40214721014391 avg_loss_c: 4.649937673490875 avg_loss_a: -57.157875372439015\n",
            "Número de pasos del episodio 9786 son episode_steps:182\n",
            "Total Steps: 636586 Episode Num: 9786 Reward: 295.9832927300528 avg_loss_c: 4.632270021752997 avg_loss_a: -58.083434136359244\n",
            "Número de pasos del episodio 9787 son episode_steps:190\n",
            "Total Steps: 636776 Episode Num: 9787 Reward: 303.8909846325894 avg_loss_c: 4.735232902828016 avg_loss_a: -58.2830252396433\n",
            "Número de pasos del episodio 9788 son episode_steps:124\n",
            "Total Steps: 636900 Episode Num: 9788 Reward: 42.21437165617984 avg_loss_c: 4.7978008312563745 avg_loss_a: -57.755588900658395\n",
            "Número de pasos del episodio 9789 son episode_steps:240\n",
            "Total Steps: 637140 Episode Num: 9789 Reward: 322.2905100182498 avg_loss_c: 4.863132071495056 avg_loss_a: -57.91132434209188\n",
            "Número de pasos del episodio 9790 son episode_steps:69\n",
            "Total Steps: 637209 Episode Num: 9790 Reward: 98.33390195956005 avg_loss_c: 4.354271660680356 avg_loss_a: -58.0868949337282\n",
            "Número de pasos del episodio 9791 son episode_steps:116\n",
            "Total Steps: 637325 Episode Num: 9791 Reward: 110.31199756258283 avg_loss_c: 5.355401540624684 avg_loss_a: -57.38005006724391\n",
            "Número de pasos del episodio 9792 son episode_steps:116\n",
            "Total Steps: 637441 Episode Num: 9792 Reward: 149.28378093406496 avg_loss_c: 5.33192738582348 avg_loss_a: -57.62801440008755\n",
            "Número de pasos del episodio 9793 son episode_steps:196\n",
            "Total Steps: 637637 Episode Num: 9793 Reward: 234.88276319856152 avg_loss_c: 4.926072057412595 avg_loss_a: -58.28619933614925\n",
            "Número de pasos del episodio 9794 son episode_steps:200\n",
            "Total Steps: 637837 Episode Num: 9794 Reward: 245.26178744204367 avg_loss_c: 4.886122493743897 avg_loss_a: -58.59915874481201\n",
            "Número de pasos del episodio 9795 son episode_steps:133\n",
            "Total Steps: 637970 Episode Num: 9795 Reward: 209.39766997804685 avg_loss_c: 4.700192958788764 avg_loss_a: -57.847567880960334\n",
            "Número de pasos del episodio 9796 son episode_steps:111\n",
            "Total Steps: 638081 Episode Num: 9796 Reward: 157.6340880954734 avg_loss_c: 4.96890724457062 avg_loss_a: -58.3575387903162\n",
            "Número de pasos del episodio 9797 son episode_steps:59\n",
            "Total Steps: 638140 Episode Num: 9797 Reward: 79.04755607053919 avg_loss_c: 4.702168238365044 avg_loss_a: -58.45612089512712\n",
            "Número de pasos del episodio 9798 son episode_steps:34\n",
            "Total Steps: 638174 Episode Num: 9798 Reward: -37.04008719316551 avg_loss_c: 5.023878728642183 avg_loss_a: -58.01645929673139\n",
            "Número de pasos del episodio 9799 son episode_steps:81\n",
            "Total Steps: 638255 Episode Num: 9799 Reward: 72.37601227887943 avg_loss_c: 5.185716431817891 avg_loss_a: -58.846416991433976\n",
            "Número de pasos del episodio 9800 son episode_steps:178\n",
            "Total Steps: 638433 Episode Num: 9800 Reward: 188.668859027164 avg_loss_c: 5.252201151312067 avg_loss_a: -57.8463767833924\n",
            "Número de pasos del episodio 9801 son episode_steps:87\n",
            "Total Steps: 638520 Episode Num: 9801 Reward: 134.6264267146323 avg_loss_c: 5.044397965244864 avg_loss_a: -58.96693942190587\n",
            "Número de pasos del episodio 9802 son episode_steps:156\n",
            "Total Steps: 638676 Episode Num: 9802 Reward: 210.34260355365402 avg_loss_c: 4.893939785468272 avg_loss_a: -58.185141685681465\n",
            "Número de pasos del episodio 9803 son episode_steps:117\n",
            "Total Steps: 638793 Episode Num: 9803 Reward: 168.1934369907411 avg_loss_c: 5.160284462138119 avg_loss_a: -58.51317857269548\n",
            "Número de pasos del episodio 9804 son episode_steps:155\n",
            "Total Steps: 638948 Episode Num: 9804 Reward: 185.31970328540166 avg_loss_c: 5.06887042753158 avg_loss_a: -58.909884865053236\n",
            "Número de pasos del episodio 9805 son episode_steps:101\n",
            "Total Steps: 639049 Episode Num: 9805 Reward: 125.62773573657427 avg_loss_c: 4.968443960246473 avg_loss_a: -58.3204338149269\n",
            "Número de pasos del episodio 9806 son episode_steps:132\n",
            "Total Steps: 639181 Episode Num: 9806 Reward: 87.70359157702455 avg_loss_c: 4.904632084297411 avg_loss_a: -58.1768802874016\n",
            "Número de pasos del episodio 9807 son episode_steps:176\n",
            "Total Steps: 639357 Episode Num: 9807 Reward: 229.0536977522786 avg_loss_c: 5.126630388877609 avg_loss_a: -58.84978758205067\n",
            "Número de pasos del episodio 9808 son episode_steps:75\n",
            "Total Steps: 639432 Episode Num: 9808 Reward: 100.66188471372769 avg_loss_c: 5.335984605153402 avg_loss_a: -59.347759653727216\n",
            "Número de pasos del episodio 9809 son episode_steps:149\n",
            "Total Steps: 639581 Episode Num: 9809 Reward: 185.50746170520506 avg_loss_c: 4.94425885309309 avg_loss_a: -58.6297274851959\n",
            "Número de pasos del episodio 9810 son episode_steps:167\n",
            "Total Steps: 639748 Episode Num: 9810 Reward: 212.72110084917358 avg_loss_c: 4.918320767179934 avg_loss_a: -59.01675890163033\n",
            "Número de pasos del episodio 9811 son episode_steps:179\n",
            "Total Steps: 639927 Episode Num: 9811 Reward: 273.50498732128034 avg_loss_c: 5.048465181329397 avg_loss_a: -59.03224101146506\n",
            "Número de pasos del episodio 9812 son episode_steps:98\n",
            "Total Steps: 640025 Episode Num: 9812 Reward: 128.0361640196823 avg_loss_c: 4.956645929083532 avg_loss_a: -58.87861633300781\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 163.894618\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9813 son episode_steps:124\n",
            "Total Steps: 640149 Episode Num: 9813 Reward: 164.18914210426752 avg_loss_c: 4.897646750173261 avg_loss_a: -59.08770358177923\n",
            "Número de pasos del episodio 9814 son episode_steps:191\n",
            "Total Steps: 640340 Episode Num: 9814 Reward: 277.5217171342527 avg_loss_c: 5.010971070584202 avg_loss_a: -58.463212557488085\n",
            "Número de pasos del episodio 9815 son episode_steps:55\n",
            "Total Steps: 640395 Episode Num: 9815 Reward: 31.793405535197756 avg_loss_c: 5.256113030693748 avg_loss_a: -58.83451628251509\n",
            "Número de pasos del episodio 9816 son episode_steps:104\n",
            "Total Steps: 640499 Episode Num: 9816 Reward: 123.61550826913316 avg_loss_c: 5.069899891431515 avg_loss_a: -58.967450215266304\n",
            "Número de pasos del episodio 9817 son episode_steps:101\n",
            "Total Steps: 640600 Episode Num: 9817 Reward: 111.64887144409727 avg_loss_c: 5.6894797051307 avg_loss_a: -58.73850658152363\n",
            "Número de pasos del episodio 9818 son episode_steps:75\n",
            "Total Steps: 640675 Episode Num: 9818 Reward: 92.53885110584923 avg_loss_c: 5.126005805333455 avg_loss_a: -58.6035796101888\n",
            "Número de pasos del episodio 9819 son episode_steps:193\n",
            "Total Steps: 640868 Episode Num: 9819 Reward: 281.28151796253593 avg_loss_c: 4.971824637348788 avg_loss_a: -59.06681859307956\n",
            "Número de pasos del episodio 9820 son episode_steps:68\n",
            "Total Steps: 640936 Episode Num: 9820 Reward: 21.06808388227885 avg_loss_c: 5.4007908912266 avg_loss_a: -58.978186551262354\n",
            "Número de pasos del episodio 9821 son episode_steps:120\n",
            "Total Steps: 641056 Episode Num: 9821 Reward: 184.47032332000214 avg_loss_c: 5.218480461835862 avg_loss_a: -58.61449120839437\n",
            "Número de pasos del episodio 9822 son episode_steps:193\n",
            "Total Steps: 641249 Episode Num: 9822 Reward: 283.6634320169186 avg_loss_c: 5.090929779981702 avg_loss_a: -58.70124348457613\n",
            "Número de pasos del episodio 9823 son episode_steps:198\n",
            "Total Steps: 641447 Episode Num: 9823 Reward: 292.7143753772146 avg_loss_c: 5.1285893218685885 avg_loss_a: -59.099498710247\n",
            "Número de pasos del episodio 9824 son episode_steps:123\n",
            "Total Steps: 641570 Episode Num: 9824 Reward: 168.77372177827135 avg_loss_c: 4.998254192553885 avg_loss_a: -59.146161118173985\n",
            "Número de pasos del episodio 9825 son episode_steps:147\n",
            "Total Steps: 641717 Episode Num: 9825 Reward: 206.76112751783842 avg_loss_c: 5.001422444168402 avg_loss_a: -59.16685859524474\n",
            "Número de pasos del episodio 9826 son episode_steps:180\n",
            "Total Steps: 641897 Episode Num: 9826 Reward: 245.8608852592462 avg_loss_c: 4.9288075049718225 avg_loss_a: -59.55099021063911\n",
            "Número de pasos del episodio 9827 son episode_steps:131\n",
            "Total Steps: 642028 Episode Num: 9827 Reward: 181.173029296669 avg_loss_c: 5.183167976277475 avg_loss_a: -59.590100761588296\n",
            "Número de pasos del episodio 9828 son episode_steps:100\n",
            "Total Steps: 642128 Episode Num: 9828 Reward: 123.52381863201852 avg_loss_c: 5.215800411701203 avg_loss_a: -59.44380859375\n",
            "Número de pasos del episodio 9829 son episode_steps:55\n",
            "Total Steps: 642183 Episode Num: 9829 Reward: 70.73009638606929 avg_loss_c: 5.252283152666959 avg_loss_a: -59.48792093450373\n",
            "Número de pasos del episodio 9830 son episode_steps:115\n",
            "Total Steps: 642298 Episode Num: 9830 Reward: 163.83504753532176 avg_loss_c: 5.065284444974816 avg_loss_a: -59.451586250636886\n",
            "Número de pasos del episodio 9831 son episode_steps:39\n",
            "Total Steps: 642337 Episode Num: 9831 Reward: 8.185941683234708 avg_loss_c: 5.031417492108467 avg_loss_a: -58.380687615810295\n",
            "Número de pasos del episodio 9832 son episode_steps:163\n",
            "Total Steps: 642500 Episode Num: 9832 Reward: 257.5963601568817 avg_loss_c: 5.226336875576183 avg_loss_a: -59.23695179289835\n",
            "Número de pasos del episodio 9833 son episode_steps:126\n",
            "Total Steps: 642626 Episode Num: 9833 Reward: 176.6027425138964 avg_loss_c: 5.172893552553086 avg_loss_a: -60.084208776080416\n",
            "Número de pasos del episodio 9834 son episode_steps:132\n",
            "Total Steps: 642758 Episode Num: 9834 Reward: 153.56197085176453 avg_loss_c: 5.469455746087161 avg_loss_a: -59.40588061014811\n",
            "Número de pasos del episodio 9835 son episode_steps:84\n",
            "Total Steps: 642842 Episode Num: 9835 Reward: 96.82873712549966 avg_loss_c: 5.323750711622692 avg_loss_a: -59.6202632359096\n",
            "Número de pasos del episodio 9836 son episode_steps:141\n",
            "Total Steps: 642983 Episode Num: 9836 Reward: 204.0935229971988 avg_loss_c: 5.262637266876005 avg_loss_a: -59.06164745574302\n",
            "Número de pasos del episodio 9837 son episode_steps:156\n",
            "Total Steps: 643139 Episode Num: 9837 Reward: 230.07144301758538 avg_loss_c: 4.928835842853937 avg_loss_a: -59.97786556146084\n",
            "Número de pasos del episodio 9838 son episode_steps:124\n",
            "Total Steps: 643263 Episode Num: 9838 Reward: 159.94446549694672 avg_loss_c: 5.2914965652650405 avg_loss_a: -59.44936555431735\n",
            "Número de pasos del episodio 9839 son episode_steps:196\n",
            "Total Steps: 643459 Episode Num: 9839 Reward: 327.56181880519483 avg_loss_c: 5.0320049731098875 avg_loss_a: -59.916826248168945\n",
            "Número de pasos del episodio 9840 son episode_steps:87\n",
            "Total Steps: 643546 Episode Num: 9840 Reward: 103.3816121128943 avg_loss_c: 4.983768857758621 avg_loss_a: -60.635896792356995\n",
            "Número de pasos del episodio 9841 son episode_steps:76\n",
            "Total Steps: 643622 Episode Num: 9841 Reward: 65.74487442712672 avg_loss_c: 5.1144086718559265 avg_loss_a: -59.76177988554302\n",
            "Número de pasos del episodio 9842 son episode_steps:111\n",
            "Total Steps: 643733 Episode Num: 9842 Reward: 128.1926491671646 avg_loss_c: 5.27540499884803 avg_loss_a: -59.33715799692515\n",
            "Número de pasos del episodio 9843 son episode_steps:143\n",
            "Total Steps: 643876 Episode Num: 9843 Reward: 203.55806282283328 avg_loss_c: 5.167810586782602 avg_loss_a: -59.23511787894722\n",
            "Número de pasos del episodio 9844 son episode_steps:81\n",
            "Total Steps: 643957 Episode Num: 9844 Reward: 117.16993923607966 avg_loss_c: 5.3672115832199285 avg_loss_a: -59.46171932455934\n",
            "Número de pasos del episodio 9845 son episode_steps:123\n",
            "Total Steps: 644080 Episode Num: 9845 Reward: 171.81539583618795 avg_loss_c: 5.256731039140282 avg_loss_a: -59.59395462904519\n",
            "Número de pasos del episodio 9846 son episode_steps:138\n",
            "Total Steps: 644218 Episode Num: 9846 Reward: 184.59531815914926 avg_loss_c: 5.22288147435672 avg_loss_a: -59.722455121468805\n",
            "Número de pasos del episodio 9847 son episode_steps:118\n",
            "Total Steps: 644336 Episode Num: 9847 Reward: 154.96244972512943 avg_loss_c: 5.453195973978204 avg_loss_a: -58.87100103345968\n",
            "Número de pasos del episodio 9848 son episode_steps:91\n",
            "Total Steps: 644427 Episode Num: 9848 Reward: 116.60963092114163 avg_loss_c: 5.446224372465532 avg_loss_a: -58.880354367769684\n",
            "Número de pasos del episodio 9849 son episode_steps:88\n",
            "Total Steps: 644515 Episode Num: 9849 Reward: 132.42542559020094 avg_loss_c: 5.3190592500296505 avg_loss_a: -58.79913720217618\n",
            "Número de pasos del episodio 9850 son episode_steps:184\n",
            "Total Steps: 644699 Episode Num: 9850 Reward: 267.2368576812828 avg_loss_c: 5.344362048999123 avg_loss_a: -59.393671740656316\n",
            "Número de pasos del episodio 9851 son episode_steps:70\n",
            "Total Steps: 644769 Episode Num: 9851 Reward: 6.3134544571914395 avg_loss_c: 5.5542283500943865 avg_loss_a: -59.455075073242185\n",
            "Número de pasos del episodio 9852 son episode_steps:87\n",
            "Total Steps: 644856 Episode Num: 9852 Reward: 73.23751098010234 avg_loss_c: 5.765620812602426 avg_loss_a: -59.77685042633407\n",
            "Número de pasos del episodio 9853 son episode_steps:244\n",
            "Total Steps: 645100 Episode Num: 9853 Reward: 308.14239464553265 avg_loss_c: 5.731641763546428 avg_loss_a: -59.93472480773926\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 165.221405\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9854 son episode_steps:78\n",
            "Total Steps: 645178 Episode Num: 9854 Reward: 99.36062194139072 avg_loss_c: 6.170878746570685 avg_loss_a: -59.449068020551636\n",
            "Número de pasos del episodio 9855 son episode_steps:126\n",
            "Total Steps: 645304 Episode Num: 9855 Reward: 167.07541669002006 avg_loss_c: 5.817845335082402 avg_loss_a: -59.048257313077414\n",
            "Número de pasos del episodio 9856 son episode_steps:101\n",
            "Total Steps: 645405 Episode Num: 9856 Reward: 159.48923514783044 avg_loss_c: 5.621327022514721 avg_loss_a: -59.341111513647704\n",
            "Número de pasos del episodio 9857 son episode_steps:264\n",
            "Total Steps: 645669 Episode Num: 9857 Reward: 349.4289745658262 avg_loss_c: 5.767083736983213 avg_loss_a: -59.817864967115\n",
            "Número de pasos del episodio 9858 son episode_steps:80\n",
            "Total Steps: 645749 Episode Num: 9858 Reward: 105.69620375011085 avg_loss_c: 5.652566686272621 avg_loss_a: -59.903962802886966\n",
            "Número de pasos del episodio 9859 son episode_steps:147\n",
            "Total Steps: 645896 Episode Num: 9859 Reward: 167.32007584450986 avg_loss_c: 5.7870448073562315 avg_loss_a: -59.651733865543285\n",
            "Número de pasos del episodio 9860 son episode_steps:98\n",
            "Total Steps: 645994 Episode Num: 9860 Reward: 147.56628342804373 avg_loss_c: 5.400830585129407 avg_loss_a: -59.77657863071987\n",
            "Número de pasos del episodio 9861 son episode_steps:96\n",
            "Total Steps: 646090 Episode Num: 9861 Reward: 2.0061699519641385 avg_loss_c: 6.018739973505338 avg_loss_a: -59.032754262288414\n",
            "Número de pasos del episodio 9862 son episode_steps:139\n",
            "Total Steps: 646229 Episode Num: 9862 Reward: 149.35528856845553 avg_loss_c: 6.013404074332697 avg_loss_a: -59.81065420795688\n",
            "Número de pasos del episodio 9863 son episode_steps:85\n",
            "Total Steps: 646314 Episode Num: 9863 Reward: 77.33282012134934 avg_loss_c: 5.952962112426758 avg_loss_a: -59.45071532305549\n",
            "Número de pasos del episodio 9864 son episode_steps:111\n",
            "Total Steps: 646425 Episode Num: 9864 Reward: 147.81824722761763 avg_loss_c: 6.022321533512425 avg_loss_a: -59.528002214861345\n",
            "Número de pasos del episodio 9865 son episode_steps:95\n",
            "Total Steps: 646520 Episode Num: 9865 Reward: 116.31048335930957 avg_loss_c: 5.755044211839374 avg_loss_a: -60.26307256598221\n",
            "Número de pasos del episodio 9866 son episode_steps:143\n",
            "Total Steps: 646663 Episode Num: 9866 Reward: 215.15267794924716 avg_loss_c: 5.538774623737469 avg_loss_a: -59.749148628928445\n",
            "Número de pasos del episodio 9867 son episode_steps:149\n",
            "Total Steps: 646812 Episode Num: 9867 Reward: 222.75260937888842 avg_loss_c: 5.661708178936235 avg_loss_a: -60.74402416152442\n",
            "Número de pasos del episodio 9868 son episode_steps:93\n",
            "Total Steps: 646905 Episode Num: 9868 Reward: 135.48550500014804 avg_loss_c: 5.661319653193156 avg_loss_a: -60.23170852661133\n",
            "Número de pasos del episodio 9869 son episode_steps:106\n",
            "Total Steps: 647011 Episode Num: 9869 Reward: 64.56963376405162 avg_loss_c: 5.842648897530897 avg_loss_a: -60.20953426720961\n",
            "Número de pasos del episodio 9870 son episode_steps:135\n",
            "Total Steps: 647146 Episode Num: 9870 Reward: 208.2849118526817 avg_loss_c: 5.7735412844905145 avg_loss_a: -59.995616828070744\n",
            "Número de pasos del episodio 9871 son episode_steps:205\n",
            "Total Steps: 647351 Episode Num: 9871 Reward: 284.40863385327515 avg_loss_c: 5.921874024228352 avg_loss_a: -59.707947428633524\n",
            "Número de pasos del episodio 9872 son episode_steps:165\n",
            "Total Steps: 647516 Episode Num: 9872 Reward: 220.32049549156682 avg_loss_c: 5.6162158749320295 avg_loss_a: -60.27893787730824\n",
            "Número de pasos del episodio 9873 son episode_steps:138\n",
            "Total Steps: 647654 Episode Num: 9873 Reward: 183.14751220749562 avg_loss_c: 5.534331741540329 avg_loss_a: -60.151048135066375\n",
            "Número de pasos del episodio 9874 son episode_steps:133\n",
            "Total Steps: 647787 Episode Num: 9874 Reward: 182.70092776388245 avg_loss_c: 5.543123239861395 avg_loss_a: -60.00150393722649\n",
            "Número de pasos del episodio 9875 son episode_steps:88\n",
            "Total Steps: 647875 Episode Num: 9875 Reward: 108.31343237835702 avg_loss_c: 5.903433675115759 avg_loss_a: -60.024103684858844\n",
            "Número de pasos del episodio 9876 son episode_steps:162\n",
            "Total Steps: 648037 Episode Num: 9876 Reward: 171.14532932432454 avg_loss_c: 5.909170724727489 avg_loss_a: -60.219863514841336\n",
            "Número de pasos del episodio 9877 son episode_steps:37\n",
            "Total Steps: 648074 Episode Num: 9877 Reward: -14.074707374444841 avg_loss_c: 6.216702255042824 avg_loss_a: -59.50124142621014\n",
            "Número de pasos del episodio 9878 son episode_steps:141\n",
            "Total Steps: 648215 Episode Num: 9878 Reward: 206.09136075658455 avg_loss_c: 5.988857566887606 avg_loss_a: -59.94350890572189\n",
            "Número de pasos del episodio 9879 son episode_steps:50\n",
            "Total Steps: 648265 Episode Num: 9879 Reward: 11.848629924245204 avg_loss_c: 5.860626230239868 avg_loss_a: -59.94740509033203\n",
            "Número de pasos del episodio 9880 son episode_steps:127\n",
            "Total Steps: 648392 Episode Num: 9880 Reward: 132.56212776230643 avg_loss_c: 6.084036479784748 avg_loss_a: -59.77279026301827\n",
            "Número de pasos del episodio 9881 son episode_steps:128\n",
            "Total Steps: 648520 Episode Num: 9881 Reward: 198.70452017515413 avg_loss_c: 5.938106890767813 avg_loss_a: -59.96123290061951\n",
            "Número de pasos del episodio 9882 son episode_steps:184\n",
            "Total Steps: 648704 Episode Num: 9882 Reward: 153.5520526668882 avg_loss_c: 6.4484470201575235 avg_loss_a: -59.506170728932254\n",
            "Número de pasos del episodio 9883 son episode_steps:108\n",
            "Total Steps: 648812 Episode Num: 9883 Reward: 154.23051511352926 avg_loss_c: 6.079191159318994 avg_loss_a: -59.49418640136719\n",
            "Número de pasos del episodio 9884 son episode_steps:96\n",
            "Total Steps: 648908 Episode Num: 9884 Reward: 143.92829065547068 avg_loss_c: 6.497471022109191 avg_loss_a: -59.38370664914449\n",
            "Número de pasos del episodio 9885 son episode_steps:103\n",
            "Total Steps: 649011 Episode Num: 9885 Reward: 166.28660362189135 avg_loss_c: 6.1469716747987615 avg_loss_a: -59.732694533264755\n",
            "Número de pasos del episodio 9886 son episode_steps:165\n",
            "Total Steps: 649176 Episode Num: 9886 Reward: 203.68748338749347 avg_loss_c: 6.286013275204283 avg_loss_a: -59.720561449455495\n",
            "Número de pasos del episodio 9887 son episode_steps:154\n",
            "Total Steps: 649330 Episode Num: 9887 Reward: 210.17700589589543 avg_loss_c: 6.317549948568468 avg_loss_a: -59.88427882999569\n",
            "Número de pasos del episodio 9888 son episode_steps:194\n",
            "Total Steps: 649524 Episode Num: 9888 Reward: 235.07664746419553 avg_loss_c: 6.387031426134798 avg_loss_a: -60.18283938378403\n",
            "Número de pasos del episodio 9889 son episode_steps:106\n",
            "Total Steps: 649630 Episode Num: 9889 Reward: 149.31988885647095 avg_loss_c: 6.885100216235754 avg_loss_a: -59.754946366795956\n",
            "Número de pasos del episodio 9890 son episode_steps:134\n",
            "Total Steps: 649764 Episode Num: 9890 Reward: 224.36176527429782 avg_loss_c: 6.690122883711288 avg_loss_a: -59.82551500690517\n",
            "Número de pasos del episodio 9891 son episode_steps:118\n",
            "Total Steps: 649882 Episode Num: 9891 Reward: 148.11202168259365 avg_loss_c: 6.3381209151219515 avg_loss_a: -60.48300086845786\n",
            "Número de pasos del episodio 9892 son episode_steps:122\n",
            "Total Steps: 650004 Episode Num: 9892 Reward: 182.59920876799285 avg_loss_c: 6.245799150623259 avg_loss_a: -59.81543981833536\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 116.443558\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9893 son episode_steps:105\n",
            "Total Steps: 650109 Episode Num: 9893 Reward: 150.25700423536594 avg_loss_c: 7.383736898785545 avg_loss_a: -59.795238276890345\n",
            "Número de pasos del episodio 9894 son episode_steps:107\n",
            "Total Steps: 650216 Episode Num: 9894 Reward: 125.61668925880969 avg_loss_c: 6.1305641682348515 avg_loss_a: -60.157075400664425\n",
            "Número de pasos del episodio 9895 son episode_steps:112\n",
            "Total Steps: 650328 Episode Num: 9895 Reward: 157.99817195794407 avg_loss_c: 6.261401457445962 avg_loss_a: -59.99158654894148\n",
            "Número de pasos del episodio 9896 son episode_steps:143\n",
            "Total Steps: 650471 Episode Num: 9896 Reward: 163.99218501677012 avg_loss_c: 6.488918526189311 avg_loss_a: -60.199682755903765\n",
            "Número de pasos del episodio 9897 son episode_steps:89\n",
            "Total Steps: 650560 Episode Num: 9897 Reward: 93.8775094568041 avg_loss_c: 6.186066812343812 avg_loss_a: -60.01443069972349\n",
            "Número de pasos del episodio 9898 son episode_steps:132\n",
            "Total Steps: 650692 Episode Num: 9898 Reward: 126.0369269347988 avg_loss_c: 6.052195319623658 avg_loss_a: -60.453373764500476\n",
            "Número de pasos del episodio 9899 son episode_steps:117\n",
            "Total Steps: 650809 Episode Num: 9899 Reward: 196.61302357243355 avg_loss_c: 6.26740768016913 avg_loss_a: -60.412605742104034\n",
            "Número de pasos del episodio 9900 son episode_steps:151\n",
            "Total Steps: 650960 Episode Num: 9900 Reward: 205.43994890522094 avg_loss_c: 6.281224512896001 avg_loss_a: -60.421398036527314\n",
            "Número de pasos del episodio 9901 son episode_steps:183\n",
            "Total Steps: 651143 Episode Num: 9901 Reward: 289.0037610365849 avg_loss_c: 5.97934769411556 avg_loss_a: -60.802888880661925\n",
            "Número de pasos del episodio 9902 son episode_steps:69\n",
            "Total Steps: 651212 Episode Num: 9902 Reward: 91.70429568950198 avg_loss_c: 6.076042610666026 avg_loss_a: -59.935828001602836\n",
            "Número de pasos del episodio 9903 son episode_steps:90\n",
            "Total Steps: 651302 Episode Num: 9903 Reward: 120.7593870047233 avg_loss_c: 6.212332985136244 avg_loss_a: -60.173943583170576\n",
            "Número de pasos del episodio 9904 son episode_steps:107\n",
            "Total Steps: 651409 Episode Num: 9904 Reward: 150.84181848726286 avg_loss_c: 6.060349156923383 avg_loss_a: -60.97536525548062\n",
            "Número de pasos del episodio 9905 son episode_steps:80\n",
            "Total Steps: 651489 Episode Num: 9905 Reward: 104.21372253117188 avg_loss_c: 6.02332991361618 avg_loss_a: -60.72288312911987\n",
            "Número de pasos del episodio 9906 son episode_steps:80\n",
            "Total Steps: 651569 Episode Num: 9906 Reward: 109.7266278121942 avg_loss_c: 5.9507519721984865 avg_loss_a: -60.80786647796631\n",
            "Número de pasos del episodio 9907 son episode_steps:64\n",
            "Total Steps: 651633 Episode Num: 9907 Reward: 98.29851994859963 avg_loss_c: 5.797243058681488 avg_loss_a: -60.591330766677856\n",
            "Número de pasos del episodio 9908 son episode_steps:84\n",
            "Total Steps: 651717 Episode Num: 9908 Reward: 115.96473258649297 avg_loss_c: 6.274501508190518 avg_loss_a: -61.22275198073614\n",
            "Número de pasos del episodio 9909 son episode_steps:172\n",
            "Total Steps: 651889 Episode Num: 9909 Reward: 248.24888109148972 avg_loss_c: 5.998431379018828 avg_loss_a: -60.854695076166195\n",
            "Número de pasos del episodio 9910 son episode_steps:101\n",
            "Total Steps: 651990 Episode Num: 9910 Reward: 154.10555404039798 avg_loss_c: 6.106327278779284 avg_loss_a: -61.20615311424331\n",
            "Número de pasos del episodio 9911 son episode_steps:124\n",
            "Total Steps: 652114 Episode Num: 9911 Reward: 185.89098724141948 avg_loss_c: 5.606981290924933 avg_loss_a: -60.75311691530289\n",
            "Número de pasos del episodio 9912 son episode_steps:61\n",
            "Total Steps: 652175 Episode Num: 9912 Reward: -26.379163866892412 avg_loss_c: 6.2362406097474645 avg_loss_a: -60.234219848132525\n",
            "Número de pasos del episodio 9913 son episode_steps:74\n",
            "Total Steps: 652249 Episode Num: 9913 Reward: 93.66418428470466 avg_loss_c: 6.464687514949489 avg_loss_a: -60.08669744955527\n",
            "Número de pasos del episodio 9914 son episode_steps:172\n",
            "Total Steps: 652421 Episode Num: 9914 Reward: 239.84393677383582 avg_loss_c: 6.130131774170454 avg_loss_a: -60.64539031095283\n",
            "Número de pasos del episodio 9915 son episode_steps:119\n",
            "Total Steps: 652540 Episode Num: 9915 Reward: 182.5063764714517 avg_loss_c: 6.314829044983167 avg_loss_a: -60.70520426646\n",
            "Número de pasos del episodio 9916 son episode_steps:131\n",
            "Total Steps: 652671 Episode Num: 9916 Reward: 214.41809780002814 avg_loss_c: 6.428490684232639 avg_loss_a: -60.93319731268264\n",
            "Número de pasos del episodio 9917 son episode_steps:263\n",
            "Total Steps: 652934 Episode Num: 9917 Reward: 327.57677611468563 avg_loss_c: 6.031556247305054 avg_loss_a: -60.96247873922718\n",
            "Número de pasos del episodio 9918 son episode_steps:235\n",
            "Total Steps: 653169 Episode Num: 9918 Reward: 373.3048106397952 avg_loss_c: 6.075163074249917 avg_loss_a: -61.53404959820686\n",
            "Número de pasos del episodio 9919 son episode_steps:64\n",
            "Total Steps: 653233 Episode Num: 9919 Reward: 93.27785284760607 avg_loss_c: 5.894538335502148 avg_loss_a: -60.82422614097595\n",
            "Número de pasos del episodio 9920 son episode_steps:107\n",
            "Total Steps: 653340 Episode Num: 9920 Reward: 154.48802991886413 avg_loss_c: 5.80899538503629 avg_loss_a: -60.844326054938485\n",
            "Número de pasos del episodio 9921 son episode_steps:122\n",
            "Total Steps: 653462 Episode Num: 9921 Reward: 176.5014166672006 avg_loss_c: 6.126051144521744 avg_loss_a: -61.3268807833312\n",
            "Número de pasos del episodio 9922 son episode_steps:224\n",
            "Total Steps: 653686 Episode Num: 9922 Reward: 295.1959153241769 avg_loss_c: 5.9751753104584555 avg_loss_a: -61.669198513031006\n",
            "Número de pasos del episodio 9923 son episode_steps:87\n",
            "Total Steps: 653773 Episode Num: 9923 Reward: 131.2691207209001 avg_loss_c: 5.758851525427281 avg_loss_a: -62.03539127042924\n",
            "Número de pasos del episodio 9924 son episode_steps:84\n",
            "Total Steps: 653857 Episode Num: 9924 Reward: 121.98605008858564 avg_loss_c: 5.779915940193903 avg_loss_a: -60.66219030107771\n",
            "Número de pasos del episodio 9925 son episode_steps:84\n",
            "Total Steps: 653941 Episode Num: 9925 Reward: 76.90179363939836 avg_loss_c: 5.762273084549677 avg_loss_a: -62.42261823018392\n",
            "Número de pasos del episodio 9926 son episode_steps:172\n",
            "Total Steps: 654113 Episode Num: 9926 Reward: 248.81724981961372 avg_loss_c: 5.614888207856999 avg_loss_a: -61.842200079629585\n",
            "Número de pasos del episodio 9927 son episode_steps:239\n",
            "Total Steps: 654352 Episode Num: 9927 Reward: 383.7372585729988 avg_loss_c: 5.882558973264494 avg_loss_a: -61.97466016314519\n",
            "Número de pasos del episodio 9928 son episode_steps:127\n",
            "Total Steps: 654479 Episode Num: 9928 Reward: 171.5504420963111 avg_loss_c: 5.579332683968731 avg_loss_a: -61.8350988373043\n",
            "Número de pasos del episodio 9929 son episode_steps:83\n",
            "Total Steps: 654562 Episode Num: 9929 Reward: 121.83640187329877 avg_loss_c: 5.448748082999724 avg_loss_a: -62.20303652659956\n",
            "Número de pasos del episodio 9930 son episode_steps:121\n",
            "Total Steps: 654683 Episode Num: 9930 Reward: 175.4912586419543 avg_loss_c: 5.606910727240822 avg_loss_a: -62.008766174316406\n",
            "Número de pasos del episodio 9931 son episode_steps:279\n",
            "Total Steps: 654962 Episode Num: 9931 Reward: 357.59326802340433 avg_loss_c: 5.786229407915505 avg_loss_a: -61.69095287528089\n",
            "Número de pasos del episodio 9932 son episode_steps:87\n",
            "Total Steps: 655049 Episode Num: 9932 Reward: 121.35298108277995 avg_loss_c: 5.541347004901404 avg_loss_a: -61.948147697010256\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 213.580058\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9933 son episode_steps:192\n",
            "Total Steps: 655241 Episode Num: 9933 Reward: 306.0424302064681 avg_loss_c: 5.556708166996638 avg_loss_a: -62.655451575915016\n",
            "Número de pasos del episodio 9934 son episode_steps:109\n",
            "Total Steps: 655350 Episode Num: 9934 Reward: 165.15621789176657 avg_loss_c: 5.587702121209661 avg_loss_a: -62.431179466597534\n",
            "Número de pasos del episodio 9935 son episode_steps:125\n",
            "Total Steps: 655475 Episode Num: 9935 Reward: 205.2950589672264 avg_loss_c: 5.631667778015137 avg_loss_a: -61.86103625488281\n",
            "Número de pasos del episodio 9936 son episode_steps:115\n",
            "Total Steps: 655590 Episode Num: 9936 Reward: 170.14669808411782 avg_loss_c: 5.544068079409392 avg_loss_a: -62.0523809681768\n",
            "Número de pasos del episodio 9937 son episode_steps:57\n",
            "Total Steps: 655647 Episode Num: 9937 Reward: 45.761293005687826 avg_loss_c: 6.257574692107084 avg_loss_a: -62.463374489232116\n",
            "Número de pasos del episodio 9938 son episode_steps:102\n",
            "Total Steps: 655749 Episode Num: 9938 Reward: 153.81011986009315 avg_loss_c: 5.459587695551853 avg_loss_a: -63.199866350959326\n",
            "Número de pasos del episodio 9939 son episode_steps:135\n",
            "Total Steps: 655884 Episode Num: 9939 Reward: 179.01677837019753 avg_loss_c: 5.763402366638184 avg_loss_a: -62.409429479528356\n",
            "Número de pasos del episodio 9940 son episode_steps:93\n",
            "Total Steps: 655977 Episode Num: 9940 Reward: 95.92134446933672 avg_loss_c: 5.930770233113279 avg_loss_a: -61.97519753568916\n",
            "Número de pasos del episodio 9941 son episode_steps:123\n",
            "Total Steps: 656100 Episode Num: 9941 Reward: 159.72327203359552 avg_loss_c: 5.977927630509788 avg_loss_a: -62.356400404519185\n",
            "Número de pasos del episodio 9942 son episode_steps:126\n",
            "Total Steps: 656226 Episode Num: 9942 Reward: 171.0696423551678 avg_loss_c: 5.762962365907336 avg_loss_a: -62.249591100783576\n",
            "Número de pasos del episodio 9943 son episode_steps:162\n",
            "Total Steps: 656388 Episode Num: 9943 Reward: 221.81559133269369 avg_loss_c: 5.677590008135195 avg_loss_a: -62.71506147031431\n",
            "Número de pasos del episodio 9944 son episode_steps:88\n",
            "Total Steps: 656476 Episode Num: 9944 Reward: 138.87024601716604 avg_loss_c: 5.731118660081517 avg_loss_a: -62.33322863145308\n",
            "Número de pasos del episodio 9945 son episode_steps:134\n",
            "Total Steps: 656610 Episode Num: 9945 Reward: 208.5467729277802 avg_loss_c: 5.542510185668718 avg_loss_a: -62.69097120370438\n",
            "Número de pasos del episodio 9946 son episode_steps:119\n",
            "Total Steps: 656729 Episode Num: 9946 Reward: 166.0331760921093 avg_loss_c: 5.781880827511058 avg_loss_a: -62.4249281682888\n",
            "Número de pasos del episodio 9947 son episode_steps:119\n",
            "Total Steps: 656848 Episode Num: 9947 Reward: 162.65520286360433 avg_loss_c: 5.985258493102899 avg_loss_a: -62.68643476983078\n",
            "Número de pasos del episodio 9948 son episode_steps:162\n",
            "Total Steps: 657010 Episode Num: 9948 Reward: 261.254185398981 avg_loss_c: 5.7570413954464 avg_loss_a: -62.54045345165111\n",
            "Número de pasos del episodio 9949 son episode_steps:53\n",
            "Total Steps: 657063 Episode Num: 9949 Reward: 31.315788840901607 avg_loss_c: 5.629976380546138 avg_loss_a: -62.67312830799031\n",
            "Número de pasos del episodio 9950 son episode_steps:121\n",
            "Total Steps: 657184 Episode Num: 9950 Reward: 135.97724259360038 avg_loss_c: 5.753376481946835 avg_loss_a: -62.5323090986772\n",
            "Número de pasos del episodio 9951 son episode_steps:126\n",
            "Total Steps: 657310 Episode Num: 9951 Reward: 199.5615753620495 avg_loss_c: 5.591015117509024 avg_loss_a: -62.68303916567848\n",
            "Número de pasos del episodio 9952 son episode_steps:81\n",
            "Total Steps: 657391 Episode Num: 9952 Reward: 118.3046164712318 avg_loss_c: 5.6726818850011 avg_loss_a: -62.60817958690502\n",
            "Número de pasos del episodio 9953 son episode_steps:119\n",
            "Total Steps: 657510 Episode Num: 9953 Reward: 188.6447534652223 avg_loss_c: 5.699093013250527 avg_loss_a: -62.51303780179064\n",
            "Número de pasos del episodio 9954 son episode_steps:212\n",
            "Total Steps: 657722 Episode Num: 9954 Reward: 329.9110393682185 avg_loss_c: 5.6148093680165845 avg_loss_a: -63.0164232793844\n",
            "Número de pasos del episodio 9955 son episode_steps:73\n",
            "Total Steps: 657795 Episode Num: 9955 Reward: 108.7528488624029 avg_loss_c: 5.526344750025501 avg_loss_a: -62.53391704820607\n",
            "Número de pasos del episodio 9956 son episode_steps:213\n",
            "Total Steps: 658008 Episode Num: 9956 Reward: 300.14152529488155 avg_loss_c: 5.504355194423121 avg_loss_a: -62.963193078555975\n",
            "Número de pasos del episodio 9957 son episode_steps:129\n",
            "Total Steps: 658137 Episode Num: 9957 Reward: 189.07708760374524 avg_loss_c: 5.675678214361501 avg_loss_a: -62.64977252575778\n",
            "Número de pasos del episodio 9958 son episode_steps:103\n",
            "Total Steps: 658240 Episode Num: 9958 Reward: 131.67968028965427 avg_loss_c: 5.263622716792579 avg_loss_a: -62.32625665016545\n",
            "Número de pasos del episodio 9959 son episode_steps:206\n",
            "Total Steps: 658446 Episode Num: 9959 Reward: 285.6786644012488 avg_loss_c: 5.603227991502262 avg_loss_a: -63.26276975465052\n",
            "Número de pasos del episodio 9960 son episode_steps:157\n",
            "Total Steps: 658603 Episode Num: 9960 Reward: 253.25530470299748 avg_loss_c: 5.436266750287098 avg_loss_a: -63.44424642575015\n",
            "Número de pasos del episodio 9961 son episode_steps:124\n",
            "Total Steps: 658727 Episode Num: 9961 Reward: 173.1452658528633 avg_loss_c: 5.723256303418067 avg_loss_a: -62.50463664147161\n",
            "Número de pasos del episodio 9962 son episode_steps:168\n",
            "Total Steps: 658895 Episode Num: 9962 Reward: 281.0539316653388 avg_loss_c: 5.347876043546767 avg_loss_a: -63.561649277096706\n",
            "Número de pasos del episodio 9963 son episode_steps:69\n",
            "Total Steps: 658964 Episode Num: 9963 Reward: 84.89154935293655 avg_loss_c: 5.569115127342335 avg_loss_a: -63.05943873308707\n",
            "Número de pasos del episodio 9964 son episode_steps:84\n",
            "Total Steps: 659048 Episode Num: 9964 Reward: 100.13563520045801 avg_loss_c: 5.323793028082166 avg_loss_a: -63.550709134056454\n",
            "Número de pasos del episodio 9965 son episode_steps:144\n",
            "Total Steps: 659192 Episode Num: 9965 Reward: 183.45270140192792 avg_loss_c: 5.607666783862644 avg_loss_a: -63.27398003472222\n",
            "Número de pasos del episodio 9966 son episode_steps:101\n",
            "Total Steps: 659293 Episode Num: 9966 Reward: 153.77347006694336 avg_loss_c: 5.6488067891338085 avg_loss_a: -63.629682370931796\n",
            "Número de pasos del episodio 9967 son episode_steps:104\n",
            "Total Steps: 659397 Episode Num: 9967 Reward: 140.24388346761384 avg_loss_c: 5.437427470317254 avg_loss_a: -63.20388177724985\n",
            "Número de pasos del episodio 9968 son episode_steps:213\n",
            "Total Steps: 659610 Episode Num: 9968 Reward: 312.5140949246586 avg_loss_c: 5.459960700200757 avg_loss_a: -63.50552262498739\n",
            "Número de pasos del episodio 9969 son episode_steps:118\n",
            "Total Steps: 659728 Episode Num: 9969 Reward: 170.59879270174346 avg_loss_c: 5.630442623364723 avg_loss_a: -63.854229878571076\n",
            "Número de pasos del episodio 9970 son episode_steps:128\n",
            "Total Steps: 659856 Episode Num: 9970 Reward: 164.9597175828984 avg_loss_c: 5.574345549568534 avg_loss_a: -63.97780603170395\n",
            "Número de pasos del episodio 9971 son episode_steps:197\n",
            "Total Steps: 660053 Episode Num: 9971 Reward: 246.89766073759236 avg_loss_c: 5.555384782365131 avg_loss_a: -63.54896258823763\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 151.749506\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 9972 son episode_steps:92\n",
            "Total Steps: 660145 Episode Num: 9972 Reward: 92.66149548280659 avg_loss_c: 5.679091733434926 avg_loss_a: -62.57099715523098\n",
            "Número de pasos del episodio 9973 son episode_steps:173\n",
            "Total Steps: 660318 Episode Num: 9973 Reward: 250.78574456910482 avg_loss_c: 5.5241973689525805 avg_loss_a: -63.89864503717147\n",
            "Número de pasos del episodio 9974 son episode_steps:128\n",
            "Total Steps: 660446 Episode Num: 9974 Reward: 187.04787676069554 avg_loss_c: 5.601775282993913 avg_loss_a: -63.57707244157791\n",
            "Número de pasos del episodio 9975 son episode_steps:148\n",
            "Total Steps: 660594 Episode Num: 9975 Reward: 210.5698239950776 avg_loss_c: 5.2272510286924 avg_loss_a: -63.524977812895905\n",
            "Número de pasos del episodio 9976 son episode_steps:169\n",
            "Total Steps: 660763 Episode Num: 9976 Reward: 234.68851795722514 avg_loss_c: 5.277646311641445 avg_loss_a: -63.385256840632515\n",
            "Número de pasos del episodio 9977 son episode_steps:142\n",
            "Total Steps: 660905 Episode Num: 9977 Reward: 200.3247259807144 avg_loss_c: 5.485133515277379 avg_loss_a: -63.97589944114148\n",
            "Número de pasos del episodio 9978 son episode_steps:142\n",
            "Total Steps: 661047 Episode Num: 9978 Reward: 153.92087205374207 avg_loss_c: 5.315762219294696 avg_loss_a: -63.75313707808374\n",
            "Número de pasos del episodio 9979 son episode_steps:48\n",
            "Total Steps: 661095 Episode Num: 9979 Reward: 32.020451677030096 avg_loss_c: 5.742823695143064 avg_loss_a: -63.61408185958862\n",
            "Número de pasos del episodio 9980 son episode_steps:352\n",
            "Total Steps: 661447 Episode Num: 9980 Reward: 503.29004674288325 avg_loss_c: 5.569529456171122 avg_loss_a: -63.442164637825705\n",
            "Número de pasos del episodio 9981 son episode_steps:136\n",
            "Total Steps: 661583 Episode Num: 9981 Reward: 126.5033630730239 avg_loss_c: 5.709201683016384 avg_loss_a: -63.865739037008844\n",
            "Número de pasos del episodio 9982 son episode_steps:56\n",
            "Total Steps: 661639 Episode Num: 9982 Reward: 32.57406744065503 avg_loss_c: 5.801081333841596 avg_loss_a: -63.39571639469692\n",
            "Número de pasos del episodio 9983 son episode_steps:302\n",
            "Total Steps: 661941 Episode Num: 9983 Reward: 453.98469711219485 avg_loss_c: 5.661264891656029 avg_loss_a: -63.64570410520036\n",
            "Número de pasos del episodio 9984 son episode_steps:47\n",
            "Total Steps: 661988 Episode Num: 9984 Reward: 27.163587314850304 avg_loss_c: 6.080483715584937 avg_loss_a: -63.495127576462764\n",
            "Número de pasos del episodio 9985 son episode_steps:43\n",
            "Total Steps: 662031 Episode Num: 9985 Reward: -20.64737219781003 avg_loss_c: 5.729985231576964 avg_loss_a: -62.50647575910701\n",
            "Número de pasos del episodio 9986 son episode_steps:95\n",
            "Total Steps: 662126 Episode Num: 9986 Reward: 103.22849398171974 avg_loss_c: 5.916604704605906 avg_loss_a: -63.400560559724504\n",
            "Número de pasos del episodio 9987 son episode_steps:77\n",
            "Total Steps: 662203 Episode Num: 9987 Reward: 94.79567551593799 avg_loss_c: 6.072357518332345 avg_loss_a: -62.61075701032366\n",
            "Número de pasos del episodio 9988 son episode_steps:274\n",
            "Total Steps: 662477 Episode Num: 9988 Reward: 407.78447927204974 avg_loss_c: 5.765555952587267 avg_loss_a: -63.54667031503942\n",
            "Número de pasos del episodio 9989 son episode_steps:87\n",
            "Total Steps: 662564 Episode Num: 9989 Reward: 83.43476837255675 avg_loss_c: 5.696236854312064 avg_loss_a: -63.33453158674569\n",
            "Número de pasos del episodio 9990 son episode_steps:197\n",
            "Total Steps: 662761 Episode Num: 9990 Reward: 268.4520508910577 avg_loss_c: 5.680272425491798 avg_loss_a: -63.02646470432959\n",
            "Número de pasos del episodio 9991 son episode_steps:137\n",
            "Total Steps: 662898 Episode Num: 9991 Reward: 109.74741695522461 avg_loss_c: 5.770724550650938 avg_loss_a: -63.1079480247776\n",
            "Número de pasos del episodio 9992 son episode_steps:202\n",
            "Total Steps: 663100 Episode Num: 9992 Reward: 253.5796194119125 avg_loss_c: 5.75082789907361 avg_loss_a: -63.061853692083076\n",
            "Número de pasos del episodio 9993 son episode_steps:338\n",
            "Total Steps: 663438 Episode Num: 9993 Reward: 546.5139985325894 avg_loss_c: 5.640922278342162 avg_loss_a: -63.08260846561229\n",
            "Número de pasos del episodio 9994 son episode_steps:56\n",
            "Total Steps: 663494 Episode Num: 9994 Reward: 36.14074155745782 avg_loss_c: 5.738250566380365 avg_loss_a: -63.680568150111604\n",
            "Número de pasos del episodio 9995 son episode_steps:308\n",
            "Total Steps: 663802 Episode Num: 9995 Reward: 424.10792895895486 avg_loss_c: 5.780682136486103 avg_loss_a: -63.583855344103526\n",
            "Número de pasos del episodio 9996 son episode_steps:82\n",
            "Total Steps: 663884 Episode Num: 9996 Reward: 93.92943801670698 avg_loss_c: 5.781893660382527 avg_loss_a: -63.614025022925404\n",
            "Número de pasos del episodio 9997 son episode_steps:66\n",
            "Total Steps: 663950 Episode Num: 9997 Reward: 29.120437432795292 avg_loss_c: 5.991883415164369 avg_loss_a: -63.437447519013375\n",
            "Número de pasos del episodio 9998 son episode_steps:193\n",
            "Total Steps: 664143 Episode Num: 9998 Reward: 267.3563156687389 avg_loss_c: 6.161600329097689 avg_loss_a: -63.40885022020093\n",
            "Número de pasos del episodio 9999 son episode_steps:71\n",
            "Total Steps: 664214 Episode Num: 9999 Reward: 77.23640750568347 avg_loss_c: 6.067841200761392 avg_loss_a: -63.12244307826942\n",
            "Número de pasos del episodio 10000 son episode_steps:113\n",
            "Total Steps: 664327 Episode Num: 10000 Reward: 88.87749179684559 avg_loss_c: 5.77137723433233 avg_loss_a: -62.65992669299641\n",
            "Número de pasos del episodio 10001 son episode_steps:73\n",
            "Total Steps: 664400 Episode Num: 10001 Reward: 38.06311028157469 avg_loss_c: 7.069447288774464 avg_loss_a: -62.920911501531734\n",
            "Número de pasos del episodio 10002 son episode_steps:129\n",
            "Total Steps: 664529 Episode Num: 10002 Reward: 168.21505609319183 avg_loss_c: 6.103087946426037 avg_loss_a: -63.23268848981044\n",
            "Número de pasos del episodio 10003 son episode_steps:193\n",
            "Total Steps: 664722 Episode Num: 10003 Reward: 271.2493877241844 avg_loss_c: 5.964106637579172 avg_loss_a: -62.86696132600616\n",
            "Número de pasos del episodio 10004 son episode_steps:344\n",
            "Total Steps: 665066 Episode Num: 10004 Reward: 448.1814890080081 avg_loss_c: 5.932655602693558 avg_loss_a: -63.38234207242034\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 271.243783\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10005 son episode_steps:143\n",
            "Total Steps: 665209 Episode Num: 10005 Reward: 206.22655908981088 avg_loss_c: 5.914988462741558 avg_loss_a: -63.16886683110591\n",
            "Número de pasos del episodio 10006 son episode_steps:79\n",
            "Total Steps: 665288 Episode Num: 10006 Reward: 91.09867841573121 avg_loss_c: 5.990350192106223 avg_loss_a: -62.87340352505068\n",
            "Número de pasos del episodio 10007 son episode_steps:548\n",
            "Total Steps: 665836 Episode Num: 10007 Reward: 855.0159437176839 avg_loss_c: 6.046331574446963 avg_loss_a: -63.55652028104684\n",
            "Número de pasos del episodio 10008 son episode_steps:82\n",
            "Total Steps: 665918 Episode Num: 10008 Reward: 90.95022931659852 avg_loss_c: 6.167657267756578 avg_loss_a: -63.284150193377236\n",
            "Número de pasos del episodio 10009 son episode_steps:256\n",
            "Total Steps: 666174 Episode Num: 10009 Reward: 254.12020175419025 avg_loss_c: 6.325861832126975 avg_loss_a: -63.20798072218895\n",
            "Número de pasos del episodio 10010 son episode_steps:95\n",
            "Total Steps: 666269 Episode Num: 10010 Reward: 121.84369505595693 avg_loss_c: 6.204032235396536 avg_loss_a: -64.07243792885228\n",
            "Número de pasos del episodio 10011 son episode_steps:171\n",
            "Total Steps: 666440 Episode Num: 10011 Reward: 265.22057320076306 avg_loss_c: 6.200964081357097 avg_loss_a: -63.41360723484329\n",
            "Número de pasos del episodio 10012 son episode_steps:116\n",
            "Total Steps: 666556 Episode Num: 10012 Reward: 101.47145524895139 avg_loss_c: 6.25183984740027 avg_loss_a: -63.857422006541285\n",
            "Número de pasos del episodio 10013 son episode_steps:198\n",
            "Total Steps: 666754 Episode Num: 10013 Reward: 259.4011062318205 avg_loss_c: 6.645836016144416 avg_loss_a: -64.19025440408726\n",
            "Número de pasos del episodio 10014 son episode_steps:84\n",
            "Total Steps: 666838 Episode Num: 10014 Reward: 59.06292565737552 avg_loss_c: 6.508908947308858 avg_loss_a: -63.631857190813335\n",
            "Número de pasos del episodio 10015 son episode_steps:49\n",
            "Total Steps: 666887 Episode Num: 10015 Reward: 14.335883926945492 avg_loss_c: 6.997532912663051 avg_loss_a: -64.16583672348334\n",
            "Número de pasos del episodio 10016 son episode_steps:268\n",
            "Total Steps: 667155 Episode Num: 10016 Reward: 407.72253471704795 avg_loss_c: 6.569414507097273 avg_loss_a: -64.46883369559673\n",
            "Número de pasos del episodio 10017 son episode_steps:178\n",
            "Total Steps: 667333 Episode Num: 10017 Reward: 231.46189620816796 avg_loss_c: 6.338182730621167 avg_loss_a: -64.22085909897022\n",
            "Número de pasos del episodio 10018 son episode_steps:79\n",
            "Total Steps: 667412 Episode Num: 10018 Reward: 88.85190797804782 avg_loss_c: 6.42881540708904 avg_loss_a: -63.930329238312154\n",
            "Número de pasos del episodio 10019 son episode_steps:152\n",
            "Total Steps: 667564 Episode Num: 10019 Reward: 215.17242449880405 avg_loss_c: 6.362580735432474 avg_loss_a: -64.16135270972\n",
            "Número de pasos del episodio 10020 son episode_steps:103\n",
            "Total Steps: 667667 Episode Num: 10020 Reward: 36.69712402142716 avg_loss_c: 6.577923452969894 avg_loss_a: -63.08607497724515\n",
            "Número de pasos del episodio 10021 son episode_steps:186\n",
            "Total Steps: 667853 Episode Num: 10021 Reward: 191.06184016861056 avg_loss_c: 6.754820259668493 avg_loss_a: -63.88654368410828\n",
            "Número de pasos del episodio 10022 son episode_steps:61\n",
            "Total Steps: 667914 Episode Num: 10022 Reward: 53.94537184772791 avg_loss_c: 6.789010946867896 avg_loss_a: -63.82667954241643\n",
            "Número de pasos del episodio 10023 son episode_steps:103\n",
            "Total Steps: 668017 Episode Num: 10023 Reward: 71.40820724188038 avg_loss_c: 6.719098642034438 avg_loss_a: -63.34931123603895\n",
            "Número de pasos del episodio 10024 son episode_steps:166\n",
            "Total Steps: 668183 Episode Num: 10024 Reward: 257.9803916292595 avg_loss_c: 6.648017386356032 avg_loss_a: -64.11588075936558\n",
            "Número de pasos del episodio 10025 son episode_steps:94\n",
            "Total Steps: 668277 Episode Num: 10025 Reward: 79.6410654081316 avg_loss_c: 6.72001365144202 avg_loss_a: -63.51038539156001\n",
            "Número de pasos del episodio 10026 son episode_steps:176\n",
            "Total Steps: 668453 Episode Num: 10026 Reward: 242.9940886543908 avg_loss_c: 6.78310413794084 avg_loss_a: -63.93623330376365\n",
            "Número de pasos del episodio 10027 son episode_steps:73\n",
            "Total Steps: 668526 Episode Num: 10027 Reward: 51.463811734779874 avg_loss_c: 6.694136665291982 avg_loss_a: -63.86736579790507\n",
            "Número de pasos del episodio 10028 son episode_steps:226\n",
            "Total Steps: 668752 Episode Num: 10028 Reward: 295.28656138133925 avg_loss_c: 7.023422205342656 avg_loss_a: -64.23559931527197\n",
            "Número de pasos del episodio 10029 son episode_steps:168\n",
            "Total Steps: 668920 Episode Num: 10029 Reward: 268.0231953437277 avg_loss_c: 7.03886448201679 avg_loss_a: -64.06195640563965\n",
            "Número de pasos del episodio 10030 son episode_steps:153\n",
            "Total Steps: 669073 Episode Num: 10030 Reward: 237.5296930398718 avg_loss_c: 6.805611538731195 avg_loss_a: -64.23710353078405\n",
            "Número de pasos del episodio 10031 son episode_steps:120\n",
            "Total Steps: 669193 Episode Num: 10031 Reward: 118.88502941108707 avg_loss_c: 6.61632623275121 avg_loss_a: -64.07021903991699\n",
            "Número de pasos del episodio 10032 son episode_steps:87\n",
            "Total Steps: 669280 Episode Num: 10032 Reward: 76.4111321254047 avg_loss_c: 6.918516975709761 avg_loss_a: -64.00882712177847\n",
            "Número de pasos del episodio 10033 son episode_steps:125\n",
            "Total Steps: 669405 Episode Num: 10033 Reward: 202.01600762179615 avg_loss_c: 6.796066646575928 avg_loss_a: -63.80132885742187\n",
            "Número de pasos del episodio 10034 son episode_steps:131\n",
            "Total Steps: 669536 Episode Num: 10034 Reward: 173.92700413339253 avg_loss_c: 6.796903723068819 avg_loss_a: -63.57082256288019\n",
            "Número de pasos del episodio 10035 son episode_steps:273\n",
            "Total Steps: 669809 Episode Num: 10035 Reward: 436.97440799012753 avg_loss_c: 6.861626632920989 avg_loss_a: -63.89634841527694\n",
            "Número de pasos del episodio 10036 son episode_steps:264\n",
            "Total Steps: 670073 Episode Num: 10036 Reward: 441.414199714495 avg_loss_c: 6.549483571991776 avg_loss_a: -63.939989032167375\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 266.020381\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10037 son episode_steps:179\n",
            "Total Steps: 670252 Episode Num: 10037 Reward: 166.35270466211176 avg_loss_c: 6.597425322292903 avg_loss_a: -64.19057809840368\n",
            "Número de pasos del episodio 10038 son episode_steps:113\n",
            "Total Steps: 670365 Episode Num: 10038 Reward: 158.03306312711786 avg_loss_c: 6.856829375292348 avg_loss_a: -64.59183873539477\n",
            "Número de pasos del episodio 10039 son episode_steps:111\n",
            "Total Steps: 670476 Episode Num: 10039 Reward: 152.30826860054648 avg_loss_c: 6.692137370238433 avg_loss_a: -63.93586160470773\n",
            "Número de pasos del episodio 10040 son episode_steps:275\n",
            "Total Steps: 670751 Episode Num: 10040 Reward: 399.7037560881531 avg_loss_c: 6.609695353074507 avg_loss_a: -64.39257815274325\n",
            "Número de pasos del episodio 10041 son episode_steps:121\n",
            "Total Steps: 670872 Episode Num: 10041 Reward: 163.2177407589812 avg_loss_c: 6.506093060674746 avg_loss_a: -65.08741750795978\n",
            "Número de pasos del episodio 10042 son episode_steps:141\n",
            "Total Steps: 671013 Episode Num: 10042 Reward: 198.1728959100693 avg_loss_c: 6.4566439195727625 avg_loss_a: -64.71886114025793\n",
            "Número de pasos del episodio 10043 son episode_steps:520\n",
            "Total Steps: 671533 Episode Num: 10043 Reward: 842.820314015312 avg_loss_c: 6.508992526622919 avg_loss_a: -65.51049681443435\n",
            "Número de pasos del episodio 10044 son episode_steps:100\n",
            "Total Steps: 671633 Episode Num: 10044 Reward: 116.44840069464506 avg_loss_c: 6.41853964805603 avg_loss_a: -65.31957740783692\n",
            "Número de pasos del episodio 10045 son episode_steps:66\n",
            "Total Steps: 671699 Episode Num: 10045 Reward: -19.587600730850493 avg_loss_c: 6.649321837858721 avg_loss_a: -65.64231398611358\n",
            "Número de pasos del episodio 10046 son episode_steps:155\n",
            "Total Steps: 671854 Episode Num: 10046 Reward: 168.26261010291333 avg_loss_c: 7.257569985235891 avg_loss_a: -64.79925064579133\n",
            "Número de pasos del episodio 10047 son episode_steps:192\n",
            "Total Steps: 672046 Episode Num: 10047 Reward: 245.7320127852717 avg_loss_c: 6.752751678228378 avg_loss_a: -65.07248767217\n",
            "Número de pasos del episodio 10048 son episode_steps:418\n",
            "Total Steps: 672464 Episode Num: 10048 Reward: 668.4349734398413 avg_loss_c: 6.666171614633223 avg_loss_a: -65.740395614405\n",
            "Número de pasos del episodio 10049 son episode_steps:134\n",
            "Total Steps: 672598 Episode Num: 10049 Reward: 198.23631538114728 avg_loss_c: 6.669867864295618 avg_loss_a: -65.78451566553828\n",
            "Número de pasos del episodio 10050 son episode_steps:247\n",
            "Total Steps: 672845 Episode Num: 10050 Reward: 309.2143649964306 avg_loss_c: 6.683772876677725 avg_loss_a: -66.13221237244393\n",
            "Número de pasos del episodio 10051 son episode_steps:185\n",
            "Total Steps: 673030 Episode Num: 10051 Reward: 276.2117240253816 avg_loss_c: 6.7497568491342905 avg_loss_a: -65.93503327240815\n",
            "Número de pasos del episodio 10052 son episode_steps:181\n",
            "Total Steps: 673211 Episode Num: 10052 Reward: 247.91407779463174 avg_loss_c: 6.84157212663092 avg_loss_a: -66.23143245633794\n",
            "Número de pasos del episodio 10053 son episode_steps:231\n",
            "Total Steps: 673442 Episode Num: 10053 Reward: 349.84073763965523 avg_loss_c: 6.867342748683252 avg_loss_a: -66.21074868074227\n",
            "Número de pasos del episodio 10054 son episode_steps:254\n",
            "Total Steps: 673696 Episode Num: 10054 Reward: 336.7748890181353 avg_loss_c: 6.755030055684368 avg_loss_a: -66.98364110631267\n",
            "Número de pasos del episodio 10055 son episode_steps:165\n",
            "Total Steps: 673861 Episode Num: 10055 Reward: 219.81122605803876 avg_loss_c: 7.0549613259055395 avg_loss_a: -66.7604188861269\n",
            "Número de pasos del episodio 10056 son episode_steps:174\n",
            "Total Steps: 674035 Episode Num: 10056 Reward: 226.34471644126504 avg_loss_c: 6.6963558608088 avg_loss_a: -66.96106912897922\n",
            "Número de pasos del episodio 10057 son episode_steps:266\n",
            "Total Steps: 674301 Episode Num: 10057 Reward: 400.0040532725336 avg_loss_c: 6.661000911454509 avg_loss_a: -67.01305240258239\n",
            "Número de pasos del episodio 10058 son episode_steps:170\n",
            "Total Steps: 674471 Episode Num: 10058 Reward: 226.38003107501433 avg_loss_c: 6.715547457863303 avg_loss_a: -67.09647387336283\n",
            "Número de pasos del episodio 10059 son episode_steps:138\n",
            "Total Steps: 674609 Episode Num: 10059 Reward: 161.2956285257065 avg_loss_c: 7.065390054730401 avg_loss_a: -67.31458929310675\n",
            "Número de pasos del episodio 10060 son episode_steps:151\n",
            "Total Steps: 674760 Episode Num: 10060 Reward: 133.3159304128804 avg_loss_c: 7.068449364592698 avg_loss_a: -67.00558668730275\n",
            "Número de pasos del episodio 10061 son episode_steps:225\n",
            "Total Steps: 674985 Episode Num: 10061 Reward: 319.15858690090073 avg_loss_c: 7.065535386403401 avg_loss_a: -67.26736650254992\n",
            "Número de pasos del episodio 10062 son episode_steps:131\n",
            "Total Steps: 675116 Episode Num: 10062 Reward: 166.94717644643984 avg_loss_c: 7.002316868032208 avg_loss_a: -67.21530873538883\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 427.481930\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10063 son episode_steps:222\n",
            "Total Steps: 675338 Episode Num: 10063 Reward: 291.44244256285054 avg_loss_c: 6.972685929891226 avg_loss_a: -67.19536171303139\n",
            "Número de pasos del episodio 10064 son episode_steps:379\n",
            "Total Steps: 675717 Episode Num: 10064 Reward: 633.1735974307447 avg_loss_c: 6.856646443419846 avg_loss_a: -67.47291591110833\n",
            "Número de pasos del episodio 10065 son episode_steps:1000\n",
            "Total Steps: 676717 Episode Num: 10065 Reward: 1632.340469983093 avg_loss_c: 6.600608673810959 avg_loss_a: -68.76624838256836\n",
            "Número de pasos del episodio 10066 son episode_steps:66\n",
            "Total Steps: 676783 Episode Num: 10066 Reward: 57.936964760952115 avg_loss_c: 6.3765724427772295 avg_loss_a: -69.07362088290128\n",
            "Número de pasos del episodio 10067 son episode_steps:223\n",
            "Total Steps: 677006 Episode Num: 10067 Reward: 348.689969915277 avg_loss_c: 6.413476402984072 avg_loss_a: -68.91909622397658\n",
            "Número de pasos del episodio 10068 son episode_steps:221\n",
            "Total Steps: 677227 Episode Num: 10068 Reward: 229.3836717037596 avg_loss_c: 6.451150028953725 avg_loss_a: -68.90115667144637\n",
            "Número de pasos del episodio 10069 son episode_steps:710\n",
            "Total Steps: 677937 Episode Num: 10069 Reward: 1114.4517123099406 avg_loss_c: 6.446609923201548 avg_loss_a: -69.54315609999107\n",
            "Número de pasos del episodio 10070 son episode_steps:781\n",
            "Total Steps: 678718 Episode Num: 10070 Reward: 1269.364290865324 avg_loss_c: 6.211729146149033 avg_loss_a: -70.6192080489194\n",
            "Número de pasos del episodio 10071 son episode_steps:219\n",
            "Total Steps: 678937 Episode Num: 10071 Reward: 240.00779879698442 avg_loss_c: 6.350390993841162 avg_loss_a: -70.73858590321998\n",
            "Número de pasos del episodio 10072 son episode_steps:207\n",
            "Total Steps: 679144 Episode Num: 10072 Reward: 317.38751044210767 avg_loss_c: 6.561074828180138 avg_loss_a: -71.04811615874802\n",
            "Número de pasos del episodio 10073 son episode_steps:75\n",
            "Total Steps: 679219 Episode Num: 10073 Reward: 1.8020300625649055 avg_loss_c: 6.722659397125244 avg_loss_a: -70.3930884806315\n",
            "Número de pasos del episodio 10074 son episode_steps:439\n",
            "Total Steps: 679658 Episode Num: 10074 Reward: 725.4027997224531 avg_loss_c: 6.443603254396443 avg_loss_a: -71.04785488189489\n",
            "Número de pasos del episodio 10075 son episode_steps:69\n",
            "Total Steps: 679727 Episode Num: 10075 Reward: 43.003120027182575 avg_loss_c: 6.48179448860279 avg_loss_a: -70.98769953630972\n",
            "Número de pasos del episodio 10076 son episode_steps:129\n",
            "Total Steps: 679856 Episode Num: 10076 Reward: 123.32128909161429 avg_loss_c: 6.543865177982537 avg_loss_a: -71.03350013910338\n",
            "Número de pasos del episodio 10077 son episode_steps:44\n",
            "Total Steps: 679900 Episode Num: 10077 Reward: 22.95632883534509 avg_loss_c: 6.655855959111994 avg_loss_a: -70.36917426369406\n",
            "Número de pasos del episodio 10078 son episode_steps:594\n",
            "Total Steps: 680494 Episode Num: 10078 Reward: 988.4678191930161 avg_loss_c: 6.41765016016334 avg_loss_a: -71.40001221216889\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 314.697971\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10079 son episode_steps:253\n",
            "Total Steps: 680747 Episode Num: 10079 Reward: 407.4760923419526 avg_loss_c: 6.400852169443968 avg_loss_a: -71.36166469287495\n",
            "Número de pasos del episodio 10080 son episode_steps:89\n",
            "Total Steps: 680836 Episode Num: 10080 Reward: 111.67576150501596 avg_loss_c: 6.446944501962554 avg_loss_a: -71.91653708125769\n",
            "Número de pasos del episodio 10081 son episode_steps:329\n",
            "Total Steps: 681165 Episode Num: 10081 Reward: 517.2922607126546 avg_loss_c: 6.3146379334586005 avg_loss_a: -71.69856693534503\n",
            "Número de pasos del episodio 10082 son episode_steps:232\n",
            "Total Steps: 681397 Episode Num: 10082 Reward: 252.04311721504115 avg_loss_c: 6.3691699165722415 avg_loss_a: -71.48118874122356\n",
            "Número de pasos del episodio 10083 son episode_steps:319\n",
            "Total Steps: 681716 Episode Num: 10083 Reward: 532.5169680227008 avg_loss_c: 6.447618981513857 avg_loss_a: -71.98699214540679\n",
            "Número de pasos del episodio 10084 son episode_steps:377\n",
            "Total Steps: 682093 Episode Num: 10084 Reward: 501.91513564607794 avg_loss_c: 6.377866792425869 avg_loss_a: -72.4956997737328\n",
            "Número de pasos del episodio 10085 son episode_steps:299\n",
            "Total Steps: 682392 Episode Num: 10085 Reward: 500.454068285949 avg_loss_c: 6.237162223229041 avg_loss_a: -72.51720007446697\n",
            "Número de pasos del episodio 10086 son episode_steps:356\n",
            "Total Steps: 682748 Episode Num: 10086 Reward: 575.7581029736772 avg_loss_c: 6.118945930111274 avg_loss_a: -72.85519284880563\n",
            "Número de pasos del episodio 10087 son episode_steps:544\n",
            "Total Steps: 683292 Episode Num: 10087 Reward: 924.6536775837658 avg_loss_c: 6.041967010235085 avg_loss_a: -72.99687966178445\n",
            "Número de pasos del episodio 10088 son episode_steps:384\n",
            "Total Steps: 683676 Episode Num: 10088 Reward: 648.7289123398756 avg_loss_c: 6.1061265636235476 avg_loss_a: -73.617582877477\n",
            "Número de pasos del episodio 10089 son episode_steps:95\n",
            "Total Steps: 683771 Episode Num: 10089 Reward: 57.74995388773371 avg_loss_c: 6.78299987441615 avg_loss_a: -73.22312373111123\n",
            "Número de pasos del episodio 10090 son episode_steps:219\n",
            "Total Steps: 683990 Episode Num: 10090 Reward: 308.5713106344869 avg_loss_c: 6.279839835754813 avg_loss_a: -73.8344400484268\n",
            "Número de pasos del episodio 10091 son episode_steps:196\n",
            "Total Steps: 684186 Episode Num: 10091 Reward: 245.41561615069563 avg_loss_c: 6.301199499441653 avg_loss_a: -73.56092087103396\n",
            "Número de pasos del episodio 10092 son episode_steps:229\n",
            "Total Steps: 684415 Episode Num: 10092 Reward: 344.3642172024594 avg_loss_c: 6.127782502028619 avg_loss_a: -74.02590079494959\n",
            "Número de pasos del episodio 10093 son episode_steps:260\n",
            "Total Steps: 684675 Episode Num: 10093 Reward: 420.19931141142195 avg_loss_c: 6.226101933992826 avg_loss_a: -74.35446994488056\n",
            "Número de pasos del episodio 10094 son episode_steps:187\n",
            "Total Steps: 684862 Episode Num: 10094 Reward: 270.8351524639451 avg_loss_c: 6.0911387989227785 avg_loss_a: -74.6331426039099\n",
            "Número de pasos del episodio 10095 son episode_steps:182\n",
            "Total Steps: 685044 Episode Num: 10095 Reward: 223.6478231583127 avg_loss_c: 6.022196279777275 avg_loss_a: -74.290648491828\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 220.454246\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10096 son episode_steps:46\n",
            "Total Steps: 685090 Episode Num: 10096 Reward: 6.934647817226578 avg_loss_c: 6.044306340424911 avg_loss_a: -75.06055549953295\n",
            "Número de pasos del episodio 10097 son episode_steps:103\n",
            "Total Steps: 685193 Episode Num: 10097 Reward: 140.18271794261668 avg_loss_c: 6.1199504287497515 avg_loss_a: -74.8751132557693\n",
            "Número de pasos del episodio 10098 son episode_steps:237\n",
            "Total Steps: 685430 Episode Num: 10098 Reward: 322.48210687795915 avg_loss_c: 6.335187871747882 avg_loss_a: -74.0985267091904\n",
            "Número de pasos del episodio 10099 son episode_steps:210\n",
            "Total Steps: 685640 Episode Num: 10099 Reward: 262.47580570670004 avg_loss_c: 6.380989094007583 avg_loss_a: -74.15709744408016\n",
            "Número de pasos del episodio 10100 son episode_steps:45\n",
            "Total Steps: 685685 Episode Num: 10100 Reward: 8.07739554515401 avg_loss_c: 6.607886547512479 avg_loss_a: -73.61797366672091\n",
            "Número de pasos del episodio 10101 son episode_steps:178\n",
            "Total Steps: 685863 Episode Num: 10101 Reward: 196.08359176499397 avg_loss_c: 6.366920508695452 avg_loss_a: -73.71916661637553\n",
            "Número de pasos del episodio 10102 son episode_steps:107\n",
            "Total Steps: 685970 Episode Num: 10102 Reward: 98.24713930922339 avg_loss_c: 7.281825609296281 avg_loss_a: -74.66077765348916\n",
            "Número de pasos del episodio 10103 son episode_steps:631\n",
            "Total Steps: 686601 Episode Num: 10103 Reward: 1056.9077201528335 avg_loss_c: 6.28069925081522 avg_loss_a: -74.95486224094397\n",
            "Número de pasos del episodio 10104 son episode_steps:348\n",
            "Total Steps: 686949 Episode Num: 10104 Reward: 388.4074330197997 avg_loss_c: 6.346123952290108 avg_loss_a: -75.17344165670461\n",
            "Número de pasos del episodio 10105 son episode_steps:219\n",
            "Total Steps: 687168 Episode Num: 10105 Reward: 331.7118216683678 avg_loss_c: 6.148784413185294 avg_loss_a: -75.08873086868356\n",
            "Número de pasos del episodio 10106 son episode_steps:197\n",
            "Total Steps: 687365 Episode Num: 10106 Reward: 261.9216956760635 avg_loss_c: 6.203498992823103 avg_loss_a: -75.23005676269531\n",
            "Número de pasos del episodio 10107 son episode_steps:756\n",
            "Total Steps: 688121 Episode Num: 10107 Reward: 1283.5272847198378 avg_loss_c: 5.975060703893187 avg_loss_a: -76.32416358826653\n",
            "Número de pasos del episodio 10108 son episode_steps:863\n",
            "Total Steps: 688984 Episode Num: 10108 Reward: 1480.3916476197955 avg_loss_c: 5.579801190355285 avg_loss_a: -77.43006106627499\n",
            "Número de pasos del episodio 10109 son episode_steps:92\n",
            "Total Steps: 689076 Episode Num: 10109 Reward: 72.82577939445434 avg_loss_c: 6.26368480661641 avg_loss_a: -77.47368555483611\n",
            "Número de pasos del episodio 10110 son episode_steps:280\n",
            "Total Steps: 689356 Episode Num: 10110 Reward: 430.88922623796327 avg_loss_c: 5.604999851328986 avg_loss_a: -77.93189958844866\n",
            "Número de pasos del episodio 10111 son episode_steps:536\n",
            "Total Steps: 689892 Episode Num: 10111 Reward: 895.5972084059371 avg_loss_c: 5.4473619025145 avg_loss_a: -78.37094232929287\n",
            "Número de pasos del episodio 10112 son episode_steps:580\n",
            "Total Steps: 690472 Episode Num: 10112 Reward: 936.9739894787832 avg_loss_c: 5.467875328146178 avg_loss_a: -78.88361421782395\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 344.930019\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10113 son episode_steps:177\n",
            "Total Steps: 690649 Episode Num: 10113 Reward: 256.5948652377478 avg_loss_c: 5.5231550696205955 avg_loss_a: -78.95157877604167\n",
            "Número de pasos del episodio 10114 son episode_steps:96\n",
            "Total Steps: 690745 Episode Num: 10114 Reward: 16.683341899754865 avg_loss_c: 6.536622554063797 avg_loss_a: -78.46594794591267\n",
            "Número de pasos del episodio 10115 son episode_steps:232\n",
            "Total Steps: 690977 Episode Num: 10115 Reward: 375.177179839022 avg_loss_c: 5.735684229382153 avg_loss_a: -79.08861285242541\n",
            "Número de pasos del episodio 10116 son episode_steps:81\n",
            "Total Steps: 691058 Episode Num: 10116 Reward: 75.64362837057782 avg_loss_c: 5.965431466514682 avg_loss_a: -79.54291977117092\n",
            "Número de pasos del episodio 10117 son episode_steps:162\n",
            "Total Steps: 691220 Episode Num: 10117 Reward: 248.62005456350823 avg_loss_c: 5.60753361236902 avg_loss_a: -79.24198244824822\n",
            "Número de pasos del episodio 10118 son episode_steps:153\n",
            "Total Steps: 691373 Episode Num: 10118 Reward: 173.1134863905177 avg_loss_c: 5.879988506728528 avg_loss_a: -78.52894293093213\n",
            "Número de pasos del episodio 10119 son episode_steps:103\n",
            "Total Steps: 691476 Episode Num: 10119 Reward: 92.56303852858426 avg_loss_c: 5.820857464688496 avg_loss_a: -78.47670886586013\n",
            "Número de pasos del episodio 10120 son episode_steps:243\n",
            "Total Steps: 691719 Episode Num: 10120 Reward: 306.89554818540984 avg_loss_c: 5.805944078743703 avg_loss_a: -78.61347251860693\n",
            "Número de pasos del episodio 10121 son episode_steps:686\n",
            "Total Steps: 692405 Episode Num: 10121 Reward: 1155.679371710267 avg_loss_c: 5.450422507680887 avg_loss_a: -79.37624525954355\n",
            "Número de pasos del episodio 10122 son episode_steps:94\n",
            "Total Steps: 692499 Episode Num: 10122 Reward: 102.66842221195911 avg_loss_c: 5.755681200230375 avg_loss_a: -80.00390982120595\n",
            "Número de pasos del episodio 10123 son episode_steps:312\n",
            "Total Steps: 692811 Episode Num: 10123 Reward: 495.693376957335 avg_loss_c: 5.479507070321303 avg_loss_a: -79.94600017254169\n",
            "Número de pasos del episodio 10124 son episode_steps:148\n",
            "Total Steps: 692959 Episode Num: 10124 Reward: 230.96425299700255 avg_loss_c: 5.361839742273898 avg_loss_a: -79.56299147734771\n",
            "Número de pasos del episodio 10125 son episode_steps:46\n",
            "Total Steps: 693005 Episode Num: 10125 Reward: 21.34603504096236 avg_loss_c: 5.520053583642711 avg_loss_a: -79.03856028681216\n",
            "Número de pasos del episodio 10126 son episode_steps:204\n",
            "Total Steps: 693209 Episode Num: 10126 Reward: 234.01127521645066 avg_loss_c: 5.699824405651467 avg_loss_a: -79.31246185302734\n",
            "Número de pasos del episodio 10127 son episode_steps:193\n",
            "Total Steps: 693402 Episode Num: 10127 Reward: 292.6727724163907 avg_loss_c: 5.71085569648545 avg_loss_a: -79.2225584119095\n",
            "Número de pasos del episodio 10128 son episode_steps:116\n",
            "Total Steps: 693518 Episode Num: 10128 Reward: 162.14125642755624 avg_loss_c: 5.618122072055422 avg_loss_a: -79.55345903593918\n",
            "Número de pasos del episodio 10129 son episode_steps:327\n",
            "Total Steps: 693845 Episode Num: 10129 Reward: 564.0703525481398 avg_loss_c: 5.456755717595418 avg_loss_a: -79.56600478519358\n",
            "Número de pasos del episodio 10130 son episode_steps:184\n",
            "Total Steps: 694029 Episode Num: 10130 Reward: 313.69582707720537 avg_loss_c: 5.537413669669109 avg_loss_a: -79.17655115542205\n",
            "Número de pasos del episodio 10131 son episode_steps:60\n",
            "Total Steps: 694089 Episode Num: 10131 Reward: 49.1703866756739 avg_loss_c: 5.459173448880514 avg_loss_a: -80.08147964477538\n",
            "Número de pasos del episodio 10132 son episode_steps:262\n",
            "Total Steps: 694351 Episode Num: 10132 Reward: 440.48542591999166 avg_loss_c: 5.628641526207669 avg_loss_a: -79.53424986628175\n",
            "Número de pasos del episodio 10133 son episode_steps:157\n",
            "Total Steps: 694508 Episode Num: 10133 Reward: 235.1320681341338 avg_loss_c: 5.317480075131556 avg_loss_a: -80.48115792244103\n",
            "Número de pasos del episodio 10134 son episode_steps:660\n",
            "Total Steps: 695168 Episode Num: 10134 Reward: 1120.5818113118326 avg_loss_c: 5.234462412559625 avg_loss_a: -80.65275502060399\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 500.271523\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10135 son episode_steps:90\n",
            "Total Steps: 695258 Episode Num: 10135 Reward: 94.06573879955805 avg_loss_c: 5.251005670759413 avg_loss_a: -80.72748904758029\n",
            "Número de pasos del episodio 10136 son episode_steps:68\n",
            "Total Steps: 695326 Episode Num: 10136 Reward: 37.83299663571988 avg_loss_c: 5.423590561922858 avg_loss_a: -80.0888027864344\n",
            "Número de pasos del episodio 10137 son episode_steps:254\n",
            "Total Steps: 695580 Episode Num: 10137 Reward: 346.90498532909055 avg_loss_c: 5.6628499650579736 avg_loss_a: -80.19195094071036\n",
            "Número de pasos del episodio 10138 son episode_steps:161\n",
            "Total Steps: 695741 Episode Num: 10138 Reward: 164.84167798697538 avg_loss_c: 5.573746906304211 avg_loss_a: -80.32732083338388\n",
            "Número de pasos del episodio 10139 son episode_steps:357\n",
            "Total Steps: 696098 Episode Num: 10139 Reward: 601.7098890568359 avg_loss_c: 5.485568353107998 avg_loss_a: -80.36186308019302\n",
            "Número de pasos del episodio 10140 son episode_steps:81\n",
            "Total Steps: 696179 Episode Num: 10140 Reward: 83.25426868505399 avg_loss_c: 5.749404180197068 avg_loss_a: -80.25757542362919\n",
            "Número de pasos del episodio 10141 son episode_steps:618\n",
            "Total Steps: 696797 Episode Num: 10141 Reward: 1070.4564308544138 avg_loss_c: 5.404303537989126 avg_loss_a: -80.69916618371859\n",
            "Número de pasos del episodio 10142 son episode_steps:176\n",
            "Total Steps: 696973 Episode Num: 10142 Reward: 274.919164521255 avg_loss_c: 5.516463386741552 avg_loss_a: -80.34967257759787\n",
            "Número de pasos del episodio 10143 son episode_steps:407\n",
            "Total Steps: 697380 Episode Num: 10143 Reward: 651.5244643584382 avg_loss_c: 5.590666476865951 avg_loss_a: -81.0224795892139\n",
            "Número de pasos del episodio 10144 son episode_steps:505\n",
            "Total Steps: 697885 Episode Num: 10144 Reward: 806.0636006983043 avg_loss_c: 5.5217824119152406 avg_loss_a: -81.0045573319539\n",
            "Número de pasos del episodio 10145 son episode_steps:391\n",
            "Total Steps: 698276 Episode Num: 10145 Reward: 674.9418007328575 avg_loss_c: 5.3706763376055475 avg_loss_a: -81.01306427470253\n",
            "Número de pasos del episodio 10146 son episode_steps:286\n",
            "Total Steps: 698562 Episode Num: 10146 Reward: 389.53055268463135 avg_loss_c: 5.365970948359349 avg_loss_a: -80.71846536489633\n",
            "Número de pasos del episodio 10147 son episode_steps:172\n",
            "Total Steps: 698734 Episode Num: 10147 Reward: 249.42933252673785 avg_loss_c: 5.407928321250649 avg_loss_a: -81.19143792085869\n",
            "Número de pasos del episodio 10148 son episode_steps:286\n",
            "Total Steps: 699020 Episode Num: 10148 Reward: 481.68226701825733 avg_loss_c: 5.17769233663599 avg_loss_a: -81.78249348460378\n",
            "Número de pasos del episodio 10149 son episode_steps:515\n",
            "Total Steps: 699535 Episode Num: 10149 Reward: 863.3948901695633 avg_loss_c: 5.013133042529948 avg_loss_a: -81.70963622158014\n",
            "Número de pasos del episodio 10150 son episode_steps:259\n",
            "Total Steps: 699794 Episode Num: 10150 Reward: 429.22331026357114 avg_loss_c: 4.945698552150064 avg_loss_a: -82.29728460127782\n",
            "Número de pasos del episodio 10151 son episode_steps:519\n",
            "Total Steps: 700313 Episode Num: 10151 Reward: 841.0068950073195 avg_loss_c: 4.937851566340423 avg_loss_a: -82.3259758774715\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 823.522500\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10152 son episode_steps:41\n",
            "Total Steps: 700354 Episode Num: 10152 Reward: 18.340271949258938 avg_loss_c: 5.137832449703682 avg_loss_a: -82.7489610997642\n",
            "Número de pasos del episodio 10153 son episode_steps:278\n",
            "Total Steps: 700632 Episode Num: 10153 Reward: 451.3979590772405 avg_loss_c: 4.90598692482324 avg_loss_a: -82.87705686281053\n",
            "Número de pasos del episodio 10154 son episode_steps:78\n",
            "Total Steps: 700710 Episode Num: 10154 Reward: 83.39086617173557 avg_loss_c: 5.015011111895244 avg_loss_a: -82.52412629738832\n",
            "Número de pasos del episodio 10155 son episode_steps:579\n",
            "Total Steps: 701289 Episode Num: 10155 Reward: 1030.4978680191234 avg_loss_c: 4.856928761553064 avg_loss_a: -83.06215505649389\n",
            "Número de pasos del episodio 10156 son episode_steps:68\n",
            "Total Steps: 701357 Episode Num: 10156 Reward: 47.2866478628274 avg_loss_c: 4.7298051188973815 avg_loss_a: -83.49167498420266\n",
            "Número de pasos del episodio 10157 son episode_steps:121\n",
            "Total Steps: 701478 Episode Num: 10157 Reward: 140.07861746326975 avg_loss_c: 4.899289602090504 avg_loss_a: -83.38939446063081\n",
            "Número de pasos del episodio 10158 son episode_steps:871\n",
            "Total Steps: 702349 Episode Num: 10158 Reward: 1554.545293478527 avg_loss_c: 4.761827990327172 avg_loss_a: -83.93547269205823\n",
            "Número de pasos del episodio 10159 son episode_steps:61\n",
            "Total Steps: 702410 Episode Num: 10159 Reward: 56.884006668520826 avg_loss_c: 4.6841787744740975 avg_loss_a: -83.83857439385086\n",
            "Número de pasos del episodio 10160 son episode_steps:61\n",
            "Total Steps: 702471 Episode Num: 10160 Reward: 2.1436410461618527 avg_loss_c: 5.013630890455402 avg_loss_a: -83.80800816270171\n",
            "Número de pasos del episodio 10161 son episode_steps:302\n",
            "Total Steps: 702773 Episode Num: 10161 Reward: 477.99642247306645 avg_loss_c: 5.016737005568498 avg_loss_a: -83.95750144301661\n",
            "Número de pasos del episodio 10162 son episode_steps:63\n",
            "Total Steps: 702836 Episode Num: 10162 Reward: 39.05485918354443 avg_loss_c: 5.309571304018536 avg_loss_a: -84.53198799254402\n",
            "Número de pasos del episodio 10163 son episode_steps:1000\n",
            "Total Steps: 703836 Episode Num: 10163 Reward: 1727.0025313235792 avg_loss_c: 4.937820326089859 avg_loss_a: -84.66714337158203\n",
            "Número de pasos del episodio 10164 son episode_steps:750\n",
            "Total Steps: 704586 Episode Num: 10164 Reward: 1293.2975821247874 avg_loss_c: 4.734233610471089 avg_loss_a: -85.6686474609375\n",
            "Número de pasos del episodio 10165 son episode_steps:186\n",
            "Total Steps: 704772 Episode Num: 10165 Reward: 279.42759581102615 avg_loss_c: 4.655887652468937 avg_loss_a: -86.15909814321867\n",
            "Número de pasos del episodio 10166 son episode_steps:93\n",
            "Total Steps: 704865 Episode Num: 10166 Reward: 116.8614561487993 avg_loss_c: 4.769265080011019 avg_loss_a: -85.68613097488239\n",
            "Número de pasos del episodio 10167 son episode_steps:105\n",
            "Total Steps: 704970 Episode Num: 10167 Reward: 26.220207845903104 avg_loss_c: 5.25508043652489 avg_loss_a: -85.2231443132673\n",
            "Número de pasos del episodio 10168 son episode_steps:306\n",
            "Total Steps: 705276 Episode Num: 10168 Reward: 499.18782213714724 avg_loss_c: 4.915238429518307 avg_loss_a: -86.20969136555989\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 201.792025\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10169 son episode_steps:46\n",
            "Total Steps: 705322 Episode Num: 10169 Reward: 27.92867900069153 avg_loss_c: 4.668316867040551 avg_loss_a: -86.00378616996433\n",
            "Número de pasos del episodio 10170 son episode_steps:98\n",
            "Total Steps: 705420 Episode Num: 10170 Reward: 115.86489164545407 avg_loss_c: 5.127916654761957 avg_loss_a: -86.06980522311464\n",
            "Número de pasos del episodio 10171 son episode_steps:74\n",
            "Total Steps: 705494 Episode Num: 10171 Reward: 46.05588885104575 avg_loss_c: 5.096764770714012 avg_loss_a: -85.64852534113703\n",
            "Número de pasos del episodio 10172 son episode_steps:163\n",
            "Total Steps: 705657 Episode Num: 10172 Reward: 194.47234607510504 avg_loss_c: 5.2001095169161 avg_loss_a: -86.24687456938386\n",
            "Número de pasos del episodio 10173 son episode_steps:165\n",
            "Total Steps: 705822 Episode Num: 10173 Reward: 62.13492182434064 avg_loss_c: 5.871221686854507 avg_loss_a: -85.87415554162227\n",
            "Número de pasos del episodio 10174 son episode_steps:1000\n",
            "Total Steps: 706822 Episode Num: 10174 Reward: 1766.482311178652 avg_loss_c: 5.131844932556152 avg_loss_a: -86.8828385925293\n",
            "Número de pasos del episodio 10175 son episode_steps:53\n",
            "Total Steps: 706875 Episode Num: 10175 Reward: 60.685841502005886 avg_loss_c: 5.066350113670781 avg_loss_a: -87.11683841921248\n",
            "Número de pasos del episodio 10176 son episode_steps:781\n",
            "Total Steps: 707656 Episode Num: 10176 Reward: 1361.6910557334475 avg_loss_c: 4.851477191939702 avg_loss_a: -87.9626464453\n",
            "Número de pasos del episodio 10177 son episode_steps:958\n",
            "Total Steps: 708614 Episode Num: 10177 Reward: 1664.6962619350354 avg_loss_c: 4.644931376851426 avg_loss_a: -88.43962869664075\n",
            "Número de pasos del episodio 10178 son episode_steps:1000\n",
            "Total Steps: 709614 Episode Num: 10178 Reward: 1744.9481039025754 avg_loss_c: 4.355581627607346 avg_loss_a: -90.00963276672363\n",
            "Número de pasos del episodio 10179 son episode_steps:1000\n",
            "Total Steps: 710614 Episode Num: 10179 Reward: 1792.066944962846 avg_loss_c: 4.172288012504578 avg_loss_a: -91.00563175964355\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 1047.613835\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10180 son episode_steps:295\n",
            "Total Steps: 710909 Episode Num: 10180 Reward: 458.01406778122845 avg_loss_c: 4.210176758846994 avg_loss_a: -92.1027379440049\n",
            "Número de pasos del episodio 10181 son episode_steps:43\n",
            "Total Steps: 710952 Episode Num: 10181 Reward: 2.79109944111199 avg_loss_c: 4.267169436743093 avg_loss_a: -92.32858436052189\n",
            "Número de pasos del episodio 10182 son episode_steps:476\n",
            "Total Steps: 711428 Episode Num: 10182 Reward: 837.5285869946964 avg_loss_c: 4.287501530987876 avg_loss_a: -92.65552043113388\n",
            "Número de pasos del episodio 10183 son episode_steps:1000\n",
            "Total Steps: 712428 Episode Num: 10183 Reward: 1704.1697429734186 avg_loss_c: 4.271533644676208 avg_loss_a: -93.97048025512696\n",
            "Número de pasos del episodio 10184 son episode_steps:120\n",
            "Total Steps: 712548 Episode Num: 10184 Reward: 101.2585030937999 avg_loss_c: 4.326276628176371 avg_loss_a: -94.08143793741861\n",
            "Número de pasos del episodio 10185 son episode_steps:198\n",
            "Total Steps: 712746 Episode Num: 10185 Reward: 273.2081194862137 avg_loss_c: 4.708929007703608 avg_loss_a: -94.13291938858804\n",
            "Número de pasos del episodio 10186 son episode_steps:1000\n",
            "Total Steps: 713746 Episode Num: 10186 Reward: 1772.3519820364468 avg_loss_c: 4.106538232564926 avg_loss_a: -95.34711921691894\n",
            "Número de pasos del episodio 10187 son episode_steps:163\n",
            "Total Steps: 713909 Episode Num: 10187 Reward: 134.2885085047937 avg_loss_c: 4.725284614445973 avg_loss_a: -95.72097998308989\n",
            "Número de pasos del episodio 10188 son episode_steps:74\n",
            "Total Steps: 713983 Episode Num: 10188 Reward: 74.90989651477895 avg_loss_c: 4.399718168619517 avg_loss_a: -95.24879971066036\n",
            "Número de pasos del episodio 10189 son episode_steps:87\n",
            "Total Steps: 714070 Episode Num: 10189 Reward: -59.042044000807586 avg_loss_c: 5.440584147113493 avg_loss_a: -95.32832362734038\n",
            "Número de pasos del episodio 10190 son episode_steps:90\n",
            "Total Steps: 714160 Episode Num: 10190 Reward: 85.47236443127743 avg_loss_c: 5.221759022606744 avg_loss_a: -94.76033732096354\n",
            "Número de pasos del episodio 10191 son episode_steps:1000\n",
            "Total Steps: 715160 Episode Num: 10191 Reward: 1676.237258176402 avg_loss_c: 4.610506811380386 avg_loss_a: -96.2499539642334\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 294.124740\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10192 son episode_steps:856\n",
            "Total Steps: 716016 Episode Num: 10192 Reward: 1369.579129136774 avg_loss_c: 4.214882929191411 avg_loss_a: -97.13218835135487\n",
            "Número de pasos del episodio 10193 son episode_steps:181\n",
            "Total Steps: 716197 Episode Num: 10193 Reward: 252.19700779781562 avg_loss_c: 4.03714942405237 avg_loss_a: -97.69114187672652\n",
            "Número de pasos del episodio 10194 son episode_steps:73\n",
            "Total Steps: 716270 Episode Num: 10194 Reward: 48.08906731853924 avg_loss_c: 4.2444355912404514 avg_loss_a: -97.37351571697079\n",
            "Número de pasos del episodio 10195 son episode_steps:1000\n",
            "Total Steps: 717270 Episode Num: 10195 Reward: 1825.6915920756874 avg_loss_c: 4.056752543210983 avg_loss_a: -98.29214833068848\n",
            "Número de pasos del episodio 10196 son episode_steps:133\n",
            "Total Steps: 717403 Episode Num: 10196 Reward: 154.0763101409503 avg_loss_c: 4.186072717035623 avg_loss_a: -98.50823091205798\n",
            "Número de pasos del episodio 10197 son episode_steps:400\n",
            "Total Steps: 717803 Episode Num: 10197 Reward: 665.2920950159157 avg_loss_c: 4.016190832853317 avg_loss_a: -98.60267250061035\n",
            "Número de pasos del episodio 10198 son episode_steps:301\n",
            "Total Steps: 718104 Episode Num: 10198 Reward: 519.9992475999233 avg_loss_c: 3.983019526218655 avg_loss_a: -99.14446334585399\n",
            "Número de pasos del episodio 10199 son episode_steps:1000\n",
            "Total Steps: 719104 Episode Num: 10199 Reward: 1766.3985280770762 avg_loss_c: 3.8336736891269685 avg_loss_a: -100.54140878295898\n",
            "Número de pasos del episodio 10200 son episode_steps:51\n",
            "Total Steps: 719155 Episode Num: 10200 Reward: 44.73222737297649 avg_loss_c: 3.9149996486364627 avg_loss_a: -100.6071018892176\n",
            "Número de pasos del episodio 10201 son episode_steps:1000\n",
            "Total Steps: 720155 Episode Num: 10201 Reward: 1809.1798231779646 avg_loss_c: 3.6383033202886583 avg_loss_a: -101.42706117248535\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 1308.173847\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10202 son episode_steps:28\n",
            "Total Steps: 720183 Episode Num: 10202 Reward: -43.76124637942189 avg_loss_c: 4.162021287849972 avg_loss_a: -101.21238054547992\n",
            "Número de pasos del episodio 10203 son episode_steps:101\n",
            "Total Steps: 720284 Episode Num: 10203 Reward: 132.64431290797293 avg_loss_c: 4.208171771304442 avg_loss_a: -101.43698339179011\n",
            "Número de pasos del episodio 10204 son episode_steps:1000\n",
            "Total Steps: 721284 Episode Num: 10204 Reward: 1773.8820425203971 avg_loss_c: 3.705607792854309 avg_loss_a: -102.76314282226562\n",
            "Número de pasos del episodio 10205 son episode_steps:486\n",
            "Total Steps: 721770 Episode Num: 10205 Reward: 710.0856568766062 avg_loss_c: 3.5994044961752714 avg_loss_a: -103.53644185007354\n",
            "Número de pasos del episodio 10206 son episode_steps:116\n",
            "Total Steps: 721886 Episode Num: 10206 Reward: 144.39115120459792 avg_loss_c: 3.702431321144104 avg_loss_a: -103.3671225186052\n",
            "Número de pasos del episodio 10207 son episode_steps:44\n",
            "Total Steps: 721930 Episode Num: 10207 Reward: 30.62716612442632 avg_loss_c: 4.017306533726779 avg_loss_a: -103.39134667136453\n",
            "Número de pasos del episodio 10208 son episode_steps:99\n",
            "Total Steps: 722029 Episode Num: 10208 Reward: 107.53470351271434 avg_loss_c: 3.580122810421568 avg_loss_a: -103.39321144181069\n",
            "Número de pasos del episodio 10209 son episode_steps:146\n",
            "Total Steps: 722175 Episode Num: 10209 Reward: 173.63738807201204 avg_loss_c: 4.047015593476491 avg_loss_a: -103.0558606500495\n",
            "Número de pasos del episodio 10210 son episode_steps:78\n",
            "Total Steps: 722253 Episode Num: 10210 Reward: 80.89184412514345 avg_loss_c: 3.9438463082680335 avg_loss_a: -102.76392638377654\n",
            "Número de pasos del episodio 10211 son episode_steps:139\n",
            "Total Steps: 722392 Episode Num: 10211 Reward: 164.18027831777022 avg_loss_c: 4.356259831421667 avg_loss_a: -103.17125136560674\n",
            "Número de pasos del episodio 10212 son episode_steps:82\n",
            "Total Steps: 722474 Episode Num: 10212 Reward: -3.94931002784969 avg_loss_c: 4.47449877494719 avg_loss_a: -102.99091934576268\n",
            "Número de pasos del episodio 10213 son episode_steps:87\n",
            "Total Steps: 722561 Episode Num: 10213 Reward: 107.87689507255497 avg_loss_c: 4.6206514122842375 avg_loss_a: -104.06328793229729\n",
            "Número de pasos del episodio 10214 son episode_steps:457\n",
            "Total Steps: 723018 Episode Num: 10214 Reward: 674.6785163537154 avg_loss_c: 4.321007068621513 avg_loss_a: -103.09601240763257\n",
            "Número de pasos del episodio 10215 son episode_steps:261\n",
            "Total Steps: 723279 Episode Num: 10215 Reward: 369.54546464814695 avg_loss_c: 4.441933822814532 avg_loss_a: -103.89559962831694\n",
            "Número de pasos del episodio 10216 son episode_steps:111\n",
            "Total Steps: 723390 Episode Num: 10216 Reward: 95.61581623395635 avg_loss_c: 4.472843589009465 avg_loss_a: -103.50852100269215\n",
            "Número de pasos del episodio 10217 son episode_steps:42\n",
            "Total Steps: 723432 Episode Num: 10217 Reward: 20.884454385579083 avg_loss_c: 4.327824484734308 avg_loss_a: -103.29918089367095\n",
            "Número de pasos del episodio 10218 son episode_steps:601\n",
            "Total Steps: 724033 Episode Num: 10218 Reward: 1025.6214961449698 avg_loss_c: 4.54912893109631 avg_loss_a: -103.22954677385022\n",
            "Número de pasos del episodio 10219 son episode_steps:179\n",
            "Total Steps: 724212 Episode Num: 10219 Reward: 238.18080235006198 avg_loss_c: 4.315563055390086 avg_loss_a: -103.22488092177407\n",
            "Número de pasos del episodio 10220 son episode_steps:1000\n",
            "Total Steps: 725212 Episode Num: 10220 Reward: 1711.5778730711972 avg_loss_c: 4.22501185297966 avg_loss_a: -104.25218864440917\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 399.759126\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10221 son episode_steps:1000\n",
            "Total Steps: 726212 Episode Num: 10221 Reward: 1742.6051162817998 avg_loss_c: 3.8353141584396364 avg_loss_a: -105.95727560424805\n",
            "Número de pasos del episodio 10222 son episode_steps:735\n",
            "Total Steps: 726947 Episode Num: 10222 Reward: 1228.2545477606998 avg_loss_c: 3.947178573348895 avg_loss_a: -106.15465030799918\n",
            "Número de pasos del episodio 10223 son episode_steps:77\n",
            "Total Steps: 727024 Episode Num: 10223 Reward: 83.87924201751015 avg_loss_c: 3.9979529318871436 avg_loss_a: -106.37560698273894\n",
            "Número de pasos del episodio 10224 son episode_steps:108\n",
            "Total Steps: 727132 Episode Num: 10224 Reward: 135.6246622939586 avg_loss_c: 3.951193312803904 avg_loss_a: -106.23614954065394\n",
            "Número de pasos del episodio 10225 son episode_steps:109\n",
            "Total Steps: 727241 Episode Num: 10225 Reward: 42.100550012476674 avg_loss_c: 4.541453352761925 avg_loss_a: -105.8492555530793\n",
            "Número de pasos del episodio 10226 son episode_steps:444\n",
            "Total Steps: 727685 Episode Num: 10226 Reward: 705.8695874756341 avg_loss_c: 4.554321483985798 avg_loss_a: -105.85377272184904\n",
            "Número de pasos del episodio 10227 son episode_steps:50\n",
            "Total Steps: 727735 Episode Num: 10227 Reward: 21.121913095610985 avg_loss_c: 4.720178899765014 avg_loss_a: -106.38344451904297\n",
            "Número de pasos del episodio 10228 son episode_steps:82\n",
            "Total Steps: 727817 Episode Num: 10228 Reward: 92.91137377314618 avg_loss_c: 4.835059712572796 avg_loss_a: -105.80674148187404\n",
            "Número de pasos del episodio 10229 son episode_steps:57\n",
            "Total Steps: 727874 Episode Num: 10229 Reward: 55.280101825735485 avg_loss_c: 4.451892204451979 avg_loss_a: -105.76445355331688\n",
            "Número de pasos del episodio 10230 son episode_steps:47\n",
            "Total Steps: 727921 Episode Num: 10230 Reward: 23.036502299388935 avg_loss_c: 4.614894562579216 avg_loss_a: -105.4253075782289\n",
            "Número de pasos del episodio 10231 son episode_steps:263\n",
            "Total Steps: 728184 Episode Num: 10231 Reward: 376.7705863009689 avg_loss_c: 4.741595557434024 avg_loss_a: -105.4586993605465\n",
            "Número de pasos del episodio 10232 son episode_steps:41\n",
            "Total Steps: 728225 Episode Num: 10232 Reward: -0.5452026403281778 avg_loss_c: 5.05418438446231 avg_loss_a: -105.49916765166492\n",
            "Número de pasos del episodio 10233 son episode_steps:206\n",
            "Total Steps: 728431 Episode Num: 10233 Reward: 322.49983000380223 avg_loss_c: 4.951137641101208 avg_loss_a: -105.40634858955457\n",
            "Número de pasos del episodio 10234 son episode_steps:274\n",
            "Total Steps: 728705 Episode Num: 10234 Reward: 398.98985036281334 avg_loss_c: 4.921737207113392 avg_loss_a: -105.24884623506644\n",
            "Número de pasos del episodio 10235 son episode_steps:339\n",
            "Total Steps: 729044 Episode Num: 10235 Reward: 523.9920887585043 avg_loss_c: 4.842043742317717 avg_loss_a: -104.83398277710322\n",
            "Número de pasos del episodio 10236 son episode_steps:457\n",
            "Total Steps: 729501 Episode Num: 10236 Reward: 646.2377293064607 avg_loss_c: 5.006857700890472 avg_loss_a: -104.89032374743039\n",
            "Número de pasos del episodio 10237 son episode_steps:855\n",
            "Total Steps: 730356 Episode Num: 10237 Reward: 1388.148374619153 avg_loss_c: 5.115773719653749 avg_loss_a: -104.44683303386844\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 641.834924\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10238 son episode_steps:1000\n",
            "Total Steps: 731356 Episode Num: 10238 Reward: 1783.1304537746414 avg_loss_c: 4.760141192913055 avg_loss_a: -105.23082289123535\n",
            "Número de pasos del episodio 10239 son episode_steps:83\n",
            "Total Steps: 731439 Episode Num: 10239 Reward: 82.32330798968158 avg_loss_c: 5.319856729852148 avg_loss_a: -104.2644375720656\n",
            "Número de pasos del episodio 10240 son episode_steps:157\n",
            "Total Steps: 731596 Episode Num: 10240 Reward: 201.36458937481927 avg_loss_c: 5.125079944634893 avg_loss_a: -105.16867638849149\n",
            "Número de pasos del episodio 10241 son episode_steps:490\n",
            "Total Steps: 732086 Episode Num: 10241 Reward: 868.7888412887997 avg_loss_c: 4.879668987527186 avg_loss_a: -105.67358152428451\n",
            "Número de pasos del episodio 10242 son episode_steps:1000\n",
            "Total Steps: 733086 Episode Num: 10242 Reward: 1768.9621280151928 avg_loss_c: 4.652569851875305 avg_loss_a: -106.16708412170411\n",
            "Número de pasos del episodio 10243 son episode_steps:279\n",
            "Total Steps: 733365 Episode Num: 10243 Reward: 414.32343575564767 avg_loss_c: 4.666579033738824 avg_loss_a: -106.5168205726104\n",
            "Número de pasos del episodio 10244 son episode_steps:75\n",
            "Total Steps: 733440 Episode Num: 10244 Reward: 77.16929359578027 avg_loss_c: 4.8073541482289635 avg_loss_a: -106.43679992675781\n",
            "Número de pasos del episodio 10245 son episode_steps:88\n",
            "Total Steps: 733528 Episode Num: 10245 Reward: 35.58114742525388 avg_loss_c: 5.049840206449682 avg_loss_a: -105.69753768227316\n",
            "Número de pasos del episodio 10246 son episode_steps:592\n",
            "Total Steps: 734120 Episode Num: 10246 Reward: 916.8508324726965 avg_loss_c: 5.056753493241362 avg_loss_a: -106.53615732450743\n",
            "Número de pasos del episodio 10247 son episode_steps:80\n",
            "Total Steps: 734200 Episode Num: 10247 Reward: 69.01062140468885 avg_loss_c: 4.871674066781997 avg_loss_a: -106.4251781463623\n",
            "Número de pasos del episodio 10248 son episode_steps:139\n",
            "Total Steps: 734339 Episode Num: 10248 Reward: 132.16351970123512 avg_loss_c: 5.279764887240293 avg_loss_a: -106.61914918748595\n",
            "Número de pasos del episodio 10249 son episode_steps:396\n",
            "Total Steps: 734735 Episode Num: 10249 Reward: 642.679762816045 avg_loss_c: 5.150404862683229 avg_loss_a: -106.5251061025292\n",
            "Número de pasos del episodio 10250 son episode_steps:71\n",
            "Total Steps: 734806 Episode Num: 10250 Reward: 60.040700418081684 avg_loss_c: 5.313885252240678 avg_loss_a: -106.16840319566323\n",
            "Número de pasos del episodio 10251 son episode_steps:1000\n",
            "Total Steps: 735806 Episode Num: 10251 Reward: 1759.343159757843 avg_loss_c: 5.020582988262176 avg_loss_a: -106.88872311401367\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 896.340982\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10252 son episode_steps:577\n",
            "Total Steps: 736383 Episode Num: 10252 Reward: 904.4910228343178 avg_loss_c: 4.978623635227593 avg_loss_a: -107.80735523613941\n",
            "Número de pasos del episodio 10253 son episode_steps:91\n",
            "Total Steps: 736474 Episode Num: 10253 Reward: 36.02126822076198 avg_loss_c: 5.2132880582914245 avg_loss_a: -107.56156745323769\n",
            "Número de pasos del episodio 10254 son episode_steps:55\n",
            "Total Steps: 736529 Episode Num: 10254 Reward: 28.76720409692587 avg_loss_c: 6.069401372562755 avg_loss_a: -107.99269603382457\n",
            "Número de pasos del episodio 10255 son episode_steps:1000\n",
            "Total Steps: 737529 Episode Num: 10255 Reward: 1836.7909838882763 avg_loss_c: 5.1943312437534335 avg_loss_a: -107.86208462524414\n",
            "Número de pasos del episodio 10256 son episode_steps:1000\n",
            "Total Steps: 738529 Episode Num: 10256 Reward: 1770.9245292754972 avg_loss_c: 4.617682813644409 avg_loss_a: -108.9421759185791\n",
            "Número de pasos del episodio 10257 son episode_steps:996\n",
            "Total Steps: 739525 Episode Num: 10257 Reward: 1803.8065808040399 avg_loss_c: 4.502444273975479 avg_loss_a: -109.57592295451336\n",
            "Número de pasos del episodio 10258 son episode_steps:161\n",
            "Total Steps: 739686 Episode Num: 10258 Reward: 144.02911616855403 avg_loss_c: 4.937749573903054 avg_loss_a: -109.18079968564999\n",
            "Número de pasos del episodio 10259 son episode_steps:81\n",
            "Total Steps: 739767 Episode Num: 10259 Reward: 96.80748047197191 avg_loss_c: 4.695010488415941 avg_loss_a: -108.65661536322699\n",
            "Número de pasos del episodio 10260 son episode_steps:130\n",
            "Total Steps: 739897 Episode Num: 10260 Reward: 161.76891780853373 avg_loss_c: 4.720429572692284 avg_loss_a: -108.91714430588942\n",
            "Número de pasos del episodio 10261 son episode_steps:141\n",
            "Total Steps: 740038 Episode Num: 10261 Reward: 144.71889727643034 avg_loss_c: 5.381098738798858 avg_loss_a: -108.52937230319841\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 729.372773\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10262 son episode_steps:879\n",
            "Total Steps: 740917 Episode Num: 10262 Reward: 1475.7899714396356 avg_loss_c: 5.078344350788781 avg_loss_a: -108.85693894908154\n",
            "Número de pasos del episodio 10263 son episode_steps:108\n",
            "Total Steps: 741025 Episode Num: 10263 Reward: 126.08262337016856 avg_loss_c: 4.991414279849441 avg_loss_a: -109.39278228194625\n",
            "Número de pasos del episodio 10264 son episode_steps:159\n",
            "Total Steps: 741184 Episode Num: 10264 Reward: 174.5834728993873 avg_loss_c: 5.192592232482238 avg_loss_a: -108.91727476299934\n",
            "Número de pasos del episodio 10265 son episode_steps:99\n",
            "Total Steps: 741283 Episode Num: 10265 Reward: 40.78719576866807 avg_loss_c: 5.482823865582245 avg_loss_a: -108.16419982910156\n",
            "Número de pasos del episodio 10266 son episode_steps:758\n",
            "Total Steps: 742041 Episode Num: 10266 Reward: 1266.83077162385 avg_loss_c: 5.190139621417567 avg_loss_a: -109.3489651440945\n",
            "Número de pasos del episodio 10267 son episode_steps:45\n",
            "Total Steps: 742086 Episode Num: 10267 Reward: 38.01980832475523 avg_loss_c: 5.412036991119384 avg_loss_a: -108.46821780734592\n",
            "Número de pasos del episodio 10268 son episode_steps:355\n",
            "Total Steps: 742441 Episode Num: 10268 Reward: 555.242503018899 avg_loss_c: 5.187077470564507 avg_loss_a: -109.75230151968942\n",
            "Número de pasos del episodio 10269 son episode_steps:404\n",
            "Total Steps: 742845 Episode Num: 10269 Reward: 629.4151736357245 avg_loss_c: 5.238915719608269 avg_loss_a: -110.24516723179582\n",
            "Número de pasos del episodio 10270 son episode_steps:122\n",
            "Total Steps: 742967 Episode Num: 10270 Reward: 98.01363847278267 avg_loss_c: 5.416498620001996 avg_loss_a: -109.93133707515528\n",
            "Número de pasos del episodio 10271 son episode_steps:88\n",
            "Total Steps: 743055 Episode Num: 10271 Reward: 49.22954379575194 avg_loss_c: 5.5008425116539 avg_loss_a: -110.10070297934793\n",
            "Número de pasos del episodio 10272 son episode_steps:92\n",
            "Total Steps: 743147 Episode Num: 10272 Reward: 70.31979129533676 avg_loss_c: 5.410316721252773 avg_loss_a: -109.85490002839461\n",
            "Número de pasos del episodio 10273 son episode_steps:70\n",
            "Total Steps: 743217 Episode Num: 10273 Reward: 62.975956552406195 avg_loss_c: 5.809329414367676 avg_loss_a: -108.85220663888114\n",
            "Número de pasos del episodio 10274 son episode_steps:782\n",
            "Total Steps: 743999 Episode Num: 10274 Reward: 1379.4763939536083 avg_loss_c: 5.4613450436336 avg_loss_a: -110.3186293501988\n",
            "Número de pasos del episodio 10275 son episode_steps:116\n",
            "Total Steps: 744115 Episode Num: 10275 Reward: 97.62263879561301 avg_loss_c: 5.690644089517923 avg_loss_a: -109.97177768575735\n",
            "Número de pasos del episodio 10276 son episode_steps:65\n",
            "Total Steps: 744180 Episode Num: 10276 Reward: 65.90247320651348 avg_loss_c: 5.5603363770705005 avg_loss_a: -110.32272749680739\n",
            "Número de pasos del episodio 10277 son episode_steps:63\n",
            "Total Steps: 744243 Episode Num: 10277 Reward: 62.20128390362606 avg_loss_c: 5.727699537125845 avg_loss_a: -110.47427840459915\n",
            "Número de pasos del episodio 10278 son episode_steps:328\n",
            "Total Steps: 744571 Episode Num: 10278 Reward: 459.6161801185612 avg_loss_c: 5.866238540265618 avg_loss_a: -109.88025916494975\n",
            "Número de pasos del episodio 10279 son episode_steps:80\n",
            "Total Steps: 744651 Episode Num: 10279 Reward: 87.05400377999123 avg_loss_c: 5.726609405875206 avg_loss_a: -110.13243827819824\n",
            "Número de pasos del episodio 10280 son episode_steps:748\n",
            "Total Steps: 745399 Episode Num: 10280 Reward: 1096.304550403491 avg_loss_c: 6.100308483297175 avg_loss_a: -109.31784065776968\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 233.284313\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10281 son episode_steps:88\n",
            "Total Steps: 745487 Episode Num: 10281 Reward: 131.50044852921434 avg_loss_c: 5.8462229560722 avg_loss_a: -109.0042781829834\n",
            "Número de pasos del episodio 10282 son episode_steps:146\n",
            "Total Steps: 745633 Episode Num: 10282 Reward: 76.69091805985092 avg_loss_c: 6.654624230241122 avg_loss_a: -109.00372481672731\n",
            "Número de pasos del episodio 10283 son episode_steps:769\n",
            "Total Steps: 746402 Episode Num: 10283 Reward: 1166.0319248132257 avg_loss_c: 6.301932509140788 avg_loss_a: -108.65823751184193\n",
            "Número de pasos del episodio 10284 son episode_steps:219\n",
            "Total Steps: 746621 Episode Num: 10284 Reward: 339.21953934604437 avg_loss_c: 6.142262862697584 avg_loss_a: -108.98321571524285\n",
            "Número de pasos del episodio 10285 son episode_steps:930\n",
            "Total Steps: 747551 Episode Num: 10285 Reward: 1516.8606940346044 avg_loss_c: 6.134699912225046 avg_loss_a: -109.4661875242828\n",
            "Número de pasos del episodio 10286 son episode_steps:71\n",
            "Total Steps: 747622 Episode Num: 10286 Reward: 83.05650849406776 avg_loss_c: 5.915092072016757 avg_loss_a: -110.27774456185354\n",
            "Número de pasos del episodio 10287 son episode_steps:924\n",
            "Total Steps: 748546 Episode Num: 10287 Reward: 1225.4082724023842 avg_loss_c: 5.998823700013099 avg_loss_a: -110.39904423503133\n",
            "Número de pasos del episodio 10288 son episode_steps:291\n",
            "Total Steps: 748837 Episode Num: 10288 Reward: 449.37190888935555 avg_loss_c: 6.3590448902235 avg_loss_a: -110.4336782763504\n",
            "Número de pasos del episodio 10289 son episode_steps:68\n",
            "Total Steps: 748905 Episode Num: 10289 Reward: 78.57803244948006 avg_loss_c: 6.3250636703827805 avg_loss_a: -109.48116504444795\n",
            "Número de pasos del episodio 10290 son episode_steps:56\n",
            "Total Steps: 748961 Episode Num: 10290 Reward: -3.955411967110158 avg_loss_c: 6.602562384946006 avg_loss_a: -109.8979001726423\n",
            "Número de pasos del episodio 10291 son episode_steps:77\n",
            "Total Steps: 749038 Episode Num: 10291 Reward: 101.24831729641483 avg_loss_c: 6.748236841969676 avg_loss_a: -109.96024411684508\n",
            "Número de pasos del episodio 10292 son episode_steps:1000\n",
            "Total Steps: 750038 Episode Num: 10292 Reward: 1701.8906752618236 avg_loss_c: 6.091164211750031 avg_loss_a: -110.24058599853515\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 943.491155\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10293 son episode_steps:1000\n",
            "Total Steps: 751038 Episode Num: 10293 Reward: 1758.1900356809979 avg_loss_c: 5.731990743637085 avg_loss_a: -110.69530264282227\n",
            "Número de pasos del episodio 10294 son episode_steps:117\n",
            "Total Steps: 751155 Episode Num: 10294 Reward: 154.55784183899212 avg_loss_c: 5.9232392739026976 avg_loss_a: -110.70528405344385\n",
            "Número de pasos del episodio 10295 son episode_steps:249\n",
            "Total Steps: 751404 Episode Num: 10295 Reward: 355.28000703852086 avg_loss_c: 6.00323777313692 avg_loss_a: -110.9700291645096\n",
            "Número de pasos del episodio 10296 son episode_steps:19\n",
            "Total Steps: 751423 Episode Num: 10296 Reward: -36.0201685565864 avg_loss_c: 6.6674661134418685 avg_loss_a: -110.86973852860301\n",
            "Número de pasos del episodio 10297 son episode_steps:242\n",
            "Total Steps: 751665 Episode Num: 10297 Reward: 312.2150048666662 avg_loss_c: 6.5149339447336745 avg_loss_a: -110.95042104169357\n",
            "Número de pasos del episodio 10298 son episode_steps:1000\n",
            "Total Steps: 752665 Episode Num: 10298 Reward: 1742.7063680469823 avg_loss_c: 5.888776637792588 avg_loss_a: -111.35934909057617\n",
            "Número de pasos del episodio 10299 son episode_steps:1000\n",
            "Total Steps: 753665 Episode Num: 10299 Reward: 1726.5504132124595 avg_loss_c: 5.375885066509247 avg_loss_a: -112.6554969329834\n",
            "Número de pasos del episodio 10300 son episode_steps:148\n",
            "Total Steps: 753813 Episode Num: 10300 Reward: 123.2427305015202 avg_loss_c: 5.603155471183158 avg_loss_a: -113.4527745633512\n",
            "Número de pasos del episodio 10301 son episode_steps:804\n",
            "Total Steps: 754617 Episode Num: 10301 Reward: 1386.7535300916006 avg_loss_c: 5.465682299872536 avg_loss_a: -113.83076302447722\n",
            "Número de pasos del episodio 10302 son episode_steps:1000\n",
            "Total Steps: 755617 Episode Num: 10302 Reward: 1807.881448519112 avg_loss_c: 5.103419401407242 avg_loss_a: -114.49792663574219\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 518.055011\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10303 son episode_steps:260\n",
            "Total Steps: 755877 Episode Num: 10303 Reward: 401.64376529574236 avg_loss_c: 5.43118477326173 avg_loss_a: -114.91301815326398\n",
            "Número de pasos del episodio 10304 son episode_steps:117\n",
            "Total Steps: 755994 Episode Num: 10304 Reward: 121.36793747860303 avg_loss_c: 5.496994020592453 avg_loss_a: -115.36104303343683\n",
            "Número de pasos del episodio 10305 son episode_steps:133\n",
            "Total Steps: 756127 Episode Num: 10305 Reward: 155.96612422521682 avg_loss_c: 5.677373251520601 avg_loss_a: -114.36576762952302\n",
            "Número de pasos del episodio 10306 son episode_steps:133\n",
            "Total Steps: 756260 Episode Num: 10306 Reward: 127.94378140812537 avg_loss_c: 5.532132338760491 avg_loss_a: -113.94797659278812\n",
            "Número de pasos del episodio 10307 son episode_steps:295\n",
            "Total Steps: 756555 Episode Num: 10307 Reward: 424.93192867089914 avg_loss_c: 6.010168821528807 avg_loss_a: -114.71781479140459\n",
            "Número de pasos del episodio 10308 son episode_steps:39\n",
            "Total Steps: 756594 Episode Num: 10308 Reward: -18.802101734700543 avg_loss_c: 6.444994889772856 avg_loss_a: -114.6309335170648\n",
            "Número de pasos del episodio 10309 son episode_steps:45\n",
            "Total Steps: 756639 Episode Num: 10309 Reward: -34.72826957970312 avg_loss_c: 6.20070530573527 avg_loss_a: -113.60171000162761\n",
            "Número de pasos del episodio 10310 son episode_steps:108\n",
            "Total Steps: 756747 Episode Num: 10310 Reward: 88.66057572923135 avg_loss_c: 6.048872632009012 avg_loss_a: -114.0820506060565\n",
            "Número de pasos del episodio 10311 son episode_steps:28\n",
            "Total Steps: 756775 Episode Num: 10311 Reward: -24.832155546763943 avg_loss_c: 6.287219882011414 avg_loss_a: -114.02445547921317\n",
            "Número de pasos del episodio 10312 son episode_steps:160\n",
            "Total Steps: 756935 Episode Num: 10312 Reward: 194.34066647890594 avg_loss_c: 7.160498201847076 avg_loss_a: -113.07003087997437\n",
            "Número de pasos del episodio 10313 son episode_steps:227\n",
            "Total Steps: 757162 Episode Num: 10313 Reward: 216.12356494484882 avg_loss_c: 6.951031976859475 avg_loss_a: -113.50816610731218\n",
            "Número de pasos del episodio 10314 son episode_steps:95\n",
            "Total Steps: 757257 Episode Num: 10314 Reward: 91.37556893366231 avg_loss_c: 6.886344324915033 avg_loss_a: -113.40611628482216\n",
            "Número de pasos del episodio 10315 son episode_steps:224\n",
            "Total Steps: 757481 Episode Num: 10315 Reward: 275.83911267985 avg_loss_c: 7.114574100290026 avg_loss_a: -112.99324880327497\n",
            "Número de pasos del episodio 10316 son episode_steps:81\n",
            "Total Steps: 757562 Episode Num: 10316 Reward: 61.708052607758376 avg_loss_c: 7.265256525557718 avg_loss_a: -113.49478215347102\n",
            "Número de pasos del episodio 10317 son episode_steps:52\n",
            "Total Steps: 757614 Episode Num: 10317 Reward: 41.885928434308845 avg_loss_c: 7.251319188338059 avg_loss_a: -112.29569801917442\n",
            "Número de pasos del episodio 10318 son episode_steps:94\n",
            "Total Steps: 757708 Episode Num: 10318 Reward: 12.844990740298947 avg_loss_c: 7.394172957602968 avg_loss_a: -112.19036881467129\n",
            "Número de pasos del episodio 10319 son episode_steps:191\n",
            "Total Steps: 757899 Episode Num: 10319 Reward: 227.2795771891145 avg_loss_c: 8.223190404981843 avg_loss_a: -111.82648284272997\n",
            "Número de pasos del episodio 10320 son episode_steps:435\n",
            "Total Steps: 758334 Episode Num: 10320 Reward: 607.6617743712038 avg_loss_c: 7.752157137859827 avg_loss_a: -111.63516063470951\n",
            "Número de pasos del episodio 10321 son episode_steps:567\n",
            "Total Steps: 758901 Episode Num: 10321 Reward: 892.9196792118488 avg_loss_c: 7.722112281402373 avg_loss_a: -111.4526002941098\n",
            "Número de pasos del episodio 10322 son episode_steps:106\n",
            "Total Steps: 759007 Episode Num: 10322 Reward: 112.99904878461415 avg_loss_c: 7.800157178123042 avg_loss_a: -110.98876406111808\n",
            "Número de pasos del episodio 10323 son episode_steps:448\n",
            "Total Steps: 759455 Episode Num: 10323 Reward: 723.9107743550217 avg_loss_c: 7.926873143230166 avg_loss_a: -110.90739076478141\n",
            "Número de pasos del episodio 10324 son episode_steps:44\n",
            "Total Steps: 759499 Episode Num: 10324 Reward: -66.59315243529058 avg_loss_c: 7.912862398407676 avg_loss_a: -110.82054276899858\n",
            "Número de pasos del episodio 10325 son episode_steps:62\n",
            "Total Steps: 759561 Episode Num: 10325 Reward: 58.352162081658264 avg_loss_c: 7.817636889796103 avg_loss_a: -110.71178067115045\n",
            "Número de pasos del episodio 10326 son episode_steps:63\n",
            "Total Steps: 759624 Episode Num: 10326 Reward: 40.8455736306061 avg_loss_c: 8.770671632554796 avg_loss_a: -109.73877510191902\n",
            "Número de pasos del episodio 10327 son episode_steps:270\n",
            "Total Steps: 759894 Episode Num: 10327 Reward: 356.6566071820426 avg_loss_c: 8.46201535154272 avg_loss_a: -111.1029372603805\n",
            "Número de pasos del episodio 10328 son episode_steps:355\n",
            "Total Steps: 760249 Episode Num: 10328 Reward: 453.3628841400399 avg_loss_c: 8.39326945425759 avg_loss_a: -111.16007628105056\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 923.713570\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10329 son episode_steps:317\n",
            "Total Steps: 760566 Episode Num: 10329 Reward: 311.0042965329634 avg_loss_c: 8.847809034943204 avg_loss_a: -110.42619778606041\n",
            "Número de pasos del episodio 10330 son episode_steps:1000\n",
            "Total Steps: 761566 Episode Num: 10330 Reward: 1669.7464194840102 avg_loss_c: 7.968839583396911 avg_loss_a: -111.54102268981934\n",
            "Número de pasos del episodio 10331 son episode_steps:151\n",
            "Total Steps: 761717 Episode Num: 10331 Reward: 145.78041354310608 avg_loss_c: 8.36167999292841 avg_loss_a: -111.41770369169728\n",
            "Número de pasos del episodio 10332 son episode_steps:242\n",
            "Total Steps: 761959 Episode Num: 10332 Reward: 302.7915678066795 avg_loss_c: 8.217524567911447 avg_loss_a: -111.6556206064776\n",
            "Número de pasos del episodio 10333 son episode_steps:976\n",
            "Total Steps: 762935 Episode Num: 10333 Reward: 1639.173793290116 avg_loss_c: 7.8266338285852655 avg_loss_a: -112.88431821103956\n",
            "Número de pasos del episodio 10334 son episode_steps:37\n",
            "Total Steps: 762972 Episode Num: 10334 Reward: -20.51514002824955 avg_loss_c: 9.104571716205493 avg_loss_a: -113.29140389932168\n",
            "Número de pasos del episodio 10335 son episode_steps:38\n",
            "Total Steps: 763010 Episode Num: 10335 Reward: -28.95280725082376 avg_loss_c: 8.189893371180483 avg_loss_a: -112.84700092516448\n",
            "Número de pasos del episodio 10336 son episode_steps:162\n",
            "Total Steps: 763172 Episode Num: 10336 Reward: 202.7213196896869 avg_loss_c: 9.117825802461601 avg_loss_a: -113.05027337721836\n",
            "Número de pasos del episodio 10337 son episode_steps:50\n",
            "Total Steps: 763222 Episode Num: 10337 Reward: -69.52271792957299 avg_loss_c: 10.39451099395752 avg_loss_a: -112.72856201171875\n",
            "Número de pasos del episodio 10338 son episode_steps:1000\n",
            "Total Steps: 764222 Episode Num: 10338 Reward: 1711.2201446188371 avg_loss_c: 8.410078447818757 avg_loss_a: -113.52735569763183\n",
            "Número de pasos del episodio 10339 son episode_steps:280\n",
            "Total Steps: 764502 Episode Num: 10339 Reward: 443.9946667372792 avg_loss_c: 7.952993495123727 avg_loss_a: -113.45345306396484\n",
            "Número de pasos del episodio 10340 son episode_steps:76\n",
            "Total Steps: 764578 Episode Num: 10340 Reward: 28.578019672300314 avg_loss_c: 8.020834778484545 avg_loss_a: -114.47121027896279\n",
            "Número de pasos del episodio 10341 son episode_steps:953\n",
            "Total Steps: 765531 Episode Num: 10341 Reward: 1609.7727992406146 avg_loss_c: 7.7671853933104185 avg_loss_a: -115.27244247644671\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 285.689607\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10342 son episode_steps:637\n",
            "Total Steps: 766168 Episode Num: 10342 Reward: 1012.9158769478287 avg_loss_c: 7.876314215607696 avg_loss_a: -115.25421402480576\n",
            "Número de pasos del episodio 10343 son episode_steps:586\n",
            "Total Steps: 766754 Episode Num: 10343 Reward: 875.3533966701083 avg_loss_c: 7.612445432985195 avg_loss_a: -116.0777859997017\n",
            "Número de pasos del episodio 10344 son episode_steps:1000\n",
            "Total Steps: 767754 Episode Num: 10344 Reward: 1585.7609723574633 avg_loss_c: 7.276687326431275 avg_loss_a: -116.2897174835205\n",
            "Número de pasos del episodio 10345 son episode_steps:75\n",
            "Total Steps: 767829 Episode Num: 10345 Reward: 11.986572454241738 avg_loss_c: 7.461161835988363 avg_loss_a: -116.64690673828125\n",
            "Número de pasos del episodio 10346 son episode_steps:459\n",
            "Total Steps: 768288 Episode Num: 10346 Reward: 749.6043535332636 avg_loss_c: 7.484796202000969 avg_loss_a: -116.72114548028684\n",
            "Número de pasos del episodio 10347 son episode_steps:47\n",
            "Total Steps: 768335 Episode Num: 10347 Reward: 39.07304127778075 avg_loss_c: 7.984469748557882 avg_loss_a: -116.72345019401388\n",
            "Número de pasos del episodio 10348 son episode_steps:626\n",
            "Total Steps: 768961 Episode Num: 10348 Reward: 971.8476562724197 avg_loss_c: 7.428178198802205 avg_loss_a: -117.8364173474784\n",
            "Número de pasos del episodio 10349 son episode_steps:367\n",
            "Total Steps: 769328 Episode Num: 10349 Reward: 576.6899520153306 avg_loss_c: 7.179443264527282 avg_loss_a: -117.83672630039807\n",
            "Número de pasos del episodio 10350 son episode_steps:1000\n",
            "Total Steps: 770328 Episode Num: 10350 Reward: 1649.384895629522 avg_loss_c: 6.914037370204926 avg_loss_a: -118.44313110351563\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 1008.028115\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10351 son episode_steps:34\n",
            "Total Steps: 770362 Episode Num: 10351 Reward: 0.8385812421110228 avg_loss_c: 7.484216381521786 avg_loss_a: -117.69009893080768\n",
            "Número de pasos del episodio 10352 son episode_steps:1000\n",
            "Total Steps: 771362 Episode Num: 10352 Reward: 1604.3422750139162 avg_loss_c: 6.61251376914978 avg_loss_a: -118.71141511535644\n",
            "Número de pasos del episodio 10353 son episode_steps:60\n",
            "Total Steps: 771422 Episode Num: 10353 Reward: -87.78075101741005 avg_loss_c: 8.341118176778158 avg_loss_a: -118.60133717854818\n",
            "Número de pasos del episodio 10354 son episode_steps:229\n",
            "Total Steps: 771651 Episode Num: 10354 Reward: 332.59190135626716 avg_loss_c: 7.322646963544288 avg_loss_a: -119.28455662623243\n",
            "Número de pasos del episodio 10355 son episode_steps:255\n",
            "Total Steps: 771906 Episode Num: 10355 Reward: 390.86030574823604 avg_loss_c: 6.558732515222886 avg_loss_a: -119.15928195130591\n",
            "Número de pasos del episodio 10356 son episode_steps:141\n",
            "Total Steps: 772047 Episode Num: 10356 Reward: 215.80851032841252 avg_loss_c: 6.980036566443477 avg_loss_a: -118.71800307686448\n",
            "Número de pasos del episodio 10357 son episode_steps:116\n",
            "Total Steps: 772163 Episode Num: 10357 Reward: 119.06799786244868 avg_loss_c: 7.322500487853741 avg_loss_a: -118.84159232830179\n",
            "Número de pasos del episodio 10358 son episode_steps:80\n",
            "Total Steps: 772243 Episode Num: 10358 Reward: 82.11260234751974 avg_loss_c: 7.465918308496475 avg_loss_a: -117.12946872711181\n",
            "Número de pasos del episodio 10359 son episode_steps:1000\n",
            "Total Steps: 773243 Episode Num: 10359 Reward: 1798.8220295239796 avg_loss_c: 6.7116581242084505 avg_loss_a: -118.96059078979492\n",
            "Número de pasos del episodio 10360 son episode_steps:201\n",
            "Total Steps: 773444 Episode Num: 10360 Reward: 272.10120513282465 avg_loss_c: 6.821667773213552 avg_loss_a: -119.26370307580748\n",
            "Número de pasos del episodio 10361 son episode_steps:341\n",
            "Total Steps: 773785 Episode Num: 10361 Reward: 440.80210908563595 avg_loss_c: 6.923426017034089 avg_loss_a: -118.3070560578377\n",
            "Número de pasos del episodio 10362 son episode_steps:332\n",
            "Total Steps: 774117 Episode Num: 10362 Reward: 535.8253869484387 avg_loss_c: 6.7730388454644075 avg_loss_a: -118.90588107741023\n",
            "Número de pasos del episodio 10363 son episode_steps:66\n",
            "Total Steps: 774183 Episode Num: 10363 Reward: 58.553095292765164 avg_loss_c: 6.696828452023593 avg_loss_a: -119.30280003403172\n",
            "Número de pasos del episodio 10364 son episode_steps:1000\n",
            "Total Steps: 775183 Episode Num: 10364 Reward: 1662.282456639216 avg_loss_c: 6.648562163114548 avg_loss_a: -118.87740251159669\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 1036.941786\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10365 son episode_steps:217\n",
            "Total Steps: 775400 Episode Num: 10365 Reward: 315.032231139167 avg_loss_c: 6.768969164465979 avg_loss_a: -118.54288943242368\n",
            "Número de pasos del episodio 10366 son episode_steps:314\n",
            "Total Steps: 775714 Episode Num: 10366 Reward: 465.37860875153945 avg_loss_c: 6.773324814571697 avg_loss_a: -118.88438264883249\n",
            "Número de pasos del episodio 10367 son episode_steps:220\n",
            "Total Steps: 775934 Episode Num: 10367 Reward: 248.86001890746175 avg_loss_c: 6.865168727527966 avg_loss_a: -118.98924872658469\n",
            "Número de pasos del episodio 10368 son episode_steps:725\n",
            "Total Steps: 776659 Episode Num: 10368 Reward: 1199.4546846359856 avg_loss_c: 6.4933870259646715 avg_loss_a: -120.26289593926792\n",
            "Número de pasos del episodio 10369 son episode_steps:97\n",
            "Total Steps: 776756 Episode Num: 10369 Reward: 127.45806471095415 avg_loss_c: 6.460954533409827 avg_loss_a: -120.26830244555916\n",
            "Número de pasos del episodio 10370 son episode_steps:655\n",
            "Total Steps: 777411 Episode Num: 10370 Reward: 1039.0475284981594 avg_loss_c: 6.776914290071444 avg_loss_a: -120.97997322373718\n",
            "Número de pasos del episodio 10371 son episode_steps:49\n",
            "Total Steps: 777460 Episode Num: 10371 Reward: 30.305110733149018 avg_loss_c: 7.1448246605542245 avg_loss_a: -122.0520382316745\n",
            "Número de pasos del episodio 10372 son episode_steps:185\n",
            "Total Steps: 777645 Episode Num: 10372 Reward: 179.48382302832238 avg_loss_c: 6.87118713791306 avg_loss_a: -120.93625719225085\n",
            "Número de pasos del episodio 10373 son episode_steps:65\n",
            "Total Steps: 777710 Episode Num: 10373 Reward: 15.44041217939096 avg_loss_c: 7.331672463050255 avg_loss_a: -121.01743868314303\n",
            "Número de pasos del episodio 10374 son episode_steps:1000\n",
            "Total Steps: 778710 Episode Num: 10374 Reward: 1730.3178732965043 avg_loss_c: 6.434452107429505 avg_loss_a: -121.88204023742676\n",
            "Número de pasos del episodio 10375 son episode_steps:275\n",
            "Total Steps: 778985 Episode Num: 10375 Reward: 383.1541589688309 avg_loss_c: 6.207141147093339 avg_loss_a: -122.12590792569247\n",
            "Número de pasos del episodio 10376 son episode_steps:333\n",
            "Total Steps: 779318 Episode Num: 10376 Reward: 378.63555911825165 avg_loss_c: 6.661591412426831 avg_loss_a: -121.87299949485619\n",
            "Número de pasos del episodio 10377 son episode_steps:1000\n",
            "Total Steps: 780318 Episode Num: 10377 Reward: 1765.3206723462774 avg_loss_c: 5.9420402464866635 avg_loss_a: -123.52063897705078\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 386.345437\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10378 son episode_steps:1000\n",
            "Total Steps: 781318 Episode Num: 10378 Reward: 1695.8489360439073 avg_loss_c: 5.594347727060318 avg_loss_a: -124.0250285949707\n",
            "Número de pasos del episodio 10379 son episode_steps:211\n",
            "Total Steps: 781529 Episode Num: 10379 Reward: 265.4726619679524 avg_loss_c: 5.771577378584875 avg_loss_a: -123.79348675334623\n",
            "Número de pasos del episodio 10380 son episode_steps:78\n",
            "Total Steps: 781607 Episode Num: 10380 Reward: 69.37944190006499 avg_loss_c: 6.015699796187572 avg_loss_a: -123.76952635936247\n",
            "Número de pasos del episodio 10381 son episode_steps:292\n",
            "Total Steps: 781899 Episode Num: 10381 Reward: 398.6546551296814 avg_loss_c: 5.801605957011654 avg_loss_a: -123.9244520631555\n",
            "Número de pasos del episodio 10382 son episode_steps:65\n",
            "Total Steps: 781964 Episode Num: 10382 Reward: 7.553845450227457 avg_loss_c: 6.3186183269207294 avg_loss_a: -124.46545691856971\n",
            "Número de pasos del episodio 10383 son episode_steps:80\n",
            "Total Steps: 782044 Episode Num: 10383 Reward: 64.68724457356045 avg_loss_c: 5.807896918058395 avg_loss_a: -124.06909618377685\n",
            "Número de pasos del episodio 10384 son episode_steps:439\n",
            "Total Steps: 782483 Episode Num: 10384 Reward: 623.1544648010382 avg_loss_c: 6.461108086049421 avg_loss_a: -123.52993685781006\n",
            "Número de pasos del episodio 10385 son episode_steps:1000\n",
            "Total Steps: 783483 Episode Num: 10385 Reward: 1584.2032858574285 avg_loss_c: 5.998903814077377 avg_loss_a: -124.24116413879395\n",
            "Número de pasos del episodio 10386 son episode_steps:68\n",
            "Total Steps: 783551 Episode Num: 10386 Reward: 82.4220821792744 avg_loss_c: 5.680578564896303 avg_loss_a: -124.47579036039464\n",
            "Número de pasos del episodio 10387 son episode_steps:73\n",
            "Total Steps: 783624 Episode Num: 10387 Reward: -37.86233056222346 avg_loss_c: 7.114321522516747 avg_loss_a: -123.97128828910932\n",
            "Número de pasos del episodio 10388 son episode_steps:68\n",
            "Total Steps: 783692 Episode Num: 10388 Reward: -7.754490559668793 avg_loss_c: 6.468338107361513 avg_loss_a: -123.18983481912052\n",
            "Número de pasos del episodio 10389 son episode_steps:400\n",
            "Total Steps: 784092 Episode Num: 10389 Reward: 556.6802771672269 avg_loss_c: 7.079173378944397 avg_loss_a: -123.49331871032715\n",
            "Número de pasos del episodio 10390 son episode_steps:79\n",
            "Total Steps: 784171 Episode Num: 10390 Reward: 33.05188547156688 avg_loss_c: 6.475318202489539 avg_loss_a: -122.89144453217712\n",
            "Número de pasos del episodio 10391 son episode_steps:71\n",
            "Total Steps: 784242 Episode Num: 10391 Reward: 18.87824504816546 avg_loss_c: 7.244664044447348 avg_loss_a: -122.8217148042061\n",
            "Número de pasos del episodio 10392 son episode_steps:543\n",
            "Total Steps: 784785 Episode Num: 10392 Reward: 855.7045804251748 avg_loss_c: 6.757564367290799 avg_loss_a: -122.9083508795357\n",
            "Número de pasos del episodio 10393 son episode_steps:294\n",
            "Total Steps: 785079 Episode Num: 10393 Reward: 433.82614254509036 avg_loss_c: 6.439886501857212 avg_loss_a: -123.3679293158914\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 32.914839\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10394 son episode_steps:117\n",
            "Total Steps: 785196 Episode Num: 10394 Reward: 81.96914864436627 avg_loss_c: 6.753970741206764 avg_loss_a: -123.49449679382846\n",
            "Número de pasos del episodio 10395 son episode_steps:138\n",
            "Total Steps: 785334 Episode Num: 10395 Reward: 40.776062711132006 avg_loss_c: 7.910362741221553 avg_loss_a: -122.78231601438661\n",
            "Número de pasos del episodio 10396 son episode_steps:107\n",
            "Total Steps: 785441 Episode Num: 10396 Reward: 111.5662396786819 avg_loss_c: 7.140105595098477 avg_loss_a: -121.8630627070632\n",
            "Número de pasos del episodio 10397 son episode_steps:278\n",
            "Total Steps: 785719 Episode Num: 10397 Reward: 402.12500740927527 avg_loss_c: 7.255837993656131 avg_loss_a: -122.70295611045343\n",
            "Número de pasos del episodio 10398 son episode_steps:71\n",
            "Total Steps: 785790 Episode Num: 10398 Reward: 55.08650641021288 avg_loss_c: 7.201493149072352 avg_loss_a: -122.74858125498596\n",
            "Número de pasos del episodio 10399 son episode_steps:73\n",
            "Total Steps: 785863 Episode Num: 10399 Reward: 46.20706933155965 avg_loss_c: 7.533262141763347 avg_loss_a: -121.55911244431587\n",
            "Número de pasos del episodio 10400 son episode_steps:60\n",
            "Total Steps: 785923 Episode Num: 10400 Reward: 2.239708975570453 avg_loss_c: 7.380185226599376 avg_loss_a: -121.70683161417644\n",
            "Número de pasos del episodio 10401 son episode_steps:129\n",
            "Total Steps: 786052 Episode Num: 10401 Reward: 104.70312495597486 avg_loss_c: 7.580163879912029 avg_loss_a: -121.49996877271076\n",
            "Número de pasos del episodio 10402 son episode_steps:73\n",
            "Total Steps: 786125 Episode Num: 10402 Reward: 75.36085741001321 avg_loss_c: 7.951793344053503 avg_loss_a: -121.62010328737024\n",
            "Número de pasos del episodio 10403 son episode_steps:75\n",
            "Total Steps: 786200 Episode Num: 10403 Reward: -14.870188516525722 avg_loss_c: 9.654607855478922 avg_loss_a: -121.13974558512369\n",
            "Número de pasos del episodio 10404 son episode_steps:201\n",
            "Total Steps: 786401 Episode Num: 10404 Reward: 276.0361176792602 avg_loss_c: 10.334121516687953 avg_loss_a: -121.10747178870054\n",
            "Número de pasos del episodio 10405 son episode_steps:78\n",
            "Total Steps: 786479 Episode Num: 10405 Reward: 8.15166239858634 avg_loss_c: 8.69649206675016 avg_loss_a: -121.50900229429587\n",
            "Número de pasos del episodio 10406 son episode_steps:76\n",
            "Total Steps: 786555 Episode Num: 10406 Reward: 62.276750499100096 avg_loss_c: 8.254353598544473 avg_loss_a: -120.94147310758892\n",
            "Número de pasos del episodio 10407 son episode_steps:67\n",
            "Total Steps: 786622 Episode Num: 10407 Reward: 57.36465753441653 avg_loss_c: 8.710374960258825 avg_loss_a: -120.57633072582644\n",
            "Número de pasos del episodio 10408 son episode_steps:153\n",
            "Total Steps: 786775 Episode Num: 10408 Reward: 126.60128085531333 avg_loss_c: 8.727100565542582 avg_loss_a: -120.03213929818347\n",
            "Número de pasos del episodio 10409 son episode_steps:63\n",
            "Total Steps: 786838 Episode Num: 10409 Reward: 33.274911929537126 avg_loss_c: 8.62668546040853 avg_loss_a: -119.26914009215339\n",
            "Número de pasos del episodio 10410 son episode_steps:144\n",
            "Total Steps: 786982 Episode Num: 10410 Reward: 135.90445783696237 avg_loss_c: 8.727642761336433 avg_loss_a: -119.62528800964355\n",
            "Número de pasos del episodio 10411 son episode_steps:65\n",
            "Total Steps: 787047 Episode Num: 10411 Reward: -11.544279562448907 avg_loss_c: 9.426785755157471 avg_loss_a: -119.6863795353816\n",
            "Número de pasos del episodio 10412 son episode_steps:117\n",
            "Total Steps: 787164 Episode Num: 10412 Reward: -62.91513203962858 avg_loss_c: 9.561805647662561 avg_loss_a: -118.73909172644981\n",
            "Número de pasos del episodio 10413 son episode_steps:176\n",
            "Total Steps: 787340 Episode Num: 10413 Reward: 102.838021829835 avg_loss_c: 9.63484053178267 avg_loss_a: -118.18621375344016\n",
            "Número de pasos del episodio 10414 son episode_steps:59\n",
            "Total Steps: 787399 Episode Num: 10414 Reward: 5.2338608052426006 avg_loss_c: 9.634836229227357 avg_loss_a: -119.36314741231628\n",
            "Número de pasos del episodio 10415 son episode_steps:66\n",
            "Total Steps: 787465 Episode Num: 10415 Reward: 32.543083536886066 avg_loss_c: 9.03873474670179 avg_loss_a: -118.95306419603753\n",
            "Número de pasos del episodio 10416 son episode_steps:281\n",
            "Total Steps: 787746 Episode Num: 10416 Reward: 356.74136361226783 avg_loss_c: 9.216429754508347 avg_loss_a: -117.75250447772152\n",
            "Número de pasos del episodio 10417 son episode_steps:62\n",
            "Total Steps: 787808 Episode Num: 10417 Reward: -33.8980632773723 avg_loss_c: 9.278854477790095 avg_loss_a: -116.60237712244833\n",
            "Número de pasos del episodio 10418 son episode_steps:58\n",
            "Total Steps: 787866 Episode Num: 10418 Reward: 43.926405578761276 avg_loss_c: 10.218327250973932 avg_loss_a: -117.93452927161907\n",
            "Número de pasos del episodio 10419 son episode_steps:67\n",
            "Total Steps: 787933 Episode Num: 10419 Reward: 5.512246082609189 avg_loss_c: 9.496079501821034 avg_loss_a: -117.51453149140771\n",
            "Número de pasos del episodio 10420 son episode_steps:1000\n",
            "Total Steps: 788933 Episode Num: 10420 Reward: 1705.541738793194 avg_loss_c: 9.319665598869324 avg_loss_a: -117.1948570098877\n",
            "Número de pasos del episodio 10421 son episode_steps:80\n",
            "Total Steps: 789013 Episode Num: 10421 Reward: 66.75254984743218 avg_loss_c: 9.052071434259414 avg_loss_a: -117.43102169036865\n",
            "Número de pasos del episodio 10422 son episode_steps:887\n",
            "Total Steps: 789900 Episode Num: 10422 Reward: 1379.2404498655053 avg_loss_c: 9.109787890446093 avg_loss_a: -117.17114631971081\n",
            "Número de pasos del episodio 10423 son episode_steps:1000\n",
            "Total Steps: 790900 Episode Num: 10423 Reward: 1785.7846830252513 avg_loss_c: 8.803486676216126 avg_loss_a: -117.33440159606934\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 886.961406\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10424 son episode_steps:70\n",
            "Total Steps: 790970 Episode Num: 10424 Reward: 45.68163184105722 avg_loss_c: 8.92810788835798 avg_loss_a: -117.34353703090123\n",
            "Número de pasos del episodio 10425 son episode_steps:1000\n",
            "Total Steps: 791970 Episode Num: 10425 Reward: 1628.1232503428184 avg_loss_c: 8.705241355419158 avg_loss_a: -117.52592985534667\n",
            "Número de pasos del episodio 10426 son episode_steps:72\n",
            "Total Steps: 792042 Episode Num: 10426 Reward: 74.46284783511555 avg_loss_c: 9.265131175518036 avg_loss_a: -117.78331798977322\n",
            "Número de pasos del episodio 10427 son episode_steps:511\n",
            "Total Steps: 792553 Episode Num: 10427 Reward: 841.7155998623983 avg_loss_c: 9.289883124618381 avg_loss_a: -117.82565821220264\n",
            "Número de pasos del episodio 10428 son episode_steps:89\n",
            "Total Steps: 792642 Episode Num: 10428 Reward: 75.56310398843765 avg_loss_c: 9.377480501539251 avg_loss_a: -117.13499184940638\n",
            "Número de pasos del episodio 10429 son episode_steps:376\n",
            "Total Steps: 793018 Episode Num: 10429 Reward: 603.082866779145 avg_loss_c: 9.005920076623877 avg_loss_a: -117.21100409487461\n",
            "Número de pasos del episodio 10430 son episode_steps:165\n",
            "Total Steps: 793183 Episode Num: 10430 Reward: 144.19004985075284 avg_loss_c: 9.639717824531324 avg_loss_a: -116.48549735329368\n",
            "Número de pasos del episodio 10431 son episode_steps:200\n",
            "Total Steps: 793383 Episode Num: 10431 Reward: 305.04625797414667 avg_loss_c: 9.208888161182404 avg_loss_a: -116.47331008911132\n",
            "Número de pasos del episodio 10432 son episode_steps:71\n",
            "Total Steps: 793454 Episode Num: 10432 Reward: 41.50010012360116 avg_loss_c: 10.460439272329841 avg_loss_a: -116.04820391157983\n",
            "Número de pasos del episodio 10433 son episode_steps:1000\n",
            "Total Steps: 794454 Episode Num: 10433 Reward: 1803.3660313422397 avg_loss_c: 8.937556192159652 avg_loss_a: -117.23135932922364\n",
            "Número de pasos del episodio 10434 son episode_steps:44\n",
            "Total Steps: 794498 Episode Num: 10434 Reward: 2.998005111019828 avg_loss_c: 9.11533615805886 avg_loss_a: -117.38104629516602\n",
            "Número de pasos del episodio 10435 son episode_steps:85\n",
            "Total Steps: 794583 Episode Num: 10435 Reward: 80.30639689382733 avg_loss_c: 9.341677160824046 avg_loss_a: -117.14664692598231\n",
            "Número de pasos del episodio 10436 son episode_steps:1000\n",
            "Total Steps: 795583 Episode Num: 10436 Reward: 1753.985789462462 avg_loss_c: 9.02382594871521 avg_loss_a: -117.57142315673828\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 534.192261\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10437 son episode_steps:1000\n",
            "Total Steps: 796583 Episode Num: 10437 Reward: 1637.6333205154353 avg_loss_c: 8.579502075195313 avg_loss_a: -118.24012139892578\n",
            "Número de pasos del episodio 10438 son episode_steps:116\n",
            "Total Steps: 796699 Episode Num: 10438 Reward: 17.90140273568805 avg_loss_c: 9.064095735549927 avg_loss_a: -118.54733434216729\n",
            "Número de pasos del episodio 10439 son episode_steps:349\n",
            "Total Steps: 797048 Episode Num: 10439 Reward: 413.457430190885 avg_loss_c: 8.841731082402532 avg_loss_a: -118.35522664242282\n",
            "Número de pasos del episodio 10440 son episode_steps:325\n",
            "Total Steps: 797373 Episode Num: 10440 Reward: 497.9172133111851 avg_loss_c: 8.661188988318811 avg_loss_a: -118.38964618389423\n",
            "Número de pasos del episodio 10441 son episode_steps:586\n",
            "Total Steps: 797959 Episode Num: 10441 Reward: 908.6530729637119 avg_loss_c: 8.464758638635837 avg_loss_a: -118.79693236367288\n",
            "Número de pasos del episodio 10442 son episode_steps:208\n",
            "Total Steps: 798167 Episode Num: 10442 Reward: 214.40764728253444 avg_loss_c: 8.645183829160837 avg_loss_a: -119.09474248152513\n",
            "Número de pasos del episodio 10443 son episode_steps:72\n",
            "Total Steps: 798239 Episode Num: 10443 Reward: 46.55074888178892 avg_loss_c: 8.789317283365461 avg_loss_a: -118.66150347391765\n",
            "Número de pasos del episodio 10444 son episode_steps:209\n",
            "Total Steps: 798448 Episode Num: 10444 Reward: 323.0633753852893 avg_loss_c: 9.083125265021073 avg_loss_a: -117.98950133255224\n",
            "Número de pasos del episodio 10445 son episode_steps:222\n",
            "Total Steps: 798670 Episode Num: 10445 Reward: 303.2811809999692 avg_loss_c: 9.014498744998967 avg_loss_a: -118.27469586896467\n",
            "Número de pasos del episodio 10446 son episode_steps:218\n",
            "Total Steps: 798888 Episode Num: 10446 Reward: 272.3917045342697 avg_loss_c: 8.840653240133863 avg_loss_a: -117.88418075141557\n",
            "Número de pasos del episodio 10447 son episode_steps:372\n",
            "Total Steps: 799260 Episode Num: 10447 Reward: 511.73272836395824 avg_loss_c: 8.977545694638325 avg_loss_a: -117.7477046187206\n",
            "Número de pasos del episodio 10448 son episode_steps:271\n",
            "Total Steps: 799531 Episode Num: 10448 Reward: 342.58256803281176 avg_loss_c: 8.56194307531378 avg_loss_a: -118.11983397086168\n",
            "Número de pasos del episodio 10449 son episode_steps:187\n",
            "Total Steps: 799718 Episode Num: 10449 Reward: 242.96310575629238 avg_loss_c: 8.979240817819687 avg_loss_a: -117.58013018439797\n",
            "Número de pasos del episodio 10450 son episode_steps:242\n",
            "Total Steps: 799960 Episode Num: 10450 Reward: 330.91254288600163 avg_loss_c: 8.747881040100223 avg_loss_a: -117.11371726043953\n",
            "Número de pasos del episodio 10451 son episode_steps:180\n",
            "Total Steps: 800140 Episode Num: 10451 Reward: 184.92381210804888 avg_loss_c: 8.728010307417975 avg_loss_a: -117.39499994913737\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 318.933847\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10452 son episode_steps:548\n",
            "Total Steps: 800688 Episode Num: 10452 Reward: 831.4364959757291 avg_loss_c: 8.741182201970233 avg_loss_a: -117.01770245071745\n",
            "Número de pasos del episodio 10453 son episode_steps:285\n",
            "Total Steps: 800973 Episode Num: 10453 Reward: 411.54661727478646 avg_loss_c: 8.854614937096311 avg_loss_a: -116.94065573173657\n",
            "Número de pasos del episodio 10454 son episode_steps:347\n",
            "Total Steps: 801320 Episode Num: 10454 Reward: 533.5651294871552 avg_loss_c: 8.7353869418933 avg_loss_a: -116.47932381313885\n",
            "Número de pasos del episodio 10455 son episode_steps:1000\n",
            "Total Steps: 802320 Episode Num: 10455 Reward: 1604.0620975567147 avg_loss_c: 8.31932859325409 avg_loss_a: -117.21271788024902\n",
            "Número de pasos del episodio 10456 son episode_steps:1000\n",
            "Total Steps: 803320 Episode Num: 10456 Reward: 1639.0630900177312 avg_loss_c: 7.863842386245728 avg_loss_a: -117.47987985229493\n",
            "Número de pasos del episodio 10457 son episode_steps:70\n",
            "Total Steps: 803390 Episode Num: 10457 Reward: 25.468937875438055 avg_loss_c: 8.280755301884243 avg_loss_a: -117.36436549595425\n",
            "Número de pasos del episodio 10458 son episode_steps:26\n",
            "Total Steps: 803416 Episode Num: 10458 Reward: -40.14323061282993 avg_loss_c: 8.568754471265352 avg_loss_a: -116.2732684795673\n",
            "Número de pasos del episodio 10459 son episode_steps:1000\n",
            "Total Steps: 804416 Episode Num: 10459 Reward: 1805.7943186698399 avg_loss_c: 7.356419656276703 avg_loss_a: -119.10681663513184\n",
            "Número de pasos del episodio 10460 son episode_steps:1000\n",
            "Total Steps: 805416 Episode Num: 10460 Reward: 1698.3607051487973 avg_loss_c: 6.947667228937149 avg_loss_a: -119.79584858703613\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 586.210365\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10461 son episode_steps:82\n",
            "Total Steps: 805498 Episode Num: 10461 Reward: 78.43264195551312 avg_loss_c: 6.98968959436184 avg_loss_a: -120.30424034304735\n",
            "Número de pasos del episodio 10462 son episode_steps:83\n",
            "Total Steps: 805581 Episode Num: 10462 Reward: 17.12970682128772 avg_loss_c: 7.403910671372011 avg_loss_a: -119.96336475050593\n",
            "Número de pasos del episodio 10463 son episode_steps:279\n",
            "Total Steps: 805860 Episode Num: 10463 Reward: 356.90346127905536 avg_loss_c: 7.572511549918882 avg_loss_a: -120.00803769019342\n",
            "Número de pasos del episodio 10464 son episode_steps:67\n",
            "Total Steps: 805927 Episode Num: 10464 Reward: 35.563327362661745 avg_loss_c: 7.489318516717028 avg_loss_a: -119.77314336976009\n",
            "Número de pasos del episodio 10465 son episode_steps:305\n",
            "Total Steps: 806232 Episode Num: 10465 Reward: 429.97360593969915 avg_loss_c: 7.438700575906722 avg_loss_a: -120.39969945188429\n",
            "Número de pasos del episodio 10466 son episode_steps:352\n",
            "Total Steps: 806584 Episode Num: 10466 Reward: 494.2809013170234 avg_loss_c: 8.001999692483382 avg_loss_a: -120.6368538683111\n",
            "Número de pasos del episodio 10467 son episode_steps:109\n",
            "Total Steps: 806693 Episode Num: 10467 Reward: 122.12977529097856 avg_loss_c: 7.808026383776183 avg_loss_a: -119.86162119174222\n",
            "Número de pasos del episodio 10468 son episode_steps:376\n",
            "Total Steps: 807069 Episode Num: 10468 Reward: 571.501463006176 avg_loss_c: 7.550308987181237 avg_loss_a: -121.40756180945863\n",
            "Número de pasos del episodio 10469 son episode_steps:1000\n",
            "Total Steps: 808069 Episode Num: 10469 Reward: 1716.2667333954346 avg_loss_c: 6.513950455665588 avg_loss_a: -123.32765510559082\n",
            "Número de pasos del episodio 10470 son episode_steps:406\n",
            "Total Steps: 808475 Episode Num: 10470 Reward: 438.40519855366557 avg_loss_c: 7.559022310919362 avg_loss_a: -122.7043865560898\n",
            "Número de pasos del episodio 10471 son episode_steps:386\n",
            "Total Steps: 808861 Episode Num: 10471 Reward: 579.3056465628198 avg_loss_c: 6.969740912086605 avg_loss_a: -122.55579668746711\n",
            "Número de pasos del episodio 10472 son episode_steps:76\n",
            "Total Steps: 808937 Episode Num: 10472 Reward: -39.30002907653023 avg_loss_c: 7.01072652402677 avg_loss_a: -123.10563679745323\n",
            "Número de pasos del episodio 10473 son episode_steps:250\n",
            "Total Steps: 809187 Episode Num: 10473 Reward: 319.81281206718944 avg_loss_c: 7.058156384468079 avg_loss_a: -122.59330670166015\n",
            "Número de pasos del episodio 10474 son episode_steps:81\n",
            "Total Steps: 809268 Episode Num: 10474 Reward: 62.833936915654675 avg_loss_c: 6.801094190573987 avg_loss_a: -122.60497378125604\n",
            "Número de pasos del episodio 10475 son episode_steps:196\n",
            "Total Steps: 809464 Episode Num: 10475 Reward: 228.66211649479257 avg_loss_c: 7.121592913355146 avg_loss_a: -121.52633939470563\n",
            "Número de pasos del episodio 10476 son episode_steps:38\n",
            "Total Steps: 809502 Episode Num: 10476 Reward: -4.715731697816244 avg_loss_c: 7.085064360969945 avg_loss_a: -120.56135960629112\n",
            "Número de pasos del episodio 10477 son episode_steps:51\n",
            "Total Steps: 809553 Episode Num: 10477 Reward: 11.62841429043931 avg_loss_c: 7.0933796237496765 avg_loss_a: -121.82183688294654\n",
            "Número de pasos del episodio 10478 son episode_steps:79\n",
            "Total Steps: 809632 Episode Num: 10478 Reward: 79.96743081152695 avg_loss_c: 7.801058853728862 avg_loss_a: -121.12033824679217\n",
            "Número de pasos del episodio 10479 son episode_steps:45\n",
            "Total Steps: 809677 Episode Num: 10479 Reward: 26.58773210909197 avg_loss_c: 7.557940875159369 avg_loss_a: -121.32709943983289\n",
            "Número de pasos del episodio 10480 son episode_steps:73\n",
            "Total Steps: 809750 Episode Num: 10480 Reward: 47.158399185358874 avg_loss_c: 8.251484211177042 avg_loss_a: -120.27200202419333\n",
            "Número de pasos del episodio 10481 son episode_steps:103\n",
            "Total Steps: 809853 Episode Num: 10481 Reward: 96.71266647095614 avg_loss_c: 8.246950672668161 avg_loss_a: -120.63227088706007\n",
            "Número de pasos del episodio 10482 son episode_steps:80\n",
            "Total Steps: 809933 Episode Num: 10482 Reward: 19.698540415164228 avg_loss_c: 8.007578241825104 avg_loss_a: -120.64370021820068\n",
            "Número de pasos del episodio 10483 son episode_steps:85\n",
            "Total Steps: 810018 Episode Num: 10483 Reward: 54.22182465285415 avg_loss_c: 8.342635508144603 avg_loss_a: -119.7350595810834\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 510.584047\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10484 son episode_steps:184\n",
            "Total Steps: 810202 Episode Num: 10484 Reward: 221.72916544359208 avg_loss_c: 8.733277660349142 avg_loss_a: -120.03087292546812\n",
            "Número de pasos del episodio 10485 son episode_steps:1000\n",
            "Total Steps: 811202 Episode Num: 10485 Reward: 1781.495469515076 avg_loss_c: 7.847746250629425 avg_loss_a: -119.99424717712402\n",
            "Número de pasos del episodio 10486 son episode_steps:58\n",
            "Total Steps: 811260 Episode Num: 10486 Reward: 27.901112463286854 avg_loss_c: 7.720779040764118 avg_loss_a: -120.85580286486396\n",
            "Número de pasos del episodio 10487 son episode_steps:104\n",
            "Total Steps: 811364 Episode Num: 10487 Reward: 118.95501607545881 avg_loss_c: 7.622353542309541 avg_loss_a: -119.24040735684909\n",
            "Número de pasos del episodio 10488 son episode_steps:1000\n",
            "Total Steps: 812364 Episode Num: 10488 Reward: 1653.6348582566727 avg_loss_c: 7.535665084123611 avg_loss_a: -119.41764045715333\n",
            "Número de pasos del episodio 10489 son episode_steps:134\n",
            "Total Steps: 812498 Episode Num: 10489 Reward: 101.22525044781577 avg_loss_c: 7.619773718848157 avg_loss_a: -119.60107171357568\n",
            "Número de pasos del episodio 10490 son episode_steps:90\n",
            "Total Steps: 812588 Episode Num: 10490 Reward: 56.59249030949301 avg_loss_c: 7.643039642439948 avg_loss_a: -119.3328852335612\n",
            "Número de pasos del episodio 10491 son episode_steps:459\n",
            "Total Steps: 813047 Episode Num: 10491 Reward: 688.3853675088635 avg_loss_c: 7.912080271311575 avg_loss_a: -119.50071111275999\n",
            "Número de pasos del episodio 10492 son episode_steps:50\n",
            "Total Steps: 813097 Episode Num: 10492 Reward: 8.210537669176585 avg_loss_c: 8.301829881668091 avg_loss_a: -118.69014709472657\n",
            "Número de pasos del episodio 10493 son episode_steps:1000\n",
            "Total Steps: 814097 Episode Num: 10493 Reward: 1639.6749592226895 avg_loss_c: 7.975830293655395 avg_loss_a: -119.428763671875\n",
            "Número de pasos del episodio 10494 son episode_steps:175\n",
            "Total Steps: 814272 Episode Num: 10494 Reward: 145.5461838152724 avg_loss_c: 8.11169403893607 avg_loss_a: -118.97894348144531\n",
            "Número de pasos del episodio 10495 son episode_steps:134\n",
            "Total Steps: 814406 Episode Num: 10495 Reward: 185.04376772185884 avg_loss_c: 7.96151628423093 avg_loss_a: -119.07242652551452\n",
            "Número de pasos del episodio 10496 son episode_steps:79\n",
            "Total Steps: 814485 Episode Num: 10496 Reward: 70.81982004701442 avg_loss_c: 8.219171258467663 avg_loss_a: -118.08802988559385\n",
            "Número de pasos del episodio 10497 son episode_steps:51\n",
            "Total Steps: 814536 Episode Num: 10497 Reward: 27.64302181226865 avg_loss_c: 8.306139029708563 avg_loss_a: -119.09198476753983\n",
            "Número de pasos del episodio 10498 son episode_steps:174\n",
            "Total Steps: 814710 Episode Num: 10498 Reward: 261.72492206424516 avg_loss_c: 8.321128636941143 avg_loss_a: -118.50647376049524\n",
            "Número de pasos del episodio 10499 son episode_steps:72\n",
            "Total Steps: 814782 Episode Num: 10499 Reward: -17.1084369523099 avg_loss_c: 9.441446569230822 avg_loss_a: -117.9565060933431\n",
            "Número de pasos del episodio 10500 son episode_steps:34\n",
            "Total Steps: 814816 Episode Num: 10500 Reward: -14.698950705769924 avg_loss_c: 9.138708605485803 avg_loss_a: -117.86521597469554\n",
            "Número de pasos del episodio 10501 son episode_steps:38\n",
            "Total Steps: 814854 Episode Num: 10501 Reward: -5.907366809848202 avg_loss_c: 9.844272437848543 avg_loss_a: -117.76591572008635\n",
            "Número de pasos del episodio 10502 son episode_steps:90\n",
            "Total Steps: 814944 Episode Num: 10502 Reward: 116.8409860756562 avg_loss_c: 9.867172045177883 avg_loss_a: -117.96114874945746\n",
            "Número de pasos del episodio 10503 son episode_steps:138\n",
            "Total Steps: 815082 Episode Num: 10503 Reward: 65.49861454217478 avg_loss_c: 9.116006177404653 avg_loss_a: -117.87916896654212\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 559.382259\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10504 son episode_steps:73\n",
            "Total Steps: 815155 Episode Num: 10504 Reward: 53.46845824879379 avg_loss_c: 10.286937876923444 avg_loss_a: -117.4131753999893\n",
            "Número de pasos del episodio 10505 son episode_steps:76\n",
            "Total Steps: 815231 Episode Num: 10505 Reward: 10.896880056599608 avg_loss_c: 10.362907121056004 avg_loss_a: -117.36033871299342\n",
            "Número de pasos del episodio 10506 son episode_steps:37\n",
            "Total Steps: 815268 Episode Num: 10506 Reward: -20.235778726371585 avg_loss_c: 10.755199741672826 avg_loss_a: -117.99956759890995\n",
            "Número de pasos del episodio 10507 son episode_steps:181\n",
            "Total Steps: 815449 Episode Num: 10507 Reward: 250.05741160424034 avg_loss_c: 10.84517034509564 avg_loss_a: -115.99552053377774\n",
            "Número de pasos del episodio 10508 son episode_steps:1000\n",
            "Total Steps: 816449 Episode Num: 10508 Reward: 1748.6751763735265 avg_loss_c: 9.43572145986557 avg_loss_a: -116.13211033630371\n",
            "Número de pasos del episodio 10509 son episode_steps:349\n",
            "Total Steps: 816798 Episode Num: 10509 Reward: 532.4334545700996 avg_loss_c: 9.351123178585894 avg_loss_a: -116.4274575744454\n",
            "Número de pasos del episodio 10510 son episode_steps:599\n",
            "Total Steps: 817397 Episode Num: 10510 Reward: 1001.9337202138698 avg_loss_c: 9.260398348106168 avg_loss_a: -116.40407665424634\n",
            "Número de pasos del episodio 10511 son episode_steps:47\n",
            "Total Steps: 817444 Episode Num: 10511 Reward: -10.145962915698908 avg_loss_c: 9.109129966573512 avg_loss_a: -116.78961733554272\n",
            "Número de pasos del episodio 10512 son episode_steps:450\n",
            "Total Steps: 817894 Episode Num: 10512 Reward: 615.8597278437255 avg_loss_c: 9.776400314966837 avg_loss_a: -116.06441290961372\n",
            "Número de pasos del episodio 10513 son episode_steps:94\n",
            "Total Steps: 817988 Episode Num: 10513 Reward: 104.98126414163534 avg_loss_c: 10.05173862234075 avg_loss_a: -115.08479958392203\n",
            "Número de pasos del episodio 10514 son episode_steps:1000\n",
            "Total Steps: 818988 Episode Num: 10514 Reward: 1759.6081758621656 avg_loss_c: 9.197063257694245 avg_loss_a: -116.90809326171875\n",
            "Número de pasos del episodio 10515 son episode_steps:447\n",
            "Total Steps: 819435 Episode Num: 10515 Reward: 719.4666041312084 avg_loss_c: 9.022798332325298 avg_loss_a: -117.11436039116025\n",
            "Número de pasos del episodio 10516 son episode_steps:1000\n",
            "Total Steps: 820435 Episode Num: 10516 Reward: 1821.3910343483017 avg_loss_c: 8.60518956708908 avg_loss_a: -118.12312976074219\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 856.469897\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10517 son episode_steps:73\n",
            "Total Steps: 820508 Episode Num: 10517 Reward: 75.90128394190293 avg_loss_c: 8.277017965708694 avg_loss_a: -118.37939118685787\n",
            "Número de pasos del episodio 10518 son episode_steps:503\n",
            "Total Steps: 821011 Episode Num: 10518 Reward: 832.8421255087341 avg_loss_c: 8.47758201955564 avg_loss_a: -118.17453639976547\n",
            "Número de pasos del episodio 10519 son episode_steps:79\n",
            "Total Steps: 821090 Episode Num: 10519 Reward: 72.61827478181308 avg_loss_c: 8.239272045183785 avg_loss_a: -118.75011772445485\n",
            "Número de pasos del episodio 10520 son episode_steps:1000\n",
            "Total Steps: 822090 Episode Num: 10520 Reward: 1641.5899842327085 avg_loss_c: 8.334689071178436 avg_loss_a: -118.38327734375\n",
            "Número de pasos del episodio 10521 son episode_steps:227\n",
            "Total Steps: 822317 Episode Num: 10521 Reward: 338.10110170098204 avg_loss_c: 8.531769954160447 avg_loss_a: -118.49969573167978\n",
            "Número de pasos del episodio 10522 son episode_steps:765\n",
            "Total Steps: 823082 Episode Num: 10522 Reward: 1288.7765451205692 avg_loss_c: 8.395760721318862 avg_loss_a: -118.22231641781876\n",
            "Número de pasos del episodio 10523 son episode_steps:116\n",
            "Total Steps: 823198 Episode Num: 10523 Reward: 121.43017723793182 avg_loss_c: 8.96171220828747 avg_loss_a: -118.28630197459253\n",
            "Número de pasos del episodio 10524 son episode_steps:481\n",
            "Total Steps: 823679 Episode Num: 10524 Reward: 738.6623461911865 avg_loss_c: 8.494477038076166 avg_loss_a: -118.46124140685909\n",
            "Número de pasos del episodio 10525 son episode_steps:28\n",
            "Total Steps: 823707 Episode Num: 10525 Reward: -24.63069542189018 avg_loss_c: 9.71221934046064 avg_loss_a: -119.31537682669503\n",
            "Número de pasos del episodio 10526 son episode_steps:108\n",
            "Total Steps: 823815 Episode Num: 10526 Reward: 85.98828700658284 avg_loss_c: 8.582866116806313 avg_loss_a: -118.38457149929471\n",
            "Número de pasos del episodio 10527 son episode_steps:30\n",
            "Total Steps: 823845 Episode Num: 10527 Reward: -21.128127126077835 avg_loss_c: 9.302218135197958 avg_loss_a: -117.79973500569662\n",
            "Número de pasos del episodio 10528 son episode_steps:53\n",
            "Total Steps: 823898 Episode Num: 10528 Reward: -15.642000292414131 avg_loss_c: 8.974065222830143 avg_loss_a: -117.73386714143574\n",
            "Número de pasos del episodio 10529 son episode_steps:130\n",
            "Total Steps: 824028 Episode Num: 10529 Reward: 152.0913665201148 avg_loss_c: 9.62337183218736 avg_loss_a: -117.02482405442458\n",
            "Número de pasos del episodio 10530 son episode_steps:166\n",
            "Total Steps: 824194 Episode Num: 10530 Reward: 141.42726978744287 avg_loss_c: 10.072307379848986 avg_loss_a: -116.95548625164722\n",
            "Número de pasos del episodio 10531 son episode_steps:45\n",
            "Total Steps: 824239 Episode Num: 10531 Reward: -7.474847321798176 avg_loss_c: 10.82039516237047 avg_loss_a: -114.8505881415473\n",
            "Número de pasos del episodio 10532 son episode_steps:146\n",
            "Total Steps: 824385 Episode Num: 10532 Reward: 165.19610668150946 avg_loss_c: 9.7259605061518 avg_loss_a: -117.0497616284514\n",
            "Número de pasos del episodio 10533 son episode_steps:808\n",
            "Total Steps: 825193 Episode Num: 10533 Reward: 1426.5730838115503 avg_loss_c: 9.58517989368722 avg_loss_a: -116.29685974121094\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 365.605295\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10534 son episode_steps:58\n",
            "Total Steps: 825251 Episode Num: 10534 Reward: 23.038357429764005 avg_loss_c: 9.902902405837487 avg_loss_a: -117.12549038591057\n",
            "Número de pasos del episodio 10535 son episode_steps:25\n",
            "Total Steps: 825276 Episode Num: 10535 Reward: -1.0279830350157213 avg_loss_c: 9.071997146606446 avg_loss_a: -114.90584655761718\n",
            "Número de pasos del episodio 10536 son episode_steps:178\n",
            "Total Steps: 825454 Episode Num: 10536 Reward: 206.26201288073352 avg_loss_c: 9.529859767870956 avg_loss_a: -116.04049785485428\n",
            "Número de pasos del episodio 10537 son episode_steps:289\n",
            "Total Steps: 825743 Episode Num: 10537 Reward: 425.7884819546579 avg_loss_c: 9.868448156799 avg_loss_a: -116.03533898587871\n",
            "Número de pasos del episodio 10538 son episode_steps:221\n",
            "Total Steps: 825964 Episode Num: 10538 Reward: 334.61318080369125 avg_loss_c: 10.436396997978244 avg_loss_a: -116.62977662237522\n",
            "Número de pasos del episodio 10539 son episode_steps:44\n",
            "Total Steps: 826008 Episode Num: 10539 Reward: 8.174505448594157 avg_loss_c: 9.579773426055908 avg_loss_a: -115.06169509887695\n",
            "Número de pasos del episodio 10540 son episode_steps:38\n",
            "Total Steps: 826046 Episode Num: 10540 Reward: 13.5504444085596 avg_loss_c: 10.697964969434237 avg_loss_a: -116.36931610107422\n",
            "Número de pasos del episodio 10541 son episode_steps:739\n",
            "Total Steps: 826785 Episode Num: 10541 Reward: 1162.4045350619122 avg_loss_c: 10.04385643947431 avg_loss_a: -117.10145561620895\n",
            "Número de pasos del episodio 10542 son episode_steps:40\n",
            "Total Steps: 826825 Episode Num: 10542 Reward: -9.850616082127825 avg_loss_c: 9.245784974098205 avg_loss_a: -117.44851226806641\n",
            "Número de pasos del episodio 10543 son episode_steps:388\n",
            "Total Steps: 827213 Episode Num: 10543 Reward: 634.7331784355671 avg_loss_c: 10.123181204205936 avg_loss_a: -117.03729790756383\n",
            "Número de pasos del episodio 10544 son episode_steps:49\n",
            "Total Steps: 827262 Episode Num: 10544 Reward: 28.735511726047278 avg_loss_c: 9.987828352013413 avg_loss_a: -117.7137477641203\n",
            "Número de pasos del episodio 10545 son episode_steps:45\n",
            "Total Steps: 827307 Episode Num: 10545 Reward: 11.991146239621594 avg_loss_c: 10.28970775604248 avg_loss_a: -117.15985785590277\n",
            "Número de pasos del episodio 10546 son episode_steps:402\n",
            "Total Steps: 827709 Episode Num: 10546 Reward: 570.7417779047248 avg_loss_c: 10.302241862709842 avg_loss_a: -116.65037790934245\n",
            "Número de pasos del episodio 10547 son episode_steps:1000\n",
            "Total Steps: 828709 Episode Num: 10547 Reward: 1622.8518359513891 avg_loss_c: 9.46239057636261 avg_loss_a: -117.16087113952636\n",
            "Número de pasos del episodio 10548 son episode_steps:42\n",
            "Total Steps: 828751 Episode Num: 10548 Reward: -1.1523969583448783 avg_loss_c: 10.322366930189586 avg_loss_a: -116.17886933826264\n",
            "Número de pasos del episodio 10549 son episode_steps:283\n",
            "Total Steps: 829034 Episode Num: 10549 Reward: 416.083184192849 avg_loss_c: 9.815342483587905 avg_loss_a: -117.46002412937555\n",
            "Número de pasos del episodio 10550 son episode_steps:63\n",
            "Total Steps: 829097 Episode Num: 10550 Reward: 16.07682320072608 avg_loss_c: 10.142143741486565 avg_loss_a: -115.89895787314764\n",
            "Número de pasos del episodio 10551 son episode_steps:1000\n",
            "Total Steps: 830097 Episode Num: 10551 Reward: 1667.3438036836371 avg_loss_c: 9.029523019313812 avg_loss_a: -120.1930690612793\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 404.577996\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10552 son episode_steps:199\n",
            "Total Steps: 830296 Episode Num: 10552 Reward: 248.14230801718506 avg_loss_c: 8.486165566660052 avg_loss_a: -120.21147102087586\n",
            "Número de pasos del episodio 10553 son episode_steps:1000\n",
            "Total Steps: 831296 Episode Num: 10553 Reward: 1773.5472553390491 avg_loss_c: 8.3846364569664 avg_loss_a: -119.9490657043457\n",
            "Número de pasos del episodio 10554 son episode_steps:1000\n",
            "Total Steps: 832296 Episode Num: 10554 Reward: 1813.0649209271683 avg_loss_c: 7.682797756195068 avg_loss_a: -120.96592076110839\n",
            "Número de pasos del episodio 10555 son episode_steps:634\n",
            "Total Steps: 832930 Episode Num: 10555 Reward: 1041.1536340243426 avg_loss_c: 7.7357293529089315 avg_loss_a: -121.88343322465096\n",
            "Número de pasos del episodio 10556 son episode_steps:36\n",
            "Total Steps: 832966 Episode Num: 10556 Reward: -8.631224765944719 avg_loss_c: 8.169478880034553 avg_loss_a: -122.28878275553386\n",
            "Número de pasos del episodio 10557 son episode_steps:255\n",
            "Total Steps: 833221 Episode Num: 10557 Reward: 339.2243934664698 avg_loss_c: 7.890466621810314 avg_loss_a: -122.23991513719746\n",
            "Número de pasos del episodio 10558 son episode_steps:141\n",
            "Total Steps: 833362 Episode Num: 10558 Reward: 120.66160810950896 avg_loss_c: 8.07673481001076 avg_loss_a: -121.45546895561489\n",
            "Número de pasos del episodio 10559 son episode_steps:138\n",
            "Total Steps: 833500 Episode Num: 10559 Reward: 126.6702485862539 avg_loss_c: 8.621727960697118 avg_loss_a: -121.36887536532637\n",
            "Número de pasos del episodio 10560 son episode_steps:34\n",
            "Total Steps: 833534 Episode Num: 10560 Reward: 0.29427557403664206 avg_loss_c: 8.017030056785135 avg_loss_a: -119.46742787080653\n",
            "Número de pasos del episodio 10561 son episode_steps:64\n",
            "Total Steps: 833598 Episode Num: 10561 Reward: 45.77848558979133 avg_loss_c: 9.175767630338669 avg_loss_a: -121.4986982345581\n",
            "Número de pasos del episodio 10562 son episode_steps:752\n",
            "Total Steps: 834350 Episode Num: 10562 Reward: 1252.294267006025 avg_loss_c: 8.492486499725505 avg_loss_a: -121.32986649046553\n",
            "Número de pasos del episodio 10563 son episode_steps:64\n",
            "Total Steps: 834414 Episode Num: 10563 Reward: 25.453410081143232 avg_loss_c: 8.801885962486267 avg_loss_a: -120.85906839370728\n",
            "Número de pasos del episodio 10564 son episode_steps:1000\n",
            "Total Steps: 835414 Episode Num: 10564 Reward: 1796.1503421999182 avg_loss_c: 7.519840605258942 avg_loss_a: -124.12240921020508\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 1108.499536\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10565 son episode_steps:1000\n",
            "Total Steps: 836414 Episode Num: 10565 Reward: 1723.8913972263804 avg_loss_c: 7.121302125692368 avg_loss_a: -124.38890893554688\n",
            "Número de pasos del episodio 10566 son episode_steps:32\n",
            "Total Steps: 836446 Episode Num: 10566 Reward: -21.31578566757183 avg_loss_c: 7.247040823101997 avg_loss_a: -125.31975412368774\n",
            "Número de pasos del episodio 10567 son episode_steps:407\n",
            "Total Steps: 836853 Episode Num: 10567 Reward: 687.2162025794836 avg_loss_c: 7.463121973618828 avg_loss_a: -124.75146463755014\n",
            "Número de pasos del episodio 10568 son episode_steps:832\n",
            "Total Steps: 837685 Episode Num: 10568 Reward: 1427.7839850065868 avg_loss_c: 7.147890829982666 avg_loss_a: -125.16277872599088\n",
            "Número de pasos del episodio 10569 son episode_steps:98\n",
            "Total Steps: 837783 Episode Num: 10569 Reward: 48.25486311132252 avg_loss_c: 8.246833562850952 avg_loss_a: -124.19651638731665\n",
            "Número de pasos del episodio 10570 son episode_steps:61\n",
            "Total Steps: 837844 Episode Num: 10570 Reward: 65.61672455989167 avg_loss_c: 7.796548976272833 avg_loss_a: -125.30335373174948\n",
            "Número de pasos del episodio 10571 son episode_steps:33\n",
            "Total Steps: 837877 Episode Num: 10571 Reward: -1.648782165908262 avg_loss_c: 7.646316889560584 avg_loss_a: -124.08398714932528\n",
            "Número de pasos del episodio 10572 son episode_steps:31\n",
            "Total Steps: 837908 Episode Num: 10572 Reward: 9.849917671010761 avg_loss_c: 7.310624907093663 avg_loss_a: -125.16088547245148\n",
            "Número de pasos del episodio 10573 son episode_steps:51\n",
            "Total Steps: 837959 Episode Num: 10573 Reward: -20.253157522167186 avg_loss_c: 8.455704876020842 avg_loss_a: -125.06246589211857\n",
            "Número de pasos del episodio 10574 son episode_steps:593\n",
            "Total Steps: 838552 Episode Num: 10574 Reward: 988.760686854314 avg_loss_c: 8.437551589277502 avg_loss_a: -124.5799688175195\n",
            "Número de pasos del episodio 10575 son episode_steps:1000\n",
            "Total Steps: 839552 Episode Num: 10575 Reward: 1829.8209639715317 avg_loss_c: 7.590186688661575 avg_loss_a: -125.51492575073242\n",
            "Número de pasos del episodio 10576 son episode_steps:214\n",
            "Total Steps: 839766 Episode Num: 10576 Reward: 283.3648178531978 avg_loss_c: 7.992658904779737 avg_loss_a: -124.9031615212699\n",
            "Número de pasos del episodio 10577 son episode_steps:49\n",
            "Total Steps: 839815 Episode Num: 10577 Reward: 7.174436869179901 avg_loss_c: 7.9793281944430605 avg_loss_a: -124.89722271354832\n",
            "Número de pasos del episodio 10578 son episode_steps:55\n",
            "Total Steps: 839870 Episode Num: 10578 Reward: -9.095966296810598 avg_loss_c: 8.194031888788397 avg_loss_a: -124.28008700284092\n",
            "Número de pasos del episodio 10579 son episode_steps:56\n",
            "Total Steps: 839926 Episode Num: 10579 Reward: -4.423085039470803 avg_loss_c: 9.62262122971671 avg_loss_a: -123.36481203351703\n",
            "Número de pasos del episodio 10580 son episode_steps:50\n",
            "Total Steps: 839976 Episode Num: 10580 Reward: 26.390865434340792 avg_loss_c: 9.43971887588501 avg_loss_a: -124.03200958251954\n",
            "Número de pasos del episodio 10581 son episode_steps:1000\n",
            "Total Steps: 840976 Episode Num: 10581 Reward: 1760.040979719801 avg_loss_c: 8.402496260404586 avg_loss_a: -124.45771144104003\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 983.995618\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10582 son episode_steps:112\n",
            "Total Steps: 841088 Episode Num: 10582 Reward: 129.56715610032282 avg_loss_c: 8.273043530327934 avg_loss_a: -124.56134046827044\n",
            "Número de pasos del episodio 10583 son episode_steps:104\n",
            "Total Steps: 841192 Episode Num: 10583 Reward: 86.78113225846609 avg_loss_c: 8.645972022643456 avg_loss_a: -124.05614823561449\n",
            "Número de pasos del episodio 10584 son episode_steps:942\n",
            "Total Steps: 842134 Episode Num: 10584 Reward: 1498.7442396327635 avg_loss_c: 8.967778374941233 avg_loss_a: -124.54726659365774\n",
            "Número de pasos del episodio 10585 son episode_steps:59\n",
            "Total Steps: 842193 Episode Num: 10585 Reward: 60.80971701998921 avg_loss_c: 8.211451077865341 avg_loss_a: -124.53699170128773\n",
            "Número de pasos del episodio 10586 son episode_steps:88\n",
            "Total Steps: 842281 Episode Num: 10586 Reward: 53.12150029866426 avg_loss_c: 8.938197482715953 avg_loss_a: -124.110145222057\n",
            "Número de pasos del episodio 10587 son episode_steps:56\n",
            "Total Steps: 842337 Episode Num: 10587 Reward: 57.29845447876862 avg_loss_c: 9.467572544302259 avg_loss_a: -124.65483583722796\n",
            "Número de pasos del episodio 10588 son episode_steps:75\n",
            "Total Steps: 842412 Episode Num: 10588 Reward: 51.38713387879482 avg_loss_c: 9.58095043182373 avg_loss_a: -123.96582814534506\n",
            "Número de pasos del episodio 10589 son episode_steps:39\n",
            "Total Steps: 842451 Episode Num: 10589 Reward: -7.06357344085561 avg_loss_c: 9.313278650626158 avg_loss_a: -123.35175030048077\n",
            "Número de pasos del episodio 10590 son episode_steps:1000\n",
            "Total Steps: 843451 Episode Num: 10590 Reward: 1732.012361291411 avg_loss_c: 8.831503166437148 avg_loss_a: -123.94982165527344\n",
            "Número de pasos del episodio 10591 son episode_steps:598\n",
            "Total Steps: 844049 Episode Num: 10591 Reward: 981.4253890300442 avg_loss_c: 8.468945238502528 avg_loss_a: -125.18565807533902\n",
            "Número de pasos del episodio 10592 son episode_steps:106\n",
            "Total Steps: 844155 Episode Num: 10592 Reward: 133.68660769904648 avg_loss_c: 9.076890365132746 avg_loss_a: -125.33793870458064\n",
            "Número de pasos del episodio 10593 son episode_steps:1000\n",
            "Total Steps: 845155 Episode Num: 10593 Reward: 1777.3729783902293 avg_loss_c: 8.020744447946548 avg_loss_a: -126.31421464538575\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 343.239869\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10594 son episode_steps:247\n",
            "Total Steps: 845402 Episode Num: 10594 Reward: 389.20925374626256 avg_loss_c: 7.760877331258797 avg_loss_a: -127.26995225666988\n",
            "Número de pasos del episodio 10595 son episode_steps:116\n",
            "Total Steps: 845518 Episode Num: 10595 Reward: 101.46937542049325 avg_loss_c: 8.721053760627221 avg_loss_a: -127.05853876574287\n",
            "Número de pasos del episodio 10596 son episode_steps:975\n",
            "Total Steps: 846493 Episode Num: 10596 Reward: 1645.692385254274 avg_loss_c: 7.800666156426455 avg_loss_a: -127.84771551670173\n",
            "Número de pasos del episodio 10597 son episode_steps:65\n",
            "Total Steps: 846558 Episode Num: 10597 Reward: 50.53417280782026 avg_loss_c: 7.632746821183424 avg_loss_a: -127.16342515211839\n",
            "Número de pasos del episodio 10598 son episode_steps:489\n",
            "Total Steps: 847047 Episode Num: 10598 Reward: 699.4391097597331 avg_loss_c: 7.972164478770063 avg_loss_a: -127.79792763801684\n",
            "Número de pasos del episodio 10599 son episode_steps:81\n",
            "Total Steps: 847128 Episode Num: 10599 Reward: 11.443210003972588 avg_loss_c: 8.033313162532853 avg_loss_a: -127.59706775053048\n",
            "Número de pasos del episodio 10600 son episode_steps:37\n",
            "Total Steps: 847165 Episode Num: 10600 Reward: 12.808303090614912 avg_loss_c: 8.61305722674808 avg_loss_a: -126.86002123033678\n",
            "Número de pasos del episodio 10601 son episode_steps:1000\n",
            "Total Steps: 848165 Episode Num: 10601 Reward: 1800.6593705634796 avg_loss_c: 7.548433052778244 avg_loss_a: -128.39988514709472\n",
            "Número de pasos del episodio 10602 son episode_steps:1000\n",
            "Total Steps: 849165 Episode Num: 10602 Reward: 1845.1742693197511 avg_loss_c: 6.995892055273056 avg_loss_a: -129.33004246520997\n",
            "Número de pasos del episodio 10603 son episode_steps:415\n",
            "Total Steps: 849580 Episode Num: 10603 Reward: 696.9642512152625 avg_loss_c: 7.155236399891865 avg_loss_a: -129.3255499046969\n",
            "Número de pasos del episodio 10604 son episode_steps:296\n",
            "Total Steps: 849876 Episode Num: 10604 Reward: 506.98921486668434 avg_loss_c: 7.455621998052339 avg_loss_a: -128.88825679469753\n",
            "Número de pasos del episodio 10605 son episode_steps:1000\n",
            "Total Steps: 850876 Episode Num: 10605 Reward: 1828.0292447129 avg_loss_c: 7.288944270849228 avg_loss_a: -129.60883564758302\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 602.543847\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10606 son episode_steps:979\n",
            "Total Steps: 851855 Episode Num: 10606 Reward: 1769.2904947448365 avg_loss_c: 7.028719099841639 avg_loss_a: -129.47146623590018\n",
            "Número de pasos del episodio 10607 son episode_steps:1000\n",
            "Total Steps: 852855 Episode Num: 10607 Reward: 1849.608700544692 avg_loss_c: 6.549047820329666 avg_loss_a: -130.08549607849122\n",
            "Número de pasos del episodio 10608 son episode_steps:140\n",
            "Total Steps: 852995 Episode Num: 10608 Reward: 149.16850633116795 avg_loss_c: 6.774441616875785 avg_loss_a: -129.8857289995466\n",
            "Número de pasos del episodio 10609 son episode_steps:87\n",
            "Total Steps: 853082 Episode Num: 10609 Reward: 81.73714077960265 avg_loss_c: 7.023135705925952 avg_loss_a: -130.04722665370196\n",
            "Número de pasos del episodio 10610 son episode_steps:946\n",
            "Total Steps: 854028 Episode Num: 10610 Reward: 1707.257495736128 avg_loss_c: 6.413832658945128 avg_loss_a: -130.98149455677378\n",
            "Número de pasos del episodio 10611 son episode_steps:39\n",
            "Total Steps: 854067 Episode Num: 10611 Reward: -5.868972427114528 avg_loss_c: 5.913198911226713 avg_loss_a: -130.42511807955228\n",
            "Número de pasos del episodio 10612 son episode_steps:95\n",
            "Total Steps: 854162 Episode Num: 10612 Reward: 81.00967107356557 avg_loss_c: 6.848667812347412 avg_loss_a: -130.60203696803043\n",
            "Número de pasos del episodio 10613 son episode_steps:1000\n",
            "Total Steps: 855162 Episode Num: 10613 Reward: 1788.0359195129479 avg_loss_c: 6.286723045349121 avg_loss_a: -131.0840673675537\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 653.411334\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10614 son episode_steps:1000\n",
            "Total Steps: 856162 Episode Num: 10614 Reward: 1798.8629285571471 avg_loss_c: 5.921715474128723 avg_loss_a: -131.51344956970215\n",
            "Número de pasos del episodio 10615 son episode_steps:49\n",
            "Total Steps: 856211 Episode Num: 10615 Reward: -56.23606375455545 avg_loss_c: 6.3364317271174215 avg_loss_a: -131.52193155094068\n",
            "Número de pasos del episodio 10616 son episode_steps:1000\n",
            "Total Steps: 857211 Episode Num: 10616 Reward: 1685.1260921416242 avg_loss_c: 5.7353192195892335 avg_loss_a: -131.773274017334\n",
            "Número de pasos del episodio 10617 son episode_steps:163\n",
            "Total Steps: 857374 Episode Num: 10617 Reward: 183.96045272540525 avg_loss_c: 5.826119684734228 avg_loss_a: -131.3842546895969\n",
            "Número de pasos del episodio 10618 son episode_steps:27\n",
            "Total Steps: 857401 Episode Num: 10618 Reward: -7.389397539116343 avg_loss_c: 6.293904887305366 avg_loss_a: -131.64575873480902\n",
            "Número de pasos del episodio 10619 son episode_steps:653\n",
            "Total Steps: 858054 Episode Num: 10619 Reward: 903.8382692587193 avg_loss_c: 6.318313707436391 avg_loss_a: -132.45689782322273\n",
            "Número de pasos del episodio 10620 son episode_steps:88\n",
            "Total Steps: 858142 Episode Num: 10620 Reward: 86.78294649907734 avg_loss_c: 6.196918159723282 avg_loss_a: -132.96574904701927\n",
            "Número de pasos del episodio 10621 son episode_steps:142\n",
            "Total Steps: 858284 Episode Num: 10621 Reward: 149.07624191858284 avg_loss_c: 6.302539011122475 avg_loss_a: -131.93577414499202\n",
            "Número de pasos del episodio 10622 son episode_steps:41\n",
            "Total Steps: 858325 Episode Num: 10622 Reward: 1.0590562329147533 avg_loss_c: 5.70290605614825 avg_loss_a: -131.3915758830745\n",
            "Número de pasos del episodio 10623 son episode_steps:50\n",
            "Total Steps: 858375 Episode Num: 10623 Reward: 28.879920192893355 avg_loss_c: 6.987793121337891 avg_loss_a: -131.2435482788086\n",
            "Número de pasos del episodio 10624 son episode_steps:67\n",
            "Total Steps: 858442 Episode Num: 10624 Reward: 47.1559104256728 avg_loss_c: 8.241199472057286 avg_loss_a: -130.3407428798391\n",
            "Número de pasos del episodio 10625 son episode_steps:63\n",
            "Total Steps: 858505 Episode Num: 10625 Reward: 36.74493455732477 avg_loss_c: 7.978396158369761 avg_loss_a: -131.6136210608104\n",
            "Número de pasos del episodio 10626 son episode_steps:117\n",
            "Total Steps: 858622 Episode Num: 10626 Reward: 115.39790904561384 avg_loss_c: 7.277437849941417 avg_loss_a: -131.14261907593817\n",
            "Número de pasos del episodio 10627 son episode_steps:106\n",
            "Total Steps: 858728 Episode Num: 10627 Reward: 34.45510693978682 avg_loss_c: 8.067333947937444 avg_loss_a: -131.16670327816368\n",
            "Número de pasos del episodio 10628 son episode_steps:41\n",
            "Total Steps: 858769 Episode Num: 10628 Reward: -28.473898675683518 avg_loss_c: 7.043694472894436 avg_loss_a: -130.1502402701029\n",
            "Número de pasos del episodio 10629 son episode_steps:117\n",
            "Total Steps: 858886 Episode Num: 10629 Reward: 119.9331913490576 avg_loss_c: 8.580085155291435 avg_loss_a: -129.99518226558325\n",
            "Número de pasos del episodio 10630 son episode_steps:60\n",
            "Total Steps: 858946 Episode Num: 10630 Reward: -17.17945316435169 avg_loss_c: 9.916734647750854 avg_loss_a: -130.30814946492512\n",
            "Número de pasos del episodio 10631 son episode_steps:42\n",
            "Total Steps: 858988 Episode Num: 10631 Reward: 5.773308289344931 avg_loss_c: 9.348214308420816 avg_loss_a: -129.03726159958612\n",
            "Número de pasos del episodio 10632 son episode_steps:450\n",
            "Total Steps: 859438 Episode Num: 10632 Reward: 705.4817230422195 avg_loss_c: 8.783555997742546 avg_loss_a: -129.08356035020617\n",
            "Número de pasos del episodio 10633 son episode_steps:86\n",
            "Total Steps: 859524 Episode Num: 10633 Reward: 73.31439974022074 avg_loss_c: 8.951541082803594 avg_loss_a: -128.72060855599338\n",
            "Número de pasos del episodio 10634 son episode_steps:50\n",
            "Total Steps: 859574 Episode Num: 10634 Reward: 0.19106020570467042 avg_loss_c: 8.10314022064209 avg_loss_a: -128.64787048339844\n",
            "Número de pasos del episodio 10635 son episode_steps:137\n",
            "Total Steps: 859711 Episode Num: 10635 Reward: 157.9096604067544 avg_loss_c: 9.31704517524608 avg_loss_a: -128.04124060860516\n",
            "Número de pasos del episodio 10636 son episode_steps:83\n",
            "Total Steps: 859794 Episode Num: 10636 Reward: 76.13515947189697 avg_loss_c: 9.07260181243161 avg_loss_a: -129.2169803481504\n",
            "Número de pasos del episodio 10637 son episode_steps:1000\n",
            "Total Steps: 860794 Episode Num: 10637 Reward: 1565.9464699229786 avg_loss_c: 8.376655571699143 avg_loss_a: -128.8858171234131\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 240.488077\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10638 son episode_steps:17\n",
            "Total Steps: 860811 Episode Num: 10638 Reward: -38.849191871546566 avg_loss_c: 8.317645465626436 avg_loss_a: -129.01836529900046\n",
            "Número de pasos del episodio 10639 son episode_steps:126\n",
            "Total Steps: 860937 Episode Num: 10639 Reward: 20.302319878341244 avg_loss_c: 10.024007869145226 avg_loss_a: -129.6184800163148\n",
            "Número de pasos del episodio 10640 son episode_steps:149\n",
            "Total Steps: 861086 Episode Num: 10640 Reward: 138.21265555154716 avg_loss_c: 9.659083196780825 avg_loss_a: -128.9676721560075\n",
            "Número de pasos del episodio 10641 son episode_steps:66\n",
            "Total Steps: 861152 Episode Num: 10641 Reward: 52.26308205403735 avg_loss_c: 10.307215484705837 avg_loss_a: -128.01489743319425\n",
            "Número de pasos del episodio 10642 son episode_steps:57\n",
            "Total Steps: 861209 Episode Num: 10642 Reward: 38.863241341176604 avg_loss_c: 9.660434747997083 avg_loss_a: -129.66304511354681\n",
            "Número de pasos del episodio 10643 son episode_steps:1000\n",
            "Total Steps: 862209 Episode Num: 10643 Reward: 1683.1404758587764 avg_loss_c: 9.01538916182518 avg_loss_a: -129.01622956848144\n",
            "Número de pasos del episodio 10644 son episode_steps:173\n",
            "Total Steps: 862382 Episode Num: 10644 Reward: 85.48030633248617 avg_loss_c: 9.821611018539164 avg_loss_a: -128.9252759459391\n",
            "Número de pasos del episodio 10645 son episode_steps:1000\n",
            "Total Steps: 863382 Episode Num: 10645 Reward: 1813.7664972800826 avg_loss_c: 8.567961691141129 avg_loss_a: -129.8989936065674\n",
            "Número de pasos del episodio 10646 son episode_steps:1000\n",
            "Total Steps: 864382 Episode Num: 10646 Reward: 1746.5818196887592 avg_loss_c: 7.500512149333954 avg_loss_a: -130.79335275268554\n",
            "Número de pasos del episodio 10647 son episode_steps:1000\n",
            "Total Steps: 865382 Episode Num: 10647 Reward: 1781.7358381296092 avg_loss_c: 6.786762359857559 avg_loss_a: -131.2190570526123\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 1236.676214\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10648 son episode_steps:241\n",
            "Total Steps: 865623 Episode Num: 10648 Reward: 174.28290675540453 avg_loss_c: 7.627635147561671 avg_loss_a: -131.06003428099066\n",
            "Número de pasos del episodio 10649 son episode_steps:1000\n",
            "Total Steps: 866623 Episode Num: 10649 Reward: 1706.630928501182 avg_loss_c: 7.1054539425373076 avg_loss_a: -131.80362969970705\n",
            "Número de pasos del episodio 10650 son episode_steps:36\n",
            "Total Steps: 866659 Episode Num: 10650 Reward: 9.155822621672014 avg_loss_c: 7.068765295876397 avg_loss_a: -132.479123433431\n",
            "Número de pasos del episodio 10651 son episode_steps:42\n",
            "Total Steps: 866701 Episode Num: 10651 Reward: 15.088101609083278 avg_loss_c: 9.736444376763844 avg_loss_a: -130.4463678995768\n",
            "Número de pasos del episodio 10652 son episode_steps:1000\n",
            "Total Steps: 867701 Episode Num: 10652 Reward: 1719.063893650782 avg_loss_c: 6.839329098701477 avg_loss_a: -132.31731185913085\n",
            "Número de pasos del episodio 10653 son episode_steps:50\n",
            "Total Steps: 867751 Episode Num: 10653 Reward: 16.745478437268023 avg_loss_c: 7.092103204727173 avg_loss_a: -131.56789581298827\n",
            "Número de pasos del episodio 10654 son episode_steps:74\n",
            "Total Steps: 867825 Episode Num: 10654 Reward: 11.18161511495745 avg_loss_c: 7.213802898252332 avg_loss_a: -131.78895197687922\n",
            "Número de pasos del episodio 10655 son episode_steps:46\n",
            "Total Steps: 867871 Episode Num: 10655 Reward: 17.784786019888 avg_loss_c: 7.342025694639786 avg_loss_a: -130.68265168563178\n",
            "Número de pasos del episodio 10656 son episode_steps:34\n",
            "Total Steps: 867905 Episode Num: 10656 Reward: -1.4184820136293808 avg_loss_c: 7.613634922925164 avg_loss_a: -129.94514779483572\n",
            "Número de pasos del episodio 10657 son episode_steps:48\n",
            "Total Steps: 867953 Episode Num: 10657 Reward: 1.371222615701173 avg_loss_c: 7.461780746777852 avg_loss_a: -131.57578627268472\n",
            "Número de pasos del episodio 10658 son episode_steps:49\n",
            "Total Steps: 868002 Episode Num: 10658 Reward: 4.356799417891647 avg_loss_c: 7.941939470719318 avg_loss_a: -130.95287587691325\n",
            "Número de pasos del episodio 10659 son episode_steps:49\n",
            "Total Steps: 868051 Episode Num: 10659 Reward: 28.660039399702498 avg_loss_c: 9.514332479360153 avg_loss_a: -130.95429245306522\n",
            "Número de pasos del episodio 10660 son episode_steps:39\n",
            "Total Steps: 868090 Episode Num: 10660 Reward: -54.152092260263444 avg_loss_c: 9.382495476649357 avg_loss_a: -130.80745168832632\n",
            "Número de pasos del episodio 10661 son episode_steps:114\n",
            "Total Steps: 868204 Episode Num: 10661 Reward: 135.80240424347335 avg_loss_c: 10.243539998405858 avg_loss_a: -130.79042187071684\n",
            "Número de pasos del episodio 10662 son episode_steps:68\n",
            "Total Steps: 868272 Episode Num: 10662 Reward: 41.01579199261976 avg_loss_c: 7.952724470811732 avg_loss_a: -129.7933188045726\n",
            "Número de pasos del episodio 10663 son episode_steps:35\n",
            "Total Steps: 868307 Episode Num: 10663 Reward: -0.08660304399782959 avg_loss_c: 10.76987852369036 avg_loss_a: -130.6408194405692\n",
            "Número de pasos del episodio 10664 son episode_steps:58\n",
            "Total Steps: 868365 Episode Num: 10664 Reward: 26.337249827818834 avg_loss_c: 11.293444995222421 avg_loss_a: -130.54084067509092\n",
            "Número de pasos del episodio 10665 son episode_steps:80\n",
            "Total Steps: 868445 Episode Num: 10665 Reward: 65.3694782889407 avg_loss_c: 9.776704883575439 avg_loss_a: -129.35243434906005\n",
            "Número de pasos del episodio 10666 son episode_steps:46\n",
            "Total Steps: 868491 Episode Num: 10666 Reward: -1.2423264091365747 avg_loss_c: 10.141560772190923 avg_loss_a: -128.29922087296197\n",
            "Número de pasos del episodio 10667 son episode_steps:485\n",
            "Total Steps: 868976 Episode Num: 10667 Reward: 583.5800791434543 avg_loss_c: 9.315812412733884 avg_loss_a: -129.26822421673646\n",
            "Número de pasos del episodio 10668 son episode_steps:252\n",
            "Total Steps: 869228 Episode Num: 10668 Reward: 337.5385677524704 avg_loss_c: 9.159235108466376 avg_loss_a: -128.87693235609265\n",
            "Número de pasos del episodio 10669 son episode_steps:69\n",
            "Total Steps: 869297 Episode Num: 10669 Reward: 62.75421557662232 avg_loss_c: 9.040756014810093 avg_loss_a: -129.04426552592844\n",
            "Número de pasos del episodio 10670 son episode_steps:45\n",
            "Total Steps: 869342 Episode Num: 10670 Reward: -9.496766721886507 avg_loss_c: 10.18735908932156 avg_loss_a: -127.74121432834201\n",
            "Número de pasos del episodio 10671 son episode_steps:1000\n",
            "Total Steps: 870342 Episode Num: 10671 Reward: 1772.3762252258612 avg_loss_c: 8.775612612009049 avg_loss_a: -128.95603463745118\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 520.381439\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10672 son episode_steps:1000\n",
            "Total Steps: 871342 Episode Num: 10672 Reward: 1646.5835166255358 avg_loss_c: 7.902250888347626 avg_loss_a: -129.32924974060057\n",
            "Número de pasos del episodio 10673 son episode_steps:1000\n",
            "Total Steps: 872342 Episode Num: 10673 Reward: 1830.3434918771006 avg_loss_c: 7.545508742809296 avg_loss_a: -129.6771038208008\n",
            "Número de pasos del episodio 10674 son episode_steps:48\n",
            "Total Steps: 872390 Episode Num: 10674 Reward: 4.864924313622888 avg_loss_c: 7.298766513665517 avg_loss_a: -130.67354170481363\n",
            "Número de pasos del episodio 10675 son episode_steps:1000\n",
            "Total Steps: 873390 Episode Num: 10675 Reward: 1778.7641106743504 avg_loss_c: 7.219508597373962 avg_loss_a: -130.75022453308105\n",
            "Número de pasos del episodio 10676 son episode_steps:104\n",
            "Total Steps: 873494 Episode Num: 10676 Reward: 125.83804499972669 avg_loss_c: 7.15292953986388 avg_loss_a: -130.98515759981595\n",
            "Número de pasos del episodio 10677 son episode_steps:1000\n",
            "Total Steps: 874494 Episode Num: 10677 Reward: 1627.3738575557838 avg_loss_c: 7.154555878877639 avg_loss_a: -131.40898439025878\n",
            "Número de pasos del episodio 10678 son episode_steps:221\n",
            "Total Steps: 874715 Episode Num: 10678 Reward: 303.34461646135003 avg_loss_c: 7.085745870797343 avg_loss_a: -130.92619406583623\n",
            "Número de pasos del episodio 10679 son episode_steps:640\n",
            "Total Steps: 875355 Episode Num: 10679 Reward: 1063.000287442766 avg_loss_c: 7.329922259598971 avg_loss_a: -130.99525554180144\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 11.723713\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10680 son episode_steps:73\n",
            "Total Steps: 875428 Episode Num: 10680 Reward: -47.562560580414186 avg_loss_c: 8.552155099502981 avg_loss_a: -130.83921876672196\n",
            "Número de pasos del episodio 10681 son episode_steps:36\n",
            "Total Steps: 875464 Episode Num: 10681 Reward: -4.276279442499054 avg_loss_c: 12.175019131766426 avg_loss_a: -130.45706176757812\n",
            "Número de pasos del episodio 10682 son episode_steps:101\n",
            "Total Steps: 875565 Episode Num: 10682 Reward: 34.38333415880097 avg_loss_c: 9.012409030800999 avg_loss_a: -130.39193468754834\n",
            "Número de pasos del episodio 10683 son episode_steps:103\n",
            "Total Steps: 875668 Episode Num: 10683 Reward: 82.83105542939865 avg_loss_c: 9.905498203722019 avg_loss_a: -129.60774534651378\n",
            "Número de pasos del episodio 10684 son episode_steps:107\n",
            "Total Steps: 875775 Episode Num: 10684 Reward: 110.30299713878172 avg_loss_c: 9.834546178300805 avg_loss_a: -129.77210606370016\n",
            "Número de pasos del episodio 10685 son episode_steps:39\n",
            "Total Steps: 875814 Episode Num: 10685 Reward: 8.92879322117966 avg_loss_c: 9.431695375687037 avg_loss_a: -128.14987065241888\n",
            "Número de pasos del episodio 10686 son episode_steps:95\n",
            "Total Steps: 875909 Episode Num: 10686 Reward: 58.824403357271315 avg_loss_c: 9.693450014214767 avg_loss_a: -128.78344461541425\n",
            "Número de pasos del episodio 10687 son episode_steps:56\n",
            "Total Steps: 875965 Episode Num: 10687 Reward: 32.38033304210301 avg_loss_c: 9.404523117201668 avg_loss_a: -128.22842597961426\n",
            "Número de pasos del episodio 10688 son episode_steps:666\n",
            "Total Steps: 876631 Episode Num: 10688 Reward: 1102.2842026084418 avg_loss_c: 9.215626027133014 avg_loss_a: -129.0788876416089\n",
            "Número de pasos del episodio 10689 son episode_steps:198\n",
            "Total Steps: 876829 Episode Num: 10689 Reward: 98.21516945808747 avg_loss_c: 9.419087145063612 avg_loss_a: -128.10212337609494\n",
            "Número de pasos del episodio 10690 son episode_steps:113\n",
            "Total Steps: 876942 Episode Num: 10690 Reward: 115.49803639938706 avg_loss_c: 9.004828883483347 avg_loss_a: -128.36934803650442\n",
            "Número de pasos del episodio 10691 son episode_steps:488\n",
            "Total Steps: 877430 Episode Num: 10691 Reward: 736.6410835508051 avg_loss_c: 9.156545565753687 avg_loss_a: -128.56298352851243\n",
            "Número de pasos del episodio 10692 son episode_steps:62\n",
            "Total Steps: 877492 Episode Num: 10692 Reward: 53.533658732145994 avg_loss_c: 8.490580420340262 avg_loss_a: -128.29244010679184\n",
            "Número de pasos del episodio 10693 son episode_steps:107\n",
            "Total Steps: 877599 Episode Num: 10693 Reward: 121.34401009249281 avg_loss_c: 8.628253344063447 avg_loss_a: -128.2383104841286\n",
            "Número de pasos del episodio 10694 son episode_steps:51\n",
            "Total Steps: 877650 Episode Num: 10694 Reward: 36.46505424576104 avg_loss_c: 8.986614040299958 avg_loss_a: -128.38851150811888\n",
            "Número de pasos del episodio 10695 son episode_steps:1000\n",
            "Total Steps: 878650 Episode Num: 10695 Reward: 1725.353617054214 avg_loss_c: 8.478631041288375 avg_loss_a: -129.7955963897705\n",
            "Número de pasos del episodio 10696 son episode_steps:1000\n",
            "Total Steps: 879650 Episode Num: 10696 Reward: 1739.6411144969622 avg_loss_c: 7.46720311999321 avg_loss_a: -132.1860567474365\n",
            "Número de pasos del episodio 10697 son episode_steps:60\n",
            "Total Steps: 879710 Episode Num: 10697 Reward: 23.297506388073735 avg_loss_c: 7.293547463417053 avg_loss_a: -131.8922472635905\n",
            "Número de pasos del episodio 10698 son episode_steps:68\n",
            "Total Steps: 879778 Episode Num: 10698 Reward: 60.62567780212833 avg_loss_c: 7.745064742424908 avg_loss_a: -131.80806485344382\n",
            "Número de pasos del episodio 10699 son episode_steps:1000\n",
            "Total Steps: 880778 Episode Num: 10699 Reward: 1745.5027256564088 avg_loss_c: 7.285826459407806 avg_loss_a: -132.84009516906738\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 549.220259\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10700 son episode_steps:44\n",
            "Total Steps: 880822 Episode Num: 10700 Reward: 28.622911779279672 avg_loss_c: 6.9859018542549824 avg_loss_a: -134.059006430886\n",
            "Número de pasos del episodio 10701 son episode_steps:522\n",
            "Total Steps: 881344 Episode Num: 10701 Reward: 815.1787403793385 avg_loss_c: 7.227092468418838 avg_loss_a: -133.06690788999828\n",
            "Número de pasos del episodio 10702 son episode_steps:60\n",
            "Total Steps: 881404 Episode Num: 10702 Reward: 28.59641297798297 avg_loss_c: 7.223344119389852 avg_loss_a: -133.5437021891276\n",
            "Número de pasos del episodio 10703 son episode_steps:1000\n",
            "Total Steps: 882404 Episode Num: 10703 Reward: 1573.8533525072116 avg_loss_c: 6.833368741750717 avg_loss_a: -133.69073431396484\n",
            "Número de pasos del episodio 10704 son episode_steps:19\n",
            "Total Steps: 882423 Episode Num: 10704 Reward: -19.339411713682747 avg_loss_c: 6.902911136024876 avg_loss_a: -133.4549769351357\n",
            "Número de pasos del episodio 10705 son episode_steps:92\n",
            "Total Steps: 882515 Episode Num: 10705 Reward: 106.550893018327 avg_loss_c: 7.445935850558073 avg_loss_a: -132.9749691175378\n",
            "Número de pasos del episodio 10706 son episode_steps:1000\n",
            "Total Steps: 883515 Episode Num: 10706 Reward: 1558.3505226617224 avg_loss_c: 7.220496643304825 avg_loss_a: -133.5232281036377\n",
            "Número de pasos del episodio 10707 son episode_steps:37\n",
            "Total Steps: 883552 Episode Num: 10707 Reward: -6.319328202612375 avg_loss_c: 7.235218995326274 avg_loss_a: -133.96172477103568\n",
            "Número de pasos del episodio 10708 son episode_steps:50\n",
            "Total Steps: 883602 Episode Num: 10708 Reward: 29.304400585091493 avg_loss_c: 7.2955555248260495 avg_loss_a: -132.90730224609376\n",
            "Número de pasos del episodio 10709 son episode_steps:774\n",
            "Total Steps: 884376 Episode Num: 10709 Reward: 1226.3823683345256 avg_loss_c: 7.742499754102347 avg_loss_a: -132.9203564942037\n",
            "Número de pasos del episodio 10710 son episode_steps:172\n",
            "Total Steps: 884548 Episode Num: 10710 Reward: 226.0178333782435 avg_loss_c: 7.544417374355849 avg_loss_a: -133.11776582584824\n",
            "Número de pasos del episodio 10711 son episode_steps:1000\n",
            "Total Steps: 885548 Episode Num: 10711 Reward: 1728.2436681193467 avg_loss_c: 7.519223283290863 avg_loss_a: -133.15600625610352\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 1204.153534\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10712 son episode_steps:1000\n",
            "Total Steps: 886548 Episode Num: 10712 Reward: 1732.4729318249106 avg_loss_c: 6.95068189740181 avg_loss_a: -133.78777159118653\n",
            "Número de pasos del episodio 10713 son episode_steps:1000\n",
            "Total Steps: 887548 Episode Num: 10713 Reward: 1617.6581580251986 avg_loss_c: 6.9007096302509305 avg_loss_a: -134.65708486938476\n",
            "Número de pasos del episodio 10714 son episode_steps:22\n",
            "Total Steps: 887570 Episode Num: 10714 Reward: -29.40714118761771 avg_loss_c: 6.739813912998546 avg_loss_a: -135.18990395285866\n",
            "Número de pasos del episodio 10715 son episode_steps:32\n",
            "Total Steps: 887602 Episode Num: 10715 Reward: -5.165491861927423 avg_loss_c: 7.442196160554886 avg_loss_a: -134.83810234069824\n",
            "Número de pasos del episodio 10716 son episode_steps:55\n",
            "Total Steps: 887657 Episode Num: 10716 Reward: 30.451175077931257 avg_loss_c: 7.550558090209961 avg_loss_a: -134.0157781427557\n",
            "Número de pasos del episodio 10717 son episode_steps:41\n",
            "Total Steps: 887698 Episode Num: 10717 Reward: 5.013260758621479 avg_loss_c: 8.935654052873938 avg_loss_a: -134.39690492211318\n",
            "Número de pasos del episodio 10718 son episode_steps:37\n",
            "Total Steps: 887735 Episode Num: 10718 Reward: -37.048004099490726 avg_loss_c: 10.256923211587441 avg_loss_a: -132.65361394108953\n",
            "Número de pasos del episodio 10719 son episode_steps:185\n",
            "Total Steps: 887920 Episode Num: 10719 Reward: 224.02584538593655 avg_loss_c: 8.98267860025973 avg_loss_a: -134.38592595280826\n",
            "Número de pasos del episodio 10720 son episode_steps:296\n",
            "Total Steps: 888216 Episode Num: 10720 Reward: 390.0614751426191 avg_loss_c: 9.32038890107258 avg_loss_a: -133.98197581316973\n",
            "Número de pasos del episodio 10721 son episode_steps:136\n",
            "Total Steps: 888352 Episode Num: 10721 Reward: 126.31680191601198 avg_loss_c: 8.694626080639223 avg_loss_a: -134.30691090752097\n",
            "Número de pasos del episodio 10722 son episode_steps:922\n",
            "Total Steps: 889274 Episode Num: 10722 Reward: 1480.5311638290389 avg_loss_c: 7.462931342083565 avg_loss_a: -135.86867993203782\n",
            "Número de pasos del episodio 10723 son episode_steps:125\n",
            "Total Steps: 889399 Episode Num: 10723 Reward: 137.7286553725158 avg_loss_c: 7.227845268249512 avg_loss_a: -135.72541516113282\n",
            "Número de pasos del episodio 10724 son episode_steps:1000\n",
            "Total Steps: 890399 Episode Num: 10724 Reward: 1611.2140890393662 avg_loss_c: 6.988246094226837 avg_loss_a: -135.99769982910155\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 308.656249\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10725 son episode_steps:1000\n",
            "Total Steps: 891399 Episode Num: 10725 Reward: 1627.2109658772295 avg_loss_c: 6.655226213216782 avg_loss_a: -135.91170248413087\n",
            "Número de pasos del episodio 10726 son episode_steps:237\n",
            "Total Steps: 891636 Episode Num: 10726 Reward: 299.4423506619108 avg_loss_c: 6.840496936427893 avg_loss_a: -135.96549034923441\n",
            "Número de pasos del episodio 10727 son episode_steps:1000\n",
            "Total Steps: 892636 Episode Num: 10727 Reward: 1749.272796802295 avg_loss_c: 6.475529498815536 avg_loss_a: -136.15126034545898\n",
            "Número de pasos del episodio 10728 son episode_steps:92\n",
            "Total Steps: 892728 Episode Num: 10728 Reward: 0.6309648208349432 avg_loss_c: 6.571276895377947 avg_loss_a: -136.7919284986413\n",
            "Número de pasos del episodio 10729 son episode_steps:1000\n",
            "Total Steps: 893728 Episode Num: 10729 Reward: 1717.2039502180437 avg_loss_c: 6.226936117887497 avg_loss_a: -136.07821250915526\n",
            "Número de pasos del episodio 10730 son episode_steps:86\n",
            "Total Steps: 893814 Episode Num: 10730 Reward: 77.62378381826417 avg_loss_c: 6.901671764462493 avg_loss_a: -135.85637079283248\n",
            "Número de pasos del episodio 10731 son episode_steps:921\n",
            "Total Steps: 894735 Episode Num: 10731 Reward: 1571.9506267899753 avg_loss_c: 6.382937451268382 avg_loss_a: -136.1454866887692\n",
            "Número de pasos del episodio 10732 son episode_steps:49\n",
            "Total Steps: 894784 Episode Num: 10732 Reward: -5.54228851784827 avg_loss_c: 7.508639695693035 avg_loss_a: -135.38415184799507\n",
            "Número de pasos del episodio 10733 son episode_steps:186\n",
            "Total Steps: 894970 Episode Num: 10733 Reward: 116.12252502701082 avg_loss_c: 7.074836978348353 avg_loss_a: -135.61451081306703\n",
            "Número de pasos del episodio 10734 son episode_steps:672\n",
            "Total Steps: 895642 Episode Num: 10734 Reward: 1148.3197501392674 avg_loss_c: 6.06078734710103 avg_loss_a: -136.51266113917032\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 107.515973\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10735 son episode_steps:156\n",
            "Total Steps: 895798 Episode Num: 10735 Reward: 144.30716636925982 avg_loss_c: 6.728894646351154 avg_loss_a: -136.34408706273788\n",
            "Número de pasos del episodio 10736 son episode_steps:29\n",
            "Total Steps: 895827 Episode Num: 10736 Reward: 13.395390120379297 avg_loss_c: 6.444994252303551 avg_loss_a: -136.65453891096445\n",
            "Número de pasos del episodio 10737 son episode_steps:904\n",
            "Total Steps: 896731 Episode Num: 10737 Reward: 1574.7247949045661 avg_loss_c: 5.958906736257857 avg_loss_a: -136.96159923182125\n",
            "Número de pasos del episodio 10738 son episode_steps:49\n",
            "Total Steps: 896780 Episode Num: 10738 Reward: 15.745443998925747 avg_loss_c: 5.994041257975053 avg_loss_a: -136.50263198541134\n",
            "Número de pasos del episodio 10739 son episode_steps:73\n",
            "Total Steps: 896853 Episode Num: 10739 Reward: 80.50855967818708 avg_loss_c: 5.776166328012127 avg_loss_a: -137.61022175828072\n",
            "Número de pasos del episodio 10740 son episode_steps:409\n",
            "Total Steps: 897262 Episode Num: 10740 Reward: 664.495860331192 avg_loss_c: 5.83792230027812 avg_loss_a: -136.92362513460566\n",
            "Número de pasos del episodio 10741 son episode_steps:57\n",
            "Total Steps: 897319 Episode Num: 10741 Reward: 18.65953959705091 avg_loss_c: 5.904008693862379 avg_loss_a: -136.74758777283785\n",
            "Número de pasos del episodio 10742 son episode_steps:19\n",
            "Total Steps: 897338 Episode Num: 10742 Reward: -29.450956412007653 avg_loss_c: 5.795633843070583 avg_loss_a: -136.07154123406661\n",
            "Número de pasos del episodio 10743 son episode_steps:444\n",
            "Total Steps: 897782 Episode Num: 10743 Reward: 672.8271568077341 avg_loss_c: 6.306203678921536 avg_loss_a: -136.91614312524194\n",
            "Número de pasos del episodio 10744 son episode_steps:601\n",
            "Total Steps: 898383 Episode Num: 10744 Reward: 961.0669796149614 avg_loss_c: 6.1065503809098995 avg_loss_a: -136.62093572886334\n",
            "Número de pasos del episodio 10745 son episode_steps:130\n",
            "Total Steps: 898513 Episode Num: 10745 Reward: 134.1321570020608 avg_loss_c: 6.4250857243171104 avg_loss_a: -136.11772848275993\n",
            "Número de pasos del episodio 10746 son episode_steps:69\n",
            "Total Steps: 898582 Episode Num: 10746 Reward: 60.08053731374522 avg_loss_c: 6.393624620161194 avg_loss_a: -136.20910622417063\n",
            "Número de pasos del episodio 10747 son episode_steps:80\n",
            "Total Steps: 898662 Episode Num: 10747 Reward: 67.79824796162646 avg_loss_c: 7.5900285869836805 avg_loss_a: -135.81272926330567\n",
            "Número de pasos del episodio 10748 son episode_steps:270\n",
            "Total Steps: 898932 Episode Num: 10748 Reward: 387.8391087779879 avg_loss_c: 7.2414588901731705 avg_loss_a: -135.90486518012153\n",
            "Número de pasos del episodio 10749 son episode_steps:63\n",
            "Total Steps: 898995 Episode Num: 10749 Reward: 58.199116917138475 avg_loss_c: 7.314122056204175 avg_loss_a: -135.4055885436043\n",
            "Número de pasos del episodio 10750 son episode_steps:1000\n",
            "Total Steps: 899995 Episode Num: 10750 Reward: 1688.9437401515722 avg_loss_c: 6.6381724989414215 avg_loss_a: -135.87246342468262\n",
            "Número de pasos del episodio 10751 son episode_steps:63\n",
            "Total Steps: 900058 Episode Num: 10751 Reward: 63.68125221570058 avg_loss_c: 6.586355080680241 avg_loss_a: -135.99178084116133\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 195.923858\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10752 son episode_steps:93\n",
            "Total Steps: 900151 Episode Num: 10752 Reward: 82.19838449112605 avg_loss_c: 7.17504084238442 avg_loss_a: -135.4559358986475\n",
            "Número de pasos del episodio 10753 son episode_steps:590\n",
            "Total Steps: 900741 Episode Num: 10753 Reward: 934.5393830113171 avg_loss_c: 6.899165202399431 avg_loss_a: -135.1466072987702\n",
            "Número de pasos del episodio 10754 son episode_steps:500\n",
            "Total Steps: 901241 Episode Num: 10754 Reward: 720.1846963466453 avg_loss_c: 6.938373650074005 avg_loss_a: -135.27493118286134\n",
            "Número de pasos del episodio 10755 son episode_steps:58\n",
            "Total Steps: 901299 Episode Num: 10755 Reward: 44.52310570023108 avg_loss_c: 7.000168249524873 avg_loss_a: -135.01098054030845\n",
            "Número de pasos del episodio 10756 son episode_steps:61\n",
            "Total Steps: 901360 Episode Num: 10756 Reward: 37.62612443437339 avg_loss_c: 6.591928165467059 avg_loss_a: -135.90536699138704\n",
            "Número de pasos del episodio 10757 son episode_steps:235\n",
            "Total Steps: 901595 Episode Num: 10757 Reward: 320.8687265795246 avg_loss_c: 7.686869120090566 avg_loss_a: -134.83361504737368\n",
            "Número de pasos del episodio 10758 son episode_steps:75\n",
            "Total Steps: 901670 Episode Num: 10758 Reward: 61.940933355307415 avg_loss_c: 7.160114736557007 avg_loss_a: -135.50929504394531\n",
            "Número de pasos del episodio 10759 son episode_steps:90\n",
            "Total Steps: 901760 Episode Num: 10759 Reward: 89.26236935722521 avg_loss_c: 7.927961418363783 avg_loss_a: -134.08870459662543\n",
            "Número de pasos del episodio 10760 son episode_steps:156\n",
            "Total Steps: 901916 Episode Num: 10760 Reward: 149.6885784630647 avg_loss_c: 8.723334070963737 avg_loss_a: -134.59042270366962\n",
            "Número de pasos del episodio 10761 son episode_steps:616\n",
            "Total Steps: 902532 Episode Num: 10761 Reward: 1003.6467234383714 avg_loss_c: 7.720884188816145 avg_loss_a: -134.31474353740742\n",
            "Número de pasos del episodio 10762 son episode_steps:141\n",
            "Total Steps: 902673 Episode Num: 10762 Reward: 167.15553464977117 avg_loss_c: 7.942892564949414 avg_loss_a: -133.44899333115166\n",
            "Número de pasos del episodio 10763 son episode_steps:62\n",
            "Total Steps: 902735 Episode Num: 10763 Reward: 52.49677298483814 avg_loss_c: 7.589029319824711 avg_loss_a: -133.77470299505418\n",
            "Número de pasos del episodio 10764 son episode_steps:75\n",
            "Total Steps: 902810 Episode Num: 10764 Reward: 41.359558398096596 avg_loss_c: 8.449389270146687 avg_loss_a: -132.84146545410155\n",
            "Número de pasos del episodio 10765 son episode_steps:137\n",
            "Total Steps: 902947 Episode Num: 10765 Reward: 138.96171757792098 avg_loss_c: 8.259387049361736 avg_loss_a: -133.0298918007064\n",
            "Número de pasos del episodio 10766 son episode_steps:123\n",
            "Total Steps: 903070 Episode Num: 10766 Reward: 58.6768668295511 avg_loss_c: 9.148824796444032 avg_loss_a: -132.4784872163602\n",
            "Número de pasos del episodio 10767 son episode_steps:328\n",
            "Total Steps: 903398 Episode Num: 10767 Reward: 472.9848219794188 avg_loss_c: 9.025435402625945 avg_loss_a: -132.47604798107614\n",
            "Número de pasos del episodio 10768 son episode_steps:65\n",
            "Total Steps: 903463 Episode Num: 10768 Reward: 21.567160088385364 avg_loss_c: 9.388276973137488 avg_loss_a: -132.88276062011718\n",
            "Número de pasos del episodio 10769 son episode_steps:738\n",
            "Total Steps: 904201 Episode Num: 10769 Reward: 1116.0033699407243 avg_loss_c: 8.840375060311501 avg_loss_a: -132.27158339172198\n",
            "Número de pasos del episodio 10770 son episode_steps:59\n",
            "Total Steps: 904260 Episode Num: 10770 Reward: 27.880919680186366 avg_loss_c: 8.984873157436565 avg_loss_a: -132.21318080061573\n",
            "Número de pasos del episodio 10771 son episode_steps:1000\n",
            "Total Steps: 905260 Episode Num: 10771 Reward: 1731.6995332272184 avg_loss_c: 8.565859416723251 avg_loss_a: -132.81409523010254\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 341.585019\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10772 son episode_steps:229\n",
            "Total Steps: 905489 Episode Num: 10772 Reward: 287.49440221930934 avg_loss_c: 8.517581100547158 avg_loss_a: -133.68489467837404\n",
            "Número de pasos del episodio 10773 son episode_steps:56\n",
            "Total Steps: 905545 Episode Num: 10773 Reward: 52.26454243799197 avg_loss_c: 8.937872665269035 avg_loss_a: -131.66298321315222\n",
            "Número de pasos del episodio 10774 son episode_steps:195\n",
            "Total Steps: 905740 Episode Num: 10774 Reward: 280.51048192909894 avg_loss_c: 9.089176152302668 avg_loss_a: -132.04171917255107\n",
            "Número de pasos del episodio 10775 son episode_steps:111\n",
            "Total Steps: 905851 Episode Num: 10775 Reward: 113.87434710170893 avg_loss_c: 9.655376863909197 avg_loss_a: -130.80051978858742\n",
            "Número de pasos del episodio 10776 son episode_steps:31\n",
            "Total Steps: 905882 Episode Num: 10776 Reward: -13.286238922685804 avg_loss_c: 10.198318727554813 avg_loss_a: -132.15779310657132\n",
            "Número de pasos del episodio 10777 son episode_steps:38\n",
            "Total Steps: 905920 Episode Num: 10777 Reward: 1.7173916726570166 avg_loss_c: 11.449443603816785 avg_loss_a: -131.11387634277344\n",
            "Número de pasos del episodio 10778 son episode_steps:606\n",
            "Total Steps: 906526 Episode Num: 10778 Reward: 963.3414105656742 avg_loss_c: 9.952033921043471 avg_loss_a: -131.31218467687222\n",
            "Número de pasos del episodio 10779 son episode_steps:1000\n",
            "Total Steps: 907526 Episode Num: 10779 Reward: 1745.376090101659 avg_loss_c: 9.140578355312348 avg_loss_a: -131.2493295135498\n",
            "Número de pasos del episodio 10780 son episode_steps:980\n",
            "Total Steps: 908506 Episode Num: 10780 Reward: 1713.1306072263494 avg_loss_c: 8.86406703092614 avg_loss_a: -133.57535459557357\n",
            "Número de pasos del episodio 10781 son episode_steps:26\n",
            "Total Steps: 908532 Episode Num: 10781 Reward: -35.7780210421988 avg_loss_c: 8.478411252682026 avg_loss_a: -132.05784606933594\n",
            "Número de pasos del episodio 10782 son episode_steps:139\n",
            "Total Steps: 908671 Episode Num: 10782 Reward: 162.54541219544194 avg_loss_c: 10.546046325628707 avg_loss_a: -133.6385371805095\n",
            "Número de pasos del episodio 10783 son episode_steps:281\n",
            "Total Steps: 908952 Episode Num: 10783 Reward: 387.8548791889057 avg_loss_c: 10.737847172068532 avg_loss_a: -133.11495678450288\n",
            "Número de pasos del episodio 10784 son episode_steps:1000\n",
            "Total Steps: 909952 Episode Num: 10784 Reward: 1832.4533732664465 avg_loss_c: 9.464270996570587 avg_loss_a: -133.45430792236328\n",
            "Número de pasos del episodio 10785 son episode_steps:145\n",
            "Total Steps: 910097 Episode Num: 10785 Reward: 127.53440118823178 avg_loss_c: 10.06884225648025 avg_loss_a: -133.26129634462555\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 636.211919\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10786 son episode_steps:720\n",
            "Total Steps: 910817 Episode Num: 10786 Reward: 1208.1459451053668 avg_loss_c: 9.960346222586102 avg_loss_a: -132.9784610112508\n",
            "Número de pasos del episodio 10787 son episode_steps:67\n",
            "Total Steps: 910884 Episode Num: 10787 Reward: 1.2157097410789772 avg_loss_c: 10.28980558309982 avg_loss_a: -132.7401977083576\n",
            "Número de pasos del episodio 10788 son episode_steps:56\n",
            "Total Steps: 910940 Episode Num: 10788 Reward: -37.157452765070865 avg_loss_c: 11.099646653447833 avg_loss_a: -132.25107220241003\n",
            "Número de pasos del episodio 10789 son episode_steps:420\n",
            "Total Steps: 911360 Episode Num: 10789 Reward: 642.4504006864565 avg_loss_c: 11.775804104123797 avg_loss_a: -131.83954976399738\n",
            "Número de pasos del episodio 10790 son episode_steps:212\n",
            "Total Steps: 911572 Episode Num: 10790 Reward: 254.6075005801037 avg_loss_c: 10.904600701242122 avg_loss_a: -131.6192991868505\n",
            "Número de pasos del episodio 10791 son episode_steps:167\n",
            "Total Steps: 911739 Episode Num: 10791 Reward: 207.35764669194094 avg_loss_c: 11.52035103015557 avg_loss_a: -130.98633223664976\n",
            "Número de pasos del episodio 10792 son episode_steps:1000\n",
            "Total Steps: 912739 Episode Num: 10792 Reward: 1736.9999414246977 avg_loss_c: 10.983231319904327 avg_loss_a: -131.96777307128906\n",
            "Número de pasos del episodio 10793 son episode_steps:1000\n",
            "Total Steps: 913739 Episode Num: 10793 Reward: 1730.5442221504125 avg_loss_c: 10.531641394138337 avg_loss_a: -132.1890517578125\n",
            "Número de pasos del episodio 10794 son episode_steps:114\n",
            "Total Steps: 913853 Episode Num: 10794 Reward: 55.64243310703369 avg_loss_c: 10.894573178207665 avg_loss_a: -132.89076888770387\n",
            "Número de pasos del episodio 10795 son episode_steps:189\n",
            "Total Steps: 914042 Episode Num: 10795 Reward: 232.30519356825042 avg_loss_c: 11.551718898551174 avg_loss_a: -131.71828311334843\n",
            "Número de pasos del episodio 10796 son episode_steps:109\n",
            "Total Steps: 914151 Episode Num: 10796 Reward: 66.16073178688906 avg_loss_c: 12.867950596940627 avg_loss_a: -131.73635836260036\n",
            "Número de pasos del episodio 10797 son episode_steps:27\n",
            "Total Steps: 914178 Episode Num: 10797 Reward: -6.0299616309783755 avg_loss_c: 11.98987305605853 avg_loss_a: -133.29772553620515\n",
            "Número de pasos del episodio 10798 son episode_steps:164\n",
            "Total Steps: 914342 Episode Num: 10798 Reward: 201.984384974948 avg_loss_c: 13.51317267301606 avg_loss_a: -131.55656758750357\n",
            "Número de pasos del episodio 10799 son episode_steps:746\n",
            "Total Steps: 915088 Episode Num: 10799 Reward: 1182.1709547042547 avg_loss_c: 12.151510679689872 avg_loss_a: -132.50312054508814\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 865.029961\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10800 son episode_steps:1000\n",
            "Total Steps: 916088 Episode Num: 10800 Reward: 1654.9364166703112 avg_loss_c: 11.025552408695221 avg_loss_a: -133.11949284362794\n",
            "Número de pasos del episodio 10801 son episode_steps:258\n",
            "Total Steps: 916346 Episode Num: 10801 Reward: 361.0584933958609 avg_loss_c: 11.363475411437278 avg_loss_a: -132.93790755161018\n",
            "Número de pasos del episodio 10802 son episode_steps:155\n",
            "Total Steps: 916501 Episode Num: 10802 Reward: 194.2013084995919 avg_loss_c: 10.878133792261924 avg_loss_a: -132.3709986532888\n",
            "Número de pasos del episodio 10803 son episode_steps:405\n",
            "Total Steps: 916906 Episode Num: 10803 Reward: 635.1902485950892 avg_loss_c: 10.736360162570152 avg_loss_a: -133.5866286289545\n",
            "Número de pasos del episodio 10804 son episode_steps:392\n",
            "Total Steps: 917298 Episode Num: 10804 Reward: 574.983994887376 avg_loss_c: 10.74343777676018 avg_loss_a: -133.6410530246034\n",
            "Número de pasos del episodio 10805 son episode_steps:502\n",
            "Total Steps: 917800 Episode Num: 10805 Reward: 727.321026326619 avg_loss_c: 10.995581317232899 avg_loss_a: -133.50089379420794\n",
            "Número de pasos del episodio 10806 son episode_steps:487\n",
            "Total Steps: 918287 Episode Num: 10806 Reward: 791.2056910318015 avg_loss_c: 10.299770157439998 avg_loss_a: -133.63983107298552\n",
            "Número de pasos del episodio 10807 son episode_steps:149\n",
            "Total Steps: 918436 Episode Num: 10807 Reward: 130.36529284703963 avg_loss_c: 11.838258253647977 avg_loss_a: -133.30740929930002\n",
            "Número de pasos del episodio 10808 son episode_steps:183\n",
            "Total Steps: 918619 Episode Num: 10808 Reward: 204.25505541852547 avg_loss_c: 11.902426018740961 avg_loss_a: -133.88462270934724\n",
            "Número de pasos del episodio 10809 son episode_steps:266\n",
            "Total Steps: 918885 Episode Num: 10809 Reward: 316.16685375356485 avg_loss_c: 11.34344564523912 avg_loss_a: -134.54157847927925\n",
            "Número de pasos del episodio 10810 son episode_steps:164\n",
            "Total Steps: 919049 Episode Num: 10810 Reward: 209.9029460668231 avg_loss_c: 11.02355423787745 avg_loss_a: -134.78660099680832\n",
            "Número de pasos del episodio 10811 son episode_steps:699\n",
            "Total Steps: 919748 Episode Num: 10811 Reward: 1130.3845948763574 avg_loss_c: 11.171530052316035 avg_loss_a: -134.43141567246596\n",
            "Número de pasos del episodio 10812 son episode_steps:126\n",
            "Total Steps: 919874 Episode Num: 10812 Reward: 127.3369525577652 avg_loss_c: 11.303212752417913 avg_loss_a: -133.95145585801868\n",
            "Número de pasos del episodio 10813 son episode_steps:275\n",
            "Total Steps: 920149 Episode Num: 10813 Reward: 398.5877880528195 avg_loss_c: 10.936398107355291 avg_loss_a: -134.0387882302024\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 262.083540\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10814 son episode_steps:492\n",
            "Total Steps: 920641 Episode Num: 10814 Reward: 771.6520757879085 avg_loss_c: 10.519487869448778 avg_loss_a: -134.01850810477404\n",
            "Número de pasos del episodio 10815 son episode_steps:284\n",
            "Total Steps: 920925 Episode Num: 10815 Reward: 376.216670248467 avg_loss_c: 10.979577443969081 avg_loss_a: -133.70778924646513\n",
            "Número de pasos del episodio 10816 son episode_steps:262\n",
            "Total Steps: 921187 Episode Num: 10816 Reward: 357.6369010745077 avg_loss_c: 10.795802946309097 avg_loss_a: -133.56637072381173\n",
            "Número de pasos del episodio 10817 son episode_steps:1000\n",
            "Total Steps: 922187 Episode Num: 10817 Reward: 1777.3462813582248 avg_loss_c: 9.79169388127327 avg_loss_a: -135.3032018737793\n",
            "Número de pasos del episodio 10818 son episode_steps:1000\n",
            "Total Steps: 923187 Episode Num: 10818 Reward: 1831.7080656056842 avg_loss_c: 8.693848227977753 avg_loss_a: -137.38643557739258\n",
            "Número de pasos del episodio 10819 son episode_steps:68\n",
            "Total Steps: 923255 Episode Num: 10819 Reward: 43.85058818016508 avg_loss_c: 9.681163212832283 avg_loss_a: -137.5040974336512\n",
            "Número de pasos del episodio 10820 son episode_steps:1000\n",
            "Total Steps: 924255 Episode Num: 10820 Reward: 1810.1986981724208 avg_loss_c: 8.56838084435463 avg_loss_a: -138.1804821472168\n",
            "Número de pasos del episodio 10821 son episode_steps:360\n",
            "Total Steps: 924615 Episode Num: 10821 Reward: 571.372959762908 avg_loss_c: 8.31990881231096 avg_loss_a: -137.86413192749023\n",
            "Número de pasos del episodio 10822 son episode_steps:87\n",
            "Total Steps: 924702 Episode Num: 10822 Reward: -17.92415558329465 avg_loss_c: 9.924387882495749 avg_loss_a: -137.94690941120015\n",
            "Número de pasos del episodio 10823 son episode_steps:110\n",
            "Total Steps: 924812 Episode Num: 10823 Reward: 139.3538385627497 avg_loss_c: 11.191195631027222 avg_loss_a: -138.23163951526988\n",
            "Número de pasos del episodio 10824 son episode_steps:36\n",
            "Total Steps: 924848 Episode Num: 10824 Reward: 5.1781047221818355 avg_loss_c: 10.121740023295084 avg_loss_a: -137.9824447631836\n",
            "Número de pasos del episodio 10825 son episode_steps:67\n",
            "Total Steps: 924915 Episode Num: 10825 Reward: 60.817840639027565 avg_loss_c: 10.250307873113831 avg_loss_a: -136.37033149377623\n",
            "Número de pasos del episodio 10826 son episode_steps:75\n",
            "Total Steps: 924990 Episode Num: 10826 Reward: 84.7248434029493 avg_loss_c: 10.716744906107584 avg_loss_a: -137.16095703125\n",
            "Número de pasos del episodio 10827 son episode_steps:395\n",
            "Total Steps: 925385 Episode Num: 10827 Reward: 586.9978464458525 avg_loss_c: 9.73732465430151 avg_loss_a: -136.44367096333565\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 788.318005\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10828 son episode_steps:542\n",
            "Total Steps: 925927 Episode Num: 10828 Reward: 853.8779371190544 avg_loss_c: 9.38097983136828 avg_loss_a: -137.7921522640214\n",
            "Número de pasos del episodio 10829 son episode_steps:65\n",
            "Total Steps: 925992 Episode Num: 10829 Reward: 56.848964773572305 avg_loss_c: 9.361160967900203 avg_loss_a: -138.21702927809494\n",
            "Número de pasos del episodio 10830 son episode_steps:1000\n",
            "Total Steps: 926992 Episode Num: 10830 Reward: 1636.1954716077955 avg_loss_c: 9.120152653217316 avg_loss_a: -138.11247647094726\n",
            "Número de pasos del episodio 10831 son episode_steps:667\n",
            "Total Steps: 927659 Episode Num: 10831 Reward: 1070.7762880747566 avg_loss_c: 9.517080408522393 avg_loss_a: -137.96488216005523\n",
            "Número de pasos del episodio 10832 son episode_steps:71\n",
            "Total Steps: 927730 Episode Num: 10832 Reward: -5.368499748843605 avg_loss_c: 9.640413391758019 avg_loss_a: -138.2159200319102\n",
            "Número de pasos del episodio 10833 son episode_steps:368\n",
            "Total Steps: 928098 Episode Num: 10833 Reward: 592.984826300039 avg_loss_c: 9.4796904027462 avg_loss_a: -136.79334221715513\n",
            "Número de pasos del episodio 10834 son episode_steps:1000\n",
            "Total Steps: 929098 Episode Num: 10834 Reward: 1766.2771113260046 avg_loss_c: 8.758806012630462 avg_loss_a: -138.12783865356445\n",
            "Número de pasos del episodio 10835 son episode_steps:46\n",
            "Total Steps: 929144 Episode Num: 10835 Reward: 32.541889904555106 avg_loss_c: 8.558332982270613 avg_loss_a: -137.93602852199388\n",
            "Número de pasos del episodio 10836 son episode_steps:30\n",
            "Total Steps: 929174 Episode Num: 10836 Reward: -38.60900503057205 avg_loss_c: 9.259534788131713 avg_loss_a: -138.618755086263\n",
            "Número de pasos del episodio 10837 son episode_steps:1000\n",
            "Total Steps: 930174 Episode Num: 10837 Reward: 1699.2479852451736 avg_loss_c: 8.89092073917389 avg_loss_a: -138.35010888671874\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 1024.165693\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10838 son episode_steps:85\n",
            "Total Steps: 930259 Episode Num: 10838 Reward: 91.79063328136017 avg_loss_c: 9.768275995815502 avg_loss_a: -138.85524453555837\n",
            "Número de pasos del episodio 10839 son episode_steps:1000\n",
            "Total Steps: 931259 Episode Num: 10839 Reward: 1606.541932677675 avg_loss_c: 8.102475804328918 avg_loss_a: -139.11137786865234\n",
            "Número de pasos del episodio 10840 son episode_steps:1000\n",
            "Total Steps: 932259 Episode Num: 10840 Reward: 1758.9900009238108 avg_loss_c: 7.16593938946724 avg_loss_a: -140.83678564453126\n",
            "Número de pasos del episodio 10841 son episode_steps:39\n",
            "Total Steps: 932298 Episode Num: 10841 Reward: 3.5409211458127414 avg_loss_c: 6.540908141013904 avg_loss_a: -141.84727399777142\n",
            "Número de pasos del episodio 10842 son episode_steps:1000\n",
            "Total Steps: 933298 Episode Num: 10842 Reward: 1700.3678549087565 avg_loss_c: 7.024362017869949 avg_loss_a: -140.9637571411133\n",
            "Número de pasos del episodio 10843 son episode_steps:790\n",
            "Total Steps: 934088 Episode Num: 10843 Reward: 1269.1932689063426 avg_loss_c: 6.899195321300362 avg_loss_a: -141.54268590226957\n",
            "Número de pasos del episodio 10844 son episode_steps:564\n",
            "Total Steps: 934652 Episode Num: 10844 Reward: 896.9297742353958 avg_loss_c: 6.865147213141124 avg_loss_a: -141.94830928288454\n",
            "Número de pasos del episodio 10845 son episode_steps:670\n",
            "Total Steps: 935322 Episode Num: 10845 Reward: 1026.506317503248 avg_loss_c: 6.655205437318602 avg_loss_a: -142.03407697535272\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 607.148198\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10846 son episode_steps:38\n",
            "Total Steps: 935360 Episode Num: 10846 Reward: 2.945602773727798 avg_loss_c: 7.116372121007819 avg_loss_a: -141.52112539190995\n",
            "Número de pasos del episodio 10847 son episode_steps:87\n",
            "Total Steps: 935447 Episode Num: 10847 Reward: 29.585348766316645 avg_loss_c: 8.669963496854935 avg_loss_a: -141.9303567820582\n",
            "Número de pasos del episodio 10848 son episode_steps:468\n",
            "Total Steps: 935915 Episode Num: 10848 Reward: 692.0278494827967 avg_loss_c: 7.273705560427445 avg_loss_a: -141.6197712564061\n",
            "Número de pasos del episodio 10849 son episode_steps:56\n",
            "Total Steps: 935971 Episode Num: 10849 Reward: 53.700977163788835 avg_loss_c: 7.6159038458551676 avg_loss_a: -141.54525320870536\n",
            "Número de pasos del episodio 10850 son episode_steps:743\n",
            "Total Steps: 936714 Episode Num: 10850 Reward: 1156.7778407748654 avg_loss_c: 6.892243513990379 avg_loss_a: -141.8437424219473\n",
            "Número de pasos del episodio 10851 son episode_steps:129\n",
            "Total Steps: 936843 Episode Num: 10851 Reward: 189.41054353878883 avg_loss_c: 8.53360525027726 avg_loss_a: -142.47479531931322\n",
            "Número de pasos del episodio 10852 son episode_steps:1000\n",
            "Total Steps: 937843 Episode Num: 10852 Reward: 1785.3404796582308 avg_loss_c: 6.881843620300293 avg_loss_a: -142.79228945922853\n",
            "Número de pasos del episodio 10853 son episode_steps:1000\n",
            "Total Steps: 938843 Episode Num: 10853 Reward: 1827.8113601515006 avg_loss_c: 6.203673100709915 avg_loss_a: -143.5877315979004\n",
            "Número de pasos del episodio 10854 son episode_steps:1000\n",
            "Total Steps: 939843 Episode Num: 10854 Reward: 1801.9926169984149 avg_loss_c: 5.376108654260635 avg_loss_a: -144.5087827758789\n",
            "Número de pasos del episodio 10855 son episode_steps:614\n",
            "Total Steps: 940457 Episode Num: 10855 Reward: 962.4602495160445 avg_loss_c: 5.014908156876455 avg_loss_a: -144.6036303889868\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 222.291752\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10856 son episode_steps:23\n",
            "Total Steps: 940480 Episode Num: 10856 Reward: -40.63277926740037 avg_loss_c: 8.513841877812924 avg_loss_a: -143.84517570163894\n",
            "Número de pasos del episodio 10857 son episode_steps:37\n",
            "Total Steps: 940517 Episode Num: 10857 Reward: -8.910534782664724 avg_loss_c: 5.783528579247965 avg_loss_a: -144.74255082413956\n",
            "Número de pasos del episodio 10858 son episode_steps:216\n",
            "Total Steps: 940733 Episode Num: 10858 Reward: 324.8513658826745 avg_loss_c: 8.021189635550535 avg_loss_a: -144.20526391488534\n",
            "Número de pasos del episodio 10859 son episode_steps:512\n",
            "Total Steps: 941245 Episode Num: 10859 Reward: 861.0125846271346 avg_loss_c: 6.346303196623921 avg_loss_a: -144.70067662000656\n",
            "Número de pasos del episodio 10860 son episode_steps:42\n",
            "Total Steps: 941287 Episode Num: 10860 Reward: 3.5089308059427013 avg_loss_c: 5.601462784267607 avg_loss_a: -144.13082377115884\n",
            "Número de pasos del episodio 10861 son episode_steps:81\n",
            "Total Steps: 941368 Episode Num: 10861 Reward: 82.47576818471515 avg_loss_c: 6.8624644956471 avg_loss_a: -143.50790273407358\n",
            "Número de pasos del episodio 10862 son episode_steps:34\n",
            "Total Steps: 941402 Episode Num: 10862 Reward: 6.320750490703057 avg_loss_c: 6.643105654155507 avg_loss_a: -143.21897888183594\n",
            "Número de pasos del episodio 10863 son episode_steps:29\n",
            "Total Steps: 941431 Episode Num: 10863 Reward: -5.611656597380735 avg_loss_c: 12.593696183171765 avg_loss_a: -144.6237450961409\n",
            "Número de pasos del episodio 10864 son episode_steps:230\n",
            "Total Steps: 941661 Episode Num: 10864 Reward: 326.6036150818126 avg_loss_c: 7.569199161944182 avg_loss_a: -143.22640035878058\n",
            "Número de pasos del episodio 10865 son episode_steps:120\n",
            "Total Steps: 941781 Episode Num: 10865 Reward: 52.78361611266484 avg_loss_c: 7.908295716842016 avg_loss_a: -143.48004480997722\n",
            "Número de pasos del episodio 10866 son episode_steps:454\n",
            "Total Steps: 942235 Episode Num: 10866 Reward: 741.3233136195171 avg_loss_c: 7.436316197139051 avg_loss_a: -143.00226603100478\n",
            "Número de pasos del episodio 10867 son episode_steps:95\n",
            "Total Steps: 942330 Episode Num: 10867 Reward: 131.74495789681205 avg_loss_c: 6.9383503160978615 avg_loss_a: -142.41846570466694\n",
            "Número de pasos del episodio 10868 son episode_steps:78\n",
            "Total Steps: 942408 Episode Num: 10868 Reward: 96.31663237225283 avg_loss_c: 8.737320138857914 avg_loss_a: -142.24260692107373\n",
            "Número de pasos del episodio 10869 son episode_steps:22\n",
            "Total Steps: 942430 Episode Num: 10869 Reward: -36.5884165773831 avg_loss_c: 12.403710061853582 avg_loss_a: -141.15654130415484\n",
            "Número de pasos del episodio 10870 son episode_steps:307\n",
            "Total Steps: 942737 Episode Num: 10870 Reward: 415.2653732523777 avg_loss_c: 8.491454418008413 avg_loss_a: -141.8898311950485\n",
            "Número de pasos del episodio 10871 son episode_steps:1000\n",
            "Total Steps: 943737 Episode Num: 10871 Reward: 1774.2575854735026 avg_loss_c: 7.53395032787323 avg_loss_a: -141.93381536865235\n",
            "Número de pasos del episodio 10872 son episode_steps:20\n",
            "Total Steps: 943757 Episode Num: 10872 Reward: -34.40587148609391 avg_loss_c: 10.123876357078553 avg_loss_a: -141.5531982421875\n",
            "Número de pasos del episodio 10873 son episode_steps:188\n",
            "Total Steps: 943945 Episode Num: 10873 Reward: 192.5817430042033 avg_loss_c: 10.248346756113337 avg_loss_a: -140.48853983777636\n",
            "Número de pasos del episodio 10874 son episode_steps:103\n",
            "Total Steps: 944048 Episode Num: 10874 Reward: 141.48836317777392 avg_loss_c: 7.673315631533132 avg_loss_a: -141.15870488731608\n",
            "Número de pasos del episodio 10875 son episode_steps:138\n",
            "Total Steps: 944186 Episode Num: 10875 Reward: 130.24417771617425 avg_loss_c: 11.161990070688551 avg_loss_a: -140.52105292721072\n",
            "Número de pasos del episodio 10876 son episode_steps:89\n",
            "Total Steps: 944275 Episode Num: 10876 Reward: 91.88502727178891 avg_loss_c: 9.741292302528125 avg_loss_a: -141.1909856903419\n",
            "Número de pasos del episodio 10877 son episode_steps:173\n",
            "Total Steps: 944448 Episode Num: 10877 Reward: 223.18618222529452 avg_loss_c: 11.704871888794651 avg_loss_a: -139.92193947499888\n",
            "Número de pasos del episodio 10878 son episode_steps:19\n",
            "Total Steps: 944467 Episode Num: 10878 Reward: -31.073825117174376 avg_loss_c: 10.938309995751633 avg_loss_a: -138.7974813360917\n",
            "Número de pasos del episodio 10879 son episode_steps:131\n",
            "Total Steps: 944598 Episode Num: 10879 Reward: 120.6324456620995 avg_loss_c: 10.40666421497141 avg_loss_a: -140.16169004949904\n",
            "Número de pasos del episodio 10880 son episode_steps:337\n",
            "Total Steps: 944935 Episode Num: 10880 Reward: 550.9063543526522 avg_loss_c: 10.776232911854187 avg_loss_a: -140.9623612310483\n",
            "Número de pasos del episodio 10881 son episode_steps:194\n",
            "Total Steps: 945129 Episode Num: 10881 Reward: 216.82584475269596 avg_loss_c: 12.40812292418529 avg_loss_a: -140.62646185491502\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 381.093921\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10882 son episode_steps:73\n",
            "Total Steps: 945202 Episode Num: 10882 Reward: 13.124479245998803 avg_loss_c: 10.941423229975243 avg_loss_a: -139.79508386899346\n",
            "Número de pasos del episodio 10883 son episode_steps:111\n",
            "Total Steps: 945313 Episode Num: 10883 Reward: 95.34622615389065 avg_loss_c: 10.381081806646812 avg_loss_a: -139.69212038882145\n",
            "Número de pasos del episodio 10884 son episode_steps:350\n",
            "Total Steps: 945663 Episode Num: 10884 Reward: 525.5382761428937 avg_loss_c: 10.423231851032803 avg_loss_a: -140.13782383510045\n",
            "Número de pasos del episodio 10885 son episode_steps:394\n",
            "Total Steps: 946057 Episode Num: 10885 Reward: 599.1344329732881 avg_loss_c: 10.086189190143257 avg_loss_a: -140.47735293625576\n",
            "Número de pasos del episodio 10886 son episode_steps:221\n",
            "Total Steps: 946278 Episode Num: 10886 Reward: 283.2165581980072 avg_loss_c: 10.421072412939633 avg_loss_a: -140.167218031387\n",
            "Número de pasos del episodio 10887 son episode_steps:215\n",
            "Total Steps: 946493 Episode Num: 10887 Reward: 300.7297653620288 avg_loss_c: 12.627954068294791 avg_loss_a: -139.84226464559865\n",
            "Número de pasos del episodio 10888 son episode_steps:140\n",
            "Total Steps: 946633 Episode Num: 10888 Reward: 158.19487727281737 avg_loss_c: 9.88024843760899 avg_loss_a: -139.80840868268695\n",
            "Número de pasos del episodio 10889 son episode_steps:31\n",
            "Total Steps: 946664 Episode Num: 10889 Reward: -3.249073185065192 avg_loss_c: 13.16815431656376 avg_loss_a: -139.44092485981602\n",
            "Número de pasos del episodio 10890 son episode_steps:113\n",
            "Total Steps: 946777 Episode Num: 10890 Reward: 96.79280645801182 avg_loss_c: 11.7399137210002 avg_loss_a: -139.40533541789097\n",
            "Número de pasos del episodio 10891 son episode_steps:33\n",
            "Total Steps: 946810 Episode Num: 10891 Reward: 8.133793119976355 avg_loss_c: 10.33822038679412 avg_loss_a: -138.8237452651515\n",
            "Número de pasos del episodio 10892 son episode_steps:48\n",
            "Total Steps: 946858 Episode Num: 10892 Reward: 32.56787926031562 avg_loss_c: 11.82755477229754 avg_loss_a: -139.3885726928711\n",
            "Número de pasos del episodio 10893 son episode_steps:258\n",
            "Total Steps: 947116 Episode Num: 10893 Reward: 322.4239539390828 avg_loss_c: 12.484113883602527 avg_loss_a: -138.83361437893655\n",
            "Número de pasos del episodio 10894 son episode_steps:65\n",
            "Total Steps: 947181 Episode Num: 10894 Reward: 47.5938719560064 avg_loss_c: 10.889944927509015 avg_loss_a: -138.24603647085337\n",
            "Número de pasos del episodio 10895 son episode_steps:75\n",
            "Total Steps: 947256 Episode Num: 10895 Reward: 46.47552181064341 avg_loss_c: 9.978105506896974 avg_loss_a: -138.61050211588542\n",
            "Número de pasos del episodio 10896 son episode_steps:113\n",
            "Total Steps: 947369 Episode Num: 10896 Reward: 119.56733907803626 avg_loss_c: 11.4520944029884 avg_loss_a: -137.46899778653034\n",
            "Número de pasos del episodio 10897 son episode_steps:790\n",
            "Total Steps: 948159 Episode Num: 10897 Reward: 1312.661859562789 avg_loss_c: 10.60716224259968 avg_loss_a: -138.4718129218379\n",
            "Número de pasos del episodio 10898 son episode_steps:76\n",
            "Total Steps: 948235 Episode Num: 10898 Reward: 54.97635678507503 avg_loss_c: 10.078129097035056 avg_loss_a: -138.17598884984068\n",
            "Número de pasos del episodio 10899 son episode_steps:65\n",
            "Total Steps: 948300 Episode Num: 10899 Reward: -0.3967011368287068 avg_loss_c: 15.238746547698975 avg_loss_a: -138.04445331280047\n",
            "Número de pasos del episodio 10900 son episode_steps:80\n",
            "Total Steps: 948380 Episode Num: 10900 Reward: 71.30292207971873 avg_loss_c: 12.286656379699707 avg_loss_a: -137.89288864135742\n",
            "Número de pasos del episodio 10901 son episode_steps:32\n",
            "Total Steps: 948412 Episode Num: 10901 Reward: 2.7447176243098914 avg_loss_c: 12.777209669351578 avg_loss_a: -135.667555809021\n",
            "Número de pasos del episodio 10902 son episode_steps:126\n",
            "Total Steps: 948538 Episode Num: 10902 Reward: 109.34353811330628 avg_loss_c: 13.785794102956379 avg_loss_a: -136.88677566770522\n",
            "Número de pasos del episodio 10903 son episode_steps:231\n",
            "Total Steps: 948769 Episode Num: 10903 Reward: 350.2139752189173 avg_loss_c: 13.05517595670956 avg_loss_a: -135.9687340806573\n",
            "Número de pasos del episodio 10904 son episode_steps:23\n",
            "Total Steps: 948792 Episode Num: 10904 Reward: -45.5036691569748 avg_loss_c: 14.089221166527789 avg_loss_a: -136.47763459578803\n",
            "Número de pasos del episodio 10905 son episode_steps:252\n",
            "Total Steps: 949044 Episode Num: 10905 Reward: 348.18682213356976 avg_loss_c: 13.664624301214067 avg_loss_a: -135.80512740120056\n",
            "Número de pasos del episodio 10906 son episode_steps:162\n",
            "Total Steps: 949206 Episode Num: 10906 Reward: 188.83486092974152 avg_loss_c: 12.623049803722052 avg_loss_a: -135.3348966056918\n",
            "Número de pasos del episodio 10907 son episode_steps:133\n",
            "Total Steps: 949339 Episode Num: 10907 Reward: 145.33433431495072 avg_loss_c: 12.191474907380298 avg_loss_a: -136.0628151570944\n",
            "Número de pasos del episodio 10908 son episode_steps:128\n",
            "Total Steps: 949467 Episode Num: 10908 Reward: 176.66261514667394 avg_loss_c: 14.996147722005844 avg_loss_a: -134.64205813407898\n",
            "Número de pasos del episodio 10909 son episode_steps:111\n",
            "Total Steps: 949578 Episode Num: 10909 Reward: 157.52735116329802 avg_loss_c: 12.77694002787272 avg_loss_a: -134.27518772434544\n",
            "Número de pasos del episodio 10910 son episode_steps:98\n",
            "Total Steps: 949676 Episode Num: 10910 Reward: 38.85106908027356 avg_loss_c: 15.002336385298749 avg_loss_a: -134.22885863635005\n",
            "Número de pasos del episodio 10911 son episode_steps:482\n",
            "Total Steps: 950158 Episode Num: 10911 Reward: 798.3878139859993 avg_loss_c: 13.932794321622097 avg_loss_a: -133.74450382849983\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 1431.056930\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10912 son episode_steps:1000\n",
            "Total Steps: 951158 Episode Num: 10912 Reward: 1840.8914060815325 avg_loss_c: 13.257417171955108 avg_loss_a: -133.95620764160157\n",
            "Número de pasos del episodio 10913 son episode_steps:447\n",
            "Total Steps: 951605 Episode Num: 10913 Reward: 627.7720490497904 avg_loss_c: 13.448144704703516 avg_loss_a: -133.6649329678324\n",
            "Número de pasos del episodio 10914 son episode_steps:161\n",
            "Total Steps: 951766 Episode Num: 10914 Reward: 165.76056834678073 avg_loss_c: 13.400701235540165 avg_loss_a: -133.70349291688908\n",
            "Número de pasos del episodio 10915 son episode_steps:1000\n",
            "Total Steps: 952766 Episode Num: 10915 Reward: 1870.534221608858 avg_loss_c: 12.321133372783661 avg_loss_a: -133.67067677307128\n",
            "Número de pasos del episodio 10916 son episode_steps:494\n",
            "Total Steps: 953260 Episode Num: 10916 Reward: 743.8123168911038 avg_loss_c: 12.751602130380236 avg_loss_a: -133.79898441947907\n",
            "Número de pasos del episodio 10917 son episode_steps:43\n",
            "Total Steps: 953303 Episode Num: 10917 Reward: 21.87057148169167 avg_loss_c: 13.686232234156408 avg_loss_a: -134.31904389137446\n",
            "Número de pasos del episodio 10918 son episode_steps:1000\n",
            "Total Steps: 954303 Episode Num: 10918 Reward: 1837.457494984511 avg_loss_c: 12.057401418685913 avg_loss_a: -134.0210518951416\n",
            "Número de pasos del episodio 10919 son episode_steps:22\n",
            "Total Steps: 954325 Episode Num: 10919 Reward: -50.71418514928706 avg_loss_c: 11.387205817482688 avg_loss_a: -133.59716242009944\n",
            "Número de pasos del episodio 10920 son episode_steps:31\n",
            "Total Steps: 954356 Episode Num: 10920 Reward: 4.513093586337779 avg_loss_c: 12.31848079927506 avg_loss_a: -134.15568345592868\n",
            "Número de pasos del episodio 10921 son episode_steps:68\n",
            "Total Steps: 954424 Episode Num: 10921 Reward: 45.44646171358896 avg_loss_c: 14.30471268120934 avg_loss_a: -133.9932217317469\n",
            "Número de pasos del episodio 10922 son episode_steps:17\n",
            "Total Steps: 954441 Episode Num: 10922 Reward: -33.50775757011478 avg_loss_c: 15.127201585208669 avg_loss_a: -132.55982701918657\n",
            "Número de pasos del episodio 10923 son episode_steps:1000\n",
            "Total Steps: 955441 Episode Num: 10923 Reward: 1707.5610015833106 avg_loss_c: 12.82217003917694 avg_loss_a: -134.63476698303222\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 403.942881\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10924 son episode_steps:73\n",
            "Total Steps: 955514 Episode Num: 10924 Reward: 50.60081163663775 avg_loss_c: 11.483520527408547 avg_loss_a: -135.32077486221104\n",
            "Número de pasos del episodio 10925 son episode_steps:165\n",
            "Total Steps: 955679 Episode Num: 10925 Reward: 160.8328622994955 avg_loss_c: 12.07791489976825 avg_loss_a: -134.1067783240116\n",
            "Número de pasos del episodio 10926 son episode_steps:18\n",
            "Total Steps: 955697 Episode Num: 10926 Reward: -50.984593303272824 avg_loss_c: 13.705115609698826 avg_loss_a: -136.01565721299914\n",
            "Número de pasos del episodio 10927 son episode_steps:229\n",
            "Total Steps: 955926 Episode Num: 10927 Reward: 320.8166527688495 avg_loss_c: 13.565360013053928 avg_loss_a: -134.1018655435487\n",
            "Número de pasos del episodio 10928 son episode_steps:155\n",
            "Total Steps: 956081 Episode Num: 10928 Reward: 215.7575449749758 avg_loss_c: 13.2588100987096 avg_loss_a: -133.50302291377898\n",
            "Número de pasos del episodio 10929 son episode_steps:27\n",
            "Total Steps: 956108 Episode Num: 10929 Reward: -49.08943485248869 avg_loss_c: 15.855510323135942 avg_loss_a: -133.24600615324798\n",
            "Número de pasos del episodio 10930 son episode_steps:207\n",
            "Total Steps: 956315 Episode Num: 10930 Reward: 274.8500974888506 avg_loss_c: 14.113306358816542 avg_loss_a: -133.5652003633803\n",
            "Número de pasos del episodio 10931 son episode_steps:204\n",
            "Total Steps: 956519 Episode Num: 10931 Reward: 310.7709173838027 avg_loss_c: 14.328595692036199 avg_loss_a: -132.9945473764457\n",
            "Número de pasos del episodio 10932 son episode_steps:514\n",
            "Total Steps: 957033 Episode Num: 10932 Reward: 880.9558280332295 avg_loss_c: 13.357010991656827 avg_loss_a: -133.25570283882348\n",
            "Número de pasos del episodio 10933 son episode_steps:502\n",
            "Total Steps: 957535 Episode Num: 10933 Reward: 866.9162850502971 avg_loss_c: 12.857495855050258 avg_loss_a: -132.79134727569215\n",
            "Número de pasos del episodio 10934 son episode_steps:268\n",
            "Total Steps: 957803 Episode Num: 10934 Reward: 449.5916100143253 avg_loss_c: 13.041165988836715 avg_loss_a: -132.10638370798594\n",
            "Número de pasos del episodio 10935 son episode_steps:24\n",
            "Total Steps: 957827 Episode Num: 10935 Reward: -38.74128642015271 avg_loss_c: 12.725393573443094 avg_loss_a: -131.2216936747233\n",
            "Número de pasos del episodio 10936 son episode_steps:106\n",
            "Total Steps: 957933 Episode Num: 10936 Reward: 156.94612217354307 avg_loss_c: 13.506641693834988 avg_loss_a: -133.05205017665648\n",
            "Número de pasos del episodio 10937 son episode_steps:191\n",
            "Total Steps: 958124 Episode Num: 10937 Reward: 165.56983737252082 avg_loss_c: 13.486844844218949 avg_loss_a: -132.04599813890707\n",
            "Número de pasos del episodio 10938 son episode_steps:245\n",
            "Total Steps: 958369 Episode Num: 10938 Reward: 247.98364369373152 avg_loss_c: 15.787210991917824 avg_loss_a: -131.34620604223136\n",
            "Número de pasos del episodio 10939 son episode_steps:1000\n",
            "Total Steps: 959369 Episode Num: 10939 Reward: 1845.2270210946144 avg_loss_c: 13.509547726154327 avg_loss_a: -130.51993103027343\n",
            "Número de pasos del episodio 10940 son episode_steps:79\n",
            "Total Steps: 959448 Episode Num: 10940 Reward: 97.91184070122476 avg_loss_c: 12.418872597851331 avg_loss_a: -129.98505700992632\n",
            "Número de pasos del episodio 10941 son episode_steps:483\n",
            "Total Steps: 959931 Episode Num: 10941 Reward: 793.2017229594054 avg_loss_c: 14.017749856471028 avg_loss_a: -130.21747794457352\n",
            "Número de pasos del episodio 10942 son episode_steps:82\n",
            "Total Steps: 960013 Episode Num: 10942 Reward: 75.08052242881774 avg_loss_c: 15.448187275630671 avg_loss_a: -129.96830619253763\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 1549.079117\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10943 son episode_steps:127\n",
            "Total Steps: 960140 Episode Num: 10943 Reward: 163.20206975613542 avg_loss_c: 14.184256335881752 avg_loss_a: -129.1988146924597\n",
            "Número de pasos del episodio 10944 son episode_steps:98\n",
            "Total Steps: 960238 Episode Num: 10944 Reward: 75.38914410132625 avg_loss_c: 14.769905109794772 avg_loss_a: -129.24484704465283\n",
            "Número de pasos del episodio 10945 son episode_steps:298\n",
            "Total Steps: 960536 Episode Num: 10945 Reward: 399.0384650434286 avg_loss_c: 14.363246893722739 avg_loss_a: -129.25528148676725\n",
            "Número de pasos del episodio 10946 son episode_steps:1000\n",
            "Total Steps: 961536 Episode Num: 10946 Reward: 1814.83043281624 avg_loss_c: 13.179453813552856 avg_loss_a: -129.97310681152345\n",
            "Número de pasos del episodio 10947 son episode_steps:750\n",
            "Total Steps: 962286 Episode Num: 10947 Reward: 1277.456449615414 avg_loss_c: 12.377414138793945 avg_loss_a: -131.23282948811848\n",
            "Número de pasos del episodio 10948 son episode_steps:174\n",
            "Total Steps: 962460 Episode Num: 10948 Reward: 227.0209490456401 avg_loss_c: 11.52273556829869 avg_loss_a: -132.6271111499304\n",
            "Número de pasos del episodio 10949 son episode_steps:77\n",
            "Total Steps: 962537 Episode Num: 10949 Reward: 90.35115073521695 avg_loss_c: 12.969076125652759 avg_loss_a: -131.11097281319755\n",
            "Número de pasos del episodio 10950 son episode_steps:788\n",
            "Total Steps: 963325 Episode Num: 10950 Reward: 1186.571547207081 avg_loss_c: 12.08750376362486 avg_loss_a: -131.16061145763106\n",
            "Número de pasos del episodio 10951 son episode_steps:911\n",
            "Total Steps: 964236 Episode Num: 10951 Reward: 1350.7225950754478 avg_loss_c: 12.162926882210993 avg_loss_a: -132.06388865030166\n",
            "Número de pasos del episodio 10952 son episode_steps:70\n",
            "Total Steps: 964306 Episode Num: 10952 Reward: 61.88715936812656 avg_loss_c: 12.050807169505529 avg_loss_a: -131.39034096854073\n",
            "Número de pasos del episodio 10953 son episode_steps:578\n",
            "Total Steps: 964884 Episode Num: 10953 Reward: 977.40379883808 avg_loss_c: 12.247328321001522 avg_loss_a: -132.83095368382016\n",
            "Número de pasos del episodio 10954 son episode_steps:341\n",
            "Total Steps: 965225 Episode Num: 10954 Reward: 545.851877479625 avg_loss_c: 11.772493691038875 avg_loss_a: -132.986610009873\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 811.049151\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10955 son episode_steps:168\n",
            "Total Steps: 965393 Episode Num: 10955 Reward: 195.41539918140316 avg_loss_c: 12.172178225857872 avg_loss_a: -132.75511823381697\n",
            "Número de pasos del episodio 10956 son episode_steps:830\n",
            "Total Steps: 966223 Episode Num: 10956 Reward: 1338.8849726684336 avg_loss_c: 11.636247117835355 avg_loss_a: -133.3433842486646\n",
            "Número de pasos del episodio 10957 son episode_steps:117\n",
            "Total Steps: 966340 Episode Num: 10957 Reward: 105.9803267462583 avg_loss_c: 11.969900921878653 avg_loss_a: -133.14557080391126\n",
            "Número de pasos del episodio 10958 son episode_steps:135\n",
            "Total Steps: 966475 Episode Num: 10958 Reward: 130.6349376112117 avg_loss_c: 12.180715557380958 avg_loss_a: -132.5836580629702\n",
            "Número de pasos del episodio 10959 son episode_steps:732\n",
            "Total Steps: 967207 Episode Num: 10959 Reward: 1031.4036850605187 avg_loss_c: 11.784324560009065 avg_loss_a: -133.5162800856627\n",
            "Número de pasos del episodio 10960 son episode_steps:230\n",
            "Total Steps: 967437 Episode Num: 10960 Reward: 331.9705725182486 avg_loss_c: 11.0150692815366 avg_loss_a: -134.54516833761463\n",
            "Número de pasos del episodio 10961 son episode_steps:31\n",
            "Total Steps: 967468 Episode Num: 10961 Reward: -48.14191386082073 avg_loss_c: 11.856938562085551 avg_loss_a: -134.9486374393586\n",
            "Número de pasos del episodio 10962 son episode_steps:91\n",
            "Total Steps: 967559 Episode Num: 10962 Reward: 49.943543889956146 avg_loss_c: 13.661837803138482 avg_loss_a: -133.10790177229995\n",
            "Número de pasos del episodio 10963 son episode_steps:654\n",
            "Total Steps: 968213 Episode Num: 10963 Reward: 1152.9889571831886 avg_loss_c: 11.94908176722512 avg_loss_a: -133.75903233986017\n",
            "Número de pasos del episodio 10964 son episode_steps:1000\n",
            "Total Steps: 969213 Episode Num: 10964 Reward: 1649.3432979967022 avg_loss_c: 10.566656988620759 avg_loss_a: -135.42312432861328\n",
            "Número de pasos del episodio 10965 son episode_steps:897\n",
            "Total Steps: 970110 Episode Num: 10965 Reward: 1581.860682411034 avg_loss_c: 9.133260917238301 avg_loss_a: -136.30306064431352\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 803.254678\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10966 son episode_steps:1000\n",
            "Total Steps: 971110 Episode Num: 10966 Reward: 1791.105480818569 avg_loss_c: 8.364843299865722 avg_loss_a: -136.88642854309083\n",
            "Número de pasos del episodio 10967 son episode_steps:825\n",
            "Total Steps: 971935 Episode Num: 10967 Reward: 1392.6904893917845 avg_loss_c: 8.0591668287913 avg_loss_a: -137.42778542258523\n",
            "Número de pasos del episodio 10968 son episode_steps:413\n",
            "Total Steps: 972348 Episode Num: 10968 Reward: 692.2534997514397 avg_loss_c: 8.162950881745568 avg_loss_a: -136.6792300688441\n",
            "Número de pasos del episodio 10969 son episode_steps:220\n",
            "Total Steps: 972568 Episode Num: 10969 Reward: 308.12514678086035 avg_loss_c: 8.20337888327512 avg_loss_a: -136.43488020463423\n",
            "Número de pasos del episodio 10970 son episode_steps:31\n",
            "Total Steps: 972599 Episode Num: 10970 Reward: -21.419861475689093 avg_loss_c: 9.058950270375897 avg_loss_a: -135.59657976704258\n",
            "Número de pasos del episodio 10971 son episode_steps:78\n",
            "Total Steps: 972677 Episode Num: 10971 Reward: 61.08673806351939 avg_loss_c: 9.92003966600467 avg_loss_a: -136.75297507261618\n",
            "Número de pasos del episodio 10972 son episode_steps:76\n",
            "Total Steps: 972753 Episode Num: 10972 Reward: 52.95130170857822 avg_loss_c: 8.690944621437474 avg_loss_a: -136.70706136603104\n",
            "Número de pasos del episodio 10973 son episode_steps:386\n",
            "Total Steps: 973139 Episode Num: 10973 Reward: 590.8203664361068 avg_loss_c: 9.466989764277798 avg_loss_a: -135.6902820409271\n",
            "Número de pasos del episodio 10974 son episode_steps:112\n",
            "Total Steps: 973251 Episode Num: 10974 Reward: 125.75093952385649 avg_loss_c: 8.982934849602836 avg_loss_a: -135.90213775634766\n",
            "Número de pasos del episodio 10975 son episode_steps:93\n",
            "Total Steps: 973344 Episode Num: 10975 Reward: 29.38504770057657 avg_loss_c: 11.264034153312766 avg_loss_a: -135.2838144610005\n",
            "Número de pasos del episodio 10976 son episode_steps:1000\n",
            "Total Steps: 974344 Episode Num: 10976 Reward: 1764.9804713125386 avg_loss_c: 9.418860265731812 avg_loss_a: -136.09031507873536\n",
            "Número de pasos del episodio 10977 son episode_steps:111\n",
            "Total Steps: 974455 Episode Num: 10977 Reward: 17.83533672963306 avg_loss_c: 8.899039530539298 avg_loss_a: -135.96848963831997\n",
            "Número de pasos del episodio 10978 son episode_steps:1000\n",
            "Total Steps: 975455 Episode Num: 10978 Reward: 1799.4448900491216 avg_loss_c: 8.66425315618515 avg_loss_a: -136.33646647644042\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 960.960753\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10979 son episode_steps:35\n",
            "Total Steps: 975490 Episode Num: 10979 Reward: -41.595742696212916 avg_loss_c: 9.508723095485143 avg_loss_a: -135.7297354561942\n",
            "Número de pasos del episodio 10980 son episode_steps:131\n",
            "Total Steps: 975621 Episode Num: 10980 Reward: 146.96323778630043 avg_loss_c: 9.187620839999832 avg_loss_a: -135.83640423257842\n",
            "Número de pasos del episodio 10981 son episode_steps:375\n",
            "Total Steps: 975996 Episode Num: 10981 Reward: 596.9214557171058 avg_loss_c: 8.92697281519572 avg_loss_a: -136.1083965250651\n",
            "Número de pasos del episodio 10982 son episode_steps:1000\n",
            "Total Steps: 976996 Episode Num: 10982 Reward: 1844.8354559793206 avg_loss_c: 8.099514174699783 avg_loss_a: -137.15177557373048\n",
            "Número de pasos del episodio 10983 son episode_steps:1000\n",
            "Total Steps: 977996 Episode Num: 10983 Reward: 1745.0053577797546 avg_loss_c: 7.570795242547989 avg_loss_a: -138.31923864746093\n",
            "Número de pasos del episodio 10984 son episode_steps:43\n",
            "Total Steps: 978039 Episode Num: 10984 Reward: -6.9605728954248365 avg_loss_c: 7.722551512163739 avg_loss_a: -138.20688682378724\n",
            "Número de pasos del episodio 10985 son episode_steps:81\n",
            "Total Steps: 978120 Episode Num: 10985 Reward: 63.702676503271576 avg_loss_c: 7.613563655335226 avg_loss_a: -138.36596773877557\n",
            "Número de pasos del episodio 10986 son episode_steps:1000\n",
            "Total Steps: 979120 Episode Num: 10986 Reward: 1795.7867019581138 avg_loss_c: 7.453381333827973 avg_loss_a: -138.6339252319336\n",
            "Número de pasos del episodio 10987 son episode_steps:798\n",
            "Total Steps: 979918 Episode Num: 10987 Reward: 1419.3572859299331 avg_loss_c: 7.469029867260677 avg_loss_a: -138.84387340880278\n",
            "Número de pasos del episodio 10988 son episode_steps:107\n",
            "Total Steps: 980025 Episode Num: 10988 Reward: 141.5027599513591 avg_loss_c: 7.17220674942587 avg_loss_a: -139.9454565315603\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 437.089216\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 10989 son episode_steps:92\n",
            "Total Steps: 980117 Episode Num: 10989 Reward: 90.85748342009748 avg_loss_c: 7.719372816707777 avg_loss_a: -138.38559756071672\n",
            "Número de pasos del episodio 10990 son episode_steps:1000\n",
            "Total Steps: 981117 Episode Num: 10990 Reward: 1656.283332263797 avg_loss_c: 7.301698501110077 avg_loss_a: -139.63825611877442\n",
            "Número de pasos del episodio 10991 son episode_steps:352\n",
            "Total Steps: 981469 Episode Num: 10991 Reward: 571.4780173176334 avg_loss_c: 7.090439865534956 avg_loss_a: -139.83646817640826\n",
            "Número de pasos del episodio 10992 son episode_steps:70\n",
            "Total Steps: 981539 Episode Num: 10992 Reward: 49.840615478180716 avg_loss_c: 7.290403907639639 avg_loss_a: -139.20939200265067\n",
            "Número de pasos del episodio 10993 son episode_steps:48\n",
            "Total Steps: 981587 Episode Num: 10993 Reward: 11.3433571759604 avg_loss_c: 7.194493263959885 avg_loss_a: -139.377711613973\n",
            "Número de pasos del episodio 10994 son episode_steps:635\n",
            "Total Steps: 982222 Episode Num: 10994 Reward: 1025.8098019146844 avg_loss_c: 7.763236966471034 avg_loss_a: -139.37794415331263\n",
            "Número de pasos del episodio 10995 son episode_steps:311\n",
            "Total Steps: 982533 Episode Num: 10995 Reward: 477.54244223094537 avg_loss_c: 7.285329952117332 avg_loss_a: -138.89137454508202\n",
            "Número de pasos del episodio 10996 son episode_steps:69\n",
            "Total Steps: 982602 Episode Num: 10996 Reward: 35.59261094920509 avg_loss_c: 7.162921756937884 avg_loss_a: -139.9190284618433\n",
            "Número de pasos del episodio 10997 son episode_steps:539\n",
            "Total Steps: 983141 Episode Num: 10997 Reward: 806.230626626569 avg_loss_c: 7.73073976159317 avg_loss_a: -138.4145797134994\n",
            "Número de pasos del episodio 10998 son episode_steps:93\n",
            "Total Steps: 983234 Episode Num: 10998 Reward: 55.21216413134957 avg_loss_c: 8.00689438850649 avg_loss_a: -138.30831351331486\n",
            "Número de pasos del episodio 10999 son episode_steps:49\n",
            "Total Steps: 983283 Episode Num: 10999 Reward: 6.899495807316565 avg_loss_c: 7.127753924350349 avg_loss_a: -138.07175585688378\n",
            "Número de pasos del episodio 11000 son episode_steps:498\n",
            "Total Steps: 983781 Episode Num: 11000 Reward: 686.8659515931789 avg_loss_c: 8.128730310972436 avg_loss_a: -137.81056832309707\n",
            "Número de pasos del episodio 11001 son episode_steps:44\n",
            "Total Steps: 983825 Episode Num: 11001 Reward: 21.39989187222625 avg_loss_c: 8.066157059236007 avg_loss_a: -137.8201911232688\n",
            "Número de pasos del episodio 11002 son episode_steps:342\n",
            "Total Steps: 984167 Episode Num: 11002 Reward: 544.3276963951853 avg_loss_c: 8.08646719846112 avg_loss_a: -137.07512062474302\n",
            "Número de pasos del episodio 11003 son episode_steps:219\n",
            "Total Steps: 984386 Episode Num: 11003 Reward: 218.65615673751395 avg_loss_c: 9.139785689306041 avg_loss_a: -136.38954740898794\n",
            "Número de pasos del episodio 11004 son episode_steps:57\n",
            "Total Steps: 984443 Episode Num: 11004 Reward: 51.79885007559219 avg_loss_c: 9.704230835563258 avg_loss_a: -135.98176976254112\n",
            "Número de pasos del episodio 11005 son episode_steps:1000\n",
            "Total Steps: 985443 Episode Num: 11005 Reward: 1726.1657233491064 avg_loss_c: 8.353514549732209 avg_loss_a: -137.31060360717774\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 298.854259\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 11006 son episode_steps:1000\n",
            "Total Steps: 986443 Episode Num: 11006 Reward: 1770.8321384983396 avg_loss_c: 7.615763423681259 avg_loss_a: -138.16726902770995\n",
            "Número de pasos del episodio 11007 son episode_steps:639\n",
            "Total Steps: 987082 Episode Num: 11007 Reward: 1096.2836845756658 avg_loss_c: 7.72616034046585 avg_loss_a: -138.16671793524276\n",
            "Número de pasos del episodio 11008 son episode_steps:748\n",
            "Total Steps: 987830 Episode Num: 11008 Reward: 1317.5634935742196 avg_loss_c: 7.247630072787484 avg_loss_a: -138.85989053491602\n",
            "Número de pasos del episodio 11009 son episode_steps:75\n",
            "Total Steps: 987905 Episode Num: 11009 Reward: 28.787266329694727 avg_loss_c: 7.785155493418376 avg_loss_a: -138.43832702636718\n",
            "Número de pasos del episodio 11010 son episode_steps:82\n",
            "Total Steps: 987987 Episode Num: 11010 Reward: -10.059433014069974 avg_loss_c: 8.260837194396228 avg_loss_a: -137.78869703339367\n",
            "Número de pasos del episodio 11011 son episode_steps:94\n",
            "Total Steps: 988081 Episode Num: 11011 Reward: 39.63619670457326 avg_loss_c: 8.898688194599558 avg_loss_a: -138.04006665818235\n",
            "Número de pasos del episodio 11012 son episode_steps:52\n",
            "Total Steps: 988133 Episode Num: 11012 Reward: 1.6238973356213617 avg_loss_c: 9.377163336827206 avg_loss_a: -137.85989555945764\n",
            "Número de pasos del episodio 11013 son episode_steps:289\n",
            "Total Steps: 988422 Episode Num: 11013 Reward: 408.5432759423825 avg_loss_c: 8.700628496783827 avg_loss_a: -137.47062170959262\n",
            "Número de pasos del episodio 11014 son episode_steps:252\n",
            "Total Steps: 988674 Episode Num: 11014 Reward: 372.91895013768493 avg_loss_c: 8.529657093305437 avg_loss_a: -137.62174224853516\n",
            "Número de pasos del episodio 11015 son episode_steps:89\n",
            "Total Steps: 988763 Episode Num: 11015 Reward: 58.887710825066364 avg_loss_c: 8.934505918052759 avg_loss_a: -137.2214113728384\n",
            "Número de pasos del episodio 11016 son episode_steps:461\n",
            "Total Steps: 989224 Episode Num: 11016 Reward: 779.0982670982102 avg_loss_c: 8.693701244486645 avg_loss_a: -137.11756572599265\n",
            "Número de pasos del episodio 11017 son episode_steps:598\n",
            "Total Steps: 989822 Episode Num: 11017 Reward: 1001.6906769798754 avg_loss_c: 8.355949497541856 avg_loss_a: -136.63781370845527\n",
            "Número de pasos del episodio 11018 son episode_steps:67\n",
            "Total Steps: 989889 Episode Num: 11018 Reward: 40.222786093244764 avg_loss_c: 9.107573295707134 avg_loss_a: -136.24773691661323\n",
            "Número de pasos del episodio 11019 son episode_steps:771\n",
            "Total Steps: 990660 Episode Num: 11019 Reward: 1272.278277612684 avg_loss_c: 8.754327816103528 avg_loss_a: -135.97667736642245\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 634.180317\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 11020 son episode_steps:246\n",
            "Total Steps: 990906 Episode Num: 11020 Reward: 319.7724670382274 avg_loss_c: 9.127725977238601 avg_loss_a: -135.80505172605436\n",
            "Número de pasos del episodio 11021 son episode_steps:650\n",
            "Total Steps: 991556 Episode Num: 11021 Reward: 1106.2256746782098 avg_loss_c: 9.01629937685453 avg_loss_a: -135.48605384239784\n",
            "Número de pasos del episodio 11022 son episode_steps:149\n",
            "Total Steps: 991705 Episode Num: 11022 Reward: 151.99638903209174 avg_loss_c: 9.094450649799116 avg_loss_a: -134.86324970834207\n",
            "Número de pasos del episodio 11023 son episode_steps:324\n",
            "Total Steps: 992029 Episode Num: 11023 Reward: 463.3725317349321 avg_loss_c: 9.136803340028834 avg_loss_a: -135.33252268661687\n",
            "Número de pasos del episodio 11024 son episode_steps:95\n",
            "Total Steps: 992124 Episode Num: 11024 Reward: 55.12887966914278 avg_loss_c: 9.357036706020958 avg_loss_a: -134.84563871684827\n",
            "Número de pasos del episodio 11025 son episode_steps:934\n",
            "Total Steps: 993058 Episode Num: 11025 Reward: 1621.659505217091 avg_loss_c: 8.696345438283311 avg_loss_a: -135.81549307518904\n",
            "Número de pasos del episodio 11026 son episode_steps:115\n",
            "Total Steps: 993173 Episode Num: 11026 Reward: 30.342970744671387 avg_loss_c: 9.082302433511485 avg_loss_a: -135.35490205184274\n",
            "Número de pasos del episodio 11027 son episode_steps:163\n",
            "Total Steps: 993336 Episode Num: 11027 Reward: 175.5385636870872 avg_loss_c: 9.807226549628322 avg_loss_a: -134.56457014025355\n",
            "Número de pasos del episodio 11028 son episode_steps:83\n",
            "Total Steps: 993419 Episode Num: 11028 Reward: 46.472453847732986 avg_loss_c: 9.966540083827743 avg_loss_a: -134.65228749470538\n",
            "Número de pasos del episodio 11029 son episode_steps:652\n",
            "Total Steps: 994071 Episode Num: 11029 Reward: 908.8630215770801 avg_loss_c: 10.255279801374565 avg_loss_a: -133.8154608837666\n",
            "Número de pasos del episodio 11030 son episode_steps:82\n",
            "Total Steps: 994153 Episode Num: 11030 Reward: 19.896846586819166 avg_loss_c: 11.357106005273215 avg_loss_a: -132.74263186571073\n",
            "Número de pasos del episodio 11031 son episode_steps:52\n",
            "Total Steps: 994205 Episode Num: 11031 Reward: 1.120970624268348 avg_loss_c: 11.114282928980314 avg_loss_a: -134.2859740624061\n",
            "Número de pasos del episodio 11032 son episode_steps:1000\n",
            "Total Steps: 995205 Episode Num: 11032 Reward: 1749.602409747254 avg_loss_c: 9.963914879798889 avg_loss_a: -133.81174032592773\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 690.170113\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v3_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_v3_1.pickle'.\n",
            "Número de pasos del episodio 11033 son episode_steps:181\n",
            "Total Steps: 995386 Episode Num: 11033 Reward: 253.05442285370123 avg_loss_c: 9.860412587118413 avg_loss_a: -133.40656090836498\n",
            "Número de pasos del episodio 11034 son episode_steps:79\n",
            "Total Steps: 995465 Episode Num: 11034 Reward: 39.6163712770401 avg_loss_c: 9.807491906081573 avg_loss_a: -133.1261289572414\n",
            "Número de pasos del episodio 11035 son episode_steps:129\n",
            "Total Steps: 995594 Episode Num: 11035 Reward: 130.72940645529334 avg_loss_c: 10.434980362884758 avg_loss_a: -132.6071882617566\n",
            "Número de pasos del episodio 11036 son episode_steps:81\n",
            "Total Steps: 995675 Episode Num: 11036 Reward: 4.037502973519769 avg_loss_c: 11.155818120932873 avg_loss_a: -133.86657432273583\n",
            "Número de pasos del episodio 11037 son episode_steps:34\n",
            "Total Steps: 995709 Episode Num: 11037 Reward: -7.028738320811687 avg_loss_c: 11.853411618401022 avg_loss_a: -132.8270793241613\n",
            "Número de pasos del episodio 11038 son episode_steps:81\n",
            "Total Steps: 995790 Episode Num: 11038 Reward: 40.735370013812805 avg_loss_c: 11.985210365719265 avg_loss_a: -131.37759135681907\n",
            "Número de pasos del episodio 11039 son episode_steps:1000\n",
            "Total Steps: 996790 Episode Num: 11039 Reward: 1758.0730325024783 avg_loss_c: 10.172168267250061 avg_loss_a: -132.39666995239259\n",
            "Número de pasos del episodio 11040 son episode_steps:104\n",
            "Total Steps: 996894 Episode Num: 11040 Reward: 54.887308712946215 avg_loss_c: 9.980555355548859 avg_loss_a: -131.96841327960675\n",
            "Número de pasos del episodio 11041 son episode_steps:23\n",
            "Total Steps: 996917 Episode Num: 11041 Reward: -51.85565064609532 avg_loss_c: 10.416666652845299 avg_loss_a: -131.72914853303328\n",
            "Número de pasos del episodio 11042 son episode_steps:1000\n",
            "Total Steps: 997917 Episode Num: 11042 Reward: 1883.9192460904005 avg_loss_c: 10.538252685070038 avg_loss_a: -132.2283270263672\n",
            "Número de pasos del episodio 11043 son episode_steps:41\n",
            "Total Steps: 997958 Episode Num: 11043 Reward: -16.442045216304063 avg_loss_c: 10.65754422908876 avg_loss_a: -131.72648695038586\n",
            "Número de pasos del episodio 11044 son episode_steps:1000\n",
            "Total Steps: 998958 Episode Num: 11044 Reward: 1832.9747884982974 avg_loss_c: 9.025011467933655 avg_loss_a: -133.08102439880372\n",
            "Número de pasos del episodio 11045 son episode_steps:1000\n",
            "Total Steps: 999958 Episode Num: 11045 Reward: 1823.9052117050956 avg_loss_c: 8.34782841682434 avg_loss_a: -133.47407341003418\n",
            "Datos de entrenamiento serializados correctamente en './results/datos_entrenamiento_v3_1.pkl'.\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 282.572229\n",
            "-------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def calc_memory_prob (total_steps, start_steps, initial_memory_prob):\n",
        "    \"\"\"\n",
        "    Define una función para calcular la probabilidad de tomar una acción de la memoria de repetición en función\n",
        "    del número total de pasos.\n",
        "\n",
        "    Args:\n",
        "        total_steps (int): El número total de pasos realizados en el entrenamiento.\n",
        "        start_steps (int): El número de pasos antes de comenzar a utilizar la red de políticas en lugar de la\n",
        "                           memoria de repetición.\n",
        "\n",
        "    Returns:\n",
        "        float: La probabilidad de tomar una acción de la memoria de repetición en el rango [0, 1].\n",
        "    \"\"\"\n",
        "    if total_steps < start_steps:\n",
        "        # Probabilidad decreciente de tomar una acción de la memoria de repetición a medida que total_steps aumenta\n",
        "        return initial_memory_prob * (1 - total_steps / start_steps)\n",
        "    else:\n",
        "        # Probabilidad creciente de tomar una acción de la memoria de repetición a medida que total_steps supera start_steps\n",
        "        return initial_memory_prob + (1 - initial_memory_prob) * (total_steps - start_steps) / (max_timesteps - start_steps)\n",
        "\n",
        "def select_action (replay, policy, env, total_steps, start_steps, memory_prob, obs):\n",
        "    \"\"\"\n",
        "      Sólo tenemos fase de explotación porque ya hemos rellenado la replaybuffer con transiciones positivas.\n",
        "\n",
        "    * Explotación: Se refiere a aprovechar al máximo el conocimiento adquirido hasta el momento,\n",
        "      es decir, elegir las acciones que el agente considera óptimas según su conocimiento actual.\n",
        "\n",
        "\n",
        "\n",
        "    Args:\n",
        "        policy      (TD3): plotica a entrenar\n",
        "        env         (gym): entorno sobre el cual se aplica el modelo\n",
        "        total_steps (int): El número total de pasos que ha realizado el agente.\n",
        "        start_steps (int): El número de pasos iniciales antes de que el agente comience a utilizar su política.\n",
        "        memory_prob (float): La probabilidad de tomar una acción de la experiencia del agente.\n",
        "        obs (array): La observación actual del entorno.\n",
        "\n",
        "    Returns:\n",
        "        array: La acción seleccionada para ser ejecutada en el entorno.\n",
        "    \"\"\"\n",
        "    #print (f'total_steps:{total_steps} - tart_steps:{start_steps}  ')\n",
        "    if (total_steps < start_steps):\n",
        "      (obs, next_obs, action, reward, done) = replay.sample_action (obs)\n",
        "      # print (reward[0])\n",
        "      action =  action [0]\n",
        "    else:\n",
        "      # Tomar una acción de la experiencia del agente (exploración)\n",
        "      action = policy.select_action(np.array(obs))\n",
        "      # Aplicar ruido a la acción para fomentar la exploración de forma más refinada\n",
        "      current_explore_noise = max_explore_noise * max(1 - total_steps / max_timesteps, 0)\n",
        "      if current_explore_noise != 0:\n",
        "          action = (action + np.random.normal(0, max_explore_noise, size=action_dim)).clip(env.action_space.low, env.action_space.high)\n",
        "\n",
        "    return action\n",
        "\n",
        "\n",
        "# Creamos el objeto DDPG TD3 con los hiperparámetros definidos anteriormente\n",
        "policy = TD3 (state_dim, action_dim, max_action,max_timesteps, initial_lr =  1e-4) # Notar que realmente el objeto entrenado definirá la política a seguir por el agente\n",
        "\n",
        "\n",
        "# replay_buff = SimplePrioritizedReplayBuffer()\n",
        "replay_buff = replay_buff_pos\n",
        "# Lista donde se guardarán las evaluaciones de la política durante el entrenamiento\n",
        "evaluations = [evaluate_train_policy (policy, env)]\n",
        "\n",
        "# Inicialización de variables utilizadas en el entrenamiento\n",
        "total_steps        = 0     # Número total de pasos de entrenamiento que llevamos realizados\n",
        "episode_steps      = 0     # Número de pasos realizados en el epidodeo\n",
        "steps_since_eval   = 0     # Número de pasos desde la última evaluación de la política\n",
        "episode_num        = 0     # Número de episodios completados durante el entrenamiento\n",
        "done               = True  # Indica si el episodio actual ha finalizado, nos lo devuelve el entorno de gym\n",
        "\n",
        "t0 = time.time()  # Tiempo inicial de referencia para medir el tiempo de entrenamiento\n",
        "n_steps_epochs = []\n",
        "all_rewards    = []\n",
        "avg_losses_c   = []\n",
        "avg_losses_a   = []\n",
        "all_losses_c   = []\n",
        "all_losses_a   = []\n",
        "target_qs_c1   = []\n",
        "target_qs_c2   = []\n",
        "target_qs      = []\n",
        "all_exploration_factor = []\n",
        "############################################################################\n",
        "# step 0: Bucle principal del entrenameinto de nuestro modelo.\n",
        "##  REalizamos tantos pasos como indica el hiperparámetro \"max_timesteps\"\n",
        "## A no ser que se estanque en un maximo local (mínimo) el humanoide aprenderá\n",
        "## mejor cuantos mñas pasos realiza. Eta implementacición V2 utiliza una estrategia e-grady\n",
        "## cuando finaliza el periodo de exploración. Es un entorno muy complicado con\n",
        "## muchos grados de libertad y acciones infinitas por lo que es facil estancarse.\n",
        "## Por ello, es muy importante el ruido aladido a las acciones.\n",
        "#############################################################################\n",
        "\n",
        "while total_steps < max_timesteps: # son pasos de tiempo\n",
        "    # step 1: Se comprueba si el episodio ha concluido. Si lo ha hehco, realiamso el entrenamiento del modelo\n",
        "    # con las acciones almacenadas en ReplayBuffer\n",
        "    if done:\n",
        "        # Comienza el entrenamiento del modelo si no es la primera iteración\n",
        "        if total_steps != 0: #Ya que no se tendrá nada en la memoria de repetición\n",
        "            print (f'Número de pasos del episodio {episode_num} son episode_steps:{episode_steps}')\n",
        "            n_steps_epochs.append (episode_steps)\n",
        "            # Realizamos el entrenamiento del modelo con las aciones almacenadas en ReplayBuffer\n",
        "            rewards, losses_c,losses_a, target_qs_critic1, target_qs_critic2, target_qs = policy.train (replay_buff, episode_steps, batch_size, gamma,\n",
        "                                                                               target_update_freq, policy_noise, noise_clip, policy_freq)\n",
        "            #############\n",
        "            # Nos guardamos las métricas del entrenamiento a estudio\n",
        "            #############\n",
        "            avg_reward = np.mean (rewards)\n",
        "            avg_loss_c = np.mean (losses_c)\n",
        "            avg_loss_a = np.mean (losses_a)\n",
        "            # avg_expl_fact = np.mean(expl_fact)\n",
        "\n",
        "            all_rewards.append (avg_reward)\n",
        "            avg_losses_c.append (avg_loss_c)\n",
        "            avg_losses_a.append (avg_loss_a)\n",
        "            all_losses_c.append (losses_c.copy())\n",
        "            all_losses_a.append (losses_a.copy())\n",
        "\n",
        "            target_qs_c1.append (target_qs_critic1.copy())\n",
        "            target_qs_c2.append (target_qs_critic2.copy())\n",
        "            target_qs.append (target_qs.copy())\n",
        "\n",
        "            # all_exploration_factor.append(avg_expl_fact)\n",
        "\n",
        "            print(\"Total Steps: {} Episode Num: {} Reward: {} avg_loss_c: {} avg_loss_a: {}\".format(total_steps, episode_num, episode_reward, avg_loss_c, avg_loss_a))\n",
        "\n",
        "\n",
        "        # step 2: Se evalúa el rendimiento del episodio actual y se guarda la política\n",
        "        # si se cumplen ciertas condiciones o criterios predefinidos.\n",
        "        if steps_since_eval >= eval_frequency:\n",
        "            steps_since_eval %= eval_frequency\n",
        "            evaluations.append (evaluate_train_policy (policy, env))\n",
        "            # Almacenamos el modelo en el estado de entrenamiento en el que se encuentra\n",
        "            policy.save(file_model_name, directory=\"./pytorch_models\")\n",
        "\n",
        "            np.save(\"./results/%s\" % (file_model_name), evaluations)\n",
        "\n",
        "            save_env(file_model_name, directory=\"./results\", env=env) # Guardamos el entorno en el estado actual\n",
        "            # Serializar el ReplayBufferMemory y guardarlo en un archivo\n",
        "            serialize_object(replay_buff, './results/replay_buffer_memory_v3_1.pickle')\n",
        "            # Serializamos las métricas del entrenamiento\n",
        "            lists_train_metrics = [all_rewards, avg_losses_c, avg_losses_a, all_losses_c, all_losses_a]\n",
        "            attribute_names = ['rewards', 'losses']\n",
        "            lists_to_serializable_object(lists_train_metrics, attribute_names, './results/serialized_list_train_metrics_v3_1.pickle')\n",
        "\n",
        "\n",
        "        # step3: Reiniciar el entorno cuando finaliza el episodio de entrenamiento\n",
        "        # Notar que según la logica del bucle, en el primer ciclo, este serña el primer paso.\n",
        "        obs = env.reset()\n",
        "\n",
        "        # Establecer \"done\" a Falso para parar el episodio\n",
        "        done = False\n",
        "\n",
        "        # Restablecer la recompensa del episodio y el contador de pasos del episodio\n",
        "        episode_reward = 0\n",
        "        episode_steps  = 0\n",
        "        episode_num   += 1\n",
        "\n",
        "    # step 4: Tomar acciones aleatorias antes de alcanzar el número de pasos iniciales\n",
        "    start_steps = max_start_steps * max(1 - total_steps / max_timesteps, 0)         # Decaimiento lineal\n",
        "    memory_prob = calc_memory_prob (total_steps, start_steps, initial_memory_prob)  # Probabilidad de tomar la acción en otro entorno\n",
        "    action      = select_action (replay_buff, policy, env, total_steps, start_steps, memory_prob, obs)\n",
        "\n",
        "    # step 5: El agente ejecuta una acción en el entorno, lo que resulta en una transición\n",
        "    # de estado. Además, el agente recibe una recompensa del entorno como resultado\n",
        "    # de su acción. Esta acción puede cambiar el estado del entorno y, por lo tanto,\n",
        "    # influir en las futuras observaciones y recompensas del agente.\n",
        "    #print (f' * nueva action:  -- tamaño:{len (action)}')\n",
        "    new_obs, reward, done, _ = env.step (action)\n",
        "    #print (f' * nuevo reward:{reward}')\n",
        "    # Comprueba si el episodio ha terminado\n",
        "    done_bool = 0 if episode_steps + 1 == max_episode_steps else float(done)\n",
        "\n",
        "    # Aumenta la recompensa total del episodio\n",
        "    episode_reward += reward\n",
        "\n",
        "    # step 6: Almacenar nueva transición en el búfer de repetición de experiencias\n",
        "    ## Hemos desestimado el buffer de repeticion con prioridad por el costo computacional\n",
        "    replay_buff.add((obs, new_obs, action, reward, done_bool))\n",
        "\n",
        "    #error_explora = 0.01 # añadimos un error muy bajo para asegurarnos que al menos se utiliza una vez\n",
        "    #replay_buff.add(error_explora, (obs, new_obs, action, reward, done_bool))\n",
        "\n",
        "    # Actualizar estado, tiempo de paso del episodio, tiempo total de pasos y pasos desde la última evaluación de la política\n",
        "    obs = new_obs\n",
        "    episode_steps    += 1\n",
        "    total_steps      += 1\n",
        "    steps_since_eval += 1\n",
        "\n",
        "    # Llamamos a la funcion para crear graficas de entrenamiento\n",
        "    create__metrics_imagen (evaluations, all_rewards,  avg_losses_c,avg_losses_a, all_losses_c,\n",
        "                                                    all_losses_a, target_qs_c1,\n",
        "                                                    target_qs_c2, target_qs,\n",
        "                                                    n_steps_epochs, \"v3_1\", episode_num, total_steps)\n",
        "\n",
        "tf = time.time()  # Tiempo final de referencia para medir el tiempo de entrenamiento\n",
        "serialize_training (t0, tf, total_steps,\"v3_1\")\n",
        "# Añadir la última actualización de la política a la lista de evaluaciones previa y guardar nuestro modelo\n",
        "evaluations.append (evaluate_train_policy (policy, env))\n",
        "if save_models:\n",
        "    policy.save(\"gready_%s\" % (file_model_name), directory=\"./pytorch_models\")\n",
        "np.save(\"./results/gready_%s\" % (file_model_name), evaluations)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba69f560-ac18-462b-858e-d2c915ee91e0",
      "metadata": {
        "id": "ba69f560-ac18-462b-858e-d2c915ee91e0"
      },
      "source": [
        "# **Step 4:** Evaluación para extraeer videos de la politicca entrenada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ab85407-30d3-483d-ac18-529f25a2e251",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ab85407-30d3-483d-ac18-529f25a2e251",
        "outputId": "0581b9dd-0887-4787-cce9-a34d1a5527c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------\n",
            "Fichero de los modelos entrenados: TD3_HumanoidBulletEnv-v0_0_v3_1\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "Configuración: TD3_HumanoidBulletEnv-v0_0_v3_1\n",
            "---------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pybullet_envs\n",
        "import gym\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from gym import wrappers\n",
        "from torch.autograd import Variable\n",
        "from collections import deque\n",
        "#import mujoco_py\n",
        "from TD3 import TD3, evaluate_policy, created_models_directory\n",
        "import pybullet as p\n",
        "\n",
        "# Iniciar el servidor de física de PyBullet\n",
        "p.connect(p.DIRECT)\n",
        "\n",
        "\n",
        "\n",
        "#######################################\n",
        "###\n",
        "######################################\n",
        "env_name           = \"HumanoidBulletEnv-v0\"  # Nombre del entorno que vamos a entrena. Con forme se ha implementado el modelo TD3 poría ser cuaalquier entorno (preferiblemente de estados de acciones continuos)\n",
        "seed               = 0        # Semilla utilizada para garantizar la reproducibilidad de los resultados\n",
        "start_steps        = 1e4      # Número de iteraciones/timesteps antes de que el modelo comience a utilizar la red de políticas en lugar de elegir acciones al azar\n",
        "eval_frequency     = 5e3      # Frecuencia de evaluación, es decir, cada cuántos pasos/timesteps se evalúa el desempeño del modelo\n",
        "max_timesteps      = 5e6      # Número máximo de iteraciones/timesteps permitidos\n",
        "save_models        = True     # Booleano que indica si se deben guardar los modelos pre-entrenados o no\n",
        "explore_noise      = 0.1      # Desviación estándar del ruido gaussiano utilizado para la exploración\n",
        "batch_size         = 100      # Tamaño del lote de muestras utilizadas en cada iteración de entrenamiento\n",
        "gamma              = 0.99     # Factor de descuento gamma que afecta la importancia de las recompensas futuras en la función de pérdida\n",
        "target_update_freq = 0.005    # Tasa de actualización para suavizar los parámetros de la red objetivo\n",
        "policy_noise       = 0.2      # Desviación estándar del ruido gaussiano agregado a las acciones para promover la exploración\n",
        "noise_clip         = 0.5      # Valor máximo permitido para el ruido gaussiano agregado a las acciones (política)\n",
        "policy_freq        = 2        # Número de iteraciones entre actualizaciones de la red de políticas (modelo actor)\n",
        "\n",
        "work_dir = os.path.join('exp', 'brs')\n",
        "monitor_dir = os.path.join(work_dir, 'monitor')\n",
        "\n",
        "\n",
        "file_model_name = created_models_directory (env_name, seed, save_models, \"v3_1\")\n",
        "print (\"---------------------------------------\")\n",
        "print (\"Configuración: %s\" % (file_model_name))\n",
        "print (\"---------------------------------------\")\n",
        "\n",
        "eval_episodes = 1000000\n",
        "save_env_vid  = True\n",
        "\n",
        "env = gym.make (env_name)\n",
        "max_episode_steps = env._max_episode_steps\n",
        "if save_env_vid:\n",
        "  env = wrappers.Monitor (env, monitor_dir, force = True)\n",
        "  # env = RecordEpisodeStatistics (env)\n",
        "  env.reset ()\n",
        "env.seed (seed)\n",
        "\n",
        "torch.manual_seed (seed)\n",
        "np.random.seed (seed)\n",
        "\n",
        "state_dim  = env.observation_space.shape [0]\n",
        "action_dim = env.action_space.shape [0]\n",
        "max_action = float (env.action_space.high [0])\n",
        "\n",
        "policy = TD3 (state_dim, action_dim, max_action,max_timesteps, initial_lr =  1e-4) # Notar que realmente el objeto entrenado definirá la política a seguir por el agente\n",
        "policy.load (file_model_name, './pytorch_models/')\n",
        "avg_reward, episode_rewards = evaluate_policy (policy, env, eval_episodes = eval_episodes)\n",
        "\n",
        "# Graficar las recompensas por episodio\n",
        "plt.plot(episode_rewards)\n",
        "plt.xlabel('Episodio')\n",
        "plt.ylabel('Recompensa')\n",
        "plt.title('Recompensa por Episodio durante la Evaluación')\n",
        "\n",
        "# Guardar la gráfica en un archivo de imagen (por ejemplo, en formato PNG)\n",
        "plt.savefig('./results/recompensas_por_episodio_evaluacion_v3_1.png')\n",
        "\n",
        "# Mostrar la gráfica en la ventana\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}