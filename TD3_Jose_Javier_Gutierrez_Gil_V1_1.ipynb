{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0e99c767-45d0-4607-9f0d-3b152077be77",
      "metadata": {
        "id": "0e99c767-45d0-4607-9f0d-3b152077be77"
      },
      "source": [
        "---\n",
        "# **Title**:TRABAJO AP. DDPG TD(3) (Gradiente de política determinista profunda (TD3) de doble retardo. Entornos de estados continuos: Humanoide). + Conexión Chatgpt (o similar)  + modelo dalle (similr)\n",
        "# **Author**: José Javier Gutiérrez Gil\n",
        "# **Date**: 2024-02-18\n",
        "# ***Univeridad de Valencia. Grado de Ciencia de Datos***\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_5GmtRidd7oJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5GmtRidd7oJ",
        "outputId": "279ee012-e48d-49e3-8ee7-fc5603833198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WS-ypYvad7yr",
      "metadata": {
        "id": "WS-ypYvad7yr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/td3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fX0CQ6kUd78S",
      "metadata": {
        "id": "fX0CQ6kUd78S"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/td3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b98ca0fc-f908-46ac-bea4-402b52106e97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b98ca0fc-f908-46ac-bea4-402b52106e97",
        "outputId": "7e970c78-2a7d-4864-f74d-3fb06664b134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pybullet\n",
            "  Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybullet\n",
            "Successfully installed pybullet-3.2.6\n",
            "Collecting gym==0.22.0\n",
            "  Downloading gym-0.22.0.tar.gz (631 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m631.1/631.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.22.0) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.22.0) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.22.0) (0.0.8)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.22.0-py3-none-any.whl size=708365 sha256=6783e444d70f182e9c7a94494fb16ed819afc8beb78c772ef52993762fc30e67\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/e8/e8/6dfbc92a1dcd76c1a5e2bb982750fd6b7e792239f46039e6b1\n",
            "Successfully built gym\n",
            "Installing collected packages: gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed gym-0.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pybullet\n",
        "!pip install gym==0.22.0 # Versión más actual que contiene la calse Monitor y así poder crear los videos del entrenamiento. Al monos en la 0.23 me da error"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1f2438c-79e2-440a-b42f-0d0b55f131f4",
      "metadata": {
        "id": "d1f2438c-79e2-440a-b42f-0d0b55f131f4"
      },
      "source": [
        "# **Step 0:** Cargamos las funciones necesarias de nuestra libreria y de python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96b52b6e-2a56-4d65-b098-7257b1d7bd81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96b52b6e-2a56-4d65-b098-7257b1d7bd81",
        "outputId": "d7e8a7c3-6502-4cfb-cf64-751d4c5e314b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#####\n",
        "import gym\n",
        "import pybullet_envs\n",
        "from gym import wrappers\n",
        "##\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#####\n",
        "from TD3 import TD3, ReplayBuffer\n",
        "from TD3 import created_models_directory, mkdir\n",
        "from TD3 import evaluate_train_policy, evaluate_policy\n",
        "from TD3 import noisy_action_wrapper, save_env, load_env, create__metrics_imagen\n",
        "from TD3 import serialize_object, lists_to_serializable_object, serialize_training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2abfbcd-1534-4894-9d4c-ab55bceb028a",
      "metadata": {
        "id": "d2abfbcd-1534-4894-9d4c-ab55bceb028a"
      },
      "source": [
        "# **Step 1:** Inicializamos los hiperparámetros del modelo e implementación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf9e1e60-97b7-4483-b65a-16e7318f2ac4",
      "metadata": {
        "id": "cf9e1e60-97b7-4483-b65a-16e7318f2ac4"
      },
      "outputs": [],
      "source": [
        "\n",
        "env_name            =  \"HumanoidBulletEnv-v0\"  # Nombre del entorno que vamos a entrena. Con forme se ha implementado el modelo TD3 poría ser cuaalquier entorno (preferiblemente de estados de acciones continuos)\n",
        "seed                = 0        # Semilla utilizada para garantizar la reproducibilidad de los resultados\n",
        "initial_memory_prob = 0.1      # Define la probabilidad inicial de tomar una acción de la memoria de repetición\n",
        "max_start_steps     = 1e4      # Define el número máximo de pasos iniciales\n",
        "#start_steps         = 1e4#1e4  --123-- lo modificamos por un decaimiento según los pasos de entrenamiento # Número de iteraciones/timesteps antes de que el modelo comience a utilizar la red de políticas en lugar de elegir acciones al azar\n",
        "eval_frequency      = 5e3      # Frecuencia de evaluación, es decir, cada cuántos pasos/timesteps se evalúa el desempeño del modelo\n",
        "max_timesteps       = 1e6      # Número máximo de iteraciones/timesteps permitidos\n",
        "save_models         = True     # Booleano que indica si se deben guardar los modelos pre-entrenados o no\n",
        "max_explore_noise   = 0.1      # Desviación estándar del ruido gaussiano utilizado para la exploración...--123-- CaMBIO  0.01 por 0.2 y creo un current_noise_explore dependiendo del steo en el que estamos\n",
        "batch_size          = 100      # Tamaño del lote de muestras utilizadas en cada iteración de entrenamiento\n",
        "gamma               = 0.99     # Factor de descuento gamma que afecta la importancia de las recompensas futuras en la función de pérdida\n",
        "target_update_freq  = 0.005    # Tasa de actualización para suavizar los parámetros de la red objetivo\n",
        "policy_noise        = 0.2      # Desviación estándar del ruido gaussiano agregado a las acciones para promover la exploración\n",
        "noise_clip          = 0.5      # Valor máximo permitido para el ruido gaussiano agregado a las acciones (política)\n",
        "policy_freq         = 2        # Número de iteraciones entre actualizaciones de la red de políticas (modelo actor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48fc757e-1f59-4156-8f8d-ef70f6f73ef5",
      "metadata": {
        "id": "48fc757e-1f59-4156-8f8d-ef70f6f73ef5"
      },
      "source": [
        "# **Step 2:** Creamos los directorios y cargamos el entorno de trabajo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d64e59c-0696-40b5-b558-8eb8e96c362a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d64e59c-0696-40b5-b558-8eb8e96c362a",
        "outputId": "d1113be2-9def-48d6-c079-ef5f0e5431bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------------\n",
            "Fichero de los modelos entrenados: TD3_HumanoidBulletEnv-v0_0_v1_1\n",
            "---------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#Creamos los directorios de almacenamento de resultados y métricas\n",
        "file_model_name = created_models_directory (env_name, seed, save_models, \"v1_1\")\n",
        "\n",
        "# Cargamos el entorno sobre el cual ejecutaremso el modelo DDPG TD3\n",
        "###############################################################################\n",
        "##  CARGAMOS EL ENTORNO HUMANOIDE V0 Y LE INTRODUCIMOS EL WRAPPER PARA AÑADIR RUIDO A\n",
        "##  LAS ACCIONES OBTENIDAS POR EXPLORACIÓN.\n",
        "################################################################################\n",
        "env = gym.make (env_name)\n",
        "max_episode_steps = env._max_episode_steps\n",
        "env = noisy_action_wrapper (env, noise_level = policy_noise) #le agregamos ruido a la accion obtenida del entorno para darle ms estabilidad al entrenamiento\n",
        "# Fijamos la semilla y obtenemos información del entorno (Estados, acciones)\n",
        "env.seed (seed)\n",
        "torch.manual_seed (seed)\n",
        "np.random.seed (seed)\n",
        "\n",
        "# Limitación de las acciones\n",
        "state_dim  = env.observation_space.shape [0]\n",
        "action_dim = env.action_space.shape [0]\n",
        "max_action = float(env.action_space.high [0])\n",
        "\n",
        "#Creamos los directorios de trabajo donde guardará los videos del entrenamiento\n",
        "work_dir          = mkdir ('exp', 'brs')\n",
        "monitor_dir       = mkdir (work_dir, 'monitor')\n",
        "\n",
        "save_env_vid      = False\n",
        "if save_env_vid:\n",
        "  env = wrappers.Monitor (env, monitor_dir, force = True)\n",
        "  env.reset()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb6ceeb0-ff57-4215-8401-aabefcf31305",
      "metadata": {
        "id": "cb6ceeb0-ff57-4215-8401-aabefcf31305"
      },
      "source": [
        "# **Step 3:** Proceso de entrenamiento\n",
        "\n",
        "En esta versión, cambiamos la estrategia de Exploración Vs Explotación. Aquí simplemente tenemos balanceado el tiempo de exploración y explotación. Como antes, tenemos un primer periodo de explotación para poder añadir la memoria de repetición antes de usar el modelo y que no tenga acciones. Una vez finalizado este proceso, tenemos un proceso de exploración. Aquí, exclusivamente utilizamos la estrategia de añadir ruido para ir refinando las acciones de exploración. Es un mecanismo de semi-exploración que mejora sustancialmente la acción si se acierta con la cantidad de ruido que se introduce. Es importante notar que puntos cercanos darán recompensas similares pero al mismo tiempo introducirán esa estocasticidad en los críticos para predecir y estimar objetivos diferentes (diferentes valore Q), así como para probar acciones distintas.\n",
        "\n",
        "Es importante destacar que también hemos intentado utilizar el replay buffer con prioridades, pero sin éxito. La razón por la que una memoria de prioridades no funciona en este problema y genera un costo de implementación y computacional mayor es debido a que el entorno y las posibles acciones son infinitas. Constantemente nos encontramos con acciones subóptimas. Por lo tanto, durante el proceso de entrenamiento, mejoramos gradualmente todas las acciones al añadirles ruido. Por este motivo, la estrategia de prioridades en el replay buffer resulta irrelevante. Además, se necesitan muchas transiciones que no serán almacenadas en el replay buffer por mucho tiempo, lo que resulta en un costo más elevado de inserción y manejo de prioridades en comparación con los beneficios que aporta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc8e914c-0170-4af2-8cce-4ad02252b0c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fc8e914c-0170-4af2-8cce-4ad02252b0c8",
        "outputId": "f8d70b11-9170-465f-df6d-19cda29c63d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "Total Steps: 602638 Episode Num: 10498 Reward: 124.44837293988876 avg_loss_c: 2.876565075502163 avg_loss_a: -46.02916224409894\n",
            "Número de pasos del episodeo 10499 son episode_steps:127\n",
            "Total Steps: 602765 Episode Num: 10499 Reward: 184.44651396640938 avg_loss_c: 2.9312123895630124 avg_loss_a: -45.93950448824665\n",
            "Número de pasos del episodeo 10500 son episode_steps:60\n",
            "Total Steps: 602825 Episode Num: 10500 Reward: 102.58965847634435 avg_loss_c: 2.5062393645445504 avg_loss_a: -45.67523396809896\n",
            "Número de pasos del episodeo 10501 son episode_steps:99\n",
            "Total Steps: 602924 Episode Num: 10501 Reward: 157.48426069099708 avg_loss_c: 2.5232319169574313 avg_loss_a: -46.17815349077937\n",
            "Número de pasos del episodeo 10502 son episode_steps:54\n",
            "Total Steps: 602978 Episode Num: 10502 Reward: 80.12646207427399 avg_loss_c: 2.8983270481780723 avg_loss_a: -45.45167696917498\n",
            "Número de pasos del episodeo 10503 son episode_steps:65\n",
            "Total Steps: 603043 Episode Num: 10503 Reward: 108.1844897704797 avg_loss_c: 2.521481592838581 avg_loss_a: -45.01684769850511\n",
            "Número de pasos del episodeo 10504 son episode_steps:89\n",
            "Total Steps: 603132 Episode Num: 10504 Reward: 144.94470856879627 avg_loss_c: 2.6520653949694686 avg_loss_a: -45.994918437486284\n",
            "Número de pasos del episodeo 10505 son episode_steps:67\n",
            "Total Steps: 603199 Episode Num: 10505 Reward: -5.164019503764529 avg_loss_c: 2.6822886111131354 avg_loss_a: -45.38589591410623\n",
            "Número de pasos del episodeo 10506 son episode_steps:53\n",
            "Total Steps: 603252 Episode Num: 10506 Reward: 62.31401916996297 avg_loss_c: 2.9713305234909058 avg_loss_a: -45.62066333698777\n",
            "Número de pasos del episodeo 10507 son episode_steps:110\n",
            "Total Steps: 603362 Episode Num: 10507 Reward: 169.70084405933187 avg_loss_c: 2.7965527415275573 avg_loss_a: -45.944898293235084\n",
            "Número de pasos del episodeo 10508 son episode_steps:81\n",
            "Total Steps: 603443 Episode Num: 10508 Reward: 16.22730826859524 avg_loss_c: 2.736632345635214 avg_loss_a: -45.44778668438947\n",
            "Número de pasos del episodeo 10509 son episode_steps:59\n",
            "Total Steps: 603502 Episode Num: 10509 Reward: 92.94902321261634 avg_loss_c: 2.733669844724364 avg_loss_a: -45.582361770888504\n",
            "Número de pasos del episodeo 10510 son episode_steps:67\n",
            "Total Steps: 603569 Episode Num: 10510 Reward: 110.41730082226432 avg_loss_c: 3.1103037649126195 avg_loss_a: -45.45147568432253\n",
            "Número de pasos del episodeo 10511 son episode_steps:71\n",
            "Total Steps: 603640 Episode Num: 10511 Reward: 86.58716620948856 avg_loss_c: 2.7482495727673384 avg_loss_a: -45.73032524216343\n",
            "Número de pasos del episodeo 10512 son episode_steps:73\n",
            "Total Steps: 603713 Episode Num: 10512 Reward: 127.28682852243922 avg_loss_c: 2.937056784760462 avg_loss_a: -45.504658633715486\n",
            "Número de pasos del episodeo 10513 son episode_steps:130\n",
            "Total Steps: 603843 Episode Num: 10513 Reward: 94.53450577845412 avg_loss_c: 3.046670943040114 avg_loss_a: -45.999583200307995\n",
            "Número de pasos del episodeo 10514 son episode_steps:56\n",
            "Total Steps: 603899 Episode Num: 10514 Reward: 87.89044438986052 avg_loss_c: 2.7313771652323857 avg_loss_a: -45.516891343253\n",
            "Número de pasos del episodeo 10515 son episode_steps:97\n",
            "Total Steps: 603996 Episode Num: 10515 Reward: 145.24349344363773 avg_loss_c: 2.7578662093152704 avg_loss_a: -46.01451834452521\n",
            "Número de pasos del episodeo 10516 son episode_steps:83\n",
            "Total Steps: 604079 Episode Num: 10516 Reward: 140.378124408847 avg_loss_c: 2.7257668699126647 avg_loss_a: -45.69268031292651\n",
            "Número de pasos del episodeo 10517 son episode_steps:125\n",
            "Total Steps: 604204 Episode Num: 10517 Reward: 180.76085681200368 avg_loss_c: 2.889739362716675 avg_loss_a: -45.926971252441405\n",
            "Número de pasos del episodeo 10518 son episode_steps:49\n",
            "Total Steps: 604253 Episode Num: 10518 Reward: 79.80843550463312 avg_loss_c: 2.8959972371860427 avg_loss_a: -46.07541960112903\n",
            "Número de pasos del episodeo 10519 son episode_steps:89\n",
            "Total Steps: 604342 Episode Num: 10519 Reward: 130.94572194380177 avg_loss_c: 2.672960298784663 avg_loss_a: -45.428978652096866\n",
            "Número de pasos del episodeo 10520 son episode_steps:75\n",
            "Total Steps: 604417 Episode Num: 10520 Reward: 121.66115837878021 avg_loss_c: 2.4909098863601686 avg_loss_a: -45.62055328369141\n",
            "Número de pasos del episodeo 10521 son episode_steps:69\n",
            "Total Steps: 604486 Episode Num: 10521 Reward: 109.09971595601439 avg_loss_c: 2.6514850889427075 avg_loss_a: -45.37017413153165\n",
            "Número de pasos del episodeo 10522 son episode_steps:82\n",
            "Total Steps: 604568 Episode Num: 10522 Reward: 134.22193313384787 avg_loss_c: 2.6763057272608686 avg_loss_a: -45.89026893057474\n",
            "Número de pasos del episodeo 10523 son episode_steps:63\n",
            "Total Steps: 604631 Episode Num: 10523 Reward: 101.04236962158691 avg_loss_c: 2.687334240428985 avg_loss_a: -44.95670173281715\n",
            "Número de pasos del episodeo 10524 son episode_steps:53\n",
            "Total Steps: 604684 Episode Num: 10524 Reward: 73.31439467654205 avg_loss_c: 2.3742654256100924 avg_loss_a: -45.96569471539191\n",
            "Número de pasos del episodeo 10525 son episode_steps:87\n",
            "Total Steps: 604771 Episode Num: 10525 Reward: 52.75031307637616 avg_loss_c: 2.9883560956209556 avg_loss_a: -45.5156258769419\n",
            "Número de pasos del episodeo 10526 son episode_steps:65\n",
            "Total Steps: 604836 Episode Num: 10526 Reward: 101.1059265856025 avg_loss_c: 2.7660840859779943 avg_loss_a: -45.00474072969877\n",
            "Número de pasos del episodeo 10527 son episode_steps:66\n",
            "Total Steps: 604902 Episode Num: 10527 Reward: 96.04247047325099 avg_loss_c: 2.9405355363181145 avg_loss_a: -46.11052010276101\n",
            "Número de pasos del episodeo 10528 son episode_steps:138\n",
            "Total Steps: 605040 Episode Num: 10528 Reward: 198.36434953442048 avg_loss_c: 2.7493904647619827 avg_loss_a: -45.78327084969783\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 116.603476\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 10529 son episode_steps:69\n",
            "Total Steps: 605109 Episode Num: 10529 Reward: 111.82686848473428 avg_loss_c: 2.6134185048117153 avg_loss_a: -45.8726938220038\n",
            "Número de pasos del episodeo 10530 son episode_steps:74\n",
            "Total Steps: 605183 Episode Num: 10530 Reward: 122.23173592250207 avg_loss_c: 2.92680793839532 avg_loss_a: -46.326936979551576\n",
            "Número de pasos del episodeo 10531 son episode_steps:129\n",
            "Total Steps: 605312 Episode Num: 10531 Reward: 93.35699997172615 avg_loss_c: 2.6547802797583646 avg_loss_a: -46.07204727054567\n",
            "Número de pasos del episodeo 10532 son episode_steps:90\n",
            "Total Steps: 605402 Episode Num: 10532 Reward: 142.66776408449354 avg_loss_c: 2.596511439482371 avg_loss_a: -45.96188006930881\n",
            "Número de pasos del episodeo 10533 son episode_steps:62\n",
            "Total Steps: 605464 Episode Num: 10533 Reward: 94.6303596347305 avg_loss_c: 2.6753331865033796 avg_loss_a: -45.281793409778224\n",
            "Número de pasos del episodeo 10534 son episode_steps:71\n",
            "Total Steps: 605535 Episode Num: 10534 Reward: 116.91970553834521 avg_loss_c: 2.7445979286247577 avg_loss_a: -45.95319785534496\n",
            "Número de pasos del episodeo 10535 son episode_steps:68\n",
            "Total Steps: 605603 Episode Num: 10535 Reward: 120.39524512361903 avg_loss_c: 2.841343855156618 avg_loss_a: -45.74937764336081\n",
            "Número de pasos del episodeo 10536 son episode_steps:52\n",
            "Total Steps: 605655 Episode Num: 10536 Reward: 84.02388996744808 avg_loss_c: 2.305442968240151 avg_loss_a: -45.43545561570387\n",
            "Número de pasos del episodeo 10537 son episode_steps:66\n",
            "Total Steps: 605721 Episode Num: 10537 Reward: 104.98594133775252 avg_loss_c: 2.6026449492483428 avg_loss_a: -46.20997168801048\n",
            "Número de pasos del episodeo 10538 son episode_steps:103\n",
            "Total Steps: 605824 Episode Num: 10538 Reward: 159.75184477037357 avg_loss_c: 2.7060204628601814 avg_loss_a: -46.5690276877394\n",
            "Número de pasos del episodeo 10539 son episode_steps:92\n",
            "Total Steps: 605916 Episode Num: 10539 Reward: 147.27602988343162 avg_loss_c: 2.5412231618943424 avg_loss_a: -45.76301425436269\n",
            "Número de pasos del episodeo 10540 son episode_steps:77\n",
            "Total Steps: 605993 Episode Num: 10540 Reward: 120.24475729186794 avg_loss_c: 2.7272547824042186 avg_loss_a: -45.80192045731978\n",
            "Número de pasos del episodeo 10541 son episode_steps:104\n",
            "Total Steps: 606097 Episode Num: 10541 Reward: 161.93372171147925 avg_loss_c: 2.5322790340735364 avg_loss_a: -45.4915373141949\n",
            "Número de pasos del episodeo 10542 son episode_steps:60\n",
            "Total Steps: 606157 Episode Num: 10542 Reward: 94.86288501122318 avg_loss_c: 2.419890646139781 avg_loss_a: -46.03492368062337\n",
            "Número de pasos del episodeo 10543 son episode_steps:54\n",
            "Total Steps: 606211 Episode Num: 10543 Reward: 62.44708253519044 avg_loss_c: 2.7570376661088734 avg_loss_a: -45.95075621428313\n",
            "Número de pasos del episodeo 10544 son episode_steps:72\n",
            "Total Steps: 606283 Episode Num: 10544 Reward: 114.4273279445508 avg_loss_c: 3.043235649665197 avg_loss_a: -46.47324742211236\n",
            "Número de pasos del episodeo 10545 son episode_steps:72\n",
            "Total Steps: 606355 Episode Num: 10545 Reward: 111.75457482567124 avg_loss_c: 2.7047479218906827 avg_loss_a: -45.848154597812226\n",
            "Número de pasos del episodeo 10546 son episode_steps:116\n",
            "Total Steps: 606471 Episode Num: 10546 Reward: 64.7966903112711 avg_loss_c: 3.089654791971733 avg_loss_a: -46.188432430398876\n",
            "Número de pasos del episodeo 10547 son episode_steps:115\n",
            "Total Steps: 606586 Episode Num: 10547 Reward: 175.65101044390764 avg_loss_c: 2.7407935349837595 avg_loss_a: -46.19610854439114\n",
            "Número de pasos del episodeo 10548 son episode_steps:39\n",
            "Total Steps: 606625 Episode Num: 10548 Reward: 34.455773546901675 avg_loss_c: 2.7079031008940477 avg_loss_a: -45.69800254626152\n",
            "Número de pasos del episodeo 10549 son episode_steps:109\n",
            "Total Steps: 606734 Episode Num: 10549 Reward: 173.21488485396728 avg_loss_c: 2.647980683440462 avg_loss_a: -46.1829745791374\n",
            "Número de pasos del episodeo 10550 son episode_steps:68\n",
            "Total Steps: 606802 Episode Num: 10550 Reward: 113.83493638941172 avg_loss_c: 2.5995958464987137 avg_loss_a: -46.139527937945196\n",
            "Número de pasos del episodeo 10551 son episode_steps:76\n",
            "Total Steps: 606878 Episode Num: 10551 Reward: 126.24386997229145 avg_loss_c: 2.5955229213363245 avg_loss_a: -45.805552432411595\n",
            "Número de pasos del episodeo 10552 son episode_steps:89\n",
            "Total Steps: 606967 Episode Num: 10552 Reward: 143.8526695029412 avg_loss_c: 2.852124885226903 avg_loss_a: -46.0028349201331\n",
            "Número de pasos del episodeo 10553 son episode_steps:61\n",
            "Total Steps: 607028 Episode Num: 10553 Reward: 91.9469465429417 avg_loss_c: 2.823242965291758 avg_loss_a: -45.35672397300845\n",
            "Número de pasos del episodeo 10554 son episode_steps:85\n",
            "Total Steps: 607113 Episode Num: 10554 Reward: 136.13149992492092 avg_loss_c: 2.683260039722218 avg_loss_a: -46.603003198960245\n",
            "Número de pasos del episodeo 10555 son episode_steps:88\n",
            "Total Steps: 607201 Episode Num: 10555 Reward: 111.08553557616874 avg_loss_c: 2.4905096820809622 avg_loss_a: -46.06904125213623\n",
            "Número de pasos del episodeo 10556 son episode_steps:81\n",
            "Total Steps: 607282 Episode Num: 10556 Reward: 132.61349336661192 avg_loss_c: 2.3124124312106473 avg_loss_a: -46.204436361053844\n",
            "Número de pasos del episodeo 10557 son episode_steps:106\n",
            "Total Steps: 607388 Episode Num: 10557 Reward: 47.75212920403263 avg_loss_c: 2.6752817776967897 avg_loss_a: -46.40979658882573\n",
            "Número de pasos del episodeo 10558 son episode_steps:59\n",
            "Total Steps: 607447 Episode Num: 10558 Reward: 93.81396332182068 avg_loss_c: 2.620727609779875 avg_loss_a: -46.57515677759203\n",
            "Número de pasos del episodeo 10559 son episode_steps:83\n",
            "Total Steps: 607530 Episode Num: 10559 Reward: 120.83386785776027 avg_loss_c: 2.5845328655587623 avg_loss_a: -46.026576720088364\n",
            "Número de pasos del episodeo 10560 son episode_steps:80\n",
            "Total Steps: 607610 Episode Num: 10560 Reward: 127.27672345171706 avg_loss_c: 2.8440287902951242 avg_loss_a: -46.05529079437256\n",
            "Número de pasos del episodeo 10561 son episode_steps:64\n",
            "Total Steps: 607674 Episode Num: 10561 Reward: 95.95485954876683 avg_loss_c: 2.6189842745661736 avg_loss_a: -45.948264360427856\n",
            "Número de pasos del episodeo 10562 son episode_steps:129\n",
            "Total Steps: 607803 Episode Num: 10562 Reward: 116.05463618447178 avg_loss_c: 2.649837944858758 avg_loss_a: -46.642535926759706\n",
            "Número de pasos del episodeo 10563 son episode_steps:50\n",
            "Total Steps: 607853 Episode Num: 10563 Reward: 54.84284594142284 avg_loss_c: 2.6841218447685242 avg_loss_a: -45.380846099853514\n",
            "Número de pasos del episodeo 10564 son episode_steps:62\n",
            "Total Steps: 607915 Episode Num: 10564 Reward: 102.54802270916923 avg_loss_c: 3.00535596570661 avg_loss_a: -46.39824270432995\n",
            "Número de pasos del episodeo 10565 son episode_steps:68\n",
            "Total Steps: 607983 Episode Num: 10565 Reward: 96.60545020691124 avg_loss_c: 2.8787006823455585 avg_loss_a: -46.24729190153234\n",
            "Número de pasos del episodeo 10566 son episode_steps:94\n",
            "Total Steps: 608077 Episode Num: 10566 Reward: 66.20477900373616 avg_loss_c: 2.822234218424939 avg_loss_a: -46.0211044473851\n",
            "Número de pasos del episodeo 10567 son episode_steps:64\n",
            "Total Steps: 608141 Episode Num: 10567 Reward: 91.48715766514134 avg_loss_c: 2.7219274565577507 avg_loss_a: -45.85231804847717\n",
            "Número de pasos del episodeo 10568 son episode_steps:96\n",
            "Total Steps: 608237 Episode Num: 10568 Reward: 127.52252337397974 avg_loss_c: 2.8634582683444023 avg_loss_a: -46.07639368375143\n",
            "Número de pasos del episodeo 10569 son episode_steps:134\n",
            "Total Steps: 608371 Episode Num: 10569 Reward: 120.71515910219676 avg_loss_c: 2.8251918518721166 avg_loss_a: -45.99866292014051\n",
            "Número de pasos del episodeo 10570 son episode_steps:92\n",
            "Total Steps: 608463 Episode Num: 10570 Reward: 117.40618127920808 avg_loss_c: 2.659929068192192 avg_loss_a: -46.783470651377804\n",
            "Número de pasos del episodeo 10571 son episode_steps:109\n",
            "Total Steps: 608572 Episode Num: 10571 Reward: 43.896839172240135 avg_loss_c: 3.024564164494156 avg_loss_a: -46.2452392578125\n",
            "Número de pasos del episodeo 10572 son episode_steps:91\n",
            "Total Steps: 608663 Episode Num: 10572 Reward: 130.36923720230473 avg_loss_c: 3.095849123629895 avg_loss_a: -45.388179653293484\n",
            "Número de pasos del episodeo 10573 son episode_steps:68\n",
            "Total Steps: 608731 Episode Num: 10573 Reward: 104.6483486820189 avg_loss_c: 2.773541098131853 avg_loss_a: -45.58187350104837\n",
            "Número de pasos del episodeo 10574 son episode_steps:121\n",
            "Total Steps: 608852 Episode Num: 10574 Reward: 52.25526100370007 avg_loss_c: 2.8962499868771263 avg_loss_a: -46.517574215723464\n",
            "Número de pasos del episodeo 10575 son episode_steps:56\n",
            "Total Steps: 608908 Episode Num: 10575 Reward: 49.20410209613788 avg_loss_c: 2.964519200580461 avg_loss_a: -46.65691811697824\n",
            "Número de pasos del episodeo 10576 son episode_steps:66\n",
            "Total Steps: 608974 Episode Num: 10576 Reward: 109.1432516495082 avg_loss_c: 2.856414608883135 avg_loss_a: -46.17366756092418\n",
            "Número de pasos del episodeo 10577 son episode_steps:76\n",
            "Total Steps: 609050 Episode Num: 10577 Reward: 129.7240090123475 avg_loss_c: 2.6418569699714056 avg_loss_a: -46.03628640425833\n",
            "Número de pasos del episodeo 10578 son episode_steps:75\n",
            "Total Steps: 609125 Episode Num: 10578 Reward: 110.11701944981678 avg_loss_c: 2.903166371981303 avg_loss_a: -46.322535603841146\n",
            "Número de pasos del episodeo 10579 son episode_steps:167\n",
            "Total Steps: 609292 Episode Num: 10579 Reward: 237.10860693284096 avg_loss_c: 2.9024955262680967 avg_loss_a: -45.97712837721773\n",
            "Número de pasos del episodeo 10580 son episode_steps:84\n",
            "Total Steps: 609376 Episode Num: 10580 Reward: 126.02332832929501 avg_loss_c: 3.1097764330250874 avg_loss_a: -46.81217911129906\n",
            "Número de pasos del episodeo 10581 son episode_steps:89\n",
            "Total Steps: 609465 Episode Num: 10581 Reward: 142.29005984715852 avg_loss_c: 2.8673633403992387 avg_loss_a: -46.57007564587539\n",
            "Número de pasos del episodeo 10582 son episode_steps:70\n",
            "Total Steps: 609535 Episode Num: 10582 Reward: 121.19966132076625 avg_loss_c: 2.874113413265773 avg_loss_a: -45.73345042637416\n",
            "Número de pasos del episodeo 10583 son episode_steps:40\n",
            "Total Steps: 609575 Episode Num: 10583 Reward: 37.59255369052594 avg_loss_c: 2.6395480751991274 avg_loss_a: -46.872617149353026\n",
            "Número de pasos del episodeo 10584 son episode_steps:57\n",
            "Total Steps: 609632 Episode Num: 10584 Reward: 85.87195936923268 avg_loss_c: 2.5141602963732 avg_loss_a: -46.34931537561249\n",
            "Número de pasos del episodeo 10585 son episode_steps:60\n",
            "Total Steps: 609692 Episode Num: 10585 Reward: 99.59201187201583 avg_loss_c: 2.5885695656140646 avg_loss_a: -45.972050221761066\n",
            "Número de pasos del episodeo 10586 son episode_steps:67\n",
            "Total Steps: 609759 Episode Num: 10586 Reward: 107.77579991669957 avg_loss_c: 2.8103966517234915 avg_loss_a: -45.94328649720149\n",
            "Número de pasos del episodeo 10587 son episode_steps:71\n",
            "Total Steps: 609830 Episode Num: 10587 Reward: 115.64953547402534 avg_loss_c: 2.7463686533377203 avg_loss_a: -46.96241126261966\n",
            "Número de pasos del episodeo 10588 son episode_steps:68\n",
            "Total Steps: 609898 Episode Num: 10588 Reward: 111.81992944701378 avg_loss_c: 2.7349710797562317 avg_loss_a: -45.8914218229406\n",
            "Número de pasos del episodeo 10589 son episode_steps:69\n",
            "Total Steps: 609967 Episode Num: 10589 Reward: 109.45289838422735 avg_loss_c: 2.575426711552385 avg_loss_a: -46.173912545909054\n",
            "Número de pasos del episodeo 10590 son episode_steps:56\n",
            "Total Steps: 610023 Episode Num: 10590 Reward: 92.48938104124845 avg_loss_c: 2.7929990930216655 avg_loss_a: -46.342063903808594\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 121.624232\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 10591 son episode_steps:96\n",
            "Total Steps: 610119 Episode Num: 10591 Reward: 158.02154321131323 avg_loss_c: 2.6275724644462266 avg_loss_a: -45.98799101511637\n",
            "Número de pasos del episodeo 10592 son episode_steps:119\n",
            "Total Steps: 610238 Episode Num: 10592 Reward: 168.10207783034772 avg_loss_c: 2.8934330659754135 avg_loss_a: -46.18497858127626\n",
            "Número de pasos del episodeo 10593 son episode_steps:61\n",
            "Total Steps: 610299 Episode Num: 10593 Reward: 97.10644237156079 avg_loss_c: 2.709520965326028 avg_loss_a: -46.04238416327805\n",
            "Número de pasos del episodeo 10594 son episode_steps:51\n",
            "Total Steps: 610350 Episode Num: 10594 Reward: 43.74748329437175 avg_loss_c: 2.677022800726049 avg_loss_a: -45.67130316940008\n",
            "Número de pasos del episodeo 10595 son episode_steps:98\n",
            "Total Steps: 610448 Episode Num: 10595 Reward: 144.1014466130346 avg_loss_c: 2.5918409131011186 avg_loss_a: -45.90503887254365\n",
            "Número de pasos del episodeo 10596 son episode_steps:99\n",
            "Total Steps: 610547 Episode Num: 10596 Reward: 148.8230587524688 avg_loss_c: 2.8145371181796297 avg_loss_a: -45.95165044611151\n",
            "Número de pasos del episodeo 10597 son episode_steps:72\n",
            "Total Steps: 610619 Episode Num: 10597 Reward: 114.82912892704735 avg_loss_c: 2.5664347029394574 avg_loss_a: -46.22902170817057\n",
            "Número de pasos del episodeo 10598 son episode_steps:70\n",
            "Total Steps: 610689 Episode Num: 10598 Reward: 65.64984321163914 avg_loss_c: 2.655264725003924 avg_loss_a: -46.046087755475725\n",
            "Número de pasos del episodeo 10599 son episode_steps:95\n",
            "Total Steps: 610784 Episode Num: 10599 Reward: 139.5559854875052 avg_loss_c: 2.596317945028606 avg_loss_a: -45.73053761532432\n",
            "Número de pasos del episodeo 10600 son episode_steps:111\n",
            "Total Steps: 610895 Episode Num: 10600 Reward: 161.2325034772655 avg_loss_c: 2.6920386703164727 avg_loss_a: -45.82916668728665\n",
            "Número de pasos del episodeo 10601 son episode_steps:78\n",
            "Total Steps: 610973 Episode Num: 10601 Reward: 129.96202693553076 avg_loss_c: 2.6294907545432067 avg_loss_a: -46.69930032583383\n",
            "Número de pasos del episodeo 10602 son episode_steps:58\n",
            "Total Steps: 611031 Episode Num: 10602 Reward: 87.25836125450809 avg_loss_c: 2.8115157669988173 avg_loss_a: -46.03840360970333\n",
            "Número de pasos del episodeo 10603 son episode_steps:65\n",
            "Total Steps: 611096 Episode Num: 10603 Reward: 106.06623388308336 avg_loss_c: 2.358660164246192 avg_loss_a: -46.56416267981896\n",
            "Número de pasos del episodeo 10604 son episode_steps:59\n",
            "Total Steps: 611155 Episode Num: 10604 Reward: 93.43432642951844 avg_loss_c: 2.5374208991810425 avg_loss_a: -46.36059803073689\n",
            "Número de pasos del episodeo 10605 son episode_steps:79\n",
            "Total Steps: 611234 Episode Num: 10605 Reward: 103.47677520444186 avg_loss_c: 2.6907564612883554 avg_loss_a: -46.338307585897326\n",
            "Número de pasos del episodeo 10606 son episode_steps:94\n",
            "Total Steps: 611328 Episode Num: 10606 Reward: 146.14007606670245 avg_loss_c: 2.4076201395785555 avg_loss_a: -46.04627154735809\n",
            "Número de pasos del episodeo 10607 son episode_steps:52\n",
            "Total Steps: 611380 Episode Num: 10607 Reward: 87.74057541108196 avg_loss_c: 2.44390360896404 avg_loss_a: -46.31189683767465\n",
            "Número de pasos del episodeo 10608 son episode_steps:188\n",
            "Total Steps: 611568 Episode Num: 10608 Reward: 285.5507651437323 avg_loss_c: 2.541257548839488 avg_loss_a: -46.53421844320094\n",
            "Número de pasos del episodeo 10609 son episode_steps:85\n",
            "Total Steps: 611653 Episode Num: 10609 Reward: 135.41729839615263 avg_loss_c: 2.3787781575146845 avg_loss_a: -46.20355265000287\n",
            "Número de pasos del episodeo 10610 son episode_steps:86\n",
            "Total Steps: 611739 Episode Num: 10610 Reward: 134.48191936769422 avg_loss_c: 2.5141435362571896 avg_loss_a: -46.59122147671012\n",
            "Número de pasos del episodeo 10611 son episode_steps:65\n",
            "Total Steps: 611804 Episode Num: 10611 Reward: 10.04548595935355 avg_loss_c: 2.6212472989008977 avg_loss_a: -46.848826892559345\n",
            "Número de pasos del episodeo 10612 son episode_steps:56\n",
            "Total Steps: 611860 Episode Num: 10612 Reward: 92.7455142086675 avg_loss_c: 2.8473844762359346 avg_loss_a: -46.25961562565395\n",
            "Número de pasos del episodeo 10613 son episode_steps:82\n",
            "Total Steps: 611942 Episode Num: 10613 Reward: 124.79364980859943 avg_loss_c: 2.587189529000259 avg_loss_a: -45.719387798774534\n",
            "Número de pasos del episodeo 10614 son episode_steps:69\n",
            "Total Steps: 612011 Episode Num: 10614 Reward: 67.34428889062957 avg_loss_c: 2.491654886715654 avg_loss_a: -46.61181303383648\n",
            "Número de pasos del episodeo 10615 son episode_steps:86\n",
            "Total Steps: 612097 Episode Num: 10615 Reward: 112.81928746535093 avg_loss_c: 2.6958837911140088 avg_loss_a: -46.23888335117074\n",
            "Número de pasos del episodeo 10616 son episode_steps:86\n",
            "Total Steps: 612183 Episode Num: 10616 Reward: 130.11293608394462 avg_loss_c: 2.533614448336668 avg_loss_a: -46.71997913094454\n",
            "Número de pasos del episodeo 10617 son episode_steps:71\n",
            "Total Steps: 612254 Episode Num: 10617 Reward: 1.0207356461848844 avg_loss_c: 2.852536829424576 avg_loss_a: -46.61362618459782\n",
            "Número de pasos del episodeo 10618 son episode_steps:67\n",
            "Total Steps: 612321 Episode Num: 10618 Reward: 112.74820496692055 avg_loss_c: 2.6220284878317988 avg_loss_a: -46.493064709563754\n",
            "Número de pasos del episodeo 10619 son episode_steps:65\n",
            "Total Steps: 612386 Episode Num: 10619 Reward: 100.22157637187357 avg_loss_c: 2.6570687422385584 avg_loss_a: -46.739113382192755\n",
            "Número de pasos del episodeo 10620 son episode_steps:84\n",
            "Total Steps: 612470 Episode Num: 10620 Reward: 121.34944469545849 avg_loss_c: 2.4007543126742044 avg_loss_a: -46.23554438636417\n",
            "Número de pasos del episodeo 10621 son episode_steps:95\n",
            "Total Steps: 612565 Episode Num: 10621 Reward: 27.798572918706604 avg_loss_c: 2.837575037855851 avg_loss_a: -46.48281314247533\n",
            "Número de pasos del episodeo 10622 son episode_steps:42\n",
            "Total Steps: 612607 Episode Num: 10622 Reward: 37.68508086443372 avg_loss_c: 2.9263050016902743 avg_loss_a: -46.21352695283436\n",
            "Número de pasos del episodeo 10623 son episode_steps:61\n",
            "Total Steps: 612668 Episode Num: 10623 Reward: 100.49185280018223 avg_loss_c: 2.6961011339406498 avg_loss_a: -46.865610279020714\n",
            "Número de pasos del episodeo 10624 son episode_steps:76\n",
            "Total Steps: 612744 Episode Num: 10624 Reward: 117.34778789858028 avg_loss_c: 2.913858876416558 avg_loss_a: -45.87580771195261\n",
            "Número de pasos del episodeo 10625 son episode_steps:66\n",
            "Total Steps: 612810 Episode Num: 10625 Reward: 94.56204247255106 avg_loss_c: 2.8766029729987634 avg_loss_a: -46.97173737034653\n",
            "Número de pasos del episodeo 10626 son episode_steps:56\n",
            "Total Steps: 612866 Episode Num: 10626 Reward: 89.54452008873932 avg_loss_c: 2.6457696918930327 avg_loss_a: -46.56059987204416\n",
            "Número de pasos del episodeo 10627 son episode_steps:89\n",
            "Total Steps: 612955 Episode Num: 10627 Reward: 9.620341348063945 avg_loss_c: 2.7598278951109125 avg_loss_a: -46.02810390343827\n",
            "Número de pasos del episodeo 10628 son episode_steps:67\n",
            "Total Steps: 613022 Episode Num: 10628 Reward: 103.39862650609246 avg_loss_c: 2.7405570638713552 avg_loss_a: -46.24764456677793\n",
            "Número de pasos del episodeo 10629 son episode_steps:89\n",
            "Total Steps: 613111 Episode Num: 10629 Reward: 121.42581009081037 avg_loss_c: 2.590668042054337 avg_loss_a: -46.07070442799772\n",
            "Número de pasos del episodeo 10630 son episode_steps:69\n",
            "Total Steps: 613180 Episode Num: 10630 Reward: 101.11189006682577 avg_loss_c: 2.6165194234986235 avg_loss_a: -46.308597619982734\n",
            "Número de pasos del episodeo 10631 son episode_steps:59\n",
            "Total Steps: 613239 Episode Num: 10631 Reward: 90.61098397263461 avg_loss_c: 3.260440525362047 avg_loss_a: -46.19189905716201\n",
            "Número de pasos del episodeo 10632 son episode_steps:72\n",
            "Total Steps: 613311 Episode Num: 10632 Reward: 102.2325324708556 avg_loss_c: 2.91836070186562 avg_loss_a: -46.502709282769096\n",
            "Número de pasos del episodeo 10633 son episode_steps:75\n",
            "Total Steps: 613386 Episode Num: 10633 Reward: 112.83752528371646 avg_loss_c: 2.739731025695801 avg_loss_a: -45.996983693440754\n",
            "Número de pasos del episodeo 10634 son episode_steps:69\n",
            "Total Steps: 613455 Episode Num: 10634 Reward: 99.42467751342821 avg_loss_c: 2.6233459054559902 avg_loss_a: -46.12216103595236\n",
            "Número de pasos del episodeo 10635 son episode_steps:88\n",
            "Total Steps: 613543 Episode Num: 10635 Reward: 114.04619335183587 avg_loss_c: 3.035058942708102 avg_loss_a: -46.317092115228824\n",
            "Número de pasos del episodeo 10636 son episode_steps:75\n",
            "Total Steps: 613618 Episode Num: 10636 Reward: 29.225920699007972 avg_loss_c: 3.010128173828125 avg_loss_a: -46.2956755065918\n",
            "Número de pasos del episodeo 10637 son episode_steps:120\n",
            "Total Steps: 613738 Episode Num: 10637 Reward: 190.8415646649224 avg_loss_c: 2.738298350572586 avg_loss_a: -46.498115158081056\n",
            "Número de pasos del episodeo 10638 son episode_steps:65\n",
            "Total Steps: 613803 Episode Num: 10638 Reward: 108.09548865938702 avg_loss_c: 2.850024656149057 avg_loss_a: -46.30308045607347\n",
            "Número de pasos del episodeo 10639 son episode_steps:161\n",
            "Total Steps: 613964 Episode Num: 10639 Reward: 76.13181025954836 avg_loss_c: 2.8951065829081566 avg_loss_a: -46.14039761087169\n",
            "Número de pasos del episodeo 10640 son episode_steps:99\n",
            "Total Steps: 614063 Episode Num: 10640 Reward: 159.03936725970783 avg_loss_c: 2.999553257768804 avg_loss_a: -45.95007825138593\n",
            "Número de pasos del episodeo 10641 son episode_steps:81\n",
            "Total Steps: 614144 Episode Num: 10641 Reward: 128.16353308147126 avg_loss_c: 2.6243202995370933 avg_loss_a: -46.20668547830464\n",
            "Número de pasos del episodeo 10642 son episode_steps:127\n",
            "Total Steps: 614271 Episode Num: 10642 Reward: 205.98015299687026 avg_loss_c: 2.6805940012293537 avg_loss_a: -46.43374474593035\n",
            "Número de pasos del episodeo 10643 son episode_steps:68\n",
            "Total Steps: 614339 Episode Num: 10643 Reward: 112.13920358011423 avg_loss_c: 2.4856006801128387 avg_loss_a: -46.393334669225354\n",
            "Número de pasos del episodeo 10644 son episode_steps:64\n",
            "Total Steps: 614403 Episode Num: 10644 Reward: 81.3178333537472 avg_loss_c: 2.4612686801701784 avg_loss_a: -46.480326533317566\n",
            "Número de pasos del episodeo 10645 son episode_steps:56\n",
            "Total Steps: 614459 Episode Num: 10645 Reward: 80.424772134993 avg_loss_c: 2.9131940454244614 avg_loss_a: -46.390113830566406\n",
            "Número de pasos del episodeo 10646 son episode_steps:44\n",
            "Total Steps: 614503 Episode Num: 10646 Reward: 35.76183375101709 avg_loss_c: 3.0653838948770002 avg_loss_a: -46.08586675470526\n",
            "Número de pasos del episodeo 10647 son episode_steps:84\n",
            "Total Steps: 614587 Episode Num: 10647 Reward: 130.44443381199457 avg_loss_c: 2.558691224881581 avg_loss_a: -46.64807619367327\n",
            "Número de pasos del episodeo 10648 son episode_steps:64\n",
            "Total Steps: 614651 Episode Num: 10648 Reward: 96.1413527075877 avg_loss_c: 2.8008830305188894 avg_loss_a: -45.94794046878815\n",
            "Número de pasos del episodeo 10649 son episode_steps:66\n",
            "Total Steps: 614717 Episode Num: 10649 Reward: 108.19247082403167 avg_loss_c: 2.475230159181537 avg_loss_a: -46.1997377800219\n",
            "Número de pasos del episodeo 10650 son episode_steps:50\n",
            "Total Steps: 614767 Episode Num: 10650 Reward: 71.64201669547295 avg_loss_c: 2.6344925808906554 avg_loss_a: -46.313356475830076\n",
            "Número de pasos del episodeo 10651 son episode_steps:75\n",
            "Total Steps: 614842 Episode Num: 10651 Reward: 116.07707358746823 avg_loss_c: 2.693624486923218 avg_loss_a: -46.49606389363607\n",
            "Número de pasos del episodeo 10652 son episode_steps:66\n",
            "Total Steps: 614908 Episode Num: 10652 Reward: 84.29365883527343 avg_loss_c: 2.619140534689932 avg_loss_a: -46.55816049286813\n",
            "Número de pasos del episodeo 10653 son episode_steps:72\n",
            "Total Steps: 614980 Episode Num: 10653 Reward: 115.86594515702794 avg_loss_c: 2.558274492621422 avg_loss_a: -46.46514076656766\n",
            "Número de pasos del episodeo 10654 son episode_steps:53\n",
            "Total Steps: 615033 Episode Num: 10654 Reward: 80.90282047856499 avg_loss_c: 2.5404447069707907 avg_loss_a: -46.28997046992464\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 94.278943\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 10655 son episode_steps:69\n",
            "Total Steps: 615102 Episode Num: 10655 Reward: 113.07814115349967 avg_loss_c: 2.719779287559399 avg_loss_a: -45.925668854644336\n",
            "Número de pasos del episodeo 10656 son episode_steps:65\n",
            "Total Steps: 615167 Episode Num: 10656 Reward: 101.10759774366245 avg_loss_c: 2.4784334072699914 avg_loss_a: -46.359674365703874\n",
            "Número de pasos del episodeo 10657 son episode_steps:50\n",
            "Total Steps: 615217 Episode Num: 10657 Reward: 46.88956872630957 avg_loss_c: 2.7500876712799074 avg_loss_a: -46.44666534423828\n",
            "Número de pasos del episodeo 10658 son episode_steps:55\n",
            "Total Steps: 615272 Episode Num: 10658 Reward: 55.216169295649735 avg_loss_c: 2.4953501809727063 avg_loss_a: -46.180289736661045\n",
            "Número de pasos del episodeo 10659 son episode_steps:69\n",
            "Total Steps: 615341 Episode Num: 10659 Reward: 105.36951708769314 avg_loss_c: 2.514880719392196 avg_loss_a: -45.88880588697351\n",
            "Número de pasos del episodeo 10660 son episode_steps:85\n",
            "Total Steps: 615426 Episode Num: 10660 Reward: 130.8335733784293 avg_loss_c: 2.571123378417071 avg_loss_a: -46.078451179055605\n",
            "Número de pasos del episodeo 10661 son episode_steps:72\n",
            "Total Steps: 615498 Episode Num: 10661 Reward: 126.43756101667064 avg_loss_c: 2.660711700717608 avg_loss_a: -46.272552702162\n",
            "Número de pasos del episodeo 10662 son episode_steps:57\n",
            "Total Steps: 615555 Episode Num: 10662 Reward: 95.70277994793348 avg_loss_c: 2.532598459929751 avg_loss_a: -46.66716699432909\n",
            "Número de pasos del episodeo 10663 son episode_steps:99\n",
            "Total Steps: 615654 Episode Num: 10663 Reward: 142.29312496757245 avg_loss_c: 2.52737640009986 avg_loss_a: -46.15853835597183\n",
            "Número de pasos del episodeo 10664 son episode_steps:59\n",
            "Total Steps: 615713 Episode Num: 10664 Reward: 86.70947371697108 avg_loss_c: 2.480042726306592 avg_loss_a: -45.93444294040486\n",
            "Número de pasos del episodeo 10665 son episode_steps:61\n",
            "Total Steps: 615774 Episode Num: 10665 Reward: 96.97918546180436 avg_loss_c: 2.639918493442848 avg_loss_a: -45.32360789814933\n",
            "Número de pasos del episodeo 10666 son episode_steps:70\n",
            "Total Steps: 615844 Episode Num: 10666 Reward: 68.58612165108464 avg_loss_c: 2.500720463480268 avg_loss_a: -46.44112363542829\n",
            "Número de pasos del episodeo 10667 son episode_steps:67\n",
            "Total Steps: 615911 Episode Num: 10667 Reward: 106.55679656908363 avg_loss_c: 2.5995799783450453 avg_loss_a: -45.93301380214407\n",
            "Número de pasos del episodeo 10668 son episode_steps:81\n",
            "Total Steps: 615992 Episode Num: 10668 Reward: 135.74726012172988 avg_loss_c: 2.453332790622005 avg_loss_a: -46.13278650354456\n",
            "Número de pasos del episodeo 10669 son episode_steps:88\n",
            "Total Steps: 616080 Episode Num: 10669 Reward: 85.15921950225841 avg_loss_c: 2.4582204900004645 avg_loss_a: -45.815060962330215\n",
            "Número de pasos del episodeo 10670 son episode_steps:95\n",
            "Total Steps: 616175 Episode Num: 10670 Reward: 146.4680184096532 avg_loss_c: 2.660078672358864 avg_loss_a: -46.355439918919615\n",
            "Número de pasos del episodeo 10671 son episode_steps:58\n",
            "Total Steps: 616233 Episode Num: 10671 Reward: 96.0181008648765 avg_loss_c: 2.7061542087587815 avg_loss_a: -46.29227986829034\n",
            "Número de pasos del episodeo 10672 son episode_steps:145\n",
            "Total Steps: 616378 Episode Num: 10672 Reward: 193.46182108731838 avg_loss_c: 2.6398724457313274 avg_loss_a: -46.562203348094016\n",
            "Número de pasos del episodeo 10673 son episode_steps:81\n",
            "Total Steps: 616459 Episode Num: 10673 Reward: 127.21554420641245 avg_loss_c: 2.565091471613189 avg_loss_a: -46.2390862453131\n",
            "Número de pasos del episodeo 10674 son episode_steps:44\n",
            "Total Steps: 616503 Episode Num: 10674 Reward: 43.2832446048333 avg_loss_c: 2.9319301708178087 avg_loss_a: -47.10027798739347\n",
            "Número de pasos del episodeo 10675 son episode_steps:109\n",
            "Total Steps: 616612 Episode Num: 10675 Reward: 147.82957076162867 avg_loss_c: 2.6435595368026594 avg_loss_a: -46.87303431099708\n",
            "Número de pasos del episodeo 10676 son episode_steps:83\n",
            "Total Steps: 616695 Episode Num: 10676 Reward: 127.53822473868514 avg_loss_c: 2.4653817185436386 avg_loss_a: -45.47737149158156\n",
            "Número de pasos del episodeo 10677 son episode_steps:77\n",
            "Total Steps: 616772 Episode Num: 10677 Reward: 121.65326285742657 avg_loss_c: 2.5056233297694814 avg_loss_a: -46.310470828762305\n",
            "Número de pasos del episodeo 10678 son episode_steps:44\n",
            "Total Steps: 616816 Episode Num: 10678 Reward: 39.87392978698048 avg_loss_c: 2.5977815823121504 avg_loss_a: -46.604195681485265\n",
            "Número de pasos del episodeo 10679 son episode_steps:69\n",
            "Total Steps: 616885 Episode Num: 10679 Reward: 51.07807444215547 avg_loss_c: 2.435598855433257 avg_loss_a: -46.7622225664664\n",
            "Número de pasos del episodeo 10680 son episode_steps:95\n",
            "Total Steps: 616980 Episode Num: 10680 Reward: 152.94583320838439 avg_loss_c: 2.4534315184543005 avg_loss_a: -46.214266646535776\n",
            "Número de pasos del episodeo 10681 son episode_steps:87\n",
            "Total Steps: 617067 Episode Num: 10681 Reward: 133.62620724114666 avg_loss_c: 2.2655923544675454 avg_loss_a: -47.09881030554059\n",
            "Número de pasos del episodeo 10682 son episode_steps:77\n",
            "Total Steps: 617144 Episode Num: 10682 Reward: 113.69440684357994 avg_loss_c: 2.4354483090437853 avg_loss_a: -46.51044929801644\n",
            "Número de pasos del episodeo 10683 son episode_steps:73\n",
            "Total Steps: 617217 Episode Num: 10683 Reward: 112.17485622290246 avg_loss_c: 2.4311314347672135 avg_loss_a: -46.50704846316821\n",
            "Número de pasos del episodeo 10684 son episode_steps:80\n",
            "Total Steps: 617297 Episode Num: 10684 Reward: 135.4280918334875 avg_loss_c: 2.155260317027569 avg_loss_a: -46.24879159927368\n",
            "Número de pasos del episodeo 10685 son episode_steps:51\n",
            "Total Steps: 617348 Episode Num: 10685 Reward: 80.18562178528688 avg_loss_c: 2.3650963890786265 avg_loss_a: -45.96582577275295\n",
            "Número de pasos del episodeo 10686 son episode_steps:80\n",
            "Total Steps: 617428 Episode Num: 10686 Reward: 139.47138798869835 avg_loss_c: 2.535236823558807 avg_loss_a: -46.56267576217651\n",
            "Número de pasos del episodeo 10687 son episode_steps:83\n",
            "Total Steps: 617511 Episode Num: 10687 Reward: 109.53235629047039 avg_loss_c: 2.51947116708181 avg_loss_a: -46.56454486157521\n",
            "Número de pasos del episodeo 10688 son episode_steps:102\n",
            "Total Steps: 617613 Episode Num: 10688 Reward: 170.62638509714512 avg_loss_c: 2.2946828334939244 avg_loss_a: -46.64547265744677\n",
            "Número de pasos del episodeo 10689 son episode_steps:68\n",
            "Total Steps: 617681 Episode Num: 10689 Reward: 62.078309562405266 avg_loss_c: 2.720562887542388 avg_loss_a: -46.33573520884794\n",
            "Número de pasos del episodeo 10690 son episode_steps:69\n",
            "Total Steps: 617750 Episode Num: 10690 Reward: 109.91053620324998 avg_loss_c: 2.6896207073460454 avg_loss_a: -46.85310684425244\n",
            "Número de pasos del episodeo 10691 son episode_steps:60\n",
            "Total Steps: 617810 Episode Num: 10691 Reward: 93.04568262722317 avg_loss_c: 2.4438027322292326 avg_loss_a: -46.930951309204104\n",
            "Número de pasos del episodeo 10692 son episode_steps:84\n",
            "Total Steps: 617894 Episode Num: 10692 Reward: 142.70474271570794 avg_loss_c: 2.58951722014518 avg_loss_a: -46.872539429437545\n",
            "Número de pasos del episodeo 10693 son episode_steps:70\n",
            "Total Steps: 617964 Episode Num: 10693 Reward: 74.70523965841448 avg_loss_c: 2.2406038880348205 avg_loss_a: -46.204693276541576\n",
            "Número de pasos del episodeo 10694 son episode_steps:80\n",
            "Total Steps: 618044 Episode Num: 10694 Reward: 126.38478547312236 avg_loss_c: 2.160603794455528 avg_loss_a: -46.84963960647583\n",
            "Número de pasos del episodeo 10695 son episode_steps:84\n",
            "Total Steps: 618128 Episode Num: 10695 Reward: 116.99258367853925 avg_loss_c: 2.3933159368378774 avg_loss_a: -46.12971387590681\n",
            "Número de pasos del episodeo 10696 son episode_steps:100\n",
            "Total Steps: 618228 Episode Num: 10696 Reward: 92.01434166158093 avg_loss_c: 2.364606822729111 avg_loss_a: -46.547172927856444\n",
            "Número de pasos del episodeo 10697 son episode_steps:86\n",
            "Total Steps: 618314 Episode Num: 10697 Reward: 130.09431338686144 avg_loss_c: 2.6945839593576832 avg_loss_a: -46.926220206327216\n",
            "Número de pasos del episodeo 10698 son episode_steps:75\n",
            "Total Steps: 618389 Episode Num: 10698 Reward: 115.98592652668303 avg_loss_c: 2.468264203071594 avg_loss_a: -46.73307200113932\n",
            "Número de pasos del episodeo 10699 son episode_steps:46\n",
            "Total Steps: 618435 Episode Num: 10699 Reward: 48.66074954474249 avg_loss_c: 2.5809068031932996 avg_loss_a: -46.50091619076936\n",
            "Número de pasos del episodeo 10700 son episode_steps:44\n",
            "Total Steps: 618479 Episode Num: 10700 Reward: 34.955465380646544 avg_loss_c: 2.4068179807879706 avg_loss_a: -46.25625645030629\n",
            "Número de pasos del episodeo 10701 son episode_steps:53\n",
            "Total Steps: 618532 Episode Num: 10701 Reward: 85.64283604657913 avg_loss_c: 2.650547893542164 avg_loss_a: -46.42452182409898\n",
            "Número de pasos del episodeo 10702 son episode_steps:62\n",
            "Total Steps: 618594 Episode Num: 10702 Reward: 86.19908972904159 avg_loss_c: 2.5088061209647887 avg_loss_a: -46.191571512529926\n",
            "Número de pasos del episodeo 10703 son episode_steps:60\n",
            "Total Steps: 618654 Episode Num: 10703 Reward: 8.169161986698356 avg_loss_c: 3.072018700838089 avg_loss_a: -46.41304346720378\n",
            "Número de pasos del episodeo 10704 son episode_steps:62\n",
            "Total Steps: 618716 Episode Num: 10704 Reward: 78.6155109046027 avg_loss_c: 2.4991646793580826 avg_loss_a: -47.3067631875315\n",
            "Número de pasos del episodeo 10705 son episode_steps:73\n",
            "Total Steps: 618789 Episode Num: 10705 Reward: 9.26421868425707 avg_loss_c: 2.7264366999064404 avg_loss_a: -45.846221767059745\n",
            "Número de pasos del episodeo 10706 son episode_steps:54\n",
            "Total Steps: 618843 Episode Num: 10706 Reward: 78.38847457068997 avg_loss_c: 2.528846005598704 avg_loss_a: -46.63764953613281\n",
            "Número de pasos del episodeo 10707 son episode_steps:62\n",
            "Total Steps: 618905 Episode Num: 10707 Reward: 65.00714719196228 avg_loss_c: 3.1844230601864476 avg_loss_a: -46.308392801592426\n",
            "Número de pasos del episodeo 10708 son episode_steps:51\n",
            "Total Steps: 618956 Episode Num: 10708 Reward: 80.27252811301952 avg_loss_c: 2.824768772312239 avg_loss_a: -46.0432986091165\n",
            "Número de pasos del episodeo 10709 son episode_steps:98\n",
            "Total Steps: 619054 Episode Num: 10709 Reward: 130.0262855395462 avg_loss_c: 2.774782202681717 avg_loss_a: -46.24125212066028\n",
            "Número de pasos del episodeo 10710 son episode_steps:103\n",
            "Total Steps: 619157 Episode Num: 10710 Reward: 155.03105972913676 avg_loss_c: 2.6997129373180058 avg_loss_a: -46.20651037716171\n",
            "Número de pasos del episodeo 10711 son episode_steps:79\n",
            "Total Steps: 619236 Episode Num: 10711 Reward: 125.03102723458962 avg_loss_c: 2.800205289563046 avg_loss_a: -45.915100918540475\n",
            "Número de pasos del episodeo 10712 son episode_steps:78\n",
            "Total Steps: 619314 Episode Num: 10712 Reward: 116.01242276993166 avg_loss_c: 2.5512063136467567 avg_loss_a: -47.12911566709861\n",
            "Número de pasos del episodeo 10713 son episode_steps:73\n",
            "Total Steps: 619387 Episode Num: 10713 Reward: 113.28123562460435 avg_loss_c: 2.657536026549666 avg_loss_a: -47.05102408422183\n",
            "Número de pasos del episodeo 10714 son episode_steps:92\n",
            "Total Steps: 619479 Episode Num: 10714 Reward: 139.65506047453928 avg_loss_c: 2.7878312377826027 avg_loss_a: -47.481653130572774\n",
            "Número de pasos del episodeo 10715 son episode_steps:94\n",
            "Total Steps: 619573 Episode Num: 10715 Reward: 149.44747981347945 avg_loss_c: 2.408184903733274 avg_loss_a: -45.9686279296875\n",
            "Número de pasos del episodeo 10716 son episode_steps:72\n",
            "Total Steps: 619645 Episode Num: 10716 Reward: 93.2996730966228 avg_loss_c: 2.4342804733249874 avg_loss_a: -47.139322174919975\n",
            "Número de pasos del episodeo 10717 son episode_steps:56\n",
            "Total Steps: 619701 Episode Num: 10717 Reward: 84.43809500280791 avg_loss_c: 2.495199903845787 avg_loss_a: -46.34079565320696\n",
            "Número de pasos del episodeo 10718 son episode_steps:94\n",
            "Total Steps: 619795 Episode Num: 10718 Reward: 82.4571849551944 avg_loss_c: 2.638764522177108 avg_loss_a: -46.584433697639625\n",
            "Número de pasos del episodeo 10719 son episode_steps:75\n",
            "Total Steps: 619870 Episode Num: 10719 Reward: 125.88221874998641 avg_loss_c: 2.7274865929285683 avg_loss_a: -46.264244842529294\n",
            "Número de pasos del episodeo 10720 son episode_steps:87\n",
            "Total Steps: 619957 Episode Num: 10720 Reward: 40.09818330544751 avg_loss_c: 2.543459985448026 avg_loss_a: -45.88464114309728\n",
            "Número de pasos del episodeo 10721 son episode_steps:74\n",
            "Total Steps: 620031 Episode Num: 10721 Reward: 65.0368684240327 avg_loss_c: 2.73005435273454 avg_loss_a: -46.27177614779086\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 93.764265\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 10722 son episode_steps:115\n",
            "Total Steps: 620146 Episode Num: 10722 Reward: 150.68440986979644 avg_loss_c: 2.695044504041257 avg_loss_a: -46.39964370727539\n",
            "Número de pasos del episodeo 10723 son episode_steps:124\n",
            "Total Steps: 620270 Episode Num: 10723 Reward: 187.83449377186523 avg_loss_c: 2.5833046426696162 avg_loss_a: -46.50740297379032\n",
            "Número de pasos del episodeo 10724 son episode_steps:105\n",
            "Total Steps: 620375 Episode Num: 10724 Reward: 152.47175136913953 avg_loss_c: 2.4994781494140623 avg_loss_a: -47.433963775634766\n",
            "Número de pasos del episodeo 10725 son episode_steps:91\n",
            "Total Steps: 620466 Episode Num: 10725 Reward: 147.0198664594224 avg_loss_c: 2.454326541869195 avg_loss_a: -46.31053639506246\n",
            "Número de pasos del episodeo 10726 son episode_steps:88\n",
            "Total Steps: 620554 Episode Num: 10726 Reward: 133.58951486630346 avg_loss_c: 2.5109062628312544 avg_loss_a: -46.51271915435791\n",
            "Número de pasos del episodeo 10727 son episode_steps:94\n",
            "Total Steps: 620648 Episode Num: 10727 Reward: 146.57691886904684 avg_loss_c: 2.523993563144765 avg_loss_a: -46.683322744166595\n",
            "Número de pasos del episodeo 10728 son episode_steps:93\n",
            "Total Steps: 620741 Episode Num: 10728 Reward: 138.7151855453832 avg_loss_c: 2.488806002883501 avg_loss_a: -46.79752600064842\n",
            "Número de pasos del episodeo 10729 son episode_steps:62\n",
            "Total Steps: 620803 Episode Num: 10729 Reward: 100.39403170189124 avg_loss_c: 2.3848862974874434 avg_loss_a: -47.06089930380544\n",
            "Número de pasos del episodeo 10730 son episode_steps:98\n",
            "Total Steps: 620901 Episode Num: 10730 Reward: 146.62895282758876 avg_loss_c: 2.437411737685301 avg_loss_a: -47.02448957793567\n",
            "Número de pasos del episodeo 10731 son episode_steps:136\n",
            "Total Steps: 621037 Episode Num: 10731 Reward: 173.94798416392828 avg_loss_c: 2.1891938518075382 avg_loss_a: -46.80584004346062\n",
            "Número de pasos del episodeo 10732 son episode_steps:28\n",
            "Total Steps: 621065 Episode Num: 10732 Reward: -3.8737202879312065 avg_loss_c: 2.4796412885189056 avg_loss_a: -46.35100255693708\n",
            "Número de pasos del episodeo 10733 son episode_steps:46\n",
            "Total Steps: 621111 Episode Num: 10733 Reward: 71.57127836201957 avg_loss_c: 2.5282998292342476 avg_loss_a: -46.90926029371179\n",
            "Número de pasos del episodeo 10734 son episode_steps:66\n",
            "Total Steps: 621177 Episode Num: 10734 Reward: 105.09597411536423 avg_loss_c: 2.4838302912134114 avg_loss_a: -46.57864275845614\n",
            "Número de pasos del episodeo 10735 son episode_steps:69\n",
            "Total Steps: 621246 Episode Num: 10735 Reward: 107.99861565069347 avg_loss_c: 2.7636398163394653 avg_loss_a: -45.86297209366508\n",
            "Número de pasos del episodeo 10736 son episode_steps:54\n",
            "Total Steps: 621300 Episode Num: 10736 Reward: 82.95427300141401 avg_loss_c: 2.526496233763518 avg_loss_a: -46.07033595332393\n",
            "Número de pasos del episodeo 10737 son episode_steps:78\n",
            "Total Steps: 621378 Episode Num: 10737 Reward: 117.18338644544076 avg_loss_c: 2.414231931551909 avg_loss_a: -46.604566427377556\n",
            "Número de pasos del episodeo 10738 son episode_steps:116\n",
            "Total Steps: 621494 Episode Num: 10738 Reward: 152.8469634305517 avg_loss_c: 2.4466281851817824 avg_loss_a: -46.56741115964692\n",
            "Número de pasos del episodeo 10739 son episode_steps:69\n",
            "Total Steps: 621563 Episode Num: 10739 Reward: 108.25349180040799 avg_loss_c: 2.304080175316852 avg_loss_a: -47.017733532449476\n",
            "Número de pasos del episodeo 10740 son episode_steps:71\n",
            "Total Steps: 621634 Episode Num: 10740 Reward: 110.63846915769368 avg_loss_c: 2.5617181029118283 avg_loss_a: -46.81354125116913\n",
            "Número de pasos del episodeo 10741 son episode_steps:87\n",
            "Total Steps: 621721 Episode Num: 10741 Reward: 100.3442288963124 avg_loss_c: 2.363292679019358 avg_loss_a: -46.18781894376908\n",
            "Número de pasos del episodeo 10742 son episode_steps:83\n",
            "Total Steps: 621804 Episode Num: 10742 Reward: 25.63388453538138 avg_loss_c: 2.2315292875450776 avg_loss_a: -46.85508737219385\n",
            "Número de pasos del episodeo 10743 son episode_steps:55\n",
            "Total Steps: 621859 Episode Num: 10743 Reward: 51.64310844477145 avg_loss_c: 2.3643067251552234 avg_loss_a: -46.51066450639205\n",
            "Número de pasos del episodeo 10744 son episode_steps:64\n",
            "Total Steps: 621923 Episode Num: 10744 Reward: 81.78416087245974 avg_loss_c: 2.553564300760627 avg_loss_a: -46.67625105381012\n",
            "Número de pasos del episodeo 10745 son episode_steps:70\n",
            "Total Steps: 621993 Episode Num: 10745 Reward: 103.70405421507849 avg_loss_c: 2.4365891660962786 avg_loss_a: -46.816121673583986\n",
            "Número de pasos del episodeo 10746 son episode_steps:67\n",
            "Total Steps: 622060 Episode Num: 10746 Reward: 109.73295696238499 avg_loss_c: 2.3719355223783807 avg_loss_a: -46.35057124806874\n",
            "Número de pasos del episodeo 10747 son episode_steps:82\n",
            "Total Steps: 622142 Episode Num: 10747 Reward: 43.60606067229917 avg_loss_c: 2.5780101287655715 avg_loss_a: -46.61183547973633\n",
            "Número de pasos del episodeo 10748 son episode_steps:83\n",
            "Total Steps: 622225 Episode Num: 10748 Reward: -10.293809654761432 avg_loss_c: 2.542150731546333 avg_loss_a: -45.87122050825372\n",
            "Número de pasos del episodeo 10749 son episode_steps:77\n",
            "Total Steps: 622302 Episode Num: 10749 Reward: 124.69199971639468 avg_loss_c: 2.4442786829812184 avg_loss_a: -46.00649187162325\n",
            "Número de pasos del episodeo 10750 son episode_steps:52\n",
            "Total Steps: 622354 Episode Num: 10750 Reward: 80.93779412360045 avg_loss_c: 2.6270114183425903 avg_loss_a: -46.158856465266304\n",
            "Número de pasos del episodeo 10751 son episode_steps:117\n",
            "Total Steps: 622471 Episode Num: 10751 Reward: 78.00446070997181 avg_loss_c: 2.785006107428135 avg_loss_a: -46.55132808848324\n",
            "Número de pasos del episodeo 10752 son episode_steps:111\n",
            "Total Steps: 622582 Episode Num: 10752 Reward: 162.80885569335828 avg_loss_c: 2.806808644586855 avg_loss_a: -46.50701546883798\n",
            "Número de pasos del episodeo 10753 son episode_steps:76\n",
            "Total Steps: 622658 Episode Num: 10753 Reward: 107.58473011459598 avg_loss_c: 2.6368411700976524 avg_loss_a: -46.09960766842491\n",
            "Número de pasos del episodeo 10754 son episode_steps:119\n",
            "Total Steps: 622777 Episode Num: 10754 Reward: 149.52293921259442 avg_loss_c: 2.7692493731234253 avg_loss_a: -45.64701272659943\n",
            "Número de pasos del episodeo 10755 son episode_steps:83\n",
            "Total Steps: 622860 Episode Num: 10755 Reward: 105.71268151227548 avg_loss_c: 2.4882852830082536 avg_loss_a: -46.22830935558641\n",
            "Número de pasos del episodeo 10756 son episode_steps:77\n",
            "Total Steps: 622937 Episode Num: 10756 Reward: 34.46242602350311 avg_loss_c: 2.8971930092031304 avg_loss_a: -45.72317242312741\n",
            "Número de pasos del episodeo 10757 son episode_steps:81\n",
            "Total Steps: 623018 Episode Num: 10757 Reward: 120.13751997622099 avg_loss_c: 2.503455634470339 avg_loss_a: -46.57080968221029\n",
            "Número de pasos del episodeo 10758 son episode_steps:59\n",
            "Total Steps: 623077 Episode Num: 10758 Reward: 98.62321325769759 avg_loss_c: 2.641872557543092 avg_loss_a: -46.016665119235796\n",
            "Número de pasos del episodeo 10759 son episode_steps:74\n",
            "Total Steps: 623151 Episode Num: 10759 Reward: 118.82468168332623 avg_loss_c: 2.7935951271572628 avg_loss_a: -45.37849158209723\n",
            "Número de pasos del episodeo 10760 son episode_steps:83\n",
            "Total Steps: 623234 Episode Num: 10760 Reward: 103.06504502061267 avg_loss_c: 2.623236414897873 avg_loss_a: -45.64075286129871\n",
            "Número de pasos del episodeo 10761 son episode_steps:76\n",
            "Total Steps: 623310 Episode Num: 10761 Reward: 5.184956460765087 avg_loss_c: 2.566587790062553 avg_loss_a: -45.39560900236431\n",
            "Número de pasos del episodeo 10762 son episode_steps:98\n",
            "Total Steps: 623408 Episode Num: 10762 Reward: 48.80896371466524 avg_loss_c: 2.8713016473517126 avg_loss_a: -45.59607167146644\n",
            "Número de pasos del episodeo 10763 son episode_steps:50\n",
            "Total Steps: 623458 Episode Num: 10763 Reward: 72.89883161377217 avg_loss_c: 2.621159119606018 avg_loss_a: -46.76918838500976\n",
            "Número de pasos del episodeo 10764 son episode_steps:74\n",
            "Total Steps: 623532 Episode Num: 10764 Reward: -10.879573715841136 avg_loss_c: 2.7493482119328267 avg_loss_a: -45.73834774945233\n",
            "Número de pasos del episodeo 10765 son episode_steps:54\n",
            "Total Steps: 623586 Episode Num: 10765 Reward: 53.97971037723273 avg_loss_c: 3.0986759309415466 avg_loss_a: -45.48244928430628\n",
            "Número de pasos del episodeo 10766 son episode_steps:39\n",
            "Total Steps: 623625 Episode Num: 10766 Reward: 16.99661458563725 avg_loss_c: 2.832637383387639 avg_loss_a: -44.97868004823342\n",
            "Número de pasos del episodeo 10767 son episode_steps:93\n",
            "Total Steps: 623718 Episode Num: 10767 Reward: 25.948184030028163 avg_loss_c: 2.666707452907357 avg_loss_a: -46.028903345907885\n",
            "Número de pasos del episodeo 10768 son episode_steps:108\n",
            "Total Steps: 623826 Episode Num: 10768 Reward: 140.822212080257 avg_loss_c: 2.81026538544231 avg_loss_a: -45.49005699157715\n",
            "Número de pasos del episodeo 10769 son episode_steps:70\n",
            "Total Steps: 623896 Episode Num: 10769 Reward: 103.46900361220182 avg_loss_c: 2.6929399013519286 avg_loss_a: -46.06113793509347\n",
            "Número de pasos del episodeo 10770 son episode_steps:56\n",
            "Total Steps: 623952 Episode Num: 10770 Reward: 91.88632457489273 avg_loss_c: 2.7769018581935336 avg_loss_a: -45.56106962476458\n",
            "Número de pasos del episodeo 10771 son episode_steps:71\n",
            "Total Steps: 624023 Episode Num: 10771 Reward: 109.76392232796402 avg_loss_c: 2.4942645254269453 avg_loss_a: -46.035775681616556\n",
            "Número de pasos del episodeo 10772 son episode_steps:79\n",
            "Total Steps: 624102 Episode Num: 10772 Reward: 131.14975023878446 avg_loss_c: 2.7546772489064857 avg_loss_a: -45.83092624326296\n",
            "Número de pasos del episodeo 10773 son episode_steps:91\n",
            "Total Steps: 624193 Episode Num: 10773 Reward: 61.97824501061757 avg_loss_c: 2.800707158151564 avg_loss_a: -45.44788633074079\n",
            "Número de pasos del episodeo 10774 son episode_steps:76\n",
            "Total Steps: 624269 Episode Num: 10774 Reward: 119.74003390484634 avg_loss_c: 2.5744410831677285 avg_loss_a: -45.69967018930536\n",
            "Número de pasos del episodeo 10775 son episode_steps:59\n",
            "Total Steps: 624328 Episode Num: 10775 Reward: 74.00298585808405 avg_loss_c: 2.523901907064147 avg_loss_a: -45.600501884848384\n",
            "Número de pasos del episodeo 10776 son episode_steps:55\n",
            "Total Steps: 624383 Episode Num: 10776 Reward: 62.89702092583889 avg_loss_c: 2.538790574940768 avg_loss_a: -45.67267629450018\n",
            "Número de pasos del episodeo 10777 son episode_steps:77\n",
            "Total Steps: 624460 Episode Num: 10777 Reward: 102.13393816702788 avg_loss_c: 2.910314103225609 avg_loss_a: -44.81353799398843\n",
            "Número de pasos del episodeo 10778 son episode_steps:76\n",
            "Total Steps: 624536 Episode Num: 10778 Reward: 118.28237492992015 avg_loss_c: 2.685440421104431 avg_loss_a: -45.0710371920937\n",
            "Número de pasos del episodeo 10779 son episode_steps:51\n",
            "Total Steps: 624587 Episode Num: 10779 Reward: 85.18974850569698 avg_loss_c: 2.594973938137877 avg_loss_a: -45.827946606804346\n",
            "Número de pasos del episodeo 10780 son episode_steps:75\n",
            "Total Steps: 624662 Episode Num: 10780 Reward: 120.16473869608905 avg_loss_c: 2.564301513036092 avg_loss_a: -45.22464630126953\n",
            "Número de pasos del episodeo 10781 son episode_steps:74\n",
            "Total Steps: 624736 Episode Num: 10781 Reward: 127.90889153903261 avg_loss_c: 2.503677352054699 avg_loss_a: -45.466821928282044\n",
            "Número de pasos del episodeo 10782 son episode_steps:79\n",
            "Total Steps: 624815 Episode Num: 10782 Reward: 50.466615916996055 avg_loss_c: 2.780928086630906 avg_loss_a: -45.5341493147838\n",
            "Número de pasos del episodeo 10783 son episode_steps:158\n",
            "Total Steps: 624973 Episode Num: 10783 Reward: 236.85537744771744 avg_loss_c: 2.7583025467546682 avg_loss_a: -45.10640315768085\n",
            "Número de pasos del episodeo 10784 son episode_steps:49\n",
            "Total Steps: 625022 Episode Num: 10784 Reward: 48.58906439797275 avg_loss_c: 2.8399720824494654 avg_loss_a: -45.82830032037229\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 117.223435\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 10785 son episode_steps:71\n",
            "Total Steps: 625093 Episode Num: 10785 Reward: 3.0284658835254286 avg_loss_c: 2.947627096108987 avg_loss_a: -45.06604068380007\n",
            "Número de pasos del episodeo 10786 son episode_steps:60\n",
            "Total Steps: 625153 Episode Num: 10786 Reward: 96.4150461892037 avg_loss_c: 3.1310245116551716 avg_loss_a: -45.447777303059894\n",
            "Número de pasos del episodeo 10787 son episode_steps:77\n",
            "Total Steps: 625230 Episode Num: 10787 Reward: 132.14398208514706 avg_loss_c: 3.081754783531288 avg_loss_a: -44.99833580116173\n",
            "Número de pasos del episodeo 10788 son episode_steps:117\n",
            "Total Steps: 625347 Episode Num: 10788 Reward: 56.15378019169961 avg_loss_c: 2.9992941465133276 avg_loss_a: -45.13561897603874\n",
            "Número de pasos del episodeo 10789 son episode_steps:115\n",
            "Total Steps: 625462 Episode Num: 10789 Reward: 52.08472909739868 avg_loss_c: 3.060217152471128 avg_loss_a: -44.638293092147165\n",
            "Número de pasos del episodeo 10790 son episode_steps:61\n",
            "Total Steps: 625523 Episode Num: 10790 Reward: 94.68033119245827 avg_loss_c: 2.98664158875825 avg_loss_a: -44.52414934752417\n",
            "Número de pasos del episodeo 10791 son episode_steps:75\n",
            "Total Steps: 625598 Episode Num: 10791 Reward: 116.70787627880588 avg_loss_c: 2.8950066566467285 avg_loss_a: -44.90922454833984\n",
            "Número de pasos del episodeo 10792 son episode_steps:123\n",
            "Total Steps: 625721 Episode Num: 10792 Reward: 192.85805216659273 avg_loss_c: 2.926643967628479 avg_loss_a: -44.97829331808943\n",
            "Número de pasos del episodeo 10793 son episode_steps:81\n",
            "Total Steps: 625802 Episode Num: 10793 Reward: 131.17569338071462 avg_loss_c: 2.7630130405779236 avg_loss_a: -45.21494118961287\n",
            "Número de pasos del episodeo 10794 son episode_steps:95\n",
            "Total Steps: 625897 Episode Num: 10794 Reward: 80.34769939861691 avg_loss_c: 2.8709289764103136 avg_loss_a: -44.26962127685547\n",
            "Número de pasos del episodeo 10795 son episode_steps:108\n",
            "Total Steps: 626005 Episode Num: 10795 Reward: 173.42828402530802 avg_loss_c: 2.8983353442615933 avg_loss_a: -44.96878751118978\n",
            "Número de pasos del episodeo 10796 son episode_steps:93\n",
            "Total Steps: 626098 Episode Num: 10796 Reward: -12.893521436386711 avg_loss_c: 3.451351992545589 avg_loss_a: -44.620267519386864\n",
            "Número de pasos del episodeo 10797 son episode_steps:72\n",
            "Total Steps: 626170 Episode Num: 10797 Reward: 87.71082193100649 avg_loss_c: 3.2430362701416016 avg_loss_a: -44.6156596077813\n",
            "Número de pasos del episodeo 10798 son episode_steps:61\n",
            "Total Steps: 626231 Episode Num: 10798 Reward: 105.30313448658691 avg_loss_c: 2.9759792284887343 avg_loss_a: -44.590605063516584\n",
            "Número de pasos del episodeo 10799 son episode_steps:77\n",
            "Total Steps: 626308 Episode Num: 10799 Reward: 26.52874757314566 avg_loss_c: 2.8689389894535013 avg_loss_a: -45.22065095777636\n",
            "Número de pasos del episodeo 10800 son episode_steps:74\n",
            "Total Steps: 626382 Episode Num: 10800 Reward: 116.26584283938053 avg_loss_c: 2.913018945101145 avg_loss_a: -44.3637742738466\n",
            "Número de pasos del episodeo 10801 son episode_steps:72\n",
            "Total Steps: 626454 Episode Num: 10801 Reward: 127.65405921249483 avg_loss_c: 3.001829410592715 avg_loss_a: -45.60028097364638\n",
            "Número de pasos del episodeo 10802 son episode_steps:51\n",
            "Total Steps: 626505 Episode Num: 10802 Reward: 75.89412020345378 avg_loss_c: 2.9486519402148677 avg_loss_a: -44.75674169203814\n",
            "Número de pasos del episodeo 10803 son episode_steps:84\n",
            "Total Steps: 626589 Episode Num: 10803 Reward: 118.91652266199924 avg_loss_c: 2.956578166711898 avg_loss_a: -44.62808681669689\n",
            "Número de pasos del episodeo 10804 son episode_steps:60\n",
            "Total Steps: 626649 Episode Num: 10804 Reward: 91.59651444323943 avg_loss_c: 3.089760520060857 avg_loss_a: -44.56586888631185\n",
            "Número de pasos del episodeo 10805 son episode_steps:67\n",
            "Total Steps: 626716 Episode Num: 10805 Reward: 92.50578076237353 avg_loss_c: 2.7455695849746022 avg_loss_a: -44.77196519766281\n",
            "Número de pasos del episodeo 10806 son episode_steps:86\n",
            "Total Steps: 626802 Episode Num: 10806 Reward: 141.8650582897661 avg_loss_c: 2.827088239581086 avg_loss_a: -44.550151115240055\n",
            "Número de pasos del episodeo 10807 son episode_steps:145\n",
            "Total Steps: 626947 Episode Num: 10807 Reward: 214.65241145704422 avg_loss_c: 2.7219360228242544 avg_loss_a: -44.56737876102842\n",
            "Número de pasos del episodeo 10808 son episode_steps:60\n",
            "Total Steps: 627007 Episode Num: 10808 Reward: 95.49626424997444 avg_loss_c: 2.805969466765722 avg_loss_a: -44.322666295369466\n",
            "Número de pasos del episodeo 10809 son episode_steps:70\n",
            "Total Steps: 627077 Episode Num: 10809 Reward: 56.08964371129679 avg_loss_c: 2.9107751505715505 avg_loss_a: -44.759046282087056\n",
            "Número de pasos del episodeo 10810 son episode_steps:18\n",
            "Total Steps: 627095 Episode Num: 10810 Reward: -37.43713169814861 avg_loss_c: 3.301763799455431 avg_loss_a: -42.815670013427734\n",
            "Número de pasos del episodeo 10811 son episode_steps:71\n",
            "Total Steps: 627166 Episode Num: 10811 Reward: 117.53397014117293 avg_loss_c: 3.073932824000506 avg_loss_a: -44.3546774958221\n",
            "Número de pasos del episodeo 10812 son episode_steps:73\n",
            "Total Steps: 627239 Episode Num: 10812 Reward: 102.97596581542533 avg_loss_c: 2.8721183734397364 avg_loss_a: -44.31483396765304\n",
            "Número de pasos del episodeo 10813 son episode_steps:56\n",
            "Total Steps: 627295 Episode Num: 10813 Reward: 53.9578503069424 avg_loss_c: 2.9883604624441693 avg_loss_a: -44.126482009887695\n",
            "Número de pasos del episodeo 10814 son episode_steps:96\n",
            "Total Steps: 627391 Episode Num: 10814 Reward: 146.86936286644152 avg_loss_c: 3.0010437493522963 avg_loss_a: -44.34414140383402\n",
            "Número de pasos del episodeo 10815 son episode_steps:72\n",
            "Total Steps: 627463 Episode Num: 10815 Reward: 110.12452781892097 avg_loss_c: 2.923516324824757 avg_loss_a: -44.44165484110514\n",
            "Número de pasos del episodeo 10816 son episode_steps:64\n",
            "Total Steps: 627527 Episode Num: 10816 Reward: 106.4847403816554 avg_loss_c: 3.0366354174911976 avg_loss_a: -44.749492168426514\n",
            "Número de pasos del episodeo 10817 son episode_steps:60\n",
            "Total Steps: 627587 Episode Num: 10817 Reward: 61.16806806215886 avg_loss_c: 3.023187454541524 avg_loss_a: -44.68011347452799\n",
            "Número de pasos del episodeo 10818 son episode_steps:65\n",
            "Total Steps: 627652 Episode Num: 10818 Reward: 108.34071849700076 avg_loss_c: 2.7995662780908437 avg_loss_a: -44.77859479464018\n",
            "Número de pasos del episodeo 10819 son episode_steps:87\n",
            "Total Steps: 627739 Episode Num: 10819 Reward: 139.38983929875897 avg_loss_c: 2.888629132303698 avg_loss_a: -44.318899001198254\n",
            "Número de pasos del episodeo 10820 son episode_steps:69\n",
            "Total Steps: 627808 Episode Num: 10820 Reward: 103.30595247069071 avg_loss_c: 3.0105153667754023 avg_loss_a: -44.93517126553301\n",
            "Número de pasos del episodeo 10821 son episode_steps:56\n",
            "Total Steps: 627864 Episode Num: 10821 Reward: 45.081096302562344 avg_loss_c: 3.202008617775781 avg_loss_a: -44.17928123474121\n",
            "Número de pasos del episodeo 10822 son episode_steps:96\n",
            "Total Steps: 627960 Episode Num: 10822 Reward: 130.12581187590524 avg_loss_c: 3.0121667397518954 avg_loss_a: -44.5086940129598\n",
            "Número de pasos del episodeo 10823 son episode_steps:97\n",
            "Total Steps: 628057 Episode Num: 10823 Reward: 114.79005055404396 avg_loss_c: 3.019732255296609 avg_loss_a: -44.738150685103896\n",
            "Número de pasos del episodeo 10824 son episode_steps:124\n",
            "Total Steps: 628181 Episode Num: 10824 Reward: 194.8801608220661 avg_loss_c: 2.918304387600191 avg_loss_a: -44.94022800076392\n",
            "Número de pasos del episodeo 10825 son episode_steps:96\n",
            "Total Steps: 628277 Episode Num: 10825 Reward: 155.25063093389687 avg_loss_c: 2.73253191759189 avg_loss_a: -44.75090710322062\n",
            "Número de pasos del episodeo 10826 son episode_steps:76\n",
            "Total Steps: 628353 Episode Num: 10826 Reward: 101.82424031868663 avg_loss_c: 2.6488551356290517 avg_loss_a: -44.48969660307232\n",
            "Número de pasos del episodeo 10827 son episode_steps:65\n",
            "Total Steps: 628418 Episode Num: 10827 Reward: 106.16096283633878 avg_loss_c: 2.7612306136351363 avg_loss_a: -44.22055963369516\n",
            "Número de pasos del episodeo 10828 son episode_steps:68\n",
            "Total Steps: 628486 Episode Num: 10828 Reward: 97.8756438050632 avg_loss_c: 2.792283931199242 avg_loss_a: -44.35338861802045\n",
            "Número de pasos del episodeo 10829 son episode_steps:111\n",
            "Total Steps: 628597 Episode Num: 10829 Reward: 20.4468689829542 avg_loss_c: 3.050362844724913 avg_loss_a: -44.65094337807045\n",
            "Número de pasos del episodeo 10830 son episode_steps:82\n",
            "Total Steps: 628679 Episode Num: 10830 Reward: 126.28006626342714 avg_loss_c: 2.7426029341976816 avg_loss_a: -44.65645878489425\n",
            "Número de pasos del episodeo 10831 son episode_steps:71\n",
            "Total Steps: 628750 Episode Num: 10831 Reward: 120.45123639692504 avg_loss_c: 2.8670023646153195 avg_loss_a: -44.17986233133665\n",
            "Número de pasos del episodeo 10832 son episode_steps:94\n",
            "Total Steps: 628844 Episode Num: 10832 Reward: 11.647366015987243 avg_loss_c: 3.3055381571992917 avg_loss_a: -44.540024696512425\n",
            "Número de pasos del episodeo 10833 son episode_steps:52\n",
            "Total Steps: 628896 Episode Num: 10833 Reward: 64.97636713769286 avg_loss_c: 2.8992939178760233 avg_loss_a: -44.06994306124174\n",
            "Número de pasos del episodeo 10834 son episode_steps:116\n",
            "Total Steps: 629012 Episode Num: 10834 Reward: 172.770915256734 avg_loss_c: 2.8628483877099793 avg_loss_a: -44.7764431525921\n",
            "Número de pasos del episodeo 10835 son episode_steps:128\n",
            "Total Steps: 629140 Episode Num: 10835 Reward: 181.16310383045047 avg_loss_c: 2.847687433473766 avg_loss_a: -44.888541519641876\n",
            "Número de pasos del episodeo 10836 son episode_steps:108\n",
            "Total Steps: 629248 Episode Num: 10836 Reward: 148.1388305218595 avg_loss_c: 2.868396427896288 avg_loss_a: -44.21442801864059\n",
            "Número de pasos del episodeo 10837 son episode_steps:95\n",
            "Total Steps: 629343 Episode Num: 10837 Reward: 159.00158634260958 avg_loss_c: 2.8001722461298892 avg_loss_a: -44.665772608706824\n",
            "Número de pasos del episodeo 10838 son episode_steps:153\n",
            "Total Steps: 629496 Episode Num: 10838 Reward: 58.06313303126351 avg_loss_c: 3.0721032970091877 avg_loss_a: -44.2070213766659\n",
            "Número de pasos del episodeo 10839 son episode_steps:106\n",
            "Total Steps: 629602 Episode Num: 10839 Reward: 152.60252203965058 avg_loss_c: 3.061178639249982 avg_loss_a: -44.18947039910083\n",
            "Número de pasos del episodeo 10840 son episode_steps:124\n",
            "Total Steps: 629726 Episode Num: 10840 Reward: 160.57562337253515 avg_loss_c: 2.9214260808883177 avg_loss_a: -44.501801706129505\n",
            "Número de pasos del episodeo 10841 son episode_steps:65\n",
            "Total Steps: 629791 Episode Num: 10841 Reward: 111.68661865879486 avg_loss_c: 2.876512499955984 avg_loss_a: -44.61709982065054\n",
            "Número de pasos del episodeo 10842 son episode_steps:77\n",
            "Total Steps: 629868 Episode Num: 10842 Reward: 122.2870977800449 avg_loss_c: 3.0186060094214104 avg_loss_a: -45.150937513871625\n",
            "Número de pasos del episodeo 10843 son episode_steps:75\n",
            "Total Steps: 629943 Episode Num: 10843 Reward: 116.31994653005052 avg_loss_c: 3.075091994603475 avg_loss_a: -44.77289052327474\n",
            "Número de pasos del episodeo 10844 son episode_steps:72\n",
            "Total Steps: 630015 Episode Num: 10844 Reward: 118.0566044872275 avg_loss_c: 3.145440806945165 avg_loss_a: -43.57104025946723\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 116.851227\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 10845 son episode_steps:73\n",
            "Total Steps: 630088 Episode Num: 10845 Reward: 117.87817420507977 avg_loss_c: 2.8197380385986746 avg_loss_a: -44.30786953233693\n",
            "Número de pasos del episodeo 10846 son episode_steps:84\n",
            "Total Steps: 630172 Episode Num: 10846 Reward: 119.25028885641395 avg_loss_c: 2.7679912263438817 avg_loss_a: -44.4334587823777\n",
            "Número de pasos del episodeo 10847 son episode_steps:55\n",
            "Total Steps: 630227 Episode Num: 10847 Reward: 72.94742349802463 avg_loss_c: 2.9314654458652845 avg_loss_a: -45.16015347567472\n",
            "Número de pasos del episodeo 10848 son episode_steps:71\n",
            "Total Steps: 630298 Episode Num: 10848 Reward: 105.1646339857597 avg_loss_c: 2.93265567363148 avg_loss_a: -44.474508258658396\n",
            "Número de pasos del episodeo 10849 son episode_steps:74\n",
            "Total Steps: 630372 Episode Num: 10849 Reward: 117.09041905563734 avg_loss_c: 2.8496469581449353 avg_loss_a: -44.2740948651288\n",
            "Número de pasos del episodeo 10850 son episode_steps:42\n",
            "Total Steps: 630414 Episode Num: 10850 Reward: 44.27598618511781 avg_loss_c: 2.8045775407836553 avg_loss_a: -43.609972272600444\n",
            "Número de pasos del episodeo 10851 son episode_steps:86\n",
            "Total Steps: 630500 Episode Num: 10851 Reward: 135.29956752716066 avg_loss_c: 2.8516107173853142 avg_loss_a: -44.0602228031602\n",
            "Número de pasos del episodeo 10852 son episode_steps:51\n",
            "Total Steps: 630551 Episode Num: 10852 Reward: 62.61485570347779 avg_loss_c: 2.897581030340756 avg_loss_a: -43.953324037439685\n",
            "Número de pasos del episodeo 10853 son episode_steps:82\n",
            "Total Steps: 630633 Episode Num: 10853 Reward: -7.3193011494844065 avg_loss_c: 3.2690121168043555 avg_loss_a: -44.040499338289585\n",
            "Número de pasos del episodeo 10854 son episode_steps:94\n",
            "Total Steps: 630727 Episode Num: 10854 Reward: 157.5384481882249 avg_loss_c: 3.0165464104490076 avg_loss_a: -43.87744879215322\n",
            "Número de pasos del episodeo 10855 son episode_steps:76\n",
            "Total Steps: 630803 Episode Num: 10855 Reward: 134.20480725511194 avg_loss_c: 2.986129503501089 avg_loss_a: -44.6532876867997\n",
            "Número de pasos del episodeo 10856 son episode_steps:110\n",
            "Total Steps: 630913 Episode Num: 10856 Reward: 175.95184601126462 avg_loss_c: 2.909994382208044 avg_loss_a: -43.63811707930132\n",
            "Número de pasos del episodeo 10857 son episode_steps:111\n",
            "Total Steps: 631024 Episode Num: 10857 Reward: 172.28672518423244 avg_loss_c: 2.8926082591752746 avg_loss_a: -44.15001822806693\n",
            "Número de pasos del episodeo 10858 son episode_steps:72\n",
            "Total Steps: 631096 Episode Num: 10858 Reward: 88.14472615607927 avg_loss_c: 2.795699833167924 avg_loss_a: -43.760195096333824\n",
            "Número de pasos del episodeo 10859 son episode_steps:107\n",
            "Total Steps: 631203 Episode Num: 10859 Reward: 183.6912553755317 avg_loss_c: 2.8401632242113632 avg_loss_a: -44.7651680206584\n",
            "Número de pasos del episodeo 10860 son episode_steps:83\n",
            "Total Steps: 631286 Episode Num: 10860 Reward: 116.55645003846267 avg_loss_c: 2.975611485630633 avg_loss_a: -44.35980454410415\n",
            "Número de pasos del episodeo 10861 son episode_steps:105\n",
            "Total Steps: 631391 Episode Num: 10861 Reward: 155.42695621746333 avg_loss_c: 3.019057958466666 avg_loss_a: -44.526781863258\n",
            "Número de pasos del episodeo 10862 son episode_steps:72\n",
            "Total Steps: 631463 Episode Num: 10862 Reward: 38.9025681883024 avg_loss_c: 2.8577470034360886 avg_loss_a: -43.61702505747477\n",
            "Número de pasos del episodeo 10863 son episode_steps:71\n",
            "Total Steps: 631534 Episode Num: 10863 Reward: 114.49987001456223 avg_loss_c: 2.830907880420416 avg_loss_a: -44.50557617402413\n",
            "Número de pasos del episodeo 10864 son episode_steps:100\n",
            "Total Steps: 631634 Episode Num: 10864 Reward: 160.0813715115761 avg_loss_c: 2.9952274489402773 avg_loss_a: -44.00605422973633\n",
            "Número de pasos del episodeo 10865 son episode_steps:79\n",
            "Total Steps: 631713 Episode Num: 10865 Reward: 129.5678228994617 avg_loss_c: 2.8623776541480535 avg_loss_a: -44.302191722242135\n",
            "Número de pasos del episodeo 10866 son episode_steps:52\n",
            "Total Steps: 631765 Episode Num: 10866 Reward: 80.91485077232798 avg_loss_c: 2.8990623354911804 avg_loss_a: -43.989781012901894\n",
            "Número de pasos del episodeo 10867 son episode_steps:55\n",
            "Total Steps: 631820 Episode Num: 10867 Reward: 85.31224202992227 avg_loss_c: 2.777372123978355 avg_loss_a: -44.238490017977625\n",
            "Número de pasos del episodeo 10868 son episode_steps:62\n",
            "Total Steps: 631882 Episode Num: 10868 Reward: 40.039410851443044 avg_loss_c: 2.704845791862857 avg_loss_a: -43.73154892459993\n",
            "Número de pasos del episodeo 10869 son episode_steps:89\n",
            "Total Steps: 631971 Episode Num: 10869 Reward: 7.936340669248209 avg_loss_c: 2.899640995464968 avg_loss_a: -44.160401933648615\n",
            "Número de pasos del episodeo 10870 son episode_steps:59\n",
            "Total Steps: 632030 Episode Num: 10870 Reward: 88.65199481249121 avg_loss_c: 2.8126603950888422 avg_loss_a: -43.532821073370464\n",
            "Número de pasos del episodeo 10871 son episode_steps:88\n",
            "Total Steps: 632118 Episode Num: 10871 Reward: 127.04246800177903 avg_loss_c: 3.0966342972083525 avg_loss_a: -43.80287395824086\n",
            "Número de pasos del episodeo 10872 son episode_steps:89\n",
            "Total Steps: 632207 Episode Num: 10872 Reward: 146.54080491935716 avg_loss_c: 2.8990471979205528 avg_loss_a: -44.60855153973183\n",
            "Número de pasos del episodeo 10873 son episode_steps:91\n",
            "Total Steps: 632298 Episode Num: 10873 Reward: 23.849457565167018 avg_loss_c: 3.1341685960581014 avg_loss_a: -44.148955921550375\n",
            "Número de pasos del episodeo 10874 son episode_steps:60\n",
            "Total Steps: 632358 Episode Num: 10874 Reward: 86.95690916599528 avg_loss_c: 3.1025055567423503 avg_loss_a: -44.2811097462972\n",
            "Número de pasos del episodeo 10875 son episode_steps:52\n",
            "Total Steps: 632410 Episode Num: 10875 Reward: 54.477925881465154 avg_loss_c: 2.9139729279738207 avg_loss_a: -44.033446091871994\n",
            "Número de pasos del episodeo 10876 son episode_steps:47\n",
            "Total Steps: 632457 Episode Num: 10876 Reward: 72.72185217522714 avg_loss_c: 2.9487406471942332 avg_loss_a: -43.19938132103453\n",
            "Número de pasos del episodeo 10877 son episode_steps:92\n",
            "Total Steps: 632549 Episode Num: 10877 Reward: 130.49538898752104 avg_loss_c: 2.988811264867368 avg_loss_a: -44.34503596761952\n",
            "Número de pasos del episodeo 10878 son episode_steps:51\n",
            "Total Steps: 632600 Episode Num: 10878 Reward: 56.449534922888205 avg_loss_c: 2.9834884148018035 avg_loss_a: -44.13369466744217\n",
            "Número de pasos del episodeo 10879 son episode_steps:77\n",
            "Total Steps: 632677 Episode Num: 10879 Reward: 117.37133192489677 avg_loss_c: 2.841491369457988 avg_loss_a: -43.99334394776976\n",
            "Número de pasos del episodeo 10880 son episode_steps:75\n",
            "Total Steps: 632752 Episode Num: 10880 Reward: 123.49240081510393 avg_loss_c: 2.872939880688985 avg_loss_a: -43.742062123616535\n",
            "Número de pasos del episodeo 10881 son episode_steps:184\n",
            "Total Steps: 632936 Episode Num: 10881 Reward: 109.6347830740057 avg_loss_c: 3.05567237475644 avg_loss_a: -44.23031139373779\n",
            "Número de pasos del episodeo 10882 son episode_steps:57\n",
            "Total Steps: 632993 Episode Num: 10882 Reward: 83.87661515783958 avg_loss_c: 2.9491870110495046 avg_loss_a: -44.06865009508635\n",
            "Número de pasos del episodeo 10883 son episode_steps:48\n",
            "Total Steps: 633041 Episode Num: 10883 Reward: 29.615707649573153 avg_loss_c: 2.867058426141739 avg_loss_a: -43.0184276898702\n",
            "Número de pasos del episodeo 10884 son episode_steps:64\n",
            "Total Steps: 633105 Episode Num: 10884 Reward: 103.33201234572117 avg_loss_c: 2.799288894981146 avg_loss_a: -44.309471011161804\n",
            "Número de pasos del episodeo 10885 son episode_steps:88\n",
            "Total Steps: 633193 Episode Num: 10885 Reward: 139.8206717128463 avg_loss_c: 3.023209197954698 avg_loss_a: -44.07481930472634\n",
            "Número de pasos del episodeo 10886 son episode_steps:70\n",
            "Total Steps: 633263 Episode Num: 10886 Reward: 119.78590991460123 avg_loss_c: 2.8277800134250097 avg_loss_a: -43.82443117414202\n",
            "Número de pasos del episodeo 10887 son episode_steps:72\n",
            "Total Steps: 633335 Episode Num: 10887 Reward: 13.076332766097599 avg_loss_c: 3.0317548546526165 avg_loss_a: -43.810764418707954\n",
            "Número de pasos del episodeo 10888 son episode_steps:70\n",
            "Total Steps: 633405 Episode Num: 10888 Reward: 115.37531664698918 avg_loss_c: 3.137522506713867 avg_loss_a: -44.08038602556501\n",
            "Número de pasos del episodeo 10889 son episode_steps:88\n",
            "Total Steps: 633493 Episode Num: 10889 Reward: 140.07767308873642 avg_loss_c: 2.9247446696866644 avg_loss_a: -44.31025305661288\n",
            "Número de pasos del episodeo 10890 son episode_steps:70\n",
            "Total Steps: 633563 Episode Num: 10890 Reward: 113.3419901274762 avg_loss_c: 3.055507356779916 avg_loss_a: -43.481039210728234\n",
            "Número de pasos del episodeo 10891 son episode_steps:91\n",
            "Total Steps: 633654 Episode Num: 10891 Reward: 138.60825771545765 avg_loss_c: 2.7034894201781725 avg_loss_a: -43.933403937371224\n",
            "Número de pasos del episodeo 10892 son episode_steps:85\n",
            "Total Steps: 633739 Episode Num: 10892 Reward: 121.85246181052024 avg_loss_c: 2.781345754511216 avg_loss_a: -43.602919006347655\n",
            "Número de pasos del episodeo 10893 son episode_steps:60\n",
            "Total Steps: 633799 Episode Num: 10893 Reward: 62.6615274524855 avg_loss_c: 3.0903637210528054 avg_loss_a: -43.364435450236\n",
            "Número de pasos del episodeo 10894 son episode_steps:101\n",
            "Total Steps: 633900 Episode Num: 10894 Reward: 160.37652379855982 avg_loss_c: 2.7694616542004122 avg_loss_a: -44.450380910741224\n",
            "Número de pasos del episodeo 10895 son episode_steps:72\n",
            "Total Steps: 633972 Episode Num: 10895 Reward: 103.95954233795217 avg_loss_c: 2.8957040442360773 avg_loss_a: -43.62279902564155\n",
            "Número de pasos del episodeo 10896 son episode_steps:78\n",
            "Total Steps: 634050 Episode Num: 10896 Reward: 124.8446120593626 avg_loss_c: 2.881238715770917 avg_loss_a: -43.603429451966896\n",
            "Número de pasos del episodeo 10897 son episode_steps:75\n",
            "Total Steps: 634125 Episode Num: 10897 Reward: 127.93649697853238 avg_loss_c: 2.816299231847127 avg_loss_a: -44.030352427164715\n",
            "Número de pasos del episodeo 10898 son episode_steps:53\n",
            "Total Steps: 634178 Episode Num: 10898 Reward: 86.81176768455724 avg_loss_c: 2.731411133172377 avg_loss_a: -43.459361454225935\n",
            "Número de pasos del episodeo 10899 son episode_steps:173\n",
            "Total Steps: 634351 Episode Num: 10899 Reward: 219.66996740087717 avg_loss_c: 2.882624353976608 avg_loss_a: -43.89717774584114\n",
            "Número de pasos del episodeo 10900 son episode_steps:54\n",
            "Total Steps: 634405 Episode Num: 10900 Reward: 80.02709047339994 avg_loss_c: 3.0376405671790794 avg_loss_a: -43.75445613154658\n",
            "Número de pasos del episodeo 10901 son episode_steps:72\n",
            "Total Steps: 634477 Episode Num: 10901 Reward: 121.34441213563323 avg_loss_c: 2.9694620851013394 avg_loss_a: -43.477403746710884\n",
            "Número de pasos del episodeo 10902 son episode_steps:91\n",
            "Total Steps: 634568 Episode Num: 10902 Reward: 139.69425625128093 avg_loss_c: 2.8468243735177174 avg_loss_a: -43.71252651005001\n",
            "Número de pasos del episodeo 10903 son episode_steps:49\n",
            "Total Steps: 634617 Episode Num: 10903 Reward: 76.73136273702244 avg_loss_c: 2.7380654422604307 avg_loss_a: -43.93671510657486\n",
            "Número de pasos del episodeo 10904 son episode_steps:75\n",
            "Total Steps: 634692 Episode Num: 10904 Reward: 110.97410678433332 avg_loss_c: 2.711522739728292 avg_loss_a: -43.895635528564455\n",
            "Número de pasos del episodeo 10905 son episode_steps:94\n",
            "Total Steps: 634786 Episode Num: 10905 Reward: 139.59602963332335 avg_loss_c: 2.629234585356205 avg_loss_a: -44.758658307663936\n",
            "Número de pasos del episodeo 10906 son episode_steps:64\n",
            "Total Steps: 634850 Episode Num: 10906 Reward: 101.36390206760413 avg_loss_c: 2.6621431950479746 avg_loss_a: -44.80775189399719\n",
            "Número de pasos del episodeo 10907 son episode_steps:121\n",
            "Total Steps: 634971 Episode Num: 10907 Reward: 179.90542457617394 avg_loss_c: 2.913968896077684 avg_loss_a: -43.75985746147219\n",
            "Número de pasos del episodeo 10908 son episode_steps:94\n",
            "Total Steps: 635065 Episode Num: 10908 Reward: 149.2845059920347 avg_loss_c: 2.703905261577444 avg_loss_a: -44.37626647949219\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 86.495461\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 10909 son episode_steps:90\n",
            "Total Steps: 635155 Episode Num: 10909 Reward: 143.78970717258062 avg_loss_c: 2.7517298261324563 avg_loss_a: -44.88332383897569\n",
            "Número de pasos del episodeo 10910 son episode_steps:102\n",
            "Total Steps: 635257 Episode Num: 10910 Reward: 154.3209073725423 avg_loss_c: 2.8226767334283567 avg_loss_a: -43.47693222644282\n",
            "Número de pasos del episodeo 10911 son episode_steps:63\n",
            "Total Steps: 635320 Episode Num: 10911 Reward: 81.49085926686493 avg_loss_c: 2.8058826109719655 avg_loss_a: -44.03989489116366\n",
            "Número de pasos del episodeo 10912 son episode_steps:147\n",
            "Total Steps: 635467 Episode Num: 10912 Reward: 213.76167173169858 avg_loss_c: 2.7400847681525615 avg_loss_a: -44.387805419714276\n",
            "Número de pasos del episodeo 10913 son episode_steps:24\n",
            "Total Steps: 635491 Episode Num: 10913 Reward: -6.934329664954138 avg_loss_c: 2.89657124876976 avg_loss_a: -43.66766770680746\n",
            "Número de pasos del episodeo 10914 son episode_steps:137\n",
            "Total Steps: 635628 Episode Num: 10914 Reward: 199.3350930027518 avg_loss_c: 2.861670193010873 avg_loss_a: -43.95539045681919\n",
            "Número de pasos del episodeo 10915 son episode_steps:117\n",
            "Total Steps: 635745 Episode Num: 10915 Reward: 183.0222366719566 avg_loss_c: 2.8414296502740974 avg_loss_a: -44.63745391063201\n",
            "Número de pasos del episodeo 10916 son episode_steps:61\n",
            "Total Steps: 635806 Episode Num: 10916 Reward: 98.02983252497724 avg_loss_c: 2.8636759695459584 avg_loss_a: -43.561364846151385\n",
            "Número de pasos del episodeo 10917 son episode_steps:99\n",
            "Total Steps: 635905 Episode Num: 10917 Reward: 155.4892586261248 avg_loss_c: 2.7906350511493105 avg_loss_a: -44.30483411538481\n",
            "Número de pasos del episodeo 10918 son episode_steps:58\n",
            "Total Steps: 635963 Episode Num: 10918 Reward: 57.29945326912303 avg_loss_c: 2.737054734394468 avg_loss_a: -44.04459525798929\n",
            "Número de pasos del episodeo 10919 son episode_steps:65\n",
            "Total Steps: 636028 Episode Num: 10919 Reward: 112.14459003973211 avg_loss_c: 2.704048483188336 avg_loss_a: -44.8311772273137\n",
            "Número de pasos del episodeo 10920 son episode_steps:102\n",
            "Total Steps: 636130 Episode Num: 10920 Reward: 143.2839007347443 avg_loss_c: 2.6406162194177214 avg_loss_a: -44.207520279229854\n",
            "Número de pasos del episodeo 10921 son episode_steps:134\n",
            "Total Steps: 636264 Episode Num: 10921 Reward: 116.47798866295146 avg_loss_c: 2.7015385867944404 avg_loss_a: -44.30175137875685\n",
            "Número de pasos del episodeo 10922 son episode_steps:94\n",
            "Total Steps: 636358 Episode Num: 10922 Reward: -11.547004061812636 avg_loss_c: 3.0831926211397698 avg_loss_a: -43.71218969466838\n",
            "Número de pasos del episodeo 10923 son episode_steps:96\n",
            "Total Steps: 636454 Episode Num: 10923 Reward: 153.24440734334001 avg_loss_c: 3.094765273233255 avg_loss_a: -43.958278020222984\n",
            "Número de pasos del episodeo 10924 son episode_steps:57\n",
            "Total Steps: 636511 Episode Num: 10924 Reward: 68.20074475643708 avg_loss_c: 3.1402988266526606 avg_loss_a: -44.71897245708265\n",
            "Número de pasos del episodeo 10925 son episode_steps:55\n",
            "Total Steps: 636566 Episode Num: 10925 Reward: 94.96861859148949 avg_loss_c: 2.839706628972834 avg_loss_a: -43.97707283713601\n",
            "Número de pasos del episodeo 10926 son episode_steps:114\n",
            "Total Steps: 636680 Episode Num: 10926 Reward: 161.7435563315735 avg_loss_c: 2.826253571008381 avg_loss_a: -44.08606947514049\n",
            "Número de pasos del episodeo 10927 son episode_steps:62\n",
            "Total Steps: 636742 Episode Num: 10927 Reward: 100.15852188704419 avg_loss_c: 2.815599310782648 avg_loss_a: -44.378150693831905\n",
            "Número de pasos del episodeo 10928 son episode_steps:31\n",
            "Total Steps: 636773 Episode Num: 10928 Reward: 5.633828239436405 avg_loss_c: 2.8272940035789245 avg_loss_a: -43.69613179852885\n",
            "Número de pasos del episodeo 10929 son episode_steps:54\n",
            "Total Steps: 636827 Episode Num: 10929 Reward: 87.06167575879573 avg_loss_c: 2.9446213995968855 avg_loss_a: -43.9868155585395\n",
            "Número de pasos del episodeo 10930 son episode_steps:60\n",
            "Total Steps: 636887 Episode Num: 10930 Reward: 106.06265463880813 avg_loss_c: 2.8823396960894265 avg_loss_a: -43.43932545979818\n",
            "Número de pasos del episodeo 10931 son episode_steps:76\n",
            "Total Steps: 636963 Episode Num: 10931 Reward: 108.20415497132889 avg_loss_c: 2.8388578703528955 avg_loss_a: -44.35204014025236\n",
            "Número de pasos del episodeo 10932 son episode_steps:138\n",
            "Total Steps: 637101 Episode Num: 10932 Reward: 212.8137869399934 avg_loss_c: 2.9483815604361934 avg_loss_a: -44.37259933913963\n",
            "Número de pasos del episodeo 10933 son episode_steps:78\n",
            "Total Steps: 637179 Episode Num: 10933 Reward: 127.59102846680224 avg_loss_c: 3.030022891668173 avg_loss_a: -43.56402793297401\n",
            "Número de pasos del episodeo 10934 son episode_steps:74\n",
            "Total Steps: 637253 Episode Num: 10934 Reward: 119.08117905904045 avg_loss_c: 3.0348270197172424 avg_loss_a: -44.29005555848818\n",
            "Número de pasos del episodeo 10935 son episode_steps:45\n",
            "Total Steps: 637298 Episode Num: 10935 Reward: 45.470744881475 avg_loss_c: 2.9463379700978596 avg_loss_a: -44.579365793863936\n",
            "Número de pasos del episodeo 10936 son episode_steps:243\n",
            "Total Steps: 637541 Episode Num: 10936 Reward: 368.59115636388896 avg_loss_c: 2.9151190401595315 avg_loss_a: -44.36769361456726\n",
            "Número de pasos del episodeo 10937 son episode_steps:132\n",
            "Total Steps: 637673 Episode Num: 10937 Reward: 171.09258166513308 avg_loss_c: 2.773824151718255 avg_loss_a: -44.47053689667673\n",
            "Número de pasos del episodeo 10938 son episode_steps:159\n",
            "Total Steps: 637832 Episode Num: 10938 Reward: 224.53800786453655 avg_loss_c: 2.8687061993580945 avg_loss_a: -44.21765750909002\n",
            "Número de pasos del episodeo 10939 son episode_steps:71\n",
            "Total Steps: 637903 Episode Num: 10939 Reward: 110.7096377054311 avg_loss_c: 2.793315314910781 avg_loss_a: -44.87587383431448\n",
            "Número de pasos del episodeo 10940 son episode_steps:65\n",
            "Total Steps: 637968 Episode Num: 10940 Reward: 102.78494340132337 avg_loss_c: 2.7688828761761006 avg_loss_a: -44.725211158165564\n",
            "Número de pasos del episodeo 10941 son episode_steps:58\n",
            "Total Steps: 638026 Episode Num: 10941 Reward: -10.267870226441069 avg_loss_c: 2.9797344002230415 avg_loss_a: -44.25347821465854\n",
            "Número de pasos del episodeo 10942 son episode_steps:63\n",
            "Total Steps: 638089 Episode Num: 10942 Reward: 110.25558376104871 avg_loss_c: 2.664236689370776 avg_loss_a: -43.86421197558206\n",
            "Número de pasos del episodeo 10943 son episode_steps:51\n",
            "Total Steps: 638140 Episode Num: 10943 Reward: 80.09076130699748 avg_loss_c: 2.942080493066825 avg_loss_a: -44.35554078046013\n",
            "Número de pasos del episodeo 10944 son episode_steps:48\n",
            "Total Steps: 638188 Episode Num: 10944 Reward: 76.73990721920585 avg_loss_c: 2.817810925344626 avg_loss_a: -44.77886724472046\n",
            "Número de pasos del episodeo 10945 son episode_steps:112\n",
            "Total Steps: 638300 Episode Num: 10945 Reward: 169.8402266838261 avg_loss_c: 2.727049494428294 avg_loss_a: -44.43909420285906\n",
            "Número de pasos del episodeo 10946 son episode_steps:80\n",
            "Total Steps: 638380 Episode Num: 10946 Reward: 128.2995571605027 avg_loss_c: 2.8908387064933776 avg_loss_a: -43.97127857208252\n",
            "Número de pasos del episodeo 10947 son episode_steps:54\n",
            "Total Steps: 638434 Episode Num: 10947 Reward: -28.76004759979658 avg_loss_c: 2.857753658736194 avg_loss_a: -44.253966861300995\n",
            "Número de pasos del episodeo 10948 son episode_steps:106\n",
            "Total Steps: 638540 Episode Num: 10948 Reward: 174.2082220607858 avg_loss_c: 2.7331059462619276 avg_loss_a: -44.36920252386129\n",
            "Número de pasos del episodeo 10949 son episode_steps:111\n",
            "Total Steps: 638651 Episode Num: 10949 Reward: 169.23361127589914 avg_loss_c: 2.904875081938666 avg_loss_a: -44.27300970403998\n",
            "Número de pasos del episodeo 10950 son episode_steps:87\n",
            "Total Steps: 638738 Episode Num: 10950 Reward: 134.7602354314285 avg_loss_c: 2.788101901953248 avg_loss_a: -44.89984464097297\n",
            "Número de pasos del episodeo 10951 son episode_steps:69\n",
            "Total Steps: 638807 Episode Num: 10951 Reward: 116.79056724167258 avg_loss_c: 2.6749366297238115 avg_loss_a: -45.30207432180211\n",
            "Número de pasos del episodeo 10952 son episode_steps:61\n",
            "Total Steps: 638868 Episode Num: 10952 Reward: 102.19219470544054 avg_loss_c: 2.5631325303531085 avg_loss_a: -45.25817139422307\n",
            "Número de pasos del episodeo 10953 son episode_steps:88\n",
            "Total Steps: 638956 Episode Num: 10953 Reward: 61.80040195661843 avg_loss_c: 2.6793619096279144 avg_loss_a: -45.16270940954035\n",
            "Número de pasos del episodeo 10954 son episode_steps:131\n",
            "Total Steps: 639087 Episode Num: 10954 Reward: 201.93655114760517 avg_loss_c: 2.661065932448584 avg_loss_a: -44.84091512665494\n",
            "Número de pasos del episodeo 10955 son episode_steps:18\n",
            "Total Steps: 639105 Episode Num: 10955 Reward: -13.382194465607224 avg_loss_c: 2.82290960682763 avg_loss_a: -44.28244145711263\n",
            "Número de pasos del episodeo 10956 son episode_steps:105\n",
            "Total Steps: 639210 Episode Num: 10956 Reward: 150.50408552346804 avg_loss_c: 2.7141212781270343 avg_loss_a: -44.74356122698103\n",
            "Número de pasos del episodeo 10957 son episode_steps:83\n",
            "Total Steps: 639293 Episode Num: 10957 Reward: 151.2610474372876 avg_loss_c: 2.7176668112536513 avg_loss_a: -44.6325036014419\n",
            "Número de pasos del episodeo 10958 son episode_steps:96\n",
            "Total Steps: 639389 Episode Num: 10958 Reward: 153.60725245295458 avg_loss_c: 2.735397775967916 avg_loss_a: -44.710874239603676\n",
            "Número de pasos del episodeo 10959 son episode_steps:84\n",
            "Total Steps: 639473 Episode Num: 10959 Reward: 140.77579295183307 avg_loss_c: 2.737501913592929 avg_loss_a: -45.14189865475609\n",
            "Número de pasos del episodeo 10960 son episode_steps:70\n",
            "Total Steps: 639543 Episode Num: 10960 Reward: 101.13741613845137 avg_loss_c: 2.7409474526132858 avg_loss_a: -44.64446531023298\n",
            "Número de pasos del episodeo 10961 son episode_steps:66\n",
            "Total Steps: 639609 Episode Num: 10961 Reward: 110.06099125041472 avg_loss_c: 2.731215587168029 avg_loss_a: -45.273972020004734\n",
            "Número de pasos del episodeo 10962 son episode_steps:141\n",
            "Total Steps: 639750 Episode Num: 10962 Reward: 115.39100739549032 avg_loss_c: 2.598846252928389 avg_loss_a: -44.903691988464786\n",
            "Número de pasos del episodeo 10963 son episode_steps:146\n",
            "Total Steps: 639896 Episode Num: 10963 Reward: 241.04125498059315 avg_loss_c: 2.7764341235160828 avg_loss_a: -45.44637157492442\n",
            "Número de pasos del episodeo 10964 son episode_steps:109\n",
            "Total Steps: 640005 Episode Num: 10964 Reward: 161.82746957929675 avg_loss_c: 2.812647772491525 avg_loss_a: -44.91760694871255\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 117.040563\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 10965 son episode_steps:74\n",
            "Total Steps: 640079 Episode Num: 10965 Reward: 95.95256988676222 avg_loss_c: 2.6199238622510754 avg_loss_a: -44.98727138622387\n",
            "Número de pasos del episodeo 10966 son episode_steps:86\n",
            "Total Steps: 640165 Episode Num: 10966 Reward: 136.55828283468873 avg_loss_c: 2.5634444550026294 avg_loss_a: -44.95096339735874\n",
            "Número de pasos del episodeo 10967 son episode_steps:61\n",
            "Total Steps: 640226 Episode Num: 10967 Reward: 102.69944414954779 avg_loss_c: 2.594014718884327 avg_loss_a: -44.9672197435723\n",
            "Número de pasos del episodeo 10968 son episode_steps:68\n",
            "Total Steps: 640294 Episode Num: 10968 Reward: 82.61329487748883 avg_loss_c: 2.3885624654152813 avg_loss_a: -45.16387961892521\n",
            "Número de pasos del episodeo 10969 son episode_steps:77\n",
            "Total Steps: 640371 Episode Num: 10969 Reward: 94.06141382942249 avg_loss_c: 2.5362803765705655 avg_loss_a: -44.9581663949149\n",
            "Número de pasos del episodeo 10970 son episode_steps:78\n",
            "Total Steps: 640449 Episode Num: 10970 Reward: 32.233239546744535 avg_loss_c: 2.781532334975707 avg_loss_a: -45.06776770567283\n",
            "Número de pasos del episodeo 10971 son episode_steps:105\n",
            "Total Steps: 640554 Episode Num: 10971 Reward: 69.2103904295694 avg_loss_c: 2.7489143280755908 avg_loss_a: -45.41908533005488\n",
            "Número de pasos del episodeo 10972 son episode_steps:104\n",
            "Total Steps: 640658 Episode Num: 10972 Reward: 163.60657132912542 avg_loss_c: 2.7696585678137264 avg_loss_a: -44.998746211712174\n",
            "Número de pasos del episodeo 10973 son episode_steps:102\n",
            "Total Steps: 640760 Episode Num: 10973 Reward: 157.38195428584604 avg_loss_c: 2.697192437508527 avg_loss_a: -44.61017885395125\n",
            "Número de pasos del episodeo 10974 son episode_steps:71\n",
            "Total Steps: 640831 Episode Num: 10974 Reward: 110.75896884706361 avg_loss_c: 2.692382943462318 avg_loss_a: -44.296026740275636\n",
            "Número de pasos del episodeo 10975 son episode_steps:47\n",
            "Total Steps: 640878 Episode Num: 10975 Reward: 24.34401771037035 avg_loss_c: 2.981346143052933 avg_loss_a: -44.58944718381192\n",
            "Número de pasos del episodeo 10976 son episode_steps:59\n",
            "Total Steps: 640937 Episode Num: 10976 Reward: 84.7010239462889 avg_loss_c: 2.626420948464992 avg_loss_a: -44.221966048418466\n",
            "Número de pasos del episodeo 10977 son episode_steps:72\n",
            "Total Steps: 641009 Episode Num: 10977 Reward: 115.68886717869226 avg_loss_c: 2.535630249314838 avg_loss_a: -44.33910931481255\n",
            "Número de pasos del episodeo 10978 son episode_steps:55\n",
            "Total Steps: 641064 Episode Num: 10978 Reward: 79.18573415930528 avg_loss_c: 2.482241502675143 avg_loss_a: -44.43923353715376\n",
            "Número de pasos del episodeo 10979 son episode_steps:71\n",
            "Total Steps: 641135 Episode Num: 10979 Reward: 119.19930139756471 avg_loss_c: 2.4994906422118066 avg_loss_a: -44.78617590246066\n",
            "Número de pasos del episodeo 10980 son episode_steps:74\n",
            "Total Steps: 641209 Episode Num: 10980 Reward: 104.28114001548558 avg_loss_c: 2.5709034768310755 avg_loss_a: -44.92258319339237\n",
            "Número de pasos del episodeo 10981 son episode_steps:68\n",
            "Total Steps: 641277 Episode Num: 10981 Reward: 107.98652477316433 avg_loss_c: 2.671685453723459 avg_loss_a: -45.05520427928251\n",
            "Número de pasos del episodeo 10982 son episode_steps:136\n",
            "Total Steps: 641413 Episode Num: 10982 Reward: 216.71573832200013 avg_loss_c: 2.5154828700949166 avg_loss_a: -45.050316474016974\n",
            "Número de pasos del episodeo 10983 son episode_steps:77\n",
            "Total Steps: 641490 Episode Num: 10983 Reward: 24.385568724292167 avg_loss_c: 2.7086913043802436 avg_loss_a: -44.89801837871601\n",
            "Número de pasos del episodeo 10984 son episode_steps:70\n",
            "Total Steps: 641560 Episode Num: 10984 Reward: 97.60134083718751 avg_loss_c: 2.848199270452772 avg_loss_a: -44.97720315115792\n",
            "Número de pasos del episodeo 10985 son episode_steps:95\n",
            "Total Steps: 641655 Episode Num: 10985 Reward: 55.949953018041896 avg_loss_c: 2.7204789914582905 avg_loss_a: -45.07991088064093\n",
            "Número de pasos del episodeo 10986 son episode_steps:43\n",
            "Total Steps: 641698 Episode Num: 10986 Reward: 27.787526389137263 avg_loss_c: 2.7761143196460814 avg_loss_a: -44.8874239367108\n",
            "Número de pasos del episodeo 10987 son episode_steps:109\n",
            "Total Steps: 641807 Episode Num: 10987 Reward: 171.75494716292127 avg_loss_c: 2.7158693698568084 avg_loss_a: -44.889287476145896\n",
            "Número de pasos del episodeo 10988 son episode_steps:97\n",
            "Total Steps: 641904 Episode Num: 10988 Reward: 149.99188963642715 avg_loss_c: 2.679318367820425 avg_loss_a: -44.82901347052191\n",
            "Número de pasos del episodeo 10989 son episode_steps:63\n",
            "Total Steps: 641967 Episode Num: 10989 Reward: 107.0817266539895 avg_loss_c: 2.6608642093719 avg_loss_a: -45.129945785280256\n",
            "Número de pasos del episodeo 10990 son episode_steps:88\n",
            "Total Steps: 642055 Episode Num: 10990 Reward: 158.278351592899 avg_loss_c: 2.7223181656815787 avg_loss_a: -44.9441256089644\n",
            "Número de pasos del episodeo 10991 son episode_steps:79\n",
            "Total Steps: 642134 Episode Num: 10991 Reward: 29.674245313241236 avg_loss_c: 2.79993228670917 avg_loss_a: -44.33051048954831\n",
            "Número de pasos del episodeo 10992 son episode_steps:65\n",
            "Total Steps: 642199 Episode Num: 10992 Reward: 18.740058071628624 avg_loss_c: 2.8299982621119573 avg_loss_a: -44.44557982224684\n",
            "Número de pasos del episodeo 10993 son episode_steps:113\n",
            "Total Steps: 642312 Episode Num: 10993 Reward: 172.61275481727344 avg_loss_c: 2.942918783795517 avg_loss_a: -44.70440157324867\n",
            "Número de pasos del episodeo 10994 son episode_steps:101\n",
            "Total Steps: 642413 Episode Num: 10994 Reward: 173.23320821154357 avg_loss_c: 2.6992546662245647 avg_loss_a: -45.45386157649578\n",
            "Número de pasos del episodeo 10995 son episode_steps:71\n",
            "Total Steps: 642484 Episode Num: 10995 Reward: 104.61023880594975 avg_loss_c: 2.627203106880188 avg_loss_a: -45.58174670582086\n",
            "Número de pasos del episodeo 10996 son episode_steps:50\n",
            "Total Steps: 642534 Episode Num: 10996 Reward: 10.925778210100095 avg_loss_c: 2.7502807497978212 avg_loss_a: -44.84779006958008\n",
            "Número de pasos del episodeo 10997 son episode_steps:92\n",
            "Total Steps: 642626 Episode Num: 10997 Reward: 134.07000123036 avg_loss_c: 2.813533385162768 avg_loss_a: -44.84171461022419\n",
            "Número de pasos del episodeo 10998 son episode_steps:179\n",
            "Total Steps: 642805 Episode Num: 10998 Reward: 256.3312749761615 avg_loss_c: 2.7370982230042613 avg_loss_a: -45.356925261087255\n",
            "Número de pasos del episodeo 10999 son episode_steps:85\n",
            "Total Steps: 642890 Episode Num: 10999 Reward: 136.50585467725452 avg_loss_c: 2.8170560247757854 avg_loss_a: -45.087264880012064\n",
            "Número de pasos del episodeo 11000 son episode_steps:98\n",
            "Total Steps: 642988 Episode Num: 11000 Reward: 161.31057313101573 avg_loss_c: 2.7237510960929248 avg_loss_a: -45.62099635844328\n",
            "Número de pasos del episodeo 11001 son episode_steps:65\n",
            "Total Steps: 643053 Episode Num: 11001 Reward: 73.25338504667327 avg_loss_c: 2.7321725368499754 avg_loss_a: -44.63187062190129\n",
            "Número de pasos del episodeo 11002 son episode_steps:86\n",
            "Total Steps: 643139 Episode Num: 11002 Reward: 139.33287748637434 avg_loss_c: 2.598736133686332 avg_loss_a: -45.18705696283385\n",
            "Número de pasos del episodeo 11003 son episode_steps:81\n",
            "Total Steps: 643220 Episode Num: 11003 Reward: 84.98109385521153 avg_loss_c: 2.7505848731523677 avg_loss_a: -45.165909284426846\n",
            "Número de pasos del episodeo 11004 son episode_steps:62\n",
            "Total Steps: 643282 Episode Num: 11004 Reward: 9.877181432898421 avg_loss_c: 3.2070666320862307 avg_loss_a: -44.98501513081212\n",
            "Número de pasos del episodeo 11005 son episode_steps:179\n",
            "Total Steps: 643461 Episode Num: 11005 Reward: 279.7341600094792 avg_loss_c: 2.7796394039132744 avg_loss_a: -45.103687584733166\n",
            "Número de pasos del episodeo 11006 son episode_steps:157\n",
            "Total Steps: 643618 Episode Num: 11006 Reward: 164.77407454404727 avg_loss_c: 2.8401675285047787 avg_loss_a: -45.186674348867626\n",
            "Número de pasos del episodeo 11007 son episode_steps:47\n",
            "Total Steps: 643665 Episode Num: 11007 Reward: 74.08197925004293 avg_loss_c: 2.7961354331767305 avg_loss_a: -46.02729561988344\n",
            "Número de pasos del episodeo 11008 son episode_steps:66\n",
            "Total Steps: 643731 Episode Num: 11008 Reward: 109.84645443803599 avg_loss_c: 2.818889195268804 avg_loss_a: -45.23340930360736\n",
            "Número de pasos del episodeo 11009 son episode_steps:109\n",
            "Total Steps: 643840 Episode Num: 11009 Reward: 165.1907046792297 avg_loss_c: 2.8431646605150416 avg_loss_a: -45.287076757588515\n",
            "Número de pasos del episodeo 11010 son episode_steps:121\n",
            "Total Steps: 643961 Episode Num: 11010 Reward: 168.44941417073588 avg_loss_c: 2.845304422142092 avg_loss_a: -45.32948060469194\n",
            "Número de pasos del episodeo 11011 son episode_steps:90\n",
            "Total Steps: 644051 Episode Num: 11011 Reward: 144.51024879122704 avg_loss_c: 2.661348017056783 avg_loss_a: -45.30038630167643\n",
            "Número de pasos del episodeo 11012 son episode_steps:62\n",
            "Total Steps: 644113 Episode Num: 11012 Reward: 16.766761073120442 avg_loss_c: 2.8537447490999774 avg_loss_a: -46.552411110170425\n",
            "Número de pasos del episodeo 11013 son episode_steps:77\n",
            "Total Steps: 644190 Episode Num: 11013 Reward: 9.214374378710279 avg_loss_c: 3.442252391344541 avg_loss_a: -45.01940774298333\n",
            "Número de pasos del episodeo 11014 son episode_steps:74\n",
            "Total Steps: 644264 Episode Num: 11014 Reward: 111.55351576473022 avg_loss_c: 3.0576368087046855 avg_loss_a: -45.41052668803447\n",
            "Número de pasos del episodeo 11015 son episode_steps:65\n",
            "Total Steps: 644329 Episode Num: 11015 Reward: 92.90097910477756 avg_loss_c: 2.862129576389606 avg_loss_a: -45.58422035804162\n",
            "Número de pasos del episodeo 11016 son episode_steps:56\n",
            "Total Steps: 644385 Episode Num: 11016 Reward: 89.44136709463837 avg_loss_c: 2.9024550084556853 avg_loss_a: -45.696811539786204\n",
            "Número de pasos del episodeo 11017 son episode_steps:77\n",
            "Total Steps: 644462 Episode Num: 11017 Reward: 121.9673410122345 avg_loss_c: 2.8934184297338708 avg_loss_a: -45.346668639740386\n",
            "Número de pasos del episodeo 11018 son episode_steps:75\n",
            "Total Steps: 644537 Episode Num: 11018 Reward: 116.19197345128482 avg_loss_c: 2.8311052719751992 avg_loss_a: -45.68723129272461\n",
            "Número de pasos del episodeo 11019 son episode_steps:77\n",
            "Total Steps: 644614 Episode Num: 11019 Reward: 111.07495483567156 avg_loss_c: 2.8644037417003085 avg_loss_a: -45.89462503210291\n",
            "Número de pasos del episodeo 11020 son episode_steps:87\n",
            "Total Steps: 644701 Episode Num: 11020 Reward: 133.58379019794657 avg_loss_c: 3.0360628284257034 avg_loss_a: -45.59405289573231\n",
            "Número de pasos del episodeo 11021 son episode_steps:89\n",
            "Total Steps: 644790 Episode Num: 11021 Reward: 131.08259187621618 avg_loss_c: 2.922317511579964 avg_loss_a: -45.12084095129806\n",
            "Número de pasos del episodeo 11022 son episode_steps:125\n",
            "Total Steps: 644915 Episode Num: 11022 Reward: 189.72941490463478 avg_loss_c: 2.962675684928894 avg_loss_a: -45.611604675292966\n",
            "Número de pasos del episodeo 11023 son episode_steps:87\n",
            "Total Steps: 645002 Episode Num: 11023 Reward: 8.812383426648642 avg_loss_c: 3.0675042251060747 avg_loss_a: -45.37684885660807\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 137.829950\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11024 son episode_steps:58\n",
            "Total Steps: 645060 Episode Num: 11024 Reward: 97.27246364005319 avg_loss_c: 3.2130638689830384 avg_loss_a: -45.176522353599815\n",
            "Número de pasos del episodeo 11025 son episode_steps:90\n",
            "Total Steps: 645150 Episode Num: 11025 Reward: 145.4433608233505 avg_loss_c: 2.7193535142474703 avg_loss_a: -45.42330390082465\n",
            "Número de pasos del episodeo 11026 son episode_steps:113\n",
            "Total Steps: 645263 Episode Num: 11026 Reward: 34.7436160004476 avg_loss_c: 2.943416027896172 avg_loss_a: -45.125085206158396\n",
            "Número de pasos del episodeo 11027 son episode_steps:93\n",
            "Total Steps: 645356 Episode Num: 11027 Reward: 143.9317577667511 avg_loss_c: 2.8567609261440974 avg_loss_a: -45.34274488879788\n",
            "Número de pasos del episodeo 11028 son episode_steps:85\n",
            "Total Steps: 645441 Episode Num: 11028 Reward: 27.408876916510238 avg_loss_c: 3.195169112261604 avg_loss_a: -45.456341283461626\n",
            "Número de pasos del episodeo 11029 son episode_steps:69\n",
            "Total Steps: 645510 Episode Num: 11029 Reward: 102.485918147845 avg_loss_c: 3.003783056701439 avg_loss_a: -46.08483953061311\n",
            "Número de pasos del episodeo 11030 son episode_steps:61\n",
            "Total Steps: 645571 Episode Num: 11030 Reward: 81.01087433834033 avg_loss_c: 2.81387710375864 avg_loss_a: -45.40878177079998\n",
            "Número de pasos del episodeo 11031 son episode_steps:60\n",
            "Total Steps: 645631 Episode Num: 11031 Reward: 99.95284534252215 avg_loss_c: 3.0093749900658926 avg_loss_a: -45.373547617594404\n",
            "Número de pasos del episodeo 11032 son episode_steps:68\n",
            "Total Steps: 645699 Episode Num: 11032 Reward: 106.7483825044437 avg_loss_c: 2.9409692304975845 avg_loss_a: -45.36335776833927\n",
            "Número de pasos del episodeo 11033 son episode_steps:56\n",
            "Total Steps: 645755 Episode Num: 11033 Reward: 15.899450763591773 avg_loss_c: 3.137192572866167 avg_loss_a: -45.86890043531145\n",
            "Número de pasos del episodeo 11034 son episode_steps:63\n",
            "Total Steps: 645818 Episode Num: 11034 Reward: 99.12627310015714 avg_loss_c: 3.025127991797432 avg_loss_a: -45.28796798463852\n",
            "Número de pasos del episodeo 11035 son episode_steps:142\n",
            "Total Steps: 645960 Episode Num: 11035 Reward: 139.13499567963004 avg_loss_c: 3.117337290669831 avg_loss_a: -45.380261219723124\n",
            "Número de pasos del episodeo 11036 son episode_steps:93\n",
            "Total Steps: 646053 Episode Num: 11036 Reward: 131.05450026912143 avg_loss_c: 2.8090451673794816 avg_loss_a: -45.72395656954858\n",
            "Número de pasos del episodeo 11037 son episode_steps:103\n",
            "Total Steps: 646156 Episode Num: 11037 Reward: 151.3744397935394 avg_loss_c: 2.9852476073700247 avg_loss_a: -45.7503995432437\n",
            "Número de pasos del episodeo 11038 son episode_steps:48\n",
            "Total Steps: 646204 Episode Num: 11038 Reward: 44.18948191414025 avg_loss_c: 3.012817583978176 avg_loss_a: -45.48906993865967\n",
            "Número de pasos del episodeo 11039 son episode_steps:74\n",
            "Total Steps: 646278 Episode Num: 11039 Reward: 129.55960579265775 avg_loss_c: 3.027927722479846 avg_loss_a: -46.06191655751821\n",
            "Número de pasos del episodeo 11040 son episode_steps:143\n",
            "Total Steps: 646421 Episode Num: 11040 Reward: 223.19194360532285 avg_loss_c: 3.0223295872028055 avg_loss_a: -45.572163295078944\n",
            "Número de pasos del episodeo 11041 son episode_steps:135\n",
            "Total Steps: 646556 Episode Num: 11041 Reward: 189.94689397273797 avg_loss_c: 2.9016032183611835 avg_loss_a: -45.98061466923466\n",
            "Número de pasos del episodeo 11042 son episode_steps:135\n",
            "Total Steps: 646691 Episode Num: 11042 Reward: 225.20010890413195 avg_loss_c: 3.0458347408859816 avg_loss_a: -46.47878573382342\n",
            "Número de pasos del episodeo 11043 son episode_steps:123\n",
            "Total Steps: 646814 Episode Num: 11043 Reward: 191.25464639562878 avg_loss_c: 2.934630624647063 avg_loss_a: -45.85702951943002\n",
            "Número de pasos del episodeo 11044 son episode_steps:136\n",
            "Total Steps: 646950 Episode Num: 11044 Reward: 217.21603420216135 avg_loss_c: 2.8860510605223038 avg_loss_a: -45.70156905230354\n",
            "Número de pasos del episodeo 11045 son episode_steps:88\n",
            "Total Steps: 647038 Episode Num: 11045 Reward: 121.54946169922903 avg_loss_c: 2.7433658797632563 avg_loss_a: -46.150306008078836\n",
            "Número de pasos del episodeo 11046 son episode_steps:69\n",
            "Total Steps: 647107 Episode Num: 11046 Reward: 91.24116171336824 avg_loss_c: 2.727048194926718 avg_loss_a: -45.93797346474468\n",
            "Número de pasos del episodeo 11047 son episode_steps:91\n",
            "Total Steps: 647198 Episode Num: 11047 Reward: 109.54976106199396 avg_loss_c: 2.8090738621386855 avg_loss_a: -46.29933418022407\n",
            "Número de pasos del episodeo 11048 son episode_steps:66\n",
            "Total Steps: 647264 Episode Num: 11048 Reward: 94.6591610280895 avg_loss_c: 2.9539888826283542 avg_loss_a: -46.339235016793914\n",
            "Número de pasos del episodeo 11049 son episode_steps:60\n",
            "Total Steps: 647324 Episode Num: 11049 Reward: 100.57344276969026 avg_loss_c: 2.6201689104239145 avg_loss_a: -46.028982925415036\n",
            "Número de pasos del episodeo 11050 son episode_steps:113\n",
            "Total Steps: 647437 Episode Num: 11050 Reward: 53.34559124551237 avg_loss_c: 3.0460191880707193 avg_loss_a: -45.998451334185305\n",
            "Número de pasos del episodeo 11051 son episode_steps:124\n",
            "Total Steps: 647561 Episode Num: 11051 Reward: 121.31009179278391 avg_loss_c: 3.1309501076898267 avg_loss_a: -46.07563431032242\n",
            "Número de pasos del episodeo 11052 son episode_steps:165\n",
            "Total Steps: 647726 Episode Num: 11052 Reward: 197.90776410218055 avg_loss_c: 3.0799106186086482 avg_loss_a: -46.09784710046017\n",
            "Número de pasos del episodeo 11053 son episode_steps:70\n",
            "Total Steps: 647796 Episode Num: 11053 Reward: 112.48265276091271 avg_loss_c: 3.1449472989354814 avg_loss_a: -45.93339669363839\n",
            "Número de pasos del episodeo 11054 son episode_steps:133\n",
            "Total Steps: 647929 Episode Num: 11054 Reward: 227.75353381596017 avg_loss_c: 2.8716714032610557 avg_loss_a: -46.52671730787234\n",
            "Número de pasos del episodeo 11055 son episode_steps:94\n",
            "Total Steps: 648023 Episode Num: 11055 Reward: 151.1009882563065 avg_loss_c: 2.9594740677387157 avg_loss_a: -46.167789053409656\n",
            "Número de pasos del episodeo 11056 son episode_steps:50\n",
            "Total Steps: 648073 Episode Num: 11056 Reward: 55.143288101076735 avg_loss_c: 2.8607473874092104 avg_loss_a: -46.2865754699707\n",
            "Número de pasos del episodeo 11057 son episode_steps:80\n",
            "Total Steps: 648153 Episode Num: 11057 Reward: 130.0321205667256 avg_loss_c: 2.956784248352051 avg_loss_a: -46.66793279647827\n",
            "Número de pasos del episodeo 11058 son episode_steps:45\n",
            "Total Steps: 648198 Episode Num: 11058 Reward: 63.729198521530215 avg_loss_c: 2.8077261394924586 avg_loss_a: -45.87280375162761\n",
            "Número de pasos del episodeo 11059 son episode_steps:143\n",
            "Total Steps: 648341 Episode Num: 11059 Reward: 220.45551093291854 avg_loss_c: 3.1388334944531633 avg_loss_a: -46.17885088086962\n",
            "Número de pasos del episodeo 11060 son episode_steps:81\n",
            "Total Steps: 648422 Episode Num: 11060 Reward: 140.3583578468183 avg_loss_c: 2.9883148272832236 avg_loss_a: -46.191395700713734\n",
            "Número de pasos del episodeo 11061 son episode_steps:75\n",
            "Total Steps: 648497 Episode Num: 11061 Reward: 113.82070415997686 avg_loss_c: 3.117263255119324 avg_loss_a: -46.21648234049479\n",
            "Número de pasos del episodeo 11062 son episode_steps:114\n",
            "Total Steps: 648611 Episode Num: 11062 Reward: 172.60025746916855 avg_loss_c: 2.933988860824652 avg_loss_a: -46.59143380951463\n",
            "Número de pasos del episodeo 11063 son episode_steps:151\n",
            "Total Steps: 648762 Episode Num: 11063 Reward: 176.62362680478333 avg_loss_c: 2.94671130338252 avg_loss_a: -45.49049435546067\n",
            "Número de pasos del episodeo 11064 son episode_steps:106\n",
            "Total Steps: 648868 Episode Num: 11064 Reward: 146.1555928378277 avg_loss_c: 2.961744375948636 avg_loss_a: -46.85957955414394\n",
            "Número de pasos del episodeo 11065 son episode_steps:81\n",
            "Total Steps: 648949 Episode Num: 11065 Reward: 124.6115855777423 avg_loss_c: 3.0749267251403243 avg_loss_a: -46.62292301507644\n",
            "Número de pasos del episodeo 11066 son episode_steps:126\n",
            "Total Steps: 649075 Episode Num: 11066 Reward: 19.04368564195478 avg_loss_c: 3.1398089414551142 avg_loss_a: -46.710447402227494\n",
            "Número de pasos del episodeo 11067 son episode_steps:60\n",
            "Total Steps: 649135 Episode Num: 11067 Reward: 90.2521852113886 avg_loss_c: 3.0606857518355053 avg_loss_a: -46.33052864074707\n",
            "Número de pasos del episodeo 11068 son episode_steps:92\n",
            "Total Steps: 649227 Episode Num: 11068 Reward: 159.30284173116112 avg_loss_c: 3.071474131034768 avg_loss_a: -46.35245082689368\n",
            "Número de pasos del episodeo 11069 son episode_steps:219\n",
            "Total Steps: 649446 Episode Num: 11069 Reward: 320.2679785673178 avg_loss_c: 3.049710540466657 avg_loss_a: -46.20281644498921\n",
            "Número de pasos del episodeo 11070 son episode_steps:144\n",
            "Total Steps: 649590 Episode Num: 11070 Reward: 221.9334401113833 avg_loss_c: 3.016231615510252 avg_loss_a: -46.50408003065321\n",
            "Número de pasos del episodeo 11071 son episode_steps:88\n",
            "Total Steps: 649678 Episode Num: 11071 Reward: 97.75192278445303 avg_loss_c: 2.8675551265478134 avg_loss_a: -46.68646517666903\n",
            "Número de pasos del episodeo 11072 son episode_steps:61\n",
            "Total Steps: 649739 Episode Num: 11072 Reward: 92.13716358026923 avg_loss_c: 2.7335376778586964 avg_loss_a: -46.8677544515641\n",
            "Número de pasos del episodeo 11073 son episode_steps:88\n",
            "Total Steps: 649827 Episode Num: 11073 Reward: 125.33023543987794 avg_loss_c: 2.9496514214710756 avg_loss_a: -46.6229698007757\n",
            "Número de pasos del episodeo 11074 son episode_steps:52\n",
            "Total Steps: 649879 Episode Num: 11074 Reward: 74.68518385397708 avg_loss_c: 2.8078019389739404 avg_loss_a: -46.416608370267426\n",
            "Número de pasos del episodeo 11075 son episode_steps:110\n",
            "Total Steps: 649989 Episode Num: 11075 Reward: 172.91246951599703 avg_loss_c: 2.7766750985925848 avg_loss_a: -46.81859006014737\n",
            "Número de pasos del episodeo 11076 son episode_steps:66\n",
            "Total Steps: 650055 Episode Num: 11076 Reward: 87.49867451872048 avg_loss_c: 2.791008806589878 avg_loss_a: -46.35930182717063\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 151.300967\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11077 son episode_steps:126\n",
            "Total Steps: 650181 Episode Num: 11077 Reward: 183.21684767090284 avg_loss_c: 2.770523382557763 avg_loss_a: -46.32481051248217\n",
            "Número de pasos del episodeo 11078 son episode_steps:62\n",
            "Total Steps: 650243 Episode Num: 11078 Reward: 101.64473824414478 avg_loss_c: 2.7554176372866475 avg_loss_a: -46.578729444934474\n",
            "Número de pasos del episodeo 11079 son episode_steps:105\n",
            "Total Steps: 650348 Episode Num: 11079 Reward: 172.6143386972362 avg_loss_c: 2.7064544234957015 avg_loss_a: -46.55929888770694\n",
            "Número de pasos del episodeo 11080 son episode_steps:123\n",
            "Total Steps: 650471 Episode Num: 11080 Reward: 187.30843537383 avg_loss_c: 2.8118570374279486 avg_loss_a: -46.59005523309475\n",
            "Número de pasos del episodeo 11081 son episode_steps:101\n",
            "Total Steps: 650572 Episode Num: 11081 Reward: 149.18614508231613 avg_loss_c: 2.83079997147664 avg_loss_a: -46.68396796802483\n",
            "Número de pasos del episodeo 11082 son episode_steps:81\n",
            "Total Steps: 650653 Episode Num: 11082 Reward: 119.54008053530886 avg_loss_c: 2.5983161779097568 avg_loss_a: -47.32815914389528\n",
            "Número de pasos del episodeo 11083 son episode_steps:123\n",
            "Total Steps: 650776 Episode Num: 11083 Reward: 85.5752275793829 avg_loss_c: 2.72794628530983 avg_loss_a: -47.10047149658203\n",
            "Número de pasos del episodeo 11084 son episode_steps:90\n",
            "Total Steps: 650866 Episode Num: 11084 Reward: 146.72950964891334 avg_loss_c: 2.8480347355206805 avg_loss_a: -46.83385365804036\n",
            "Número de pasos del episodeo 11085 son episode_steps:45\n",
            "Total Steps: 650911 Episode Num: 11085 Reward: 1.6288544378866066 avg_loss_c: 2.872940844959683 avg_loss_a: -47.35612275865343\n",
            "Número de pasos del episodeo 11086 son episode_steps:42\n",
            "Total Steps: 650953 Episode Num: 11086 Reward: 36.320445533942646 avg_loss_c: 2.922270865667434 avg_loss_a: -46.63391676403227\n",
            "Número de pasos del episodeo 11087 son episode_steps:84\n",
            "Total Steps: 651037 Episode Num: 11087 Reward: 135.76386272857036 avg_loss_c: 2.8064500944955006 avg_loss_a: -46.47763806297665\n",
            "Número de pasos del episodeo 11088 son episode_steps:161\n",
            "Total Steps: 651198 Episode Num: 11088 Reward: 259.4492305499749 avg_loss_c: 2.886298604633497 avg_loss_a: -46.67750869182326\n",
            "Número de pasos del episodeo 11089 son episode_steps:91\n",
            "Total Steps: 651289 Episode Num: 11089 Reward: 152.238926815561 avg_loss_c: 2.8118161735953864 avg_loss_a: -46.9063597878257\n",
            "Número de pasos del episodeo 11090 son episode_steps:168\n",
            "Total Steps: 651457 Episode Num: 11090 Reward: 263.1762287112206 avg_loss_c: 2.908430116517203 avg_loss_a: -46.86945465632847\n",
            "Número de pasos del episodeo 11091 son episode_steps:51\n",
            "Total Steps: 651508 Episode Num: 11091 Reward: 82.47644416524416 avg_loss_c: 2.708679098708957 avg_loss_a: -46.37588553335152\n",
            "Número de pasos del episodeo 11092 son episode_steps:95\n",
            "Total Steps: 651603 Episode Num: 11092 Reward: 149.63248305916622 avg_loss_c: 2.7498608288012054 avg_loss_a: -46.907422557630035\n",
            "Número de pasos del episodeo 11093 son episode_steps:57\n",
            "Total Steps: 651660 Episode Num: 11093 Reward: 90.75515281742382 avg_loss_c: 2.6905275164989004 avg_loss_a: -47.03454717000326\n",
            "Número de pasos del episodeo 11094 son episode_steps:89\n",
            "Total Steps: 651749 Episode Num: 11094 Reward: 143.58150628517163 avg_loss_c: 2.8440009355545044 avg_loss_a: -46.69596365596471\n",
            "Número de pasos del episodeo 11095 son episode_steps:62\n",
            "Total Steps: 651811 Episode Num: 11095 Reward: 98.00625125112389 avg_loss_c: 2.923390486548024 avg_loss_a: -47.22981963619109\n",
            "Número de pasos del episodeo 11096 son episode_steps:112\n",
            "Total Steps: 651923 Episode Num: 11096 Reward: 150.75796277593255 avg_loss_c: 2.632416364337717 avg_loss_a: -46.584318024771555\n",
            "Número de pasos del episodeo 11097 son episode_steps:33\n",
            "Total Steps: 651956 Episode Num: 11097 Reward: -7.920690907529437 avg_loss_c: 2.601793744347312 avg_loss_a: -47.68293831565163\n",
            "Número de pasos del episodeo 11098 son episode_steps:50\n",
            "Total Steps: 652006 Episode Num: 11098 Reward: 75.1890801071658 avg_loss_c: 3.060158619880676 avg_loss_a: -46.54774948120117\n",
            "Número de pasos del episodeo 11099 son episode_steps:70\n",
            "Total Steps: 652076 Episode Num: 11099 Reward: 123.49173544849786 avg_loss_c: 2.817274764605931 avg_loss_a: -47.15673261369977\n",
            "Número de pasos del episodeo 11100 son episode_steps:76\n",
            "Total Steps: 652152 Episode Num: 11100 Reward: 122.82372628073944 avg_loss_c: 2.7607508207622327 avg_loss_a: -47.2067544836747\n",
            "Número de pasos del episodeo 11101 son episode_steps:72\n",
            "Total Steps: 652224 Episode Num: 11101 Reward: 115.85036141216479 avg_loss_c: 2.747131104270617 avg_loss_a: -46.9767181608412\n",
            "Número de pasos del episodeo 11102 son episode_steps:60\n",
            "Total Steps: 652284 Episode Num: 11102 Reward: 49.09654714165785 avg_loss_c: 2.8124027291933698 avg_loss_a: -47.40625762939453\n",
            "Número de pasos del episodeo 11103 son episode_steps:75\n",
            "Total Steps: 652359 Episode Num: 11103 Reward: 127.98255172127381 avg_loss_c: 2.814115589459737 avg_loss_a: -46.64656397501628\n",
            "Número de pasos del episodeo 11104 son episode_steps:107\n",
            "Total Steps: 652466 Episode Num: 11104 Reward: 25.240322912197563 avg_loss_c: 3.5226690000462755 avg_loss_a: -46.71207695363838\n",
            "Número de pasos del episodeo 11105 son episode_steps:89\n",
            "Total Steps: 652555 Episode Num: 11105 Reward: 142.35462815864358 avg_loss_c: 3.397957742883918 avg_loss_a: -46.8756064511417\n",
            "Número de pasos del episodeo 11106 son episode_steps:115\n",
            "Total Steps: 652670 Episode Num: 11106 Reward: 161.16044814693623 avg_loss_c: 2.8877575677374137 avg_loss_a: -47.330200527025305\n",
            "Número de pasos del episodeo 11107 son episode_steps:77\n",
            "Total Steps: 652747 Episode Num: 11107 Reward: 120.88545403849312 avg_loss_c: 2.9923727171761647 avg_loss_a: -47.62478142280083\n",
            "Número de pasos del episodeo 11108 son episode_steps:46\n",
            "Total Steps: 652793 Episode Num: 11108 Reward: 47.559064106830526 avg_loss_c: 2.788026249927023 avg_loss_a: -47.93226656706437\n",
            "Número de pasos del episodeo 11109 son episode_steps:65\n",
            "Total Steps: 652858 Episode Num: 11109 Reward: 101.39366920695599 avg_loss_c: 2.7827878695267896 avg_loss_a: -47.025357231727014\n",
            "Número de pasos del episodeo 11110 son episode_steps:71\n",
            "Total Steps: 652929 Episode Num: 11110 Reward: 111.71823049354718 avg_loss_c: 3.06107815050743 avg_loss_a: -47.46884789265378\n",
            "Número de pasos del episodeo 11111 son episode_steps:128\n",
            "Total Steps: 653057 Episode Num: 11111 Reward: 194.56146633253363 avg_loss_c: 3.1375623466446996 avg_loss_a: -47.54442435503006\n",
            "Número de pasos del episodeo 11112 son episode_steps:68\n",
            "Total Steps: 653125 Episode Num: 11112 Reward: 113.48847843504622 avg_loss_c: 2.9630334570127377 avg_loss_a: -48.07600066241096\n",
            "Número de pasos del episodeo 11113 son episode_steps:116\n",
            "Total Steps: 653241 Episode Num: 11113 Reward: 131.08763930610723 avg_loss_c: 3.1029563967523903 avg_loss_a: -47.483696115428\n",
            "Número de pasos del episodeo 11114 son episode_steps:46\n",
            "Total Steps: 653287 Episode Num: 11114 Reward: 51.47536451782476 avg_loss_c: 2.976330492807471 avg_loss_a: -48.07564411992612\n",
            "Número de pasos del episodeo 11115 son episode_steps:60\n",
            "Total Steps: 653347 Episode Num: 11115 Reward: 92.82846967912674 avg_loss_c: 3.1974436680475873 avg_loss_a: -47.97867126464844\n",
            "Número de pasos del episodeo 11116 son episode_steps:65\n",
            "Total Steps: 653412 Episode Num: 11116 Reward: 110.05849752043677 avg_loss_c: 2.954472440939683 avg_loss_a: -47.537351696307844\n",
            "Número de pasos del episodeo 11117 son episode_steps:123\n",
            "Total Steps: 653535 Episode Num: 11117 Reward: 85.39891810155838 avg_loss_c: 3.1589583400788346 avg_loss_a: -47.60816208133853\n",
            "Número de pasos del episodeo 11118 son episode_steps:238\n",
            "Total Steps: 653773 Episode Num: 11118 Reward: 350.3435003334139 avg_loss_c: 3.114369763546631 avg_loss_a: -47.568967739073166\n",
            "Número de pasos del episodeo 11119 son episode_steps:73\n",
            "Total Steps: 653846 Episode Num: 11119 Reward: 110.6598666042436 avg_loss_c: 3.0330773477684962 avg_loss_a: -47.45684856258026\n",
            "Número de pasos del episodeo 11120 son episode_steps:61\n",
            "Total Steps: 653907 Episode Num: 11120 Reward: 101.30505673206956 avg_loss_c: 3.2485508723337144 avg_loss_a: -46.73954679145188\n",
            "Número de pasos del episodeo 11121 son episode_steps:65\n",
            "Total Steps: 653972 Episode Num: 11121 Reward: 108.67645837678944 avg_loss_c: 3.019845940516545 avg_loss_a: -47.9606451181265\n",
            "Número de pasos del episodeo 11122 son episode_steps:84\n",
            "Total Steps: 654056 Episode Num: 11122 Reward: 137.12259810962215 avg_loss_c: 3.0183867130960738 avg_loss_a: -47.23943955557687\n",
            "Número de pasos del episodeo 11123 son episode_steps:74\n",
            "Total Steps: 654130 Episode Num: 11123 Reward: 59.83929751165746 avg_loss_c: 3.027945750468486 avg_loss_a: -47.10498036565007\n",
            "Número de pasos del episodeo 11124 son episode_steps:82\n",
            "Total Steps: 654212 Episode Num: 11124 Reward: 129.59752487682633 avg_loss_c: 3.3112350484219992 avg_loss_a: -46.873174713879095\n",
            "Número de pasos del episodeo 11125 son episode_steps:57\n",
            "Total Steps: 654269 Episode Num: 11125 Reward: 88.81580897816772 avg_loss_c: 3.065507784224393 avg_loss_a: -47.80155335811146\n",
            "Número de pasos del episodeo 11126 son episode_steps:99\n",
            "Total Steps: 654368 Episode Num: 11126 Reward: 162.77863170256288 avg_loss_c: 3.170180011277247 avg_loss_a: -47.50646552654228\n",
            "Número de pasos del episodeo 11127 son episode_steps:47\n",
            "Total Steps: 654415 Episode Num: 11127 Reward: 58.64434635564237 avg_loss_c: 3.2659796146636313 avg_loss_a: -47.566738372153424\n",
            "Número de pasos del episodeo 11128 son episode_steps:44\n",
            "Total Steps: 654459 Episode Num: 11128 Reward: 23.590239754067127 avg_loss_c: 2.8417327295650137 avg_loss_a: -47.069219242442735\n",
            "Número de pasos del episodeo 11129 son episode_steps:76\n",
            "Total Steps: 654535 Episode Num: 11129 Reward: 117.17570450640979 avg_loss_c: 3.0858781949469916 avg_loss_a: -47.677383824398646\n",
            "Número de pasos del episodeo 11130 son episode_steps:88\n",
            "Total Steps: 654623 Episode Num: 11130 Reward: 130.96711836453818 avg_loss_c: 3.34009666334499 avg_loss_a: -47.327745871110395\n",
            "Número de pasos del episodeo 11131 son episode_steps:99\n",
            "Total Steps: 654722 Episode Num: 11131 Reward: 171.44874374289427 avg_loss_c: 3.095767951974965 avg_loss_a: -48.279364961566344\n",
            "Número de pasos del episodeo 11132 son episode_steps:58\n",
            "Total Steps: 654780 Episode Num: 11132 Reward: 91.53622583150307 avg_loss_c: 2.9074317812919617 avg_loss_a: -47.51359084556843\n",
            "Número de pasos del episodeo 11133 son episode_steps:72\n",
            "Total Steps: 654852 Episode Num: 11133 Reward: 125.71810027661176 avg_loss_c: 3.2345709088775845 avg_loss_a: -47.84271346198188\n",
            "Número de pasos del episodeo 11134 son episode_steps:83\n",
            "Total Steps: 654935 Episode Num: 11134 Reward: 140.56688404125552 avg_loss_c: 3.048906491463443 avg_loss_a: -47.48333276036274\n",
            "Número de pasos del episodeo 11135 son episode_steps:82\n",
            "Total Steps: 655017 Episode Num: 11135 Reward: 24.525371032393732 avg_loss_c: 3.1513652583447898 avg_loss_a: -47.12780454682141\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 118.483029\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11136 son episode_steps:65\n",
            "Total Steps: 655082 Episode Num: 11136 Reward: 105.33282320034915 avg_loss_c: 3.32301756968865 avg_loss_a: -47.64800778902494\n",
            "Número de pasos del episodeo 11137 son episode_steps:124\n",
            "Total Steps: 655206 Episode Num: 11137 Reward: 172.36478363334086 avg_loss_c: 2.9750147740687094 avg_loss_a: -47.53227695342033\n",
            "Número de pasos del episodeo 11138 son episode_steps:79\n",
            "Total Steps: 655285 Episode Num: 11138 Reward: 134.9953892546943 avg_loss_c: 2.9207912653307373 avg_loss_a: -48.018298378473595\n",
            "Número de pasos del episodeo 11139 son episode_steps:92\n",
            "Total Steps: 655377 Episode Num: 11139 Reward: 147.8029542520047 avg_loss_c: 2.79375763302264 avg_loss_a: -47.28507605842922\n",
            "Número de pasos del episodeo 11140 son episode_steps:63\n",
            "Total Steps: 655440 Episode Num: 11140 Reward: 70.25373686704285 avg_loss_c: 2.8405807869774953 avg_loss_a: -47.19066928681873\n",
            "Número de pasos del episodeo 11141 son episode_steps:86\n",
            "Total Steps: 655526 Episode Num: 11141 Reward: 132.158503208507 avg_loss_c: 2.9223625105480817 avg_loss_a: -47.394729348116144\n",
            "Número de pasos del episodeo 11142 son episode_steps:57\n",
            "Total Steps: 655583 Episode Num: 11142 Reward: 73.29038737315808 avg_loss_c: 2.9400853190505716 avg_loss_a: -47.2923594023052\n",
            "Número de pasos del episodeo 11143 son episode_steps:60\n",
            "Total Steps: 655643 Episode Num: 11143 Reward: 91.7696773615122 avg_loss_c: 3.0851938088734943 avg_loss_a: -47.88062566121419\n",
            "Número de pasos del episodeo 11144 son episode_steps:18\n",
            "Total Steps: 655661 Episode Num: 11144 Reward: -17.66297453392741 avg_loss_c: 3.2572821776072183 avg_loss_a: -47.16687350802951\n",
            "Número de pasos del episodeo 11145 son episode_steps:116\n",
            "Total Steps: 655777 Episode Num: 11145 Reward: 173.91012643731457 avg_loss_c: 3.254079794061595 avg_loss_a: -46.70465147084203\n",
            "Número de pasos del episodeo 11146 son episode_steps:82\n",
            "Total Steps: 655859 Episode Num: 11146 Reward: 111.24651765585496 avg_loss_c: 3.16642169981468 avg_loss_a: -47.40850625387052\n",
            "Número de pasos del episodeo 11147 son episode_steps:91\n",
            "Total Steps: 655950 Episode Num: 11147 Reward: 134.1110877612253 avg_loss_c: 3.276116696032849 avg_loss_a: -47.40668147998852\n",
            "Número de pasos del episodeo 11148 son episode_steps:74\n",
            "Total Steps: 656024 Episode Num: 11148 Reward: 98.19519650930405 avg_loss_c: 2.952107698530764 avg_loss_a: -47.50796075769373\n",
            "Número de pasos del episodeo 11149 son episode_steps:60\n",
            "Total Steps: 656084 Episode Num: 11149 Reward: 68.21021940547985 avg_loss_c: 3.2578474303086598 avg_loss_a: -47.45084800720215\n",
            "Número de pasos del episodeo 11150 son episode_steps:47\n",
            "Total Steps: 656131 Episode Num: 11150 Reward: 48.82215430222416 avg_loss_c: 3.071570619623712 avg_loss_a: -47.772915454621014\n",
            "Número de pasos del episodeo 11151 son episode_steps:141\n",
            "Total Steps: 656272 Episode Num: 11151 Reward: 226.2421091809657 avg_loss_c: 3.0882630745569863 avg_loss_a: -47.80461634642689\n",
            "Número de pasos del episodeo 11152 son episode_steps:58\n",
            "Total Steps: 656330 Episode Num: 11152 Reward: 88.66335352906846 avg_loss_c: 3.06635713988337 avg_loss_a: -47.579213504133556\n",
            "Número de pasos del episodeo 11153 son episode_steps:75\n",
            "Total Steps: 656405 Episode Num: 11153 Reward: 118.96221975696893 avg_loss_c: 3.05676508585612 avg_loss_a: -48.166766255696615\n",
            "Número de pasos del episodeo 11154 son episode_steps:76\n",
            "Total Steps: 656481 Episode Num: 11154 Reward: 127.37364595394682 avg_loss_c: 3.2308196456808793 avg_loss_a: -47.80776917307001\n",
            "Número de pasos del episodeo 11155 son episode_steps:81\n",
            "Total Steps: 656562 Episode Num: 11155 Reward: 112.86426261110843 avg_loss_c: 3.369528047832442 avg_loss_a: -47.49917894528236\n",
            "Número de pasos del episodeo 11156 son episode_steps:115\n",
            "Total Steps: 656677 Episode Num: 11156 Reward: 189.60966701126827 avg_loss_c: 2.8991594076156617 avg_loss_a: -47.7257698059082\n",
            "Número de pasos del episodeo 11157 son episode_steps:107\n",
            "Total Steps: 656784 Episode Num: 11157 Reward: 167.08075598728576 avg_loss_c: 3.17429491404061 avg_loss_a: -47.49420732872508\n",
            "Número de pasos del episodeo 11158 son episode_steps:154\n",
            "Total Steps: 656938 Episode Num: 11158 Reward: 259.9327429395305 avg_loss_c: 3.1684391397934455 avg_loss_a: -48.04230335780552\n",
            "Número de pasos del episodeo 11159 son episode_steps:109\n",
            "Total Steps: 657047 Episode Num: 11159 Reward: 182.5426317549599 avg_loss_c: 3.254494551124923 avg_loss_a: -47.819070098596974\n",
            "Número de pasos del episodeo 11160 son episode_steps:64\n",
            "Total Steps: 657111 Episode Num: 11160 Reward: 93.29232259187285 avg_loss_c: 3.138589471578598 avg_loss_a: -48.40623474121094\n",
            "Número de pasos del episodeo 11161 son episode_steps:84\n",
            "Total Steps: 657195 Episode Num: 11161 Reward: 136.89050021698552 avg_loss_c: 3.1240664436703636 avg_loss_a: -48.12435522533598\n",
            "Número de pasos del episodeo 11162 son episode_steps:98\n",
            "Total Steps: 657293 Episode Num: 11162 Reward: 162.4121707687961 avg_loss_c: 2.9559117409647726 avg_loss_a: -47.958747941620494\n",
            "Número de pasos del episodeo 11163 son episode_steps:77\n",
            "Total Steps: 657370 Episode Num: 11163 Reward: 132.60798222617296 avg_loss_c: 2.7299807520655843 avg_loss_a: -47.947021583458046\n",
            "Número de pasos del episodeo 11164 son episode_steps:133\n",
            "Total Steps: 657503 Episode Num: 11164 Reward: 203.44782490542502 avg_loss_c: 3.03494483904731 avg_loss_a: -48.01468629765331\n",
            "Número de pasos del episodeo 11165 son episode_steps:77\n",
            "Total Steps: 657580 Episode Num: 11165 Reward: 115.43218361481655 avg_loss_c: 3.1681349556167406 avg_loss_a: -48.108750380478895\n",
            "Número de pasos del episodeo 11166 son episode_steps:66\n",
            "Total Steps: 657646 Episode Num: 11166 Reward: 107.30715743980959 avg_loss_c: 2.7992403904596963 avg_loss_a: -48.02698308771307\n",
            "Número de pasos del episodeo 11167 son episode_steps:123\n",
            "Total Steps: 657769 Episode Num: 11167 Reward: 164.44288875423035 avg_loss_c: 2.9377212611640373 avg_loss_a: -48.1268821964419\n",
            "Número de pasos del episodeo 11168 son episode_steps:102\n",
            "Total Steps: 657871 Episode Num: 11168 Reward: 173.7304530403874 avg_loss_c: 2.868250907636156 avg_loss_a: -47.828185287176396\n",
            "Número de pasos del episodeo 11169 son episode_steps:116\n",
            "Total Steps: 657987 Episode Num: 11169 Reward: 125.9740970093426 avg_loss_c: 3.081183205390799 avg_loss_a: -48.23786761842925\n",
            "Número de pasos del episodeo 11170 son episode_steps:58\n",
            "Total Steps: 658045 Episode Num: 11170 Reward: 94.13758742208307 avg_loss_c: 2.8540430685569502 avg_loss_a: -48.68534430142107\n",
            "Número de pasos del episodeo 11171 son episode_steps:75\n",
            "Total Steps: 658120 Episode Num: 11171 Reward: 116.3919076310485 avg_loss_c: 3.288487819035848 avg_loss_a: -48.11637812296549\n",
            "Número de pasos del episodeo 11172 son episode_steps:63\n",
            "Total Steps: 658183 Episode Num: 11172 Reward: 59.273265598899975 avg_loss_c: 3.112090298107692 avg_loss_a: -48.243828364780974\n",
            "Número de pasos del episodeo 11173 son episode_steps:178\n",
            "Total Steps: 658361 Episode Num: 11173 Reward: 278.59329422773925 avg_loss_c: 2.904874623491523 avg_loss_a: -48.14463274666433\n",
            "Número de pasos del episodeo 11174 son episode_steps:60\n",
            "Total Steps: 658421 Episode Num: 11174 Reward: 91.25558664689417 avg_loss_c: 3.180322712659836 avg_loss_a: -48.44253679911296\n",
            "Número de pasos del episodeo 11175 son episode_steps:47\n",
            "Total Steps: 658468 Episode Num: 11175 Reward: 52.41718682425813 avg_loss_c: 3.1396773597027394 avg_loss_a: -48.17904930926384\n",
            "Número de pasos del episodeo 11176 son episode_steps:68\n",
            "Total Steps: 658536 Episode Num: 11176 Reward: 107.7459176809918 avg_loss_c: 3.2776756514521206 avg_loss_a: -48.121026207419\n",
            "Número de pasos del episodeo 11177 son episode_steps:59\n",
            "Total Steps: 658595 Episode Num: 11177 Reward: 77.32975219134032 avg_loss_c: 3.2285816790693898 avg_loss_a: -48.68649848032806\n",
            "Número de pasos del episodeo 11178 son episode_steps:143\n",
            "Total Steps: 658738 Episode Num: 11178 Reward: 211.85278377280736 avg_loss_c: 2.9430082627943346 avg_loss_a: -48.74791456102491\n",
            "Número de pasos del episodeo 11179 son episode_steps:93\n",
            "Total Steps: 658831 Episode Num: 11179 Reward: 131.67035813978833 avg_loss_c: 2.988720425995447 avg_loss_a: -48.53087345246346\n",
            "Número de pasos del episodeo 11180 son episode_steps:112\n",
            "Total Steps: 658943 Episode Num: 11180 Reward: 161.6650577357647 avg_loss_c: 3.0955734657389775 avg_loss_a: -48.913910729544504\n",
            "Número de pasos del episodeo 11181 son episode_steps:83\n",
            "Total Steps: 659026 Episode Num: 11181 Reward: 131.4543805307443 avg_loss_c: 2.90264973008489 avg_loss_a: -48.62550643553217\n",
            "Número de pasos del episodeo 11182 son episode_steps:55\n",
            "Total Steps: 659081 Episode Num: 11182 Reward: 84.26700842458605 avg_loss_c: 3.105398498881947 avg_loss_a: -48.95179332386363\n",
            "Número de pasos del episodeo 11183 son episode_steps:119\n",
            "Total Steps: 659200 Episode Num: 11183 Reward: 183.04892238595028 avg_loss_c: 2.880951348473044 avg_loss_a: -48.70407139754095\n",
            "Número de pasos del episodeo 11184 son episode_steps:93\n",
            "Total Steps: 659293 Episode Num: 11184 Reward: 139.8157752083238 avg_loss_c: 2.9369696558162732 avg_loss_a: -49.01706986786217\n",
            "Número de pasos del episodeo 11185 son episode_steps:98\n",
            "Total Steps: 659391 Episode Num: 11185 Reward: 154.3218729762631 avg_loss_c: 2.9322844768057066 avg_loss_a: -48.498167466144174\n",
            "Número de pasos del episodeo 11186 son episode_steps:47\n",
            "Total Steps: 659438 Episode Num: 11186 Reward: 45.45564118201436 avg_loss_c: 2.971418023109436 avg_loss_a: -48.68305214415205\n",
            "Número de pasos del episodeo 11187 son episode_steps:155\n",
            "Total Steps: 659593 Episode Num: 11187 Reward: 258.16456293195154 avg_loss_c: 3.1132687422537035 avg_loss_a: -48.87451422906691\n",
            "Número de pasos del episodeo 11188 son episode_steps:65\n",
            "Total Steps: 659658 Episode Num: 11188 Reward: 8.916974469745204 avg_loss_c: 3.1210892365528986 avg_loss_a: -48.53975589458759\n",
            "Número de pasos del episodeo 11189 son episode_steps:90\n",
            "Total Steps: 659748 Episode Num: 11189 Reward: 141.96663156573763 avg_loss_c: 2.8951719350285 avg_loss_a: -49.0147592332628\n",
            "Número de pasos del episodeo 11190 son episode_steps:73\n",
            "Total Steps: 659821 Episode Num: 11190 Reward: 39.52098862081716 avg_loss_c: 3.0074337916831446 avg_loss_a: -48.645033901684904\n",
            "Número de pasos del episodeo 11191 son episode_steps:135\n",
            "Total Steps: 659956 Episode Num: 11191 Reward: 212.51323459040586 avg_loss_c: 3.1203515662087336 avg_loss_a: -48.44029080426252\n",
            "Número de pasos del episodeo 11192 son episode_steps:90\n",
            "Total Steps: 660046 Episode Num: 11192 Reward: 141.65105334552567 avg_loss_c: 2.727782204416063 avg_loss_a: -48.76362135145399\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 135.378502\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11193 son episode_steps:57\n",
            "Total Steps: 660103 Episode Num: 11193 Reward: 91.40274032940518 avg_loss_c: 2.8356832935099017 avg_loss_a: -48.85247514958967\n",
            "Número de pasos del episodeo 11194 son episode_steps:160\n",
            "Total Steps: 660263 Episode Num: 11194 Reward: 253.06504741444908 avg_loss_c: 2.8951810494065287 avg_loss_a: -48.46538004875183\n",
            "Número de pasos del episodeo 11195 son episode_steps:72\n",
            "Total Steps: 660335 Episode Num: 11195 Reward: 122.85215532293294 avg_loss_c: 2.996533046166102 avg_loss_a: -48.334676848517525\n",
            "Número de pasos del episodeo 11196 son episode_steps:93\n",
            "Total Steps: 660428 Episode Num: 11196 Reward: 137.13660386140802 avg_loss_c: 3.0472112240329867 avg_loss_a: -49.27997113299626\n",
            "Número de pasos del episodeo 11197 son episode_steps:116\n",
            "Total Steps: 660544 Episode Num: 11197 Reward: 186.89731880788744 avg_loss_c: 3.1262988766719557 avg_loss_a: -49.01638050737052\n",
            "Número de pasos del episodeo 11198 son episode_steps:20\n",
            "Total Steps: 660564 Episode Num: 11198 Reward: -46.18649921815759 avg_loss_c: 2.711212730407715 avg_loss_a: -48.25657615661621\n",
            "Número de pasos del episodeo 11199 son episode_steps:150\n",
            "Total Steps: 660714 Episode Num: 11199 Reward: 242.82158255196413 avg_loss_c: 3.299945374329885 avg_loss_a: -48.76382858276367\n",
            "Número de pasos del episodeo 11200 son episode_steps:150\n",
            "Total Steps: 660864 Episode Num: 11200 Reward: 219.9731673721472 avg_loss_c: 2.9603234640757243 avg_loss_a: -48.953560231526694\n",
            "Número de pasos del episodeo 11201 son episode_steps:70\n",
            "Total Steps: 660934 Episode Num: 11201 Reward: 117.11573394207912 avg_loss_c: 2.8460324747221812 avg_loss_a: -48.845599801199775\n",
            "Número de pasos del episodeo 11202 son episode_steps:41\n",
            "Total Steps: 660975 Episode Num: 11202 Reward: 34.827053273854105 avg_loss_c: 2.8938423133477933 avg_loss_a: -48.42851815572599\n",
            "Número de pasos del episodeo 11203 son episode_steps:112\n",
            "Total Steps: 661087 Episode Num: 11203 Reward: 127.26311116073032 avg_loss_c: 3.195162819964545 avg_loss_a: -49.29888752528599\n",
            "Número de pasos del episodeo 11204 son episode_steps:108\n",
            "Total Steps: 661195 Episode Num: 11204 Reward: 175.99695896632184 avg_loss_c: 3.0481049473638886 avg_loss_a: -49.231607295848704\n",
            "Número de pasos del episodeo 11205 son episode_steps:100\n",
            "Total Steps: 661295 Episode Num: 11205 Reward: 132.06491292279 avg_loss_c: 3.3304282808303833 avg_loss_a: -49.32649574279785\n",
            "Número de pasos del episodeo 11206 son episode_steps:45\n",
            "Total Steps: 661340 Episode Num: 11206 Reward: 47.54824273426661 avg_loss_c: 3.4913517077763876 avg_loss_a: -49.23545845879449\n",
            "Número de pasos del episodeo 11207 son episode_steps:172\n",
            "Total Steps: 661512 Episode Num: 11207 Reward: 266.20716720056157 avg_loss_c: 3.202461314755817 avg_loss_a: -49.31899580844613\n",
            "Número de pasos del episodeo 11208 son episode_steps:95\n",
            "Total Steps: 661607 Episode Num: 11208 Reward: 148.11408593277417 avg_loss_c: 3.0293772245708266 avg_loss_a: -50.06411446019223\n",
            "Número de pasos del episodeo 11209 son episode_steps:200\n",
            "Total Steps: 661807 Episode Num: 11209 Reward: 279.72074421613735 avg_loss_c: 3.0874595952034 avg_loss_a: -49.87287792205811\n",
            "Número de pasos del episodeo 11210 son episode_steps:92\n",
            "Total Steps: 661899 Episode Num: 11210 Reward: 147.23533407045932 avg_loss_c: 2.9475451928118 avg_loss_a: -49.78588701331097\n",
            "Número de pasos del episodeo 11211 son episode_steps:160\n",
            "Total Steps: 662059 Episode Num: 11211 Reward: 197.5354569056333 avg_loss_c: 3.104755041748285 avg_loss_a: -49.94749712944031\n",
            "Número de pasos del episodeo 11212 son episode_steps:110\n",
            "Total Steps: 662169 Episode Num: 11212 Reward: 167.705358903771 avg_loss_c: 3.110766200585799 avg_loss_a: -50.05614055286754\n",
            "Número de pasos del episodeo 11213 son episode_steps:68\n",
            "Total Steps: 662237 Episode Num: 11213 Reward: 101.82899805328745 avg_loss_c: 2.954036302426282 avg_loss_a: -49.95131638470818\n",
            "Número de pasos del episodeo 11214 son episode_steps:68\n",
            "Total Steps: 662305 Episode Num: 11214 Reward: 100.09744806915516 avg_loss_c: 3.0565846369547 avg_loss_a: -49.95187063778148\n",
            "Número de pasos del episodeo 11215 son episode_steps:136\n",
            "Total Steps: 662441 Episode Num: 11215 Reward: 206.45556331691247 avg_loss_c: 3.0353687800028744 avg_loss_a: -49.95063950033749\n",
            "Número de pasos del episodeo 11216 son episode_steps:64\n",
            "Total Steps: 662505 Episode Num: 11216 Reward: 91.14009570394255 avg_loss_c: 2.985816093161702 avg_loss_a: -50.49657893180847\n",
            "Número de pasos del episodeo 11217 son episode_steps:116\n",
            "Total Steps: 662621 Episode Num: 11217 Reward: 156.15910581519665 avg_loss_c: 3.3126203962441148 avg_loss_a: -49.88131509978196\n",
            "Número de pasos del episodeo 11218 son episode_steps:105\n",
            "Total Steps: 662726 Episode Num: 11218 Reward: 172.35806314090817 avg_loss_c: 2.9124386344637188 avg_loss_a: -49.81611724126907\n",
            "Número de pasos del episodeo 11219 son episode_steps:149\n",
            "Total Steps: 662875 Episode Num: 11219 Reward: 229.0380237068374 avg_loss_c: 2.826813481798108 avg_loss_a: -50.55385958268339\n",
            "Número de pasos del episodeo 11220 son episode_steps:157\n",
            "Total Steps: 663032 Episode Num: 11220 Reward: 213.69555861552476 avg_loss_c: 2.8887119779161585 avg_loss_a: -50.141375620653676\n",
            "Número de pasos del episodeo 11221 son episode_steps:130\n",
            "Total Steps: 663162 Episode Num: 11221 Reward: 177.41913596569592 avg_loss_c: 2.978448410217579 avg_loss_a: -50.50315405038687\n",
            "Número de pasos del episodeo 11222 son episode_steps:118\n",
            "Total Steps: 663280 Episode Num: 11222 Reward: 179.89851957299456 avg_loss_c: 3.316720201807507 avg_loss_a: -50.945517200534624\n",
            "Número de pasos del episodeo 11223 son episode_steps:77\n",
            "Total Steps: 663357 Episode Num: 11223 Reward: 87.38647177125968 avg_loss_c: 3.0530835374609215 avg_loss_a: -50.69448054920543\n",
            "Número de pasos del episodeo 11224 son episode_steps:60\n",
            "Total Steps: 663417 Episode Num: 11224 Reward: 94.59483461036537 avg_loss_c: 3.05493571360906 avg_loss_a: -50.20079650878906\n",
            "Número de pasos del episodeo 11225 son episode_steps:63\n",
            "Total Steps: 663480 Episode Num: 11225 Reward: 98.68807484240234 avg_loss_c: 3.0290812613472107 avg_loss_a: -49.708262549506294\n",
            "Número de pasos del episodeo 11226 son episode_steps:75\n",
            "Total Steps: 663555 Episode Num: 11226 Reward: 83.15665320964068 avg_loss_c: 3.219613486925761 avg_loss_a: -50.44835912068685\n",
            "Número de pasos del episodeo 11227 son episode_steps:121\n",
            "Total Steps: 663676 Episode Num: 11227 Reward: 200.53988680461077 avg_loss_c: 3.167604494685969 avg_loss_a: -50.655410451337325\n",
            "Número de pasos del episodeo 11228 son episode_steps:106\n",
            "Total Steps: 663782 Episode Num: 11228 Reward: 160.57486979981383 avg_loss_c: 3.2225465549612946 avg_loss_a: -50.410450053664874\n",
            "Número de pasos del episodeo 11229 son episode_steps:69\n",
            "Total Steps: 663851 Episode Num: 11229 Reward: 99.04941556592729 avg_loss_c: 3.2527949326280234 avg_loss_a: -50.37321339482846\n",
            "Número de pasos del episodeo 11230 son episode_steps:56\n",
            "Total Steps: 663907 Episode Num: 11230 Reward: 83.52255859454266 avg_loss_c: 3.03912339253085 avg_loss_a: -50.84768772125244\n",
            "Número de pasos del episodeo 11231 son episode_steps:77\n",
            "Total Steps: 663984 Episode Num: 11231 Reward: 133.91069298109036 avg_loss_c: 2.9945974535756297 avg_loss_a: -50.62334362872235\n",
            "Número de pasos del episodeo 11232 son episode_steps:84\n",
            "Total Steps: 664068 Episode Num: 11232 Reward: 143.79554369385042 avg_loss_c: 3.201122897011893 avg_loss_a: -49.98669079371861\n",
            "Número de pasos del episodeo 11233 son episode_steps:92\n",
            "Total Steps: 664160 Episode Num: 11233 Reward: 149.46824568763225 avg_loss_c: 3.0500637189201685 avg_loss_a: -50.42826868140179\n",
            "Número de pasos del episodeo 11234 son episode_steps:54\n",
            "Total Steps: 664214 Episode Num: 11234 Reward: -8.280987760546198 avg_loss_c: 3.1494693049678095 avg_loss_a: -50.623451939335574\n",
            "Número de pasos del episodeo 11235 son episode_steps:174\n",
            "Total Steps: 664388 Episode Num: 11235 Reward: 272.66945684641576 avg_loss_c: 3.0633985667393127 avg_loss_a: -50.598193026137075\n",
            "Número de pasos del episodeo 11236 son episode_steps:94\n",
            "Total Steps: 664482 Episode Num: 11236 Reward: 143.29390271769182 avg_loss_c: 3.063765158044531 avg_loss_a: -50.91141932061378\n",
            "Número de pasos del episodeo 11237 son episode_steps:116\n",
            "Total Steps: 664598 Episode Num: 11237 Reward: 185.23130271222755 avg_loss_c: 2.8299913632458655 avg_loss_a: -51.152441682486696\n",
            "Número de pasos del episodeo 11238 son episode_steps:164\n",
            "Total Steps: 664762 Episode Num: 11238 Reward: 250.90789243384265 avg_loss_c: 2.9489770291782005 avg_loss_a: -50.8729133605957\n",
            "Número de pasos del episodeo 11239 son episode_steps:81\n",
            "Total Steps: 664843 Episode Num: 11239 Reward: 131.02825451856896 avg_loss_c: 2.923432610653065 avg_loss_a: -51.57453532277802\n",
            "Número de pasos del episodeo 11240 son episode_steps:64\n",
            "Total Steps: 664907 Episode Num: 11240 Reward: 32.66726213620989 avg_loss_c: 3.2002828139811754 avg_loss_a: -50.86782670021057\n",
            "Número de pasos del episodeo 11241 son episode_steps:54\n",
            "Total Steps: 664961 Episode Num: 11241 Reward: 56.08061234030887 avg_loss_c: 3.352764251055541 avg_loss_a: -51.12501285694264\n",
            "Número de pasos del episodeo 11242 son episode_steps:116\n",
            "Total Steps: 665077 Episode Num: 11242 Reward: 184.13399631406475 avg_loss_c: 3.0792778863989074 avg_loss_a: -50.94870988253889\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 136.424158\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11243 son episode_steps:161\n",
            "Total Steps: 665238 Episode Num: 11243 Reward: 238.2801711556622 avg_loss_c: 2.974270579237375 avg_loss_a: -51.39481422471704\n",
            "Número de pasos del episodeo 11244 son episode_steps:89\n",
            "Total Steps: 665327 Episode Num: 11244 Reward: 134.19271378913658 avg_loss_c: 2.913175497162208 avg_loss_a: -51.08077780048499\n",
            "Número de pasos del episodeo 11245 son episode_steps:116\n",
            "Total Steps: 665443 Episode Num: 11245 Reward: 65.60852344769548 avg_loss_c: 3.318342799770421 avg_loss_a: -51.21345875181001\n",
            "Número de pasos del episodeo 11246 son episode_steps:93\n",
            "Total Steps: 665536 Episode Num: 11246 Reward: 101.04260665902288 avg_loss_c: 3.1921353301694317 avg_loss_a: -51.25105462023007\n",
            "Número de pasos del episodeo 11247 son episode_steps:90\n",
            "Total Steps: 665626 Episode Num: 11247 Reward: 135.4352008060842 avg_loss_c: 3.005488379796346 avg_loss_a: -51.22262530856662\n",
            "Número de pasos del episodeo 11248 son episode_steps:84\n",
            "Total Steps: 665710 Episode Num: 11248 Reward: 143.06313236654586 avg_loss_c: 3.1496271065303256 avg_loss_a: -50.92187209356399\n",
            "Número de pasos del episodeo 11249 son episode_steps:90\n",
            "Total Steps: 665800 Episode Num: 11249 Reward: 143.3635612233295 avg_loss_c: 3.24726329114702 avg_loss_a: -50.83043721516927\n",
            "Número de pasos del episodeo 11250 son episode_steps:132\n",
            "Total Steps: 665932 Episode Num: 11250 Reward: 169.97472375114316 avg_loss_c: 2.914867936661749 avg_loss_a: -50.74788642652107\n",
            "Número de pasos del episodeo 11251 son episode_steps:115\n",
            "Total Steps: 666047 Episode Num: 11251 Reward: 150.79362810930235 avg_loss_c: 3.0339936308238817 avg_loss_a: -51.21363137286642\n",
            "Número de pasos del episodeo 11252 son episode_steps:161\n",
            "Total Steps: 666208 Episode Num: 11252 Reward: 241.15242563196728 avg_loss_c: 3.1049900062335944 avg_loss_a: -51.22656368468859\n",
            "Número de pasos del episodeo 11253 son episode_steps:52\n",
            "Total Steps: 666260 Episode Num: 11253 Reward: -34.45007252977704 avg_loss_c: 3.369586564027346 avg_loss_a: -51.150267087496246\n",
            "Número de pasos del episodeo 11254 son episode_steps:75\n",
            "Total Steps: 666335 Episode Num: 11254 Reward: 96.3614390069338 avg_loss_c: 3.174553098678589 avg_loss_a: -51.41152369181315\n",
            "Número de pasos del episodeo 11255 son episode_steps:67\n",
            "Total Steps: 666402 Episode Num: 11255 Reward: 113.08498973172316 avg_loss_c: 3.3725469628376747 avg_loss_a: -51.41733397298784\n",
            "Número de pasos del episodeo 11256 son episode_steps:126\n",
            "Total Steps: 666528 Episode Num: 11256 Reward: 146.93952246753358 avg_loss_c: 3.130791545860351 avg_loss_a: -50.98096726432679\n",
            "Número de pasos del episodeo 11257 son episode_steps:78\n",
            "Total Steps: 666606 Episode Num: 11257 Reward: 111.8485694015119 avg_loss_c: 2.980046877494225 avg_loss_a: -50.694268446702225\n",
            "Número de pasos del episodeo 11258 son episode_steps:70\n",
            "Total Steps: 666676 Episode Num: 11258 Reward: 78.4115169889201 avg_loss_c: 3.0315000125340053 avg_loss_a: -51.502002825055804\n",
            "Número de pasos del episodeo 11259 son episode_steps:107\n",
            "Total Steps: 666783 Episode Num: 11259 Reward: 162.3558913933769 avg_loss_c: 2.9508688093345854 avg_loss_a: -51.01371918437637\n",
            "Número de pasos del episodeo 11260 son episode_steps:62\n",
            "Total Steps: 666845 Episode Num: 11260 Reward: 103.54547384388655 avg_loss_c: 3.5070576706240253 avg_loss_a: -51.000279949557395\n",
            "Número de pasos del episodeo 11261 son episode_steps:163\n",
            "Total Steps: 667008 Episode Num: 11261 Reward: 263.92258308672535 avg_loss_c: 2.913887584867653 avg_loss_a: -50.90651976696552\n",
            "Número de pasos del episodeo 11262 son episode_steps:116\n",
            "Total Steps: 667124 Episode Num: 11262 Reward: 161.83325085008263 avg_loss_c: 3.075149403563861 avg_loss_a: -50.823310128573716\n",
            "Número de pasos del episodeo 11263 son episode_steps:52\n",
            "Total Steps: 667176 Episode Num: 11263 Reward: 32.40189640793778 avg_loss_c: 3.272257080444923 avg_loss_a: -51.26614658649151\n",
            "Número de pasos del episodeo 11264 son episode_steps:80\n",
            "Total Steps: 667256 Episode Num: 11264 Reward: 126.53908817474094 avg_loss_c: 3.1563755974173544 avg_loss_a: -50.345803833007814\n",
            "Número de pasos del episodeo 11265 son episode_steps:96\n",
            "Total Steps: 667352 Episode Num: 11265 Reward: 166.9460874803074 avg_loss_c: 3.133488251517216 avg_loss_a: -50.75146516164144\n",
            "Número de pasos del episodeo 11266 son episode_steps:112\n",
            "Total Steps: 667464 Episode Num: 11266 Reward: 170.92655974862555 avg_loss_c: 2.8369572524513518 avg_loss_a: -51.14635794503348\n",
            "Número de pasos del episodeo 11267 son episode_steps:95\n",
            "Total Steps: 667559 Episode Num: 11267 Reward: 144.1330028429885 avg_loss_c: 2.9685524651878756 avg_loss_a: -51.77794390226665\n",
            "Número de pasos del episodeo 11268 son episode_steps:111\n",
            "Total Steps: 667670 Episode Num: 11268 Reward: 184.2351458843143 avg_loss_c: 2.8564589893495715 avg_loss_a: -51.34977948987806\n",
            "Número de pasos del episodeo 11269 son episode_steps:182\n",
            "Total Steps: 667852 Episode Num: 11269 Reward: 274.2269271805304 avg_loss_c: 2.85452256163398 avg_loss_a: -51.447216327373795\n",
            "Número de pasos del episodeo 11270 son episode_steps:78\n",
            "Total Steps: 667930 Episode Num: 11270 Reward: 108.73197847908786 avg_loss_c: 2.9695031199699793 avg_loss_a: -51.089993305695366\n",
            "Número de pasos del episodeo 11271 son episode_steps:82\n",
            "Total Steps: 668012 Episode Num: 11271 Reward: 129.5504467039891 avg_loss_c: 2.660842601845904 avg_loss_a: -51.343045583585415\n",
            "Número de pasos del episodeo 11272 son episode_steps:90\n",
            "Total Steps: 668102 Episode Num: 11272 Reward: 162.10444611057588 avg_loss_c: 2.937012044588725 avg_loss_a: -51.030281745062936\n",
            "Número de pasos del episodeo 11273 son episode_steps:61\n",
            "Total Steps: 668163 Episode Num: 11273 Reward: 85.1979680213332 avg_loss_c: 2.72604721296029 avg_loss_a: -51.277535047687465\n",
            "Número de pasos del episodeo 11274 son episode_steps:101\n",
            "Total Steps: 668264 Episode Num: 11274 Reward: 167.5030652670992 avg_loss_c: 3.006625750277302 avg_loss_a: -51.051318782390936\n",
            "Número de pasos del episodeo 11275 son episode_steps:69\n",
            "Total Steps: 668333 Episode Num: 11275 Reward: 116.47819229513321 avg_loss_c: 2.765919892684273 avg_loss_a: -51.95254665872325\n",
            "Número de pasos del episodeo 11276 son episode_steps:150\n",
            "Total Steps: 668483 Episode Num: 11276 Reward: 207.97997642441166 avg_loss_c: 2.7926418081919353 avg_loss_a: -50.85875742594401\n",
            "Número de pasos del episodeo 11277 son episode_steps:133\n",
            "Total Steps: 668616 Episode Num: 11277 Reward: 213.66498477911054 avg_loss_c: 2.8710740392369436 avg_loss_a: -51.52658935776331\n",
            "Número de pasos del episodeo 11278 son episode_steps:97\n",
            "Total Steps: 668713 Episode Num: 11278 Reward: 174.63988358066618 avg_loss_c: 2.8441050089511677 avg_loss_a: -51.66511303616553\n",
            "Número de pasos del episodeo 11279 son episode_steps:111\n",
            "Total Steps: 668824 Episode Num: 11279 Reward: 178.20718823578676 avg_loss_c: 2.779049883017669 avg_loss_a: -51.66112167770798\n",
            "Número de pasos del episodeo 11280 son episode_steps:102\n",
            "Total Steps: 668926 Episode Num: 11280 Reward: 154.77466912364895 avg_loss_c: 2.8079441002770964 avg_loss_a: -51.894212086995445\n",
            "Número de pasos del episodeo 11281 son episode_steps:72\n",
            "Total Steps: 668998 Episode Num: 11281 Reward: 120.96087401921264 avg_loss_c: 2.659522737065951 avg_loss_a: -51.33280743492974\n",
            "Número de pasos del episodeo 11282 son episode_steps:94\n",
            "Total Steps: 669092 Episode Num: 11282 Reward: 149.36594654719832 avg_loss_c: 2.705312012357915 avg_loss_a: -52.08698792153216\n",
            "Número de pasos del episodeo 11283 son episode_steps:132\n",
            "Total Steps: 669224 Episode Num: 11283 Reward: 223.19039224752402 avg_loss_c: 2.5955077770984536 avg_loss_a: -51.78175273086085\n",
            "Número de pasos del episodeo 11284 son episode_steps:83\n",
            "Total Steps: 669307 Episode Num: 11284 Reward: 134.75142566537934 avg_loss_c: 2.5741554182696054 avg_loss_a: -51.493818443941784\n",
            "Número de pasos del episodeo 11285 son episode_steps:96\n",
            "Total Steps: 669403 Episode Num: 11285 Reward: 140.8217414803666 avg_loss_c: 2.6593521448473134 avg_loss_a: -51.97651775677999\n",
            "Número de pasos del episodeo 11286 son episode_steps:118\n",
            "Total Steps: 669521 Episode Num: 11286 Reward: 179.38501117181366 avg_loss_c: 2.5756037497924544 avg_loss_a: -51.38411079018803\n",
            "Número de pasos del episodeo 11287 son episode_steps:46\n",
            "Total Steps: 669567 Episode Num: 11287 Reward: 27.16872576367931 avg_loss_c: 2.7685405560161755 avg_loss_a: -51.79819123641305\n",
            "Número de pasos del episodeo 11288 son episode_steps:106\n",
            "Total Steps: 669673 Episode Num: 11288 Reward: 156.5723632180981 avg_loss_c: 2.6683843788110986 avg_loss_a: -52.00299979155918\n",
            "Número de pasos del episodeo 11289 son episode_steps:53\n",
            "Total Steps: 669726 Episode Num: 11289 Reward: 42.614473893682025 avg_loss_c: 2.6621454324362412 avg_loss_a: -51.9334569967018\n",
            "Número de pasos del episodeo 11290 son episode_steps:92\n",
            "Total Steps: 669818 Episode Num: 11290 Reward: 108.30680887572862 avg_loss_c: 2.5827155890672104 avg_loss_a: -51.51679229736328\n",
            "Número de pasos del episodeo 11291 son episode_steps:47\n",
            "Total Steps: 669865 Episode Num: 11291 Reward: 53.4312352317066 avg_loss_c: 2.6934650958852564 avg_loss_a: -51.36678687562334\n",
            "Número de pasos del episodeo 11292 son episode_steps:61\n",
            "Total Steps: 669926 Episode Num: 11292 Reward: 83.45580808234915 avg_loss_c: 2.9299806805907704 avg_loss_a: -51.24284250228131\n",
            "Número de pasos del episodeo 11293 son episode_steps:48\n",
            "Total Steps: 669974 Episode Num: 11293 Reward: -12.447954066930592 avg_loss_c: 2.7962912718454995 avg_loss_a: -51.12248579661051\n",
            "Número de pasos del episodeo 11294 son episode_steps:70\n",
            "Total Steps: 670044 Episode Num: 11294 Reward: 78.40621672164664 avg_loss_c: 2.822709778376988 avg_loss_a: -51.5618896484375\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 145.841927\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11295 son episode_steps:114\n",
            "Total Steps: 670158 Episode Num: 11295 Reward: 190.31573997109373 avg_loss_c: 2.792050488162459 avg_loss_a: -51.615033199912624\n",
            "Número de pasos del episodeo 11296 son episode_steps:139\n",
            "Total Steps: 670297 Episode Num: 11296 Reward: 220.19826682422644 avg_loss_c: 2.819422907108883 avg_loss_a: -51.511015473509865\n",
            "Número de pasos del episodeo 11297 son episode_steps:148\n",
            "Total Steps: 670445 Episode Num: 11297 Reward: 233.82708761614748 avg_loss_c: 2.6190598051290253 avg_loss_a: -51.338653616003086\n",
            "Número de pasos del episodeo 11298 son episode_steps:90\n",
            "Total Steps: 670535 Episode Num: 11298 Reward: 85.30357236207672 avg_loss_c: 2.732970819208357 avg_loss_a: -51.9558347913954\n",
            "Número de pasos del episodeo 11299 son episode_steps:65\n",
            "Total Steps: 670600 Episode Num: 11299 Reward: 76.82563715550071 avg_loss_c: 2.639486989608178 avg_loss_a: -51.947658597506006\n",
            "Número de pasos del episodeo 11300 son episode_steps:68\n",
            "Total Steps: 670668 Episode Num: 11300 Reward: 97.86086536580797 avg_loss_c: 2.931568815427668 avg_loss_a: -51.84720723769244\n",
            "Número de pasos del episodeo 11301 son episode_steps:125\n",
            "Total Steps: 670793 Episode Num: 11301 Reward: 188.88652400107546 avg_loss_c: 2.677379409790039 avg_loss_a: -51.31316595458984\n",
            "Número de pasos del episodeo 11302 son episode_steps:72\n",
            "Total Steps: 670865 Episode Num: 11302 Reward: 114.14254983056105 avg_loss_c: 3.165950294997957 avg_loss_a: -51.54300340016683\n",
            "Número de pasos del episodeo 11303 son episode_steps:67\n",
            "Total Steps: 670932 Episode Num: 11303 Reward: 107.2511258348872 avg_loss_c: 2.647461759510325 avg_loss_a: -51.355982424607916\n",
            "Número de pasos del episodeo 11304 son episode_steps:151\n",
            "Total Steps: 671083 Episode Num: 11304 Reward: 241.0241006658682 avg_loss_c: 2.6743894704919775 avg_loss_a: -51.8490868120004\n",
            "Número de pasos del episodeo 11305 son episode_steps:103\n",
            "Total Steps: 671186 Episode Num: 11305 Reward: 130.36601950580393 avg_loss_c: 2.683612229754624 avg_loss_a: -51.902849919587666\n",
            "Número de pasos del episodeo 11306 son episode_steps:131\n",
            "Total Steps: 671317 Episode Num: 11306 Reward: 180.14186956876773 avg_loss_c: 2.727603355436835 avg_loss_a: -51.85649167126372\n",
            "Número de pasos del episodeo 11307 son episode_steps:108\n",
            "Total Steps: 671425 Episode Num: 11307 Reward: 186.13142150061913 avg_loss_c: 2.6128901971711054 avg_loss_a: -51.56616811399107\n",
            "Número de pasos del episodeo 11308 son episode_steps:49\n",
            "Total Steps: 671474 Episode Num: 11308 Reward: 76.6078383796002 avg_loss_c: 2.56356486252376 avg_loss_a: -51.35807418823242\n",
            "Número de pasos del episodeo 11309 son episode_steps:162\n",
            "Total Steps: 671636 Episode Num: 11309 Reward: 242.56258686292526 avg_loss_c: 2.622249467137419 avg_loss_a: -51.77616660977587\n",
            "Número de pasos del episodeo 11310 son episode_steps:46\n",
            "Total Steps: 671682 Episode Num: 11310 Reward: 67.40965997528674 avg_loss_c: 2.5763675052186716 avg_loss_a: -51.106717648713484\n",
            "Número de pasos del episodeo 11311 son episode_steps:56\n",
            "Total Steps: 671738 Episode Num: 11311 Reward: 92.42714205872261 avg_loss_c: 2.536655558007104 avg_loss_a: -51.080934388296946\n",
            "Número de pasos del episodeo 11312 son episode_steps:68\n",
            "Total Steps: 671806 Episode Num: 11312 Reward: 115.99472414698589 avg_loss_c: 2.5430787275819218 avg_loss_a: -51.60299435783835\n",
            "Número de pasos del episodeo 11313 son episode_steps:141\n",
            "Total Steps: 671947 Episode Num: 11313 Reward: 230.17822279666552 avg_loss_c: 2.4904986603040222 avg_loss_a: -51.745153873524764\n",
            "Número de pasos del episodeo 11314 son episode_steps:141\n",
            "Total Steps: 672088 Episode Num: 11314 Reward: 186.89245593440418 avg_loss_c: 2.6113699065878038 avg_loss_a: -52.01848283050754\n",
            "Número de pasos del episodeo 11315 son episode_steps:104\n",
            "Total Steps: 672192 Episode Num: 11315 Reward: 148.3912568495045 avg_loss_c: 2.621042150717515 avg_loss_a: -51.65758529076209\n",
            "Número de pasos del episodeo 11316 son episode_steps:120\n",
            "Total Steps: 672312 Episode Num: 11316 Reward: 196.26270535871828 avg_loss_c: 2.6025285998980205 avg_loss_a: -51.829994201660156\n",
            "Número de pasos del episodeo 11317 son episode_steps:70\n",
            "Total Steps: 672382 Episode Num: 11317 Reward: 118.50275671935015 avg_loss_c: 2.673535771029336 avg_loss_a: -51.44640633719308\n",
            "Número de pasos del episodeo 11318 son episode_steps:90\n",
            "Total Steps: 672472 Episode Num: 11318 Reward: 38.473411985636666 avg_loss_c: 2.6685488515430027 avg_loss_a: -51.766788228352866\n",
            "Número de pasos del episodeo 11319 son episode_steps:64\n",
            "Total Steps: 672536 Episode Num: 11319 Reward: 87.78230858240546 avg_loss_c: 2.6051862202584743 avg_loss_a: -51.98175287246704\n",
            "Número de pasos del episodeo 11320 son episode_steps:93\n",
            "Total Steps: 672629 Episode Num: 11320 Reward: 150.2348623513515 avg_loss_c: 2.562265187181452 avg_loss_a: -51.71050385505922\n",
            "Número de pasos del episodeo 11321 son episode_steps:17\n",
            "Total Steps: 672646 Episode Num: 11321 Reward: -21.148734108706364 avg_loss_c: 2.765396433718064 avg_loss_a: -52.76711228314568\n",
            "Número de pasos del episodeo 11322 son episode_steps:131\n",
            "Total Steps: 672777 Episode Num: 11322 Reward: 187.3440616802689 avg_loss_c: 2.7754408366807546 avg_loss_a: -51.54071871924946\n",
            "Número de pasos del episodeo 11323 son episode_steps:99\n",
            "Total Steps: 672876 Episode Num: 11323 Reward: 153.90781638163884 avg_loss_c: 3.1289802669274684 avg_loss_a: -52.02348693693527\n",
            "Número de pasos del episodeo 11324 son episode_steps:21\n",
            "Total Steps: 672897 Episode Num: 11324 Reward: -10.822495083807254 avg_loss_c: 3.1477695192609514 avg_loss_a: -51.81034760248093\n",
            "Número de pasos del episodeo 11325 son episode_steps:78\n",
            "Total Steps: 672975 Episode Num: 11325 Reward: 129.21147268943255 avg_loss_c: 2.927081421399728 avg_loss_a: -52.36184526101137\n",
            "Número de pasos del episodeo 11326 son episode_steps:80\n",
            "Total Steps: 673055 Episode Num: 11326 Reward: 123.37597954461958 avg_loss_c: 2.6616320818662644 avg_loss_a: -52.19022359848022\n",
            "Número de pasos del episodeo 11327 son episode_steps:97\n",
            "Total Steps: 673152 Episode Num: 11327 Reward: 141.79584251415622 avg_loss_c: 2.6483656475224446 avg_loss_a: -51.97818339239691\n",
            "Número de pasos del episodeo 11328 son episode_steps:88\n",
            "Total Steps: 673240 Episode Num: 11328 Reward: 127.80977731191015 avg_loss_c: 2.8079849901524456 avg_loss_a: -51.88864794644442\n",
            "Número de pasos del episodeo 11329 son episode_steps:68\n",
            "Total Steps: 673308 Episode Num: 11329 Reward: 115.04438026059925 avg_loss_c: 2.7485154253595017 avg_loss_a: -51.79342382094439\n",
            "Número de pasos del episodeo 11330 son episode_steps:81\n",
            "Total Steps: 673389 Episode Num: 11330 Reward: 124.27697321312705 avg_loss_c: 2.8111330609262724 avg_loss_a: -52.60936619322977\n",
            "Número de pasos del episodeo 11331 son episode_steps:167\n",
            "Total Steps: 673556 Episode Num: 11331 Reward: 267.211204315573 avg_loss_c: 2.8080380676749224 avg_loss_a: -52.36254930781747\n",
            "Número de pasos del episodeo 11332 son episode_steps:53\n",
            "Total Steps: 673609 Episode Num: 11332 Reward: 84.10886240680517 avg_loss_c: 2.959599787334226 avg_loss_a: -51.96760681440245\n",
            "Número de pasos del episodeo 11333 son episode_steps:64\n",
            "Total Steps: 673673 Episode Num: 11333 Reward: 98.31546736883422 avg_loss_c: 2.841268928721547 avg_loss_a: -52.206950306892395\n",
            "Número de pasos del episodeo 11334 son episode_steps:88\n",
            "Total Steps: 673761 Episode Num: 11334 Reward: 14.194230223173653 avg_loss_c: 2.8048350607806984 avg_loss_a: -52.096237962896176\n",
            "Número de pasos del episodeo 11335 son episode_steps:54\n",
            "Total Steps: 673815 Episode Num: 11335 Reward: 89.1089839959101 avg_loss_c: 2.6673974990844727 avg_loss_a: -51.52017197785554\n",
            "Número de pasos del episodeo 11336 son episode_steps:51\n",
            "Total Steps: 673866 Episode Num: 11336 Reward: 42.48740959651188 avg_loss_c: 3.6334918036180386 avg_loss_a: -51.44444013109394\n",
            "Número de pasos del episodeo 11337 son episode_steps:132\n",
            "Total Steps: 673998 Episode Num: 11337 Reward: 203.6529455845251 avg_loss_c: 2.978821274909106 avg_loss_a: -52.134553504712656\n",
            "Número de pasos del episodeo 11338 son episode_steps:99\n",
            "Total Steps: 674097 Episode Num: 11338 Reward: 132.7770302728033 avg_loss_c: 2.73676154830239 avg_loss_a: -52.273545467492305\n",
            "Número de pasos del episodeo 11339 son episode_steps:93\n",
            "Total Steps: 674190 Episode Num: 11339 Reward: 21.378763982780683 avg_loss_c: 3.3639986950864076 avg_loss_a: -51.917498311688824\n",
            "Número de pasos del episodeo 11340 son episode_steps:61\n",
            "Total Steps: 674251 Episode Num: 11340 Reward: 104.2184618539502 avg_loss_c: 2.8728932454937794 avg_loss_a: -52.55792742869893\n",
            "Número de pasos del episodeo 11341 son episode_steps:192\n",
            "Total Steps: 674443 Episode Num: 11341 Reward: 290.34894788936293 avg_loss_c: 3.007981015369296 avg_loss_a: -51.93760168552399\n",
            "Número de pasos del episodeo 11342 son episode_steps:93\n",
            "Total Steps: 674536 Episode Num: 11342 Reward: 147.57597960928993 avg_loss_c: 2.9136908887535014 avg_loss_a: -52.56813738423009\n",
            "Número de pasos del episodeo 11343 son episode_steps:46\n",
            "Total Steps: 674582 Episode Num: 11343 Reward: 26.22846144110276 avg_loss_c: 3.599435459012571 avg_loss_a: -51.75064053742782\n",
            "Número de pasos del episodeo 11344 son episode_steps:96\n",
            "Total Steps: 674678 Episode Num: 11344 Reward: 156.19261476595435 avg_loss_c: 2.9764321570595107 avg_loss_a: -51.91352621714274\n",
            "Número de pasos del episodeo 11345 son episode_steps:200\n",
            "Total Steps: 674878 Episode Num: 11345 Reward: 321.3346946403685 avg_loss_c: 2.8778352332115174 avg_loss_a: -52.337180366516115\n",
            "Número de pasos del episodeo 11346 son episode_steps:77\n",
            "Total Steps: 674955 Episode Num: 11346 Reward: 125.57401641408485 avg_loss_c: 3.305135274862314 avg_loss_a: -53.13033299631887\n",
            "Número de pasos del episodeo 11347 son episode_steps:92\n",
            "Total Steps: 675047 Episode Num: 11347 Reward: 113.2825100464008 avg_loss_c: 2.645475662272909 avg_loss_a: -52.42875969928244\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 155.829468\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11348 son episode_steps:132\n",
            "Total Steps: 675179 Episode Num: 11348 Reward: 226.93020060982553 avg_loss_c: 2.7611679353497247 avg_loss_a: -52.49716070926551\n",
            "Número de pasos del episodeo 11349 son episode_steps:46\n",
            "Total Steps: 675225 Episode Num: 11349 Reward: 63.39380311372053 avg_loss_c: 3.5262985125831934 avg_loss_a: -52.5500372181768\n",
            "Número de pasos del episodeo 11350 son episode_steps:175\n",
            "Total Steps: 675400 Episode Num: 11350 Reward: 275.54197541942796 avg_loss_c: 3.1356777306965418 avg_loss_a: -52.220931505475725\n",
            "Número de pasos del episodeo 11351 son episode_steps:111\n",
            "Total Steps: 675511 Episode Num: 11351 Reward: 170.61586045870746 avg_loss_c: 2.6404641458580085 avg_loss_a: -52.50961609574052\n",
            "Número de pasos del episodeo 11352 son episode_steps:125\n",
            "Total Steps: 675636 Episode Num: 11352 Reward: 198.74885505995775 avg_loss_c: 3.0663631973266603 avg_loss_a: -52.34865576171875\n",
            "Número de pasos del episodeo 11353 son episode_steps:90\n",
            "Total Steps: 675726 Episode Num: 11353 Reward: 149.12804155353885 avg_loss_c: 2.8840238915549383 avg_loss_a: -52.44088422987196\n",
            "Número de pasos del episodeo 11354 son episode_steps:134\n",
            "Total Steps: 675860 Episode Num: 11354 Reward: 199.45180171756917 avg_loss_c: 2.9625174314228455 avg_loss_a: -52.39714249568199\n",
            "Número de pasos del episodeo 11355 son episode_steps:87\n",
            "Total Steps: 675947 Episode Num: 11355 Reward: 118.43817592353196 avg_loss_c: 2.797552086841101 avg_loss_a: -53.26458499075353\n",
            "Número de pasos del episodeo 11356 son episode_steps:95\n",
            "Total Steps: 676042 Episode Num: 11356 Reward: 162.10835063576667 avg_loss_c: 2.841975151865106 avg_loss_a: -52.934783132452715\n",
            "Número de pasos del episodeo 11357 son episode_steps:116\n",
            "Total Steps: 676158 Episode Num: 11357 Reward: 164.769300251045 avg_loss_c: 2.9018206185307998 avg_loss_a: -52.89515896501212\n",
            "Número de pasos del episodeo 11358 son episode_steps:114\n",
            "Total Steps: 676272 Episode Num: 11358 Reward: 148.19838564098052 avg_loss_c: 2.622910258017088 avg_loss_a: -53.152946739866024\n",
            "Número de pasos del episodeo 11359 son episode_steps:89\n",
            "Total Steps: 676361 Episode Num: 11359 Reward: 145.14166687750105 avg_loss_c: 2.59383725316337 avg_loss_a: -53.36032837428404\n",
            "Número de pasos del episodeo 11360 son episode_steps:108\n",
            "Total Steps: 676469 Episode Num: 11360 Reward: 162.99241631329102 avg_loss_c: 2.6418973063981093 avg_loss_a: -52.321974719012225\n",
            "Número de pasos del episodeo 11361 son episode_steps:158\n",
            "Total Steps: 676627 Episode Num: 11361 Reward: 248.79188649490064 avg_loss_c: 2.9799373240410527 avg_loss_a: -53.02567156055306\n",
            "Número de pasos del episodeo 11362 son episode_steps:181\n",
            "Total Steps: 676808 Episode Num: 11362 Reward: 187.64623338372544 avg_loss_c: 2.8958335317959443 avg_loss_a: -52.98269214946262\n",
            "Número de pasos del episodeo 11363 son episode_steps:58\n",
            "Total Steps: 676866 Episode Num: 11363 Reward: 76.63022735989189 avg_loss_c: 2.7582888623763777 avg_loss_a: -52.79972365806843\n",
            "Número de pasos del episodeo 11364 son episode_steps:92\n",
            "Total Steps: 676958 Episode Num: 11364 Reward: 95.93344204675114 avg_loss_c: 2.7734789744667383 avg_loss_a: -53.53005351190982\n",
            "Número de pasos del episodeo 11365 son episode_steps:102\n",
            "Total Steps: 677060 Episode Num: 11365 Reward: 24.93051405952288 avg_loss_c: 3.257243244086995 avg_loss_a: -52.45420119341682\n",
            "Número de pasos del episodeo 11366 son episode_steps:76\n",
            "Total Steps: 677136 Episode Num: 11366 Reward: 5.405792251562534 avg_loss_c: 3.440042643170608 avg_loss_a: -52.747718610261614\n",
            "Número de pasos del episodeo 11367 son episode_steps:72\n",
            "Total Steps: 677208 Episode Num: 11367 Reward: 115.87490512622873 avg_loss_c: 3.5182478527228036 avg_loss_a: -53.44050206078423\n",
            "Número de pasos del episodeo 11368 son episode_steps:162\n",
            "Total Steps: 677370 Episode Num: 11368 Reward: 124.3844605315538 avg_loss_c: 3.3522793415151995 avg_loss_a: -53.424579055220995\n",
            "Número de pasos del episodeo 11369 son episode_steps:41\n",
            "Total Steps: 677411 Episode Num: 11369 Reward: 45.38980181224145 avg_loss_c: 3.319838840787004 avg_loss_a: -52.25654806741854\n",
            "Número de pasos del episodeo 11370 son episode_steps:73\n",
            "Total Steps: 677484 Episode Num: 11370 Reward: 107.76582813833245 avg_loss_c: 3.0283689580551565 avg_loss_a: -52.307973313005\n",
            "Número de pasos del episodeo 11371 son episode_steps:105\n",
            "Total Steps: 677589 Episode Num: 11371 Reward: 158.1362976004333 avg_loss_c: 3.1591844683601744 avg_loss_a: -52.91730902535575\n",
            "Número de pasos del episodeo 11372 son episode_steps:50\n",
            "Total Steps: 677639 Episode Num: 11372 Reward: 32.11601871720651 avg_loss_c: 3.1445529460906982 avg_loss_a: -53.171046600341796\n",
            "Número de pasos del episodeo 11373 son episode_steps:262\n",
            "Total Steps: 677901 Episode Num: 11373 Reward: 406.89954495474257 avg_loss_c: 3.275485418225063 avg_loss_a: -52.61604009147819\n",
            "Número de pasos del episodeo 11374 son episode_steps:180\n",
            "Total Steps: 678081 Episode Num: 11374 Reward: 275.94553497289616 avg_loss_c: 3.0442946122752295 avg_loss_a: -52.76838595072429\n",
            "Número de pasos del episodeo 11375 son episode_steps:65\n",
            "Total Steps: 678146 Episode Num: 11375 Reward: 82.47220208206508 avg_loss_c: 2.9073222710536077 avg_loss_a: -52.72830006526067\n",
            "Número de pasos del episodeo 11376 son episode_steps:81\n",
            "Total Steps: 678227 Episode Num: 11376 Reward: 134.4648694276206 avg_loss_c: 3.3967569212854642 avg_loss_a: -52.8347048347379\n",
            "Número de pasos del episodeo 11377 son episode_steps:91\n",
            "Total Steps: 678318 Episode Num: 11377 Reward: 72.0697106089207 avg_loss_c: 3.1218030125230225 avg_loss_a: -52.86124931586968\n",
            "Número de pasos del episodeo 11378 son episode_steps:81\n",
            "Total Steps: 678399 Episode Num: 11378 Reward: 128.10312955569538 avg_loss_c: 2.961355717093856 avg_loss_a: -53.129732343885635\n",
            "Número de pasos del episodeo 11379 son episode_steps:135\n",
            "Total Steps: 678534 Episode Num: 11379 Reward: 108.8459616281141 avg_loss_c: 3.294457525677151 avg_loss_a: -53.187162469934535\n",
            "Número de pasos del episodeo 11380 son episode_steps:285\n",
            "Total Steps: 678819 Episode Num: 11380 Reward: 468.2389570736967 avg_loss_c: 3.273158169211003 avg_loss_a: -52.99107347454941\n",
            "Número de pasos del episodeo 11381 son episode_steps:131\n",
            "Total Steps: 678950 Episode Num: 11381 Reward: 182.49645250620543 avg_loss_c: 3.1925442928576286 avg_loss_a: -53.166629150623585\n",
            "Número de pasos del episodeo 11382 son episode_steps:64\n",
            "Total Steps: 679014 Episode Num: 11382 Reward: 93.16159410984633 avg_loss_c: 3.0697307977825403 avg_loss_a: -53.08256542682648\n",
            "Número de pasos del episodeo 11383 son episode_steps:126\n",
            "Total Steps: 679140 Episode Num: 11383 Reward: 203.72403185554896 avg_loss_c: 3.06515687136423 avg_loss_a: -52.99025453839983\n",
            "Número de pasos del episodeo 11384 son episode_steps:162\n",
            "Total Steps: 679302 Episode Num: 11384 Reward: 245.08770809671412 avg_loss_c: 3.138514065448149 avg_loss_a: -53.287220472170986\n",
            "Número de pasos del episodeo 11385 son episode_steps:162\n",
            "Total Steps: 679464 Episode Num: 11385 Reward: 261.05770272694383 avg_loss_c: 3.0964586904019487 avg_loss_a: -53.58358472659264\n",
            "Número de pasos del episodeo 11386 son episode_steps:74\n",
            "Total Steps: 679538 Episode Num: 11386 Reward: 120.123263054584 avg_loss_c: 2.9534853632385665 avg_loss_a: -52.99039057138804\n",
            "Número de pasos del episodeo 11387 son episode_steps:282\n",
            "Total Steps: 679820 Episode Num: 11387 Reward: 444.04658752088756 avg_loss_c: 3.037943088416512 avg_loss_a: -53.43692979744986\n",
            "Número de pasos del episodeo 11388 son episode_steps:154\n",
            "Total Steps: 679974 Episode Num: 11388 Reward: 240.2992392310479 avg_loss_c: 2.9999381056079617 avg_loss_a: -53.26087758448217\n",
            "Número de pasos del episodeo 11389 son episode_steps:49\n",
            "Total Steps: 680023 Episode Num: 11389 Reward: 43.793476139178345 avg_loss_c: 3.015989989650493 avg_loss_a: -53.29331222845583\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 167.693731\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11390 son episode_steps:104\n",
            "Total Steps: 680127 Episode Num: 11390 Reward: 153.81877284915166 avg_loss_c: 3.008532537863805 avg_loss_a: -53.70092509343074\n",
            "Número de pasos del episodeo 11391 son episode_steps:112\n",
            "Total Steps: 680239 Episode Num: 11391 Reward: 173.06584303011826 avg_loss_c: 2.922163190586226 avg_loss_a: -53.18108354296003\n",
            "Número de pasos del episodeo 11392 son episode_steps:97\n",
            "Total Steps: 680336 Episode Num: 11392 Reward: 158.4741399575475 avg_loss_c: 3.0122699860445 avg_loss_a: -53.00974918640766\n",
            "Número de pasos del episodeo 11393 son episode_steps:80\n",
            "Total Steps: 680416 Episode Num: 11393 Reward: 118.66693767485164 avg_loss_c: 2.7225329905748366 avg_loss_a: -53.47387046813965\n",
            "Número de pasos del episodeo 11394 son episode_steps:71\n",
            "Total Steps: 680487 Episode Num: 11394 Reward: 67.38047463916233 avg_loss_c: 2.8392207538577874 avg_loss_a: -53.70083682637819\n",
            "Número de pasos del episodeo 11395 son episode_steps:212\n",
            "Total Steps: 680699 Episode Num: 11395 Reward: 317.0731916594851 avg_loss_c: 2.9777140071931876 avg_loss_a: -53.34318765604271\n",
            "Número de pasos del episodeo 11396 son episode_steps:140\n",
            "Total Steps: 680839 Episode Num: 11396 Reward: 219.67273966470174 avg_loss_c: 2.965090072154999 avg_loss_a: -53.57532103402274\n",
            "Número de pasos del episodeo 11397 son episode_steps:159\n",
            "Total Steps: 680998 Episode Num: 11397 Reward: 254.12390286639643 avg_loss_c: 2.8668170844983756 avg_loss_a: -53.371620610075176\n",
            "Número de pasos del episodeo 11398 son episode_steps:74\n",
            "Total Steps: 681072 Episode Num: 11398 Reward: 116.97554868319693 avg_loss_c: 2.799172365987623 avg_loss_a: -53.99271238172376\n",
            "Número de pasos del episodeo 11399 son episode_steps:103\n",
            "Total Steps: 681175 Episode Num: 11399 Reward: 155.3838964180829 avg_loss_c: 2.948625134032907 avg_loss_a: -53.5591057712592\n",
            "Número de pasos del episodeo 11400 son episode_steps:122\n",
            "Total Steps: 681297 Episode Num: 11400 Reward: 165.06878467099753 avg_loss_c: 2.8741038158291676 avg_loss_a: -53.28044090896356\n",
            "Número de pasos del episodeo 11401 son episode_steps:29\n",
            "Total Steps: 681326 Episode Num: 11401 Reward: -6.112556349238007 avg_loss_c: 2.796929014140162 avg_loss_a: -54.15929518074825\n",
            "Número de pasos del episodeo 11402 son episode_steps:148\n",
            "Total Steps: 681474 Episode Num: 11402 Reward: 137.53376488608697 avg_loss_c: 3.0313698665515796 avg_loss_a: -53.63645893818623\n",
            "Número de pasos del episodeo 11403 son episode_steps:193\n",
            "Total Steps: 681667 Episode Num: 11403 Reward: 250.8323729324608 avg_loss_c: 3.007264468954017 avg_loss_a: -53.63301201064352\n",
            "Número de pasos del episodeo 11404 son episode_steps:112\n",
            "Total Steps: 681779 Episode Num: 11404 Reward: 145.10533249690008 avg_loss_c: 2.8123922188367163 avg_loss_a: -53.64216327667236\n",
            "Número de pasos del episodeo 11405 son episode_steps:193\n",
            "Total Steps: 681972 Episode Num: 11405 Reward: 280.4446745781455 avg_loss_c: 3.026117623161158 avg_loss_a: -53.753306591449004\n",
            "Número de pasos del episodeo 11406 son episode_steps:51\n",
            "Total Steps: 682023 Episode Num: 11406 Reward: 40.33512442200719 avg_loss_c: 3.0356240693260643 avg_loss_a: -53.43952178955078\n",
            "Número de pasos del episodeo 11407 son episode_steps:190\n",
            "Total Steps: 682213 Episode Num: 11407 Reward: 292.6830510869104 avg_loss_c: 2.9045402244517677 avg_loss_a: -53.87365642346834\n",
            "Número de pasos del episodeo 11408 son episode_steps:120\n",
            "Total Steps: 682333 Episode Num: 11408 Reward: 182.97982910339073 avg_loss_c: 2.728252148628235 avg_loss_a: -53.44223327636719\n",
            "Número de pasos del episodeo 11409 son episode_steps:113\n",
            "Total Steps: 682446 Episode Num: 11409 Reward: 160.27584963299216 avg_loss_c: 2.967025765275533 avg_loss_a: -54.20461320455095\n",
            "Número de pasos del episodeo 11410 son episode_steps:92\n",
            "Total Steps: 682538 Episode Num: 11410 Reward: 92.99375510282833 avg_loss_c: 2.9802750763685806 avg_loss_a: -53.86808693927267\n",
            "Número de pasos del episodeo 11411 son episode_steps:75\n",
            "Total Steps: 682613 Episode Num: 11411 Reward: 120.12207655403185 avg_loss_c: 2.8078188546498617 avg_loss_a: -54.267564900716145\n",
            "Número de pasos del episodeo 11412 son episode_steps:150\n",
            "Total Steps: 682763 Episode Num: 11412 Reward: 194.59908993311552 avg_loss_c: 2.8075981664657594 avg_loss_a: -53.91111760457357\n",
            "Número de pasos del episodeo 11413 son episode_steps:125\n",
            "Total Steps: 682888 Episode Num: 11413 Reward: 185.3396168703842 avg_loss_c: 2.853666350364685 avg_loss_a: -53.62544714355469\n",
            "Número de pasos del episodeo 11414 son episode_steps:208\n",
            "Total Steps: 683096 Episode Num: 11414 Reward: 339.20531772899704 avg_loss_c: 2.853854283117331 avg_loss_a: -53.95172328215379\n",
            "Número de pasos del episodeo 11415 son episode_steps:53\n",
            "Total Steps: 683149 Episode Num: 11415 Reward: 47.96457804965785 avg_loss_c: 2.828108204985565 avg_loss_a: -53.76666166197579\n",
            "Número de pasos del episodeo 11416 son episode_steps:189\n",
            "Total Steps: 683338 Episode Num: 11416 Reward: 254.39081124550177 avg_loss_c: 3.067224464088521 avg_loss_a: -53.866349396882235\n",
            "Número de pasos del episodeo 11417 son episode_steps:108\n",
            "Total Steps: 683446 Episode Num: 11417 Reward: 171.1041780440868 avg_loss_c: 2.8084046940008798 avg_loss_a: -54.522721184624565\n",
            "Número de pasos del episodeo 11418 son episode_steps:133\n",
            "Total Steps: 683579 Episode Num: 11418 Reward: 198.4350194887023 avg_loss_c: 2.7368452719279697 avg_loss_a: -54.04515600562992\n",
            "Número de pasos del episodeo 11419 son episode_steps:173\n",
            "Total Steps: 683752 Episode Num: 11419 Reward: 223.18574153841325 avg_loss_c: 2.7667875717141035 avg_loss_a: -54.193195673771676\n",
            "Número de pasos del episodeo 11420 son episode_steps:218\n",
            "Total Steps: 683970 Episode Num: 11420 Reward: 304.6738971404906 avg_loss_c: 2.7559731558922236 avg_loss_a: -53.972077080962855\n",
            "Número de pasos del episodeo 11421 son episode_steps:82\n",
            "Total Steps: 684052 Episode Num: 11421 Reward: 126.80516444499237 avg_loss_c: 2.838334611276301 avg_loss_a: -53.97459169713462\n",
            "Número de pasos del episodeo 11422 son episode_steps:43\n",
            "Total Steps: 684095 Episode Num: 11422 Reward: -33.140736598337426 avg_loss_c: 3.2360082393468814 avg_loss_a: -53.764894884686136\n",
            "Número de pasos del episodeo 11423 son episode_steps:138\n",
            "Total Steps: 684233 Episode Num: 11423 Reward: 196.0395111897663 avg_loss_c: 3.0859781218611677 avg_loss_a: -54.24347449040067\n",
            "Número de pasos del episodeo 11424 son episode_steps:324\n",
            "Total Steps: 684557 Episode Num: 11424 Reward: 452.51350443320445 avg_loss_c: 2.9635262489318848 avg_loss_a: -54.09922543278447\n",
            "Número de pasos del episodeo 11425 son episode_steps:130\n",
            "Total Steps: 684687 Episode Num: 11425 Reward: 126.50553607875155 avg_loss_c: 2.944478443952707 avg_loss_a: -54.42849496694711\n",
            "Número de pasos del episodeo 11426 son episode_steps:86\n",
            "Total Steps: 684773 Episode Num: 11426 Reward: 96.21208406131498 avg_loss_c: 3.0592339815095415 avg_loss_a: -54.22713701115098\n",
            "Número de pasos del episodeo 11427 son episode_steps:138\n",
            "Total Steps: 684911 Episode Num: 11427 Reward: 182.4923121292167 avg_loss_c: 2.9617046247357908 avg_loss_a: -54.18050627777542\n",
            "Número de pasos del episodeo 11428 son episode_steps:74\n",
            "Total Steps: 684985 Episode Num: 11428 Reward: 90.10902882454478 avg_loss_c: 2.9685671490591927 avg_loss_a: -54.109097867398646\n",
            "Número de pasos del episodeo 11429 son episode_steps:140\n",
            "Total Steps: 685125 Episode Num: 11429 Reward: 213.4785411161182 avg_loss_c: 2.913222893646785 avg_loss_a: -54.20199688502721\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 106.687343\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11430 son episode_steps:50\n",
            "Total Steps: 685175 Episode Num: 11430 Reward: 47.596299972680136 avg_loss_c: 3.0558093214035034 avg_loss_a: -54.07472885131836\n",
            "Número de pasos del episodeo 11431 son episode_steps:213\n",
            "Total Steps: 685388 Episode Num: 11431 Reward: 339.9699550084163 avg_loss_c: 2.918187952377427 avg_loss_a: -54.323708243213346\n",
            "Número de pasos del episodeo 11432 son episode_steps:69\n",
            "Total Steps: 685457 Episode Num: 11432 Reward: 106.80473103853255 avg_loss_c: 2.868557815966399 avg_loss_a: -54.51973619322846\n",
            "Número de pasos del episodeo 11433 son episode_steps:52\n",
            "Total Steps: 685509 Episode Num: 11433 Reward: 34.794920326295525 avg_loss_c: 3.018496586726262 avg_loss_a: -54.457377213698166\n",
            "Número de pasos del episodeo 11434 son episode_steps:54\n",
            "Total Steps: 685563 Episode Num: 11434 Reward: 67.48851090183659 avg_loss_c: 2.9086065557267933 avg_loss_a: -53.163545537877965\n",
            "Número de pasos del episodeo 11435 son episode_steps:164\n",
            "Total Steps: 685727 Episode Num: 11435 Reward: 267.56564800777596 avg_loss_c: 2.934064145495252 avg_loss_a: -54.91859426731017\n",
            "Número de pasos del episodeo 11436 son episode_steps:101\n",
            "Total Steps: 685828 Episode Num: 11436 Reward: 34.34879036023885 avg_loss_c: 3.0249638002697785 avg_loss_a: -54.38497977681679\n",
            "Número de pasos del episodeo 11437 son episode_steps:98\n",
            "Total Steps: 685926 Episode Num: 11437 Reward: 123.97638045265269 avg_loss_c: 3.3438983985355923 avg_loss_a: -54.022128591732105\n",
            "Número de pasos del episodeo 11438 son episode_steps:112\n",
            "Total Steps: 686038 Episode Num: 11438 Reward: 34.31774257747373 avg_loss_c: 3.0098998897842 avg_loss_a: -54.221616881234304\n",
            "Número de pasos del episodeo 11439 son episode_steps:104\n",
            "Total Steps: 686142 Episode Num: 11439 Reward: 131.84862473238886 avg_loss_c: 3.2455994601433096 avg_loss_a: -53.767753234276405\n",
            "Número de pasos del episodeo 11440 son episode_steps:174\n",
            "Total Steps: 686316 Episode Num: 11440 Reward: 254.70014734481518 avg_loss_c: 2.99741585432798 avg_loss_a: -54.25872829042632\n",
            "Número de pasos del episodeo 11441 son episode_steps:71\n",
            "Total Steps: 686387 Episode Num: 11441 Reward: 88.79763943151856 avg_loss_c: 3.205510053836124 avg_loss_a: -54.34343472333022\n",
            "Número de pasos del episodeo 11442 son episode_steps:68\n",
            "Total Steps: 686455 Episode Num: 11442 Reward: 76.42092483653705 avg_loss_c: 3.2180687031325172 avg_loss_a: -54.025876325719494\n",
            "Número de pasos del episodeo 11443 son episode_steps:123\n",
            "Total Steps: 686578 Episode Num: 11443 Reward: 175.2507123538187 avg_loss_c: 2.797916702138699 avg_loss_a: -54.3194153328252\n",
            "Número de pasos del episodeo 11444 son episode_steps:93\n",
            "Total Steps: 686671 Episode Num: 11444 Reward: 143.26142741277138 avg_loss_c: 3.1786406732374624 avg_loss_a: -54.07862201813729\n",
            "Número de pasos del episodeo 11445 son episode_steps:84\n",
            "Total Steps: 686755 Episode Num: 11445 Reward: 108.08387613922504 avg_loss_c: 2.89138571705137 avg_loss_a: -53.97160648164295\n",
            "Número de pasos del episodeo 11446 son episode_steps:205\n",
            "Total Steps: 686960 Episode Num: 11446 Reward: 320.8567960868484 avg_loss_c: 2.8824862154518684 avg_loss_a: -54.2120049639446\n",
            "Número de pasos del episodeo 11447 son episode_steps:116\n",
            "Total Steps: 687076 Episode Num: 11447 Reward: 179.16889344273605 avg_loss_c: 2.89838143874859 avg_loss_a: -54.389387722673085\n",
            "Número de pasos del episodeo 11448 son episode_steps:106\n",
            "Total Steps: 687182 Episode Num: 11448 Reward: 134.6240835723771 avg_loss_c: 2.783009606712269 avg_loss_a: -54.81448040368422\n",
            "Número de pasos del episodeo 11449 son episode_steps:73\n",
            "Total Steps: 687255 Episode Num: 11449 Reward: 103.48393952250805 avg_loss_c: 2.862035774204829 avg_loss_a: -55.090391812259206\n",
            "Número de pasos del episodeo 11450 son episode_steps:74\n",
            "Total Steps: 687329 Episode Num: 11450 Reward: 108.99796407053049 avg_loss_c: 3.134689864274618 avg_loss_a: -54.57571472992768\n",
            "Número de pasos del episodeo 11451 son episode_steps:91\n",
            "Total Steps: 687420 Episode Num: 11451 Reward: 128.22675989855657 avg_loss_c: 2.9156874195559994 avg_loss_a: -53.92069324032291\n",
            "Número de pasos del episodeo 11452 son episode_steps:89\n",
            "Total Steps: 687509 Episode Num: 11452 Reward: 132.99412444049185 avg_loss_c: 2.944869065552615 avg_loss_a: -54.37853553857696\n",
            "Número de pasos del episodeo 11453 son episode_steps:191\n",
            "Total Steps: 687700 Episode Num: 11453 Reward: 304.4674308356721 avg_loss_c: 2.994556411398643 avg_loss_a: -54.16520253525979\n",
            "Número de pasos del episodeo 11454 son episode_steps:100\n",
            "Total Steps: 687800 Episode Num: 11454 Reward: 122.3990776784667 avg_loss_c: 2.950141894817352 avg_loss_a: -54.7180298614502\n",
            "Número de pasos del episodeo 11455 son episode_steps:39\n",
            "Total Steps: 687839 Episode Num: 11455 Reward: -58.05164279059239 avg_loss_c: 3.874572808925922 avg_loss_a: -53.60163683769031\n",
            "Número de pasos del episodeo 11456 son episode_steps:103\n",
            "Total Steps: 687942 Episode Num: 11456 Reward: 145.42654769058115 avg_loss_c: 3.6028478747432673 avg_loss_a: -53.68184050772954\n",
            "Número de pasos del episodeo 11457 son episode_steps:79\n",
            "Total Steps: 688021 Episode Num: 11457 Reward: 129.47016659751887 avg_loss_c: 3.1525844607172133 avg_loss_a: -54.14765331413172\n",
            "Número de pasos del episodeo 11458 son episode_steps:120\n",
            "Total Steps: 688141 Episode Num: 11458 Reward: 178.53825229200407 avg_loss_c: 3.55953169465065 avg_loss_a: -53.48294372558594\n",
            "Número de pasos del episodeo 11459 son episode_steps:106\n",
            "Total Steps: 688247 Episode Num: 11459 Reward: 137.56299322367468 avg_loss_c: 2.7852531828970277 avg_loss_a: -53.88970601783608\n",
            "Número de pasos del episodeo 11460 son episode_steps:91\n",
            "Total Steps: 688338 Episode Num: 11460 Reward: 138.14249864123428 avg_loss_c: 3.275887525998629 avg_loss_a: -53.628912328363775\n",
            "Número de pasos del episodeo 11461 son episode_steps:203\n",
            "Total Steps: 688541 Episode Num: 11461 Reward: 329.0742892716256 avg_loss_c: 2.892795268537963 avg_loss_a: -54.01828850431395\n",
            "Número de pasos del episodeo 11462 son episode_steps:72\n",
            "Total Steps: 688613 Episode Num: 11462 Reward: 101.81526520876045 avg_loss_c: 2.9433323542277017 avg_loss_a: -53.679318004184296\n",
            "Número de pasos del episodeo 11463 son episode_steps:46\n",
            "Total Steps: 688659 Episode Num: 11463 Reward: 51.02617264107697 avg_loss_c: 2.8007350175277046 avg_loss_a: -53.71975807521654\n",
            "Número de pasos del episodeo 11464 son episode_steps:75\n",
            "Total Steps: 688734 Episode Num: 11464 Reward: 114.69129911179371 avg_loss_c: 3.010189943313599 avg_loss_a: -53.897589111328124\n",
            "Número de pasos del episodeo 11465 son episode_steps:83\n",
            "Total Steps: 688817 Episode Num: 11465 Reward: 77.9415951456558 avg_loss_c: 2.854099497737655 avg_loss_a: -53.81064803341785\n",
            "Número de pasos del episodeo 11466 son episode_steps:146\n",
            "Total Steps: 688963 Episode Num: 11466 Reward: 224.40429237757968 avg_loss_c: 3.0146422320849275 avg_loss_a: -54.17226775704998\n",
            "Número de pasos del episodeo 11467 son episode_steps:83\n",
            "Total Steps: 689046 Episode Num: 11467 Reward: 129.9876316502351 avg_loss_c: 3.065840456859175 avg_loss_a: -53.57904379051852\n",
            "Número de pasos del episodeo 11468 son episode_steps:79\n",
            "Total Steps: 689125 Episode Num: 11468 Reward: 98.38787400742322 avg_loss_c: 2.817597639711597 avg_loss_a: -54.119587910326224\n",
            "Número de pasos del episodeo 11469 son episode_steps:105\n",
            "Total Steps: 689230 Episode Num: 11469 Reward: 168.30392805515595 avg_loss_c: 2.9655126140231176 avg_loss_a: -53.6870608375186\n",
            "Número de pasos del episodeo 11470 son episode_steps:213\n",
            "Total Steps: 689443 Episode Num: 11470 Reward: 309.5036364699455 avg_loss_c: 2.868442988171824 avg_loss_a: -54.36788218681801\n",
            "Número de pasos del episodeo 11471 son episode_steps:110\n",
            "Total Steps: 689553 Episode Num: 11471 Reward: 163.2894648516969 avg_loss_c: 2.912160879915411 avg_loss_a: -53.884899971701884\n",
            "Número de pasos del episodeo 11472 son episode_steps:95\n",
            "Total Steps: 689648 Episode Num: 11472 Reward: 141.72071253318632 avg_loss_c: 2.8117940727033113 avg_loss_a: -54.2949711849815\n",
            "Número de pasos del episodeo 11473 son episode_steps:96\n",
            "Total Steps: 689744 Episode Num: 11473 Reward: 144.53857865343122 avg_loss_c: 2.874785794566075 avg_loss_a: -54.47818843523661\n",
            "Número de pasos del episodeo 11474 son episode_steps:70\n",
            "Total Steps: 689814 Episode Num: 11474 Reward: 99.62388243727844 avg_loss_c: 2.9041585734912325 avg_loss_a: -54.44008047921317\n",
            "Número de pasos del episodeo 11475 son episode_steps:47\n",
            "Total Steps: 689861 Episode Num: 11475 Reward: 33.82139092998351 avg_loss_c: 2.968292753747169 avg_loss_a: -54.206980116823885\n",
            "Número de pasos del episodeo 11476 son episode_steps:80\n",
            "Total Steps: 689941 Episode Num: 11476 Reward: 106.93837043320656 avg_loss_c: 2.9511356115341187 avg_loss_a: -54.45479230880737\n",
            "Número de pasos del episodeo 11477 son episode_steps:110\n",
            "Total Steps: 690051 Episode Num: 11477 Reward: 159.02632220039345 avg_loss_c: 3.048191371831027 avg_loss_a: -54.62311782836914\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 149.804253\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11478 son episode_steps:85\n",
            "Total Steps: 690136 Episode Num: 11478 Reward: 144.67761900454772 avg_loss_c: 3.0425841836368335 avg_loss_a: -54.94547738467946\n",
            "Número de pasos del episodeo 11479 son episode_steps:79\n",
            "Total Steps: 690215 Episode Num: 11479 Reward: 110.99169583050116 avg_loss_c: 2.886381974703149 avg_loss_a: -54.217987543419945\n",
            "Número de pasos del episodeo 11480 son episode_steps:90\n",
            "Total Steps: 690305 Episode Num: 11480 Reward: 110.76150108536118 avg_loss_c: 2.8140708208084106 avg_loss_a: -53.94878497653537\n",
            "Número de pasos del episodeo 11481 son episode_steps:104\n",
            "Total Steps: 690409 Episode Num: 11481 Reward: 126.62677342369065 avg_loss_c: 2.8793217895122676 avg_loss_a: -54.443451367891754\n",
            "Número de pasos del episodeo 11482 son episode_steps:104\n",
            "Total Steps: 690513 Episode Num: 11482 Reward: 108.52170212629582 avg_loss_c: 3.143953426526143 avg_loss_a: -54.133385731623726\n",
            "Número de pasos del episodeo 11483 son episode_steps:155\n",
            "Total Steps: 690668 Episode Num: 11483 Reward: 259.35378795113894 avg_loss_c: 3.0023686985815723 avg_loss_a: -54.97310606433499\n",
            "Número de pasos del episodeo 11484 son episode_steps:74\n",
            "Total Steps: 690742 Episode Num: 11484 Reward: 81.26143536603504 avg_loss_c: 2.9468078597171887 avg_loss_a: -55.24496789880701\n",
            "Número de pasos del episodeo 11485 son episode_steps:170\n",
            "Total Steps: 690912 Episode Num: 11485 Reward: 232.74889125090803 avg_loss_c: 2.814005535490373 avg_loss_a: -54.2936751870548\n",
            "Número de pasos del episodeo 11486 son episode_steps:89\n",
            "Total Steps: 691001 Episode Num: 11486 Reward: 69.23322586258905 avg_loss_c: 3.1565509217508723 avg_loss_a: -54.758675178785005\n",
            "Número de pasos del episodeo 11487 son episode_steps:69\n",
            "Total Steps: 691070 Episode Num: 11487 Reward: 106.6858870183399 avg_loss_c: 3.0053179471389107 avg_loss_a: -54.777319092681445\n",
            "Número de pasos del episodeo 11488 son episode_steps:90\n",
            "Total Steps: 691160 Episode Num: 11488 Reward: 18.00722902093597 avg_loss_c: 3.2542157332102457 avg_loss_a: -54.28816511366102\n",
            "Número de pasos del episodeo 11489 son episode_steps:39\n",
            "Total Steps: 691199 Episode Num: 11489 Reward: 38.84369852800249 avg_loss_c: 3.0117211158459005 avg_loss_a: -53.97506146553235\n",
            "Número de pasos del episodeo 11490 son episode_steps:76\n",
            "Total Steps: 691275 Episode Num: 11490 Reward: 104.2323248349988 avg_loss_c: 3.1556165437949333 avg_loss_a: -54.56241296467028\n",
            "Número de pasos del episodeo 11491 son episode_steps:72\n",
            "Total Steps: 691347 Episode Num: 11491 Reward: 98.57275315325359 avg_loss_c: 3.2592794034216137 avg_loss_a: -53.9555598364936\n",
            "Número de pasos del episodeo 11492 son episode_steps:202\n",
            "Total Steps: 691549 Episode Num: 11492 Reward: 287.05616633420726 avg_loss_c: 3.219744622117222 avg_loss_a: -54.56832972611531\n",
            "Número de pasos del episodeo 11493 son episode_steps:37\n",
            "Total Steps: 691586 Episode Num: 11493 Reward: 22.771315909325097 avg_loss_c: 2.9811130729881494 avg_loss_a: -54.691449964368665\n",
            "Número de pasos del episodeo 11494 son episode_steps:122\n",
            "Total Steps: 691708 Episode Num: 11494 Reward: 180.65448955993185 avg_loss_c: 3.0424488792653945 avg_loss_a: -54.87029097510166\n",
            "Número de pasos del episodeo 11495 son episode_steps:147\n",
            "Total Steps: 691855 Episode Num: 11495 Reward: 225.56385731778127 avg_loss_c: 3.214380389168149 avg_loss_a: -54.28069528592687\n",
            "Número de pasos del episodeo 11496 son episode_steps:129\n",
            "Total Steps: 691984 Episode Num: 11496 Reward: 200.73319463118318 avg_loss_c: 2.9773807008137076 avg_loss_a: -54.41899141415145\n",
            "Número de pasos del episodeo 11497 son episode_steps:87\n",
            "Total Steps: 692071 Episode Num: 11497 Reward: 135.92476373266493 avg_loss_c: 3.6338408308467645 avg_loss_a: -54.377836117799255\n",
            "Número de pasos del episodeo 11498 son episode_steps:114\n",
            "Total Steps: 692185 Episode Num: 11498 Reward: 179.86890562896218 avg_loss_c: 3.5275329497822545 avg_loss_a: -54.7912916216934\n",
            "Número de pasos del episodeo 11499 son episode_steps:103\n",
            "Total Steps: 692288 Episode Num: 11499 Reward: 151.8703534529499 avg_loss_c: 3.2787322998046875 avg_loss_a: -54.54705040200243\n",
            "Número de pasos del episodeo 11500 son episode_steps:53\n",
            "Total Steps: 692341 Episode Num: 11500 Reward: 72.9002847465071 avg_loss_c: 3.0382078278739497 avg_loss_a: -54.14559058423312\n",
            "Número de pasos del episodeo 11501 son episode_steps:81\n",
            "Total Steps: 692422 Episode Num: 11501 Reward: 125.73843248383437 avg_loss_c: 3.2605481883625926 avg_loss_a: -54.39731527257849\n",
            "Número de pasos del episodeo 11502 son episode_steps:88\n",
            "Total Steps: 692510 Episode Num: 11502 Reward: 127.5892003679834 avg_loss_c: 3.1003187705170023 avg_loss_a: -54.09609014337713\n",
            "Número de pasos del episodeo 11503 son episode_steps:151\n",
            "Total Steps: 692661 Episode Num: 11503 Reward: 234.5155244300048 avg_loss_c: 3.0628333502257896 avg_loss_a: -54.27804767532854\n",
            "Número de pasos del episodeo 11504 son episode_steps:111\n",
            "Total Steps: 692772 Episode Num: 11504 Reward: 156.95343578622985 avg_loss_c: 3.1132934651933275 avg_loss_a: -53.95715902517508\n",
            "Número de pasos del episodeo 11505 son episode_steps:67\n",
            "Total Steps: 692839 Episode Num: 11505 Reward: 113.09044832942462 avg_loss_c: 3.2533046327420134 avg_loss_a: -54.81734312826128\n",
            "Número de pasos del episodeo 11506 son episode_steps:71\n",
            "Total Steps: 692910 Episode Num: 11506 Reward: 120.36966982294776 avg_loss_c: 2.999145299615994 avg_loss_a: -54.09604623284138\n",
            "Número de pasos del episodeo 11507 son episode_steps:123\n",
            "Total Steps: 693033 Episode Num: 11507 Reward: 170.56023697009056 avg_loss_c: 3.1154956701325207 avg_loss_a: -54.0812051974661\n",
            "Número de pasos del episodeo 11508 son episode_steps:126\n",
            "Total Steps: 693159 Episode Num: 11508 Reward: 180.71207332487728 avg_loss_c: 3.2362744600053817 avg_loss_a: -54.21258629692925\n",
            "Número de pasos del episodeo 11509 son episode_steps:54\n",
            "Total Steps: 693213 Episode Num: 11509 Reward: 56.13544192344817 avg_loss_c: 2.8820077180862427 avg_loss_a: -53.77544643260814\n",
            "Número de pasos del episodeo 11510 son episode_steps:114\n",
            "Total Steps: 693327 Episode Num: 11510 Reward: 73.88823388608122 avg_loss_c: 3.028469945255079 avg_loss_a: -54.24349707887884\n",
            "Número de pasos del episodeo 11511 son episode_steps:173\n",
            "Total Steps: 693500 Episode Num: 11511 Reward: 254.76471109783805 avg_loss_c: 3.1629548479366854 avg_loss_a: -54.25618735076375\n",
            "Número de pasos del episodeo 11512 son episode_steps:60\n",
            "Total Steps: 693560 Episode Num: 11512 Reward: 89.00109939952833 avg_loss_c: 3.1125067551930745 avg_loss_a: -54.22661616007487\n",
            "Número de pasos del episodeo 11513 son episode_steps:164\n",
            "Total Steps: 693724 Episode Num: 11513 Reward: 210.211317586374 avg_loss_c: 3.1098665173460796 avg_loss_a: -55.06530329076255\n",
            "Número de pasos del episodeo 11514 son episode_steps:92\n",
            "Total Steps: 693816 Episode Num: 11514 Reward: 142.64419712384245 avg_loss_c: 3.0099562549072765 avg_loss_a: -54.39298961473548\n",
            "Número de pasos del episodeo 11515 son episode_steps:166\n",
            "Total Steps: 693982 Episode Num: 11515 Reward: 241.21168757742757 avg_loss_c: 3.0917654324726884 avg_loss_a: -54.69874255628471\n",
            "Número de pasos del episodeo 11516 son episode_steps:91\n",
            "Total Steps: 694073 Episode Num: 11516 Reward: 147.02342524130393 avg_loss_c: 3.044655066270095 avg_loss_a: -54.71117987999549\n",
            "Número de pasos del episodeo 11517 son episode_steps:71\n",
            "Total Steps: 694144 Episode Num: 11517 Reward: 97.46542930110564 avg_loss_c: 3.028184667439528 avg_loss_a: -54.90956411227374\n",
            "Número de pasos del episodeo 11518 son episode_steps:117\n",
            "Total Steps: 694261 Episode Num: 11518 Reward: 179.92555112805218 avg_loss_c: 3.1404093279797807 avg_loss_a: -54.696398058508194\n",
            "Número de pasos del episodeo 11519 son episode_steps:145\n",
            "Total Steps: 694406 Episode Num: 11519 Reward: 188.19744305567107 avg_loss_c: 3.1614487171173096 avg_loss_a: -54.7823116170949\n",
            "Número de pasos del episodeo 11520 son episode_steps:174\n",
            "Total Steps: 694580 Episode Num: 11520 Reward: 282.69726001955297 avg_loss_c: 3.2331269294366067 avg_loss_a: -55.19909225113091\n",
            "Número de pasos del episodeo 11521 son episode_steps:67\n",
            "Total Steps: 694647 Episode Num: 11521 Reward: 68.74360035030169 avg_loss_c: 2.9874192921083367 avg_loss_a: -55.148283887265336\n",
            "Número de pasos del episodeo 11522 son episode_steps:215\n",
            "Total Steps: 694862 Episode Num: 11522 Reward: 212.22936763439702 avg_loss_c: 3.1067707948906476 avg_loss_a: -54.880256617346475\n",
            "Número de pasos del episodeo 11523 son episode_steps:93\n",
            "Total Steps: 694955 Episode Num: 11523 Reward: -3.2228326672073875 avg_loss_c: 3.3754268846204205 avg_loss_a: -54.80027196740591\n",
            "Número de pasos del episodeo 11524 son episode_steps:119\n",
            "Total Steps: 695074 Episode Num: 11524 Reward: 178.95238264953426 avg_loss_c: 3.431389081377943 avg_loss_a: -54.88347616115538\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 208.465830\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11525 son episode_steps:106\n",
            "Total Steps: 695180 Episode Num: 11525 Reward: 172.30484980031784 avg_loss_c: 3.2545895835138716 avg_loss_a: -54.74423606440706\n",
            "Número de pasos del episodeo 11526 son episode_steps:82\n",
            "Total Steps: 695262 Episode Num: 11526 Reward: 130.90150761407608 avg_loss_c: 3.437412977218628 avg_loss_a: -55.18060526033727\n",
            "Número de pasos del episodeo 11527 son episode_steps:130\n",
            "Total Steps: 695392 Episode Num: 11527 Reward: 202.50562614270586 avg_loss_c: 3.224931889313918 avg_loss_a: -54.328790283203126\n",
            "Número de pasos del episodeo 11528 son episode_steps:161\n",
            "Total Steps: 695553 Episode Num: 11528 Reward: 240.96504834896842 avg_loss_c: 3.103470666067941 avg_loss_a: -54.91688940391777\n",
            "Número de pasos del episodeo 11529 son episode_steps:164\n",
            "Total Steps: 695717 Episode Num: 11529 Reward: 257.22249187659844 avg_loss_c: 3.1137774615752987 avg_loss_a: -54.90254681284835\n",
            "Número de pasos del episodeo 11530 son episode_steps:98\n",
            "Total Steps: 695815 Episode Num: 11530 Reward: 151.69082122754136 avg_loss_c: 2.8809401380772495 avg_loss_a: -55.48724622142558\n",
            "Número de pasos del episodeo 11531 son episode_steps:88\n",
            "Total Steps: 695903 Episode Num: 11531 Reward: 136.26065553873806 avg_loss_c: 3.14664104309949 avg_loss_a: -54.77617073059082\n",
            "Número de pasos del episodeo 11532 son episode_steps:197\n",
            "Total Steps: 696100 Episode Num: 11532 Reward: 303.0664129401175 avg_loss_c: 3.12653743555098 avg_loss_a: -55.153838995144454\n",
            "Número de pasos del episodeo 11533 son episode_steps:207\n",
            "Total Steps: 696307 Episode Num: 11533 Reward: 337.1478654936457 avg_loss_c: 3.0915223480998604 avg_loss_a: -55.49392744423687\n",
            "Número de pasos del episodeo 11534 son episode_steps:71\n",
            "Total Steps: 696378 Episode Num: 11534 Reward: 96.25924390162498 avg_loss_c: 3.0758706549523582 avg_loss_a: -55.01332070793904\n",
            "Número de pasos del episodeo 11535 son episode_steps:106\n",
            "Total Steps: 696484 Episode Num: 11535 Reward: 162.5922367316814 avg_loss_c: 3.0925791938349887 avg_loss_a: -55.00545890376253\n",
            "Número de pasos del episodeo 11536 son episode_steps:101\n",
            "Total Steps: 696585 Episode Num: 11536 Reward: 113.36382440431856 avg_loss_c: 2.9669110987446095 avg_loss_a: -55.00227314410824\n",
            "Número de pasos del episodeo 11537 son episode_steps:87\n",
            "Total Steps: 696672 Episode Num: 11537 Reward: 124.73608616043845 avg_loss_c: 3.386294688301525 avg_loss_a: -55.153419757711475\n",
            "Número de pasos del episodeo 11538 son episode_steps:188\n",
            "Total Steps: 696860 Episode Num: 11538 Reward: 270.1218673324471 avg_loss_c: 3.1006847315646233 avg_loss_a: -55.00934641411964\n",
            "Número de pasos del episodeo 11539 son episode_steps:112\n",
            "Total Steps: 696972 Episode Num: 11539 Reward: 172.45187403189715 avg_loss_c: 3.0496290741222247 avg_loss_a: -55.24158723013742\n",
            "Número de pasos del episodeo 11540 son episode_steps:136\n",
            "Total Steps: 697108 Episode Num: 11540 Reward: 178.6208825300591 avg_loss_c: 2.974472220329677 avg_loss_a: -55.34128598605885\n",
            "Número de pasos del episodeo 11541 son episode_steps:121\n",
            "Total Steps: 697229 Episode Num: 11541 Reward: 191.03613659257297 avg_loss_c: 3.1821604937561285 avg_loss_a: -55.25770061272235\n",
            "Número de pasos del episodeo 11542 son episode_steps:79\n",
            "Total Steps: 697308 Episode Num: 11542 Reward: 13.146872034533123 avg_loss_c: 3.1288691230967074 avg_loss_a: -55.03661307805701\n",
            "Número de pasos del episodeo 11543 son episode_steps:107\n",
            "Total Steps: 697415 Episode Num: 11543 Reward: 168.9028171571141 avg_loss_c: 3.0507386243231944 avg_loss_a: -55.69377546221296\n",
            "Número de pasos del episodeo 11544 son episode_steps:159\n",
            "Total Steps: 697574 Episode Num: 11544 Reward: 231.87323472592468 avg_loss_c: 3.0013044082893514 avg_loss_a: -55.14558789715077\n",
            "Número de pasos del episodeo 11545 son episode_steps:208\n",
            "Total Steps: 697782 Episode Num: 11545 Reward: 363.2315722872213 avg_loss_c: 2.9668151684678516 avg_loss_a: -55.525063074552094\n",
            "Número de pasos del episodeo 11546 son episode_steps:149\n",
            "Total Steps: 697931 Episode Num: 11546 Reward: 206.0815442731069 avg_loss_c: 2.966264069480384 avg_loss_a: -55.48034365865208\n",
            "Número de pasos del episodeo 11547 son episode_steps:66\n",
            "Total Steps: 697997 Episode Num: 11547 Reward: 96.71420156738438 avg_loss_c: 3.0407675035072095 avg_loss_a: -55.95210589784564\n",
            "Número de pasos del episodeo 11548 son episode_steps:90\n",
            "Total Steps: 698087 Episode Num: 11548 Reward: 134.53503834591714 avg_loss_c: 2.742009471522437 avg_loss_a: -55.33550940619575\n",
            "Número de pasos del episodeo 11549 son episode_steps:46\n",
            "Total Steps: 698133 Episode Num: 11549 Reward: 28.152846472951712 avg_loss_c: 3.4603558908338132 avg_loss_a: -56.42015258125637\n",
            "Número de pasos del episodeo 11550 son episode_steps:55\n",
            "Total Steps: 698188 Episode Num: 11550 Reward: 51.97739499186765 avg_loss_c: 3.383249907060103 avg_loss_a: -54.955386491255325\n",
            "Número de pasos del episodeo 11551 son episode_steps:128\n",
            "Total Steps: 698316 Episode Num: 11551 Reward: 179.61186896379346 avg_loss_c: 3.0258755907416344 avg_loss_a: -55.52501428127289\n",
            "Número de pasos del episodeo 11552 son episode_steps:197\n",
            "Total Steps: 698513 Episode Num: 11552 Reward: 293.7762774743523 avg_loss_c: 3.1972023430209475 avg_loss_a: -55.02761865993442\n",
            "Número de pasos del episodeo 11553 son episode_steps:136\n",
            "Total Steps: 698649 Episode Num: 11553 Reward: 215.47137787390554 avg_loss_c: 2.9780128519324696 avg_loss_a: -55.25394254572251\n",
            "Número de pasos del episodeo 11554 son episode_steps:107\n",
            "Total Steps: 698756 Episode Num: 11554 Reward: 172.2632602560726 avg_loss_c: 2.9510296003840795 avg_loss_a: -54.618337613399895\n",
            "Número de pasos del episodeo 11555 son episode_steps:214\n",
            "Total Steps: 698970 Episode Num: 11555 Reward: 357.14696893242524 avg_loss_c: 3.0784697376679038 avg_loss_a: -55.23470470392815\n",
            "Número de pasos del episodeo 11556 son episode_steps:108\n",
            "Total Steps: 699078 Episode Num: 11556 Reward: 169.70756226702403 avg_loss_c: 3.0376233513708466 avg_loss_a: -54.650806992142286\n",
            "Número de pasos del episodeo 11557 son episode_steps:118\n",
            "Total Steps: 699196 Episode Num: 11557 Reward: 154.07113931726354 avg_loss_c: 3.105500752643003 avg_loss_a: -55.07434747986874\n",
            "Número de pasos del episodeo 11558 son episode_steps:237\n",
            "Total Steps: 699433 Episode Num: 11558 Reward: 391.9711937003916 avg_loss_c: 3.0762402196473713 avg_loss_a: -55.58442295251516\n",
            "Número de pasos del episodeo 11559 son episode_steps:117\n",
            "Total Steps: 699550 Episode Num: 11559 Reward: 180.6019309211984 avg_loss_c: 2.8682693069816656 avg_loss_a: -55.415887848943726\n",
            "Número de pasos del episodeo 11560 son episode_steps:38\n",
            "Total Steps: 699588 Episode Num: 11560 Reward: 0.47993258196689714 avg_loss_c: 3.1147899878652474 avg_loss_a: -54.74223789415861\n",
            "Número de pasos del episodeo 11561 son episode_steps:75\n",
            "Total Steps: 699663 Episode Num: 11561 Reward: 63.735241318457184 avg_loss_c: 3.1698399639129637 avg_loss_a: -55.55815180460612\n",
            "Número de pasos del episodeo 11562 son episode_steps:115\n",
            "Total Steps: 699778 Episode Num: 11562 Reward: 174.27423230437262 avg_loss_c: 3.2830110104187673 avg_loss_a: -55.0357285209324\n",
            "Número de pasos del episodeo 11563 son episode_steps:68\n",
            "Total Steps: 699846 Episode Num: 11563 Reward: 105.16027437670434 avg_loss_c: 3.467899592483745 avg_loss_a: -54.68867324380314\n",
            "Número de pasos del episodeo 11564 son episode_steps:68\n",
            "Total Steps: 699914 Episode Num: 11564 Reward: 101.21295142782921 avg_loss_c: 3.1385608560898723 avg_loss_a: -55.17995924108169\n",
            "Número de pasos del episodeo 11565 son episode_steps:159\n",
            "Total Steps: 700073 Episode Num: 11565 Reward: 251.3257424891612 avg_loss_c: 3.2477676298633313 avg_loss_a: -54.97335354786999\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 290.534235\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11566 son episode_steps:121\n",
            "Total Steps: 700194 Episode Num: 11566 Reward: 166.16207164462278 avg_loss_c: 3.2017391516157416 avg_loss_a: -54.87606704333597\n",
            "Número de pasos del episodeo 11567 son episode_steps:56\n",
            "Total Steps: 700250 Episode Num: 11567 Reward: 70.29443931886298 avg_loss_c: 3.7037686152117595 avg_loss_a: -55.062474387032644\n",
            "Número de pasos del episodeo 11568 son episode_steps:69\n",
            "Total Steps: 700319 Episode Num: 11568 Reward: 99.75886035545685 avg_loss_c: 3.345863221348196 avg_loss_a: -54.33685612332994\n",
            "Número de pasos del episodeo 11569 son episode_steps:169\n",
            "Total Steps: 700488 Episode Num: 11569 Reward: 257.56963866499865 avg_loss_c: 3.1662068367004395 avg_loss_a: -55.1396780521912\n",
            "Número de pasos del episodeo 11570 son episode_steps:78\n",
            "Total Steps: 700566 Episode Num: 11570 Reward: 123.23501945366819 avg_loss_c: 3.4870075415342283 avg_loss_a: -54.64551514845628\n",
            "Número de pasos del episodeo 11571 son episode_steps:76\n",
            "Total Steps: 700642 Episode Num: 11571 Reward: 122.31381841537265 avg_loss_c: 3.161903651137101 avg_loss_a: -54.846128965678965\n",
            "Número de pasos del episodeo 11572 son episode_steps:199\n",
            "Total Steps: 700841 Episode Num: 11572 Reward: 215.24695369582747 avg_loss_c: 3.1375441203764334 avg_loss_a: -54.936405546102094\n",
            "Número de pasos del episodeo 11573 son episode_steps:123\n",
            "Total Steps: 700964 Episode Num: 11573 Reward: 135.2270879010454 avg_loss_c: 3.2476660255494156 avg_loss_a: -54.878165206288905\n",
            "Número de pasos del episodeo 11574 son episode_steps:86\n",
            "Total Steps: 701050 Episode Num: 11574 Reward: 125.49382511758138 avg_loss_c: 3.042357414267784 avg_loss_a: -55.10037843571153\n",
            "Número de pasos del episodeo 11575 son episode_steps:222\n",
            "Total Steps: 701272 Episode Num: 11575 Reward: 368.40779118499273 avg_loss_c: 3.03793931114781 avg_loss_a: -55.048948098947335\n",
            "Número de pasos del episodeo 11576 son episode_steps:114\n",
            "Total Steps: 701386 Episode Num: 11576 Reward: 184.14980153435687 avg_loss_c: 3.1593630920376694 avg_loss_a: -55.14430123044733\n",
            "Número de pasos del episodeo 11577 son episode_steps:90\n",
            "Total Steps: 701476 Episode Num: 11577 Reward: 129.28302156931122 avg_loss_c: 3.2337308671739367 avg_loss_a: -54.851524183485246\n",
            "Número de pasos del episodeo 11578 son episode_steps:225\n",
            "Total Steps: 701701 Episode Num: 11578 Reward: 371.85654054873794 avg_loss_c: 3.2318006462521023 avg_loss_a: -54.87136594984266\n",
            "Número de pasos del episodeo 11579 son episode_steps:112\n",
            "Total Steps: 701813 Episode Num: 11579 Reward: 168.36381689271528 avg_loss_c: 3.234007753431797 avg_loss_a: -55.016236441476\n",
            "Número de pasos del episodeo 11580 son episode_steps:116\n",
            "Total Steps: 701929 Episode Num: 11580 Reward: 147.39778050773887 avg_loss_c: 3.020127829806558 avg_loss_a: -54.70778892780172\n",
            "Número de pasos del episodeo 11581 son episode_steps:175\n",
            "Total Steps: 702104 Episode Num: 11581 Reward: 274.60867028343586 avg_loss_c: 3.056361528805324 avg_loss_a: -55.000398581368586\n",
            "Número de pasos del episodeo 11582 son episode_steps:176\n",
            "Total Steps: 702280 Episode Num: 11582 Reward: 221.0832859259924 avg_loss_c: 3.0426393564451826 avg_loss_a: -54.994927406311035\n",
            "Número de pasos del episodeo 11583 son episode_steps:63\n",
            "Total Steps: 702343 Episode Num: 11583 Reward: 80.73851439431806 avg_loss_c: 3.1633576438540505 avg_loss_a: -54.94229253133138\n",
            "Número de pasos del episodeo 11584 son episode_steps:100\n",
            "Total Steps: 702443 Episode Num: 11584 Reward: 154.0562485806437 avg_loss_c: 3.072317063808441 avg_loss_a: -54.381466674804685\n",
            "Número de pasos del episodeo 11585 son episode_steps:114\n",
            "Total Steps: 702557 Episode Num: 11585 Reward: 156.583014518779 avg_loss_c: 3.2068639481276797 avg_loss_a: -54.46550375955147\n",
            "Número de pasos del episodeo 11586 son episode_steps:64\n",
            "Total Steps: 702621 Episode Num: 11586 Reward: 65.43078618212108 avg_loss_c: 3.1782145500183105 avg_loss_a: -54.58942723274231\n",
            "Número de pasos del episodeo 11587 son episode_steps:41\n",
            "Total Steps: 702662 Episode Num: 11587 Reward: -4.305688502907064 avg_loss_c: 3.000448538035881 avg_loss_a: -54.40088951296923\n",
            "Número de pasos del episodeo 11588 son episode_steps:228\n",
            "Total Steps: 702890 Episode Num: 11588 Reward: 327.77772767792857 avg_loss_c: 3.3531537547446133 avg_loss_a: -54.80772841604132\n",
            "Número de pasos del episodeo 11589 son episode_steps:194\n",
            "Total Steps: 703084 Episode Num: 11589 Reward: 315.8921759446362 avg_loss_c: 3.288742438419578 avg_loss_a: -54.73764580795445\n",
            "Número de pasos del episodeo 11590 son episode_steps:101\n",
            "Total Steps: 703185 Episode Num: 11590 Reward: 144.19517662687346 avg_loss_c: 3.2658122317625744 avg_loss_a: -54.45306313391959\n",
            "Número de pasos del episodeo 11591 son episode_steps:225\n",
            "Total Steps: 703410 Episode Num: 11591 Reward: 366.8417113963651 avg_loss_c: 3.136152678595649 avg_loss_a: -54.76718361748589\n",
            "Número de pasos del episodeo 11592 son episode_steps:101\n",
            "Total Steps: 703511 Episode Num: 11592 Reward: 148.2146545383868 avg_loss_c: 3.0786354895865564 avg_loss_a: -54.70193390799041\n",
            "Número de pasos del episodeo 11593 son episode_steps:103\n",
            "Total Steps: 703614 Episode Num: 11593 Reward: 162.37105903841396 avg_loss_c: 3.2017589286693093 avg_loss_a: -55.13196008182266\n",
            "Número de pasos del episodeo 11594 son episode_steps:68\n",
            "Total Steps: 703682 Episode Num: 11594 Reward: 92.86227748538785 avg_loss_c: 3.1684636964517483 avg_loss_a: -54.82975421232336\n",
            "Número de pasos del episodeo 11595 son episode_steps:142\n",
            "Total Steps: 703824 Episode Num: 11595 Reward: 215.39562043331065 avg_loss_c: 3.108455670551515 avg_loss_a: -54.82424776319047\n",
            "Número de pasos del episodeo 11596 son episode_steps:94\n",
            "Total Steps: 703918 Episode Num: 11596 Reward: 132.77131523252558 avg_loss_c: 3.066546374178947 avg_loss_a: -54.647444542418135\n",
            "Número de pasos del episodeo 11597 son episode_steps:104\n",
            "Total Steps: 704022 Episode Num: 11597 Reward: 155.86852353563597 avg_loss_c: 3.07338714828858 avg_loss_a: -54.62091768704928\n",
            "Número de pasos del episodeo 11598 son episode_steps:124\n",
            "Total Steps: 704146 Episode Num: 11598 Reward: 182.67585824950643 avg_loss_c: 3.0183116351404498 avg_loss_a: -54.772713076683786\n",
            "Número de pasos del episodeo 11599 son episode_steps:99\n",
            "Total Steps: 704245 Episode Num: 11599 Reward: 152.25332960400362 avg_loss_c: 3.0289521795330625 avg_loss_a: -54.69954253688003\n",
            "Número de pasos del episodeo 11600 son episode_steps:205\n",
            "Total Steps: 704450 Episode Num: 11600 Reward: 341.9644828031917 avg_loss_c: 2.9496217611359388 avg_loss_a: -54.364561053020196\n",
            "Número de pasos del episodeo 11601 son episode_steps:116\n",
            "Total Steps: 704566 Episode Num: 11601 Reward: 178.11505072696883 avg_loss_c: 3.0154278113924224 avg_loss_a: -54.89422666615453\n",
            "Número de pasos del episodeo 11602 son episode_steps:108\n",
            "Total Steps: 704674 Episode Num: 11602 Reward: 153.15299432421048 avg_loss_c: 3.0567907602698714 avg_loss_a: -55.2165852299443\n",
            "Número de pasos del episodeo 11603 son episode_steps:136\n",
            "Total Steps: 704810 Episode Num: 11603 Reward: 198.4428988558469 avg_loss_c: 3.019339391413857 avg_loss_a: -54.69109243505142\n",
            "Número de pasos del episodeo 11604 son episode_steps:121\n",
            "Total Steps: 704931 Episode Num: 11604 Reward: 177.30243588124682 avg_loss_c: 3.0076763423021173 avg_loss_a: -54.37775134252123\n",
            "Número de pasos del episodeo 11605 son episode_steps:143\n",
            "Total Steps: 705074 Episode Num: 11605 Reward: 209.12627648460878 avg_loss_c: 2.9040601937087267 avg_loss_a: -55.21900187672435\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 165.122655\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11606 son episode_steps:128\n",
            "Total Steps: 705202 Episode Num: 11606 Reward: 185.57546045061954 avg_loss_c: 2.9566970048472285 avg_loss_a: -55.122046053409576\n",
            "Número de pasos del episodeo 11607 son episode_steps:134\n",
            "Total Steps: 705336 Episode Num: 11607 Reward: 199.56725706442387 avg_loss_c: 2.8643941754725444 avg_loss_a: -55.23971318486911\n",
            "Número de pasos del episodeo 11608 son episode_steps:181\n",
            "Total Steps: 705517 Episode Num: 11608 Reward: 186.6346091449888 avg_loss_c: 3.08798117005364 avg_loss_a: -54.891401048523285\n",
            "Número de pasos del episodeo 11609 son episode_steps:45\n",
            "Total Steps: 705562 Episode Num: 11609 Reward: 36.873410436322565 avg_loss_c: 2.8199716515011257 avg_loss_a: -55.48251597086588\n",
            "Número de pasos del episodeo 11610 son episode_steps:124\n",
            "Total Steps: 705686 Episode Num: 11610 Reward: 174.311379587831 avg_loss_c: 3.0917473819948014 avg_loss_a: -55.20511338018602\n",
            "Número de pasos del episodeo 11611 son episode_steps:57\n",
            "Total Steps: 705743 Episode Num: 11611 Reward: 35.24793457153409 avg_loss_c: 3.207567863297044 avg_loss_a: -55.31902085689076\n",
            "Número de pasos del episodeo 11612 son episode_steps:168\n",
            "Total Steps: 705911 Episode Num: 11612 Reward: 188.34480226130458 avg_loss_c: 2.9979113673879985 avg_loss_a: -55.06252656664167\n",
            "Número de pasos del episodeo 11613 son episode_steps:111\n",
            "Total Steps: 706022 Episode Num: 11613 Reward: 157.9122526317581 avg_loss_c: 2.9854593062186026 avg_loss_a: -55.02237677359366\n",
            "Número de pasos del episodeo 11614 son episode_steps:41\n",
            "Total Steps: 706063 Episode Num: 11614 Reward: -6.5108337741308375 avg_loss_c: 3.1241104719115467 avg_loss_a: -55.57906285727896\n",
            "Número de pasos del episodeo 11615 son episode_steps:74\n",
            "Total Steps: 706137 Episode Num: 11615 Reward: 112.55007406139684 avg_loss_c: 3.4383200310372017 avg_loss_a: -55.311572719264674\n",
            "Número de pasos del episodeo 11616 son episode_steps:93\n",
            "Total Steps: 706230 Episode Num: 11616 Reward: 131.53017960902935 avg_loss_c: 3.113352103899884 avg_loss_a: -55.58986089562857\n",
            "Número de pasos del episodeo 11617 son episode_steps:56\n",
            "Total Steps: 706286 Episode Num: 11617 Reward: 79.09274631004764 avg_loss_c: 2.7759028545447757 avg_loss_a: -55.72046429770334\n",
            "Número de pasos del episodeo 11618 son episode_steps:78\n",
            "Total Steps: 706364 Episode Num: 11618 Reward: 121.64594590626821 avg_loss_c: 3.1189727233006406 avg_loss_a: -55.721168029002655\n",
            "Número de pasos del episodeo 11619 son episode_steps:166\n",
            "Total Steps: 706530 Episode Num: 11619 Reward: 261.4741988719735 avg_loss_c: 3.0789764408605644 avg_loss_a: -55.30677193331431\n",
            "Número de pasos del episodeo 11620 son episode_steps:153\n",
            "Total Steps: 706683 Episode Num: 11620 Reward: 235.16359298738163 avg_loss_c: 3.4155884490293613 avg_loss_a: -55.66817302329868\n",
            "Número de pasos del episodeo 11621 son episode_steps:90\n",
            "Total Steps: 706773 Episode Num: 11621 Reward: 137.37906271320435 avg_loss_c: 3.05704476568434 avg_loss_a: -55.607852935791016\n",
            "Número de pasos del episodeo 11622 son episode_steps:130\n",
            "Total Steps: 706903 Episode Num: 11622 Reward: 211.28851976189853 avg_loss_c: 2.9878079139269316 avg_loss_a: -55.43949232835036\n",
            "Número de pasos del episodeo 11623 son episode_steps:54\n",
            "Total Steps: 706957 Episode Num: 11623 Reward: 46.759056618452306 avg_loss_c: 2.8735963062003806 avg_loss_a: -55.07156103628653\n",
            "Número de pasos del episodeo 11624 son episode_steps:58\n",
            "Total Steps: 707015 Episode Num: 11624 Reward: 55.93185152937672 avg_loss_c: 2.9301597126599015 avg_loss_a: -54.8081730809705\n",
            "Número de pasos del episodeo 11625 son episode_steps:45\n",
            "Total Steps: 707060 Episode Num: 11625 Reward: 25.765719388202278 avg_loss_c: 3.180835909313626 avg_loss_a: -55.52803158230252\n",
            "Número de pasos del episodeo 11626 son episode_steps:109\n",
            "Total Steps: 707169 Episode Num: 11626 Reward: 167.23362955589636 avg_loss_c: 2.993661392719374 avg_loss_a: -54.4986457824707\n",
            "Número de pasos del episodeo 11627 son episode_steps:164\n",
            "Total Steps: 707333 Episode Num: 11627 Reward: 245.79737216125153 avg_loss_c: 2.8494454055297664 avg_loss_a: -55.7142504715338\n",
            "Número de pasos del episodeo 11628 son episode_steps:116\n",
            "Total Steps: 707449 Episode Num: 11628 Reward: 185.0805679726076 avg_loss_c: 2.8837215674334558 avg_loss_a: -54.87515429792733\n",
            "Número de pasos del episodeo 11629 son episode_steps:97\n",
            "Total Steps: 707546 Episode Num: 11629 Reward: 130.4082706088697 avg_loss_c: 3.1248646298634637 avg_loss_a: -55.5522661897325\n",
            "Número de pasos del episodeo 11630 son episode_steps:121\n",
            "Total Steps: 707667 Episode Num: 11630 Reward: 188.60164397625178 avg_loss_c: 3.0840028967739137 avg_loss_a: -55.66412265241639\n",
            "Número de pasos del episodeo 11631 son episode_steps:98\n",
            "Total Steps: 707765 Episode Num: 11631 Reward: 143.57727218467252 avg_loss_c: 2.8311344239176535 avg_loss_a: -55.39331194819236\n",
            "Número de pasos del episodeo 11632 son episode_steps:130\n",
            "Total Steps: 707895 Episode Num: 11632 Reward: 206.33472496087774 avg_loss_c: 2.8764789287860575 avg_loss_a: -54.985459665151744\n",
            "Número de pasos del episodeo 11633 son episode_steps:136\n",
            "Total Steps: 708031 Episode Num: 11633 Reward: 191.9892742239765 avg_loss_c: 2.910627426470027 avg_loss_a: -55.672658527598664\n",
            "Número de pasos del episodeo 11634 son episode_steps:203\n",
            "Total Steps: 708234 Episode Num: 11634 Reward: 299.6136354620693 avg_loss_c: 2.981975226566709 avg_loss_a: -55.69455102629262\n",
            "Número de pasos del episodeo 11635 son episode_steps:56\n",
            "Total Steps: 708290 Episode Num: 11635 Reward: 43.0857708724198 avg_loss_c: 2.9611389466694424 avg_loss_a: -55.229171889168875\n",
            "Número de pasos del episodeo 11636 son episode_steps:106\n",
            "Total Steps: 708396 Episode Num: 11636 Reward: 153.59576130651857 avg_loss_c: 2.8769077523699345 avg_loss_a: -56.03011343614111\n",
            "Número de pasos del episodeo 11637 son episode_steps:100\n",
            "Total Steps: 708496 Episode Num: 11637 Reward: 11.83307163594035 avg_loss_c: 3.0748451244831085 avg_loss_a: -55.61987533569336\n",
            "Número de pasos del episodeo 11638 son episode_steps:155\n",
            "Total Steps: 708651 Episode Num: 11638 Reward: 229.0924648094365 avg_loss_c: 3.0443555324308336 avg_loss_a: -55.7507923003166\n",
            "Número de pasos del episodeo 11639 son episode_steps:126\n",
            "Total Steps: 708777 Episode Num: 11639 Reward: 201.08958392803072 avg_loss_c: 3.055992579649365 avg_loss_a: -56.020089649018786\n",
            "Número de pasos del episodeo 11640 son episode_steps:134\n",
            "Total Steps: 708911 Episode Num: 11640 Reward: 188.09598109336207 avg_loss_c: 2.9611821779564247 avg_loss_a: -55.9664758141361\n",
            "Número de pasos del episodeo 11641 son episode_steps:125\n",
            "Total Steps: 709036 Episode Num: 11641 Reward: 20.4686067501976 avg_loss_c: 3.6164986915588377 avg_loss_a: -55.62064642333984\n",
            "Número de pasos del episodeo 11642 son episode_steps:165\n",
            "Total Steps: 709201 Episode Num: 11642 Reward: 255.6357277582896 avg_loss_c: 3.0632267995314164 avg_loss_a: -55.84148083311139\n",
            "Número de pasos del episodeo 11643 son episode_steps:190\n",
            "Total Steps: 709391 Episode Num: 11643 Reward: 287.15408493732446 avg_loss_c: 2.9389626201830414 avg_loss_a: -55.745829291092726\n",
            "Número de pasos del episodeo 11644 son episode_steps:132\n",
            "Total Steps: 709523 Episode Num: 11644 Reward: 199.31636043321126 avg_loss_c: 2.9755296327851037 avg_loss_a: -55.738603707515836\n",
            "Número de pasos del episodeo 11645 son episode_steps:170\n",
            "Total Steps: 709693 Episode Num: 11645 Reward: 210.59128644056858 avg_loss_c: 3.1738002882284277 avg_loss_a: -55.624108662324794\n",
            "Número de pasos del episodeo 11646 son episode_steps:123\n",
            "Total Steps: 709816 Episode Num: 11646 Reward: 194.9596887653571 avg_loss_c: 3.1859328708028407 avg_loss_a: -55.87699942860177\n",
            "Número de pasos del episodeo 11647 son episode_steps:75\n",
            "Total Steps: 709891 Episode Num: 11647 Reward: 112.19744177811361 avg_loss_c: 3.125216628710429 avg_loss_a: -55.91866836547852\n",
            "Número de pasos del episodeo 11648 son episode_steps:111\n",
            "Total Steps: 710002 Episode Num: 11648 Reward: 153.30408815609206 avg_loss_c: 3.4435317688160114 avg_loss_a: -56.28310961336703\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 196.797854\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11649 son episode_steps:145\n",
            "Total Steps: 710147 Episode Num: 11649 Reward: 225.51923409483757 avg_loss_c: 3.002591478413549 avg_loss_a: -55.88410865520609\n",
            "Número de pasos del episodeo 11650 son episode_steps:223\n",
            "Total Steps: 710370 Episode Num: 11650 Reward: 317.4613119990442 avg_loss_c: 2.8759655294931523 avg_loss_a: -56.17080493465133\n",
            "Número de pasos del episodeo 11651 son episode_steps:113\n",
            "Total Steps: 710483 Episode Num: 11651 Reward: 79.55878959388137 avg_loss_c: 3.2781584874718592 avg_loss_a: -56.442889390793525\n",
            "Número de pasos del episodeo 11652 son episode_steps:144\n",
            "Total Steps: 710627 Episode Num: 11652 Reward: 218.44737074728073 avg_loss_c: 3.1410308521654873 avg_loss_a: -56.65458552042643\n",
            "Número de pasos del episodeo 11653 son episode_steps:176\n",
            "Total Steps: 710803 Episode Num: 11653 Reward: 256.877562050882 avg_loss_c: 2.986668959259987 avg_loss_a: -55.9318152774464\n",
            "Número de pasos del episodeo 11654 son episode_steps:117\n",
            "Total Steps: 710920 Episode Num: 11654 Reward: 191.83000599552207 avg_loss_c: 3.082725673659235 avg_loss_a: -55.761584583510704\n",
            "Número de pasos del episodeo 11655 son episode_steps:119\n",
            "Total Steps: 711039 Episode Num: 11655 Reward: 168.011213228418 avg_loss_c: 3.0223314191112998 avg_loss_a: -56.60318121389181\n",
            "Número de pasos del episodeo 11656 son episode_steps:138\n",
            "Total Steps: 711177 Episode Num: 11656 Reward: 212.18103767349106 avg_loss_c: 2.985052465528682 avg_loss_a: -56.0131740293641\n",
            "Número de pasos del episodeo 11657 son episode_steps:168\n",
            "Total Steps: 711345 Episode Num: 11657 Reward: 234.3597159577444 avg_loss_c: 2.9615475691500164 avg_loss_a: -56.57077880132766\n",
            "Número de pasos del episodeo 11658 son episode_steps:93\n",
            "Total Steps: 711438 Episode Num: 11658 Reward: 142.2676829868533 avg_loss_c: 2.936177089650144 avg_loss_a: -56.68283708633915\n",
            "Número de pasos del episodeo 11659 son episode_steps:144\n",
            "Total Steps: 711582 Episode Num: 11659 Reward: 228.58974414698005 avg_loss_c: 2.8475340604782104 avg_loss_a: -56.35278638203939\n",
            "Número de pasos del episodeo 11660 son episode_steps:161\n",
            "Total Steps: 711743 Episode Num: 11660 Reward: 254.163523899408 avg_loss_c: 2.8615208975276594 avg_loss_a: -56.501477709468105\n",
            "Número de pasos del episodeo 11661 son episode_steps:48\n",
            "Total Steps: 711791 Episode Num: 11661 Reward: 64.30163258881188 avg_loss_c: 2.926282870272795 avg_loss_a: -56.24256865183512\n",
            "Número de pasos del episodeo 11662 son episode_steps:132\n",
            "Total Steps: 711923 Episode Num: 11662 Reward: 158.26604841722303 avg_loss_c: 2.9496050278345742 avg_loss_a: -56.99094425548207\n",
            "Número de pasos del episodeo 11663 son episode_steps:168\n",
            "Total Steps: 712091 Episode Num: 11663 Reward: 244.4601491614741 avg_loss_c: 2.9379117715926397 avg_loss_a: -56.36916310446603\n",
            "Número de pasos del episodeo 11664 son episode_steps:61\n",
            "Total Steps: 712152 Episode Num: 11664 Reward: 85.02648569694762 avg_loss_c: 2.9587549147058705 avg_loss_a: -56.08067903362337\n",
            "Número de pasos del episodeo 11665 son episode_steps:137\n",
            "Total Steps: 712289 Episode Num: 11665 Reward: 222.54698021933203 avg_loss_c: 3.0371749331481266 avg_loss_a: -56.42778187772653\n",
            "Número de pasos del episodeo 11666 son episode_steps:127\n",
            "Total Steps: 712416 Episode Num: 11666 Reward: 204.15625712640224 avg_loss_c: 2.9525541583384114 avg_loss_a: -56.791334948201815\n",
            "Número de pasos del episodeo 11667 son episode_steps:162\n",
            "Total Steps: 712578 Episode Num: 11667 Reward: 252.87534752241194 avg_loss_c: 2.9528184717084156 avg_loss_a: -56.48020567717376\n",
            "Número de pasos del episodeo 11668 son episode_steps:99\n",
            "Total Steps: 712677 Episode Num: 11668 Reward: 143.9930274823157 avg_loss_c: 3.114335369582128 avg_loss_a: -56.75082216359148\n",
            "Número de pasos del episodeo 11669 son episode_steps:147\n",
            "Total Steps: 712824 Episode Num: 11669 Reward: 234.94714156339913 avg_loss_c: 2.799956818016208 avg_loss_a: -56.10674908696389\n",
            "Número de pasos del episodeo 11670 son episode_steps:85\n",
            "Total Steps: 712909 Episode Num: 11670 Reward: -2.7285020054929228 avg_loss_c: 3.078135881704443 avg_loss_a: -57.03469170963063\n",
            "Número de pasos del episodeo 11671 son episode_steps:59\n",
            "Total Steps: 712968 Episode Num: 11671 Reward: 45.62534817497728 avg_loss_c: 2.913078809188584 avg_loss_a: -57.285871861344674\n",
            "Número de pasos del episodeo 11672 son episode_steps:43\n",
            "Total Steps: 713011 Episode Num: 11672 Reward: 13.184427031993923 avg_loss_c: 3.1593317819196125 avg_loss_a: -56.175904207451396\n",
            "Número de pasos del episodeo 11673 son episode_steps:90\n",
            "Total Steps: 713101 Episode Num: 11673 Reward: 124.72737777544259 avg_loss_c: 3.0411331401930917 avg_loss_a: -56.41772783067491\n",
            "Número de pasos del episodeo 11674 son episode_steps:61\n",
            "Total Steps: 713162 Episode Num: 11674 Reward: 92.3194886421897 avg_loss_c: 3.3989194709746564 avg_loss_a: -55.977757188140366\n",
            "Número de pasos del episodeo 11675 son episode_steps:111\n",
            "Total Steps: 713273 Episode Num: 11675 Reward: 180.38042068463784 avg_loss_c: 2.887797669247464 avg_loss_a: -56.360510714419256\n",
            "Número de pasos del episodeo 11676 son episode_steps:223\n",
            "Total Steps: 713496 Episode Num: 11676 Reward: 338.4366553642526 avg_loss_c: 3.0549800117988757 avg_loss_a: -56.739767510794735\n",
            "Número de pasos del episodeo 11677 son episode_steps:64\n",
            "Total Steps: 713560 Episode Num: 11677 Reward: 93.87308614802599 avg_loss_c: 3.0138391368091106 avg_loss_a: -56.30873262882233\n",
            "Número de pasos del episodeo 11678 son episode_steps:159\n",
            "Total Steps: 713719 Episode Num: 11678 Reward: 229.79583359573886 avg_loss_c: 2.9749750708633997 avg_loss_a: -57.06780828320005\n",
            "Número de pasos del episodeo 11679 son episode_steps:80\n",
            "Total Steps: 713799 Episode Num: 11679 Reward: 105.26661067101084 avg_loss_c: 3.20953808426857 avg_loss_a: -56.97677154541016\n",
            "Número de pasos del episodeo 11680 son episode_steps:106\n",
            "Total Steps: 713905 Episode Num: 11680 Reward: 148.7902097269472 avg_loss_c: 3.244912604116044 avg_loss_a: -56.61517967368072\n",
            "Número de pasos del episodeo 11681 son episode_steps:87\n",
            "Total Steps: 713992 Episode Num: 11681 Reward: 48.45119748274987 avg_loss_c: 3.2961679546312355 avg_loss_a: -57.21623422907687\n",
            "Número de pasos del episodeo 11682 son episode_steps:79\n",
            "Total Steps: 714071 Episode Num: 11682 Reward: 106.62966702856889 avg_loss_c: 3.1736351840103727 avg_loss_a: -56.30509591404396\n",
            "Número de pasos del episodeo 11683 son episode_steps:95\n",
            "Total Steps: 714166 Episode Num: 11683 Reward: 138.98144088914665 avg_loss_c: 3.15237109033685 avg_loss_a: -56.66698644537675\n",
            "Número de pasos del episodeo 11684 son episode_steps:86\n",
            "Total Steps: 714252 Episode Num: 11684 Reward: 123.60328708253827 avg_loss_c: 3.1211279894030373 avg_loss_a: -56.80392571382745\n",
            "Número de pasos del episodeo 11685 son episode_steps:164\n",
            "Total Steps: 714416 Episode Num: 11685 Reward: 262.5697350941816 avg_loss_c: 3.100390818060898 avg_loss_a: -56.83578151609839\n",
            "Número de pasos del episodeo 11686 son episode_steps:54\n",
            "Total Steps: 714470 Episode Num: 11686 Reward: 64.87506432952297 avg_loss_c: 3.4425195764612266 avg_loss_a: -56.481902793601705\n",
            "Número de pasos del episodeo 11687 son episode_steps:81\n",
            "Total Steps: 714551 Episode Num: 11687 Reward: 125.79474767376452 avg_loss_c: 3.2323348257276745 avg_loss_a: -56.01271000614873\n",
            "Número de pasos del episodeo 11688 son episode_steps:102\n",
            "Total Steps: 714653 Episode Num: 11688 Reward: 161.70615862074433 avg_loss_c: 3.0655266888001385 avg_loss_a: -56.81593352673101\n",
            "Número de pasos del episodeo 11689 son episode_steps:65\n",
            "Total Steps: 714718 Episode Num: 11689 Reward: 79.92494696353606 avg_loss_c: 2.8287993100973274 avg_loss_a: -56.77247513991136\n",
            "Número de pasos del episodeo 11690 son episode_steps:75\n",
            "Total Steps: 714793 Episode Num: 11690 Reward: 42.72869839034068 avg_loss_c: 3.1758652178446454 avg_loss_a: -56.34398808797201\n",
            "Número de pasos del episodeo 11691 son episode_steps:112\n",
            "Total Steps: 714905 Episode Num: 11691 Reward: 81.83704539620838 avg_loss_c: 3.7936104940516606 avg_loss_a: -56.2560841696603\n",
            "Número de pasos del episodeo 11692 son episode_steps:104\n",
            "Total Steps: 715009 Episode Num: 11692 Reward: 174.23919238342523 avg_loss_c: 3.130518606075874 avg_loss_a: -56.36638003129225\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 168.793080\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11693 son episode_steps:130\n",
            "Total Steps: 715139 Episode Num: 11693 Reward: 196.497790194077 avg_loss_c: 3.2711913438943716 avg_loss_a: -56.690036714993994\n",
            "Número de pasos del episodeo 11694 son episode_steps:143\n",
            "Total Steps: 715282 Episode Num: 11694 Reward: 236.9939007016711 avg_loss_c: 3.1511609604308655 avg_loss_a: -57.00970760425488\n",
            "Número de pasos del episodeo 11695 son episode_steps:122\n",
            "Total Steps: 715404 Episode Num: 11695 Reward: 17.242582344976192 avg_loss_c: 3.6715052733655837 avg_loss_a: -56.180926150962954\n",
            "Número de pasos del episodeo 11696 son episode_steps:197\n",
            "Total Steps: 715601 Episode Num: 11696 Reward: 304.94350405012693 avg_loss_c: 3.3587389185949026 avg_loss_a: -56.48695251542299\n",
            "Número de pasos del episodeo 11697 son episode_steps:125\n",
            "Total Steps: 715726 Episode Num: 11697 Reward: 193.57736047956382 avg_loss_c: 3.3828832721710205 avg_loss_a: -56.19822009277344\n",
            "Número de pasos del episodeo 11698 son episode_steps:40\n",
            "Total Steps: 715766 Episode Num: 11698 Reward: -13.007517236102672 avg_loss_c: 3.1557011663913728 avg_loss_a: -56.43586654663086\n",
            "Número de pasos del episodeo 11699 son episode_steps:98\n",
            "Total Steps: 715864 Episode Num: 11699 Reward: 27.092967121572123 avg_loss_c: 3.611843617594972 avg_loss_a: -56.479489696269134\n",
            "Número de pasos del episodeo 11700 son episode_steps:91\n",
            "Total Steps: 715955 Episode Num: 11700 Reward: 31.240238697159988 avg_loss_c: 4.420629695221618 avg_loss_a: -55.873329162597656\n",
            "Número de pasos del episodeo 11701 son episode_steps:96\n",
            "Total Steps: 716051 Episode Num: 11701 Reward: 137.75754472156245 avg_loss_c: 4.489161665240924 avg_loss_a: -55.52707282702128\n",
            "Número de pasos del episodeo 11702 son episode_steps:105\n",
            "Total Steps: 716156 Episode Num: 11702 Reward: 149.04041526987203 avg_loss_c: 3.6014806656610396 avg_loss_a: -55.99431570143927\n",
            "Número de pasos del episodeo 11703 son episode_steps:48\n",
            "Total Steps: 716204 Episode Num: 11703 Reward: 42.50352812401166 avg_loss_c: 3.52817831436793 avg_loss_a: -55.64559602737427\n",
            "Número de pasos del episodeo 11704 son episode_steps:45\n",
            "Total Steps: 716249 Episode Num: 11704 Reward: 42.24781228125447 avg_loss_c: 3.922811656528049 avg_loss_a: -55.91426637437608\n",
            "Número de pasos del episodeo 11705 son episode_steps:91\n",
            "Total Steps: 716340 Episode Num: 11705 Reward: 129.9708854561617 avg_loss_c: 3.771158899579729 avg_loss_a: -55.46972182556823\n",
            "Número de pasos del episodeo 11706 son episode_steps:58\n",
            "Total Steps: 716398 Episode Num: 11706 Reward: 19.634579075690944 avg_loss_c: 3.700692353577449 avg_loss_a: -56.13028046180462\n",
            "Número de pasos del episodeo 11707 son episode_steps:143\n",
            "Total Steps: 716541 Episode Num: 11707 Reward: 175.60262144146665 avg_loss_c: 4.015357861152062 avg_loss_a: -55.213743009767335\n",
            "Número de pasos del episodeo 11708 son episode_steps:90\n",
            "Total Steps: 716631 Episode Num: 11708 Reward: 134.0182829737893 avg_loss_c: 3.7583035416073267 avg_loss_a: -55.86963356865777\n",
            "Número de pasos del episodeo 11709 son episode_steps:65\n",
            "Total Steps: 716696 Episode Num: 11709 Reward: 82.15096395193903 avg_loss_c: 3.7159019066737247 avg_loss_a: -55.87206731942984\n",
            "Número de pasos del episodeo 11710 son episode_steps:65\n",
            "Total Steps: 716761 Episode Num: 11710 Reward: 34.06504435288785 avg_loss_c: 3.855328523195707 avg_loss_a: -54.93974222036508\n",
            "Número de pasos del episodeo 11711 son episode_steps:72\n",
            "Total Steps: 716833 Episode Num: 11711 Reward: 113.62480819647836 avg_loss_c: 3.563669698105918 avg_loss_a: -55.807651095920136\n",
            "Número de pasos del episodeo 11712 son episode_steps:64\n",
            "Total Steps: 716897 Episode Num: 11712 Reward: 14.809075442903065 avg_loss_c: 3.8793316073715687 avg_loss_a: -55.283602356910706\n",
            "Número de pasos del episodeo 11713 son episode_steps:130\n",
            "Total Steps: 717027 Episode Num: 11713 Reward: 142.10984395399763 avg_loss_c: 3.904450304691608 avg_loss_a: -55.297743459848256\n",
            "Número de pasos del episodeo 11714 son episode_steps:102\n",
            "Total Steps: 717129 Episode Num: 11714 Reward: 152.05390244478093 avg_loss_c: 3.7856204860350666 avg_loss_a: -55.793003830255245\n",
            "Número de pasos del episodeo 11715 son episode_steps:90\n",
            "Total Steps: 717219 Episode Num: 11715 Reward: 141.3503381738678 avg_loss_c: 3.689330138100518 avg_loss_a: -55.64674970838759\n",
            "Número de pasos del episodeo 11716 son episode_steps:196\n",
            "Total Steps: 717415 Episode Num: 11716 Reward: 312.43788813623127 avg_loss_c: 3.8310724861767826 avg_loss_a: -55.64275885601433\n",
            "Número de pasos del episodeo 11717 son episode_steps:88\n",
            "Total Steps: 717503 Episode Num: 11717 Reward: 131.25625952668156 avg_loss_c: 3.6002912006594916 avg_loss_a: -55.79688254269686\n",
            "Número de pasos del episodeo 11718 son episode_steps:151\n",
            "Total Steps: 717654 Episode Num: 11718 Reward: 234.81410213871692 avg_loss_c: 3.5755594771429404 avg_loss_a: -56.095463127489914\n",
            "Número de pasos del episodeo 11719 son episode_steps:27\n",
            "Total Steps: 717681 Episode Num: 11719 Reward: -41.30252080261774 avg_loss_c: 4.813100320321542 avg_loss_a: -55.16361688684534\n",
            "Número de pasos del episodeo 11720 son episode_steps:61\n",
            "Total Steps: 717742 Episode Num: 11720 Reward: 89.86299132071689 avg_loss_c: 4.070753382854774 avg_loss_a: -55.77987189371078\n",
            "Número de pasos del episodeo 11721 son episode_steps:115\n",
            "Total Steps: 717857 Episode Num: 11721 Reward: 175.12248695895724 avg_loss_c: 3.9554227974103844 avg_loss_a: -56.049738278596294\n",
            "Número de pasos del episodeo 11722 son episode_steps:40\n",
            "Total Steps: 717897 Episode Num: 11722 Reward: 23.528223260068618 avg_loss_c: 3.6011526823043822 avg_loss_a: -54.756961059570315\n",
            "Número de pasos del episodeo 11723 son episode_steps:91\n",
            "Total Steps: 717988 Episode Num: 11723 Reward: 103.62775719518326 avg_loss_c: 3.631001781631302 avg_loss_a: -54.93138881306072\n",
            "Número de pasos del episodeo 11724 son episode_steps:48\n",
            "Total Steps: 718036 Episode Num: 11724 Reward: 30.942372759939392 avg_loss_c: 3.947054217259089 avg_loss_a: -56.03182411193848\n",
            "Número de pasos del episodeo 11725 son episode_steps:43\n",
            "Total Steps: 718079 Episode Num: 11725 Reward: 28.75198256453975 avg_loss_c: 3.6474071547042493 avg_loss_a: -55.3582025572311\n",
            "Número de pasos del episodeo 11726 son episode_steps:64\n",
            "Total Steps: 718143 Episode Num: 11726 Reward: 37.69291996571348 avg_loss_c: 3.853100508451462 avg_loss_a: -55.35846829414368\n",
            "Número de pasos del episodeo 11727 son episode_steps:85\n",
            "Total Steps: 718228 Episode Num: 11727 Reward: 21.77356073109768 avg_loss_c: 4.0529539374744195 avg_loss_a: -55.61463623046875\n",
            "Número de pasos del episodeo 11728 son episode_steps:76\n",
            "Total Steps: 718304 Episode Num: 11728 Reward: 116.61690437011356 avg_loss_c: 4.612927279974285 avg_loss_a: -55.14897898623818\n",
            "Número de pasos del episodeo 11729 son episode_steps:59\n",
            "Total Steps: 718363 Episode Num: 11729 Reward: -8.943883301223387 avg_loss_c: 4.265059459007393 avg_loss_a: -55.31154134718038\n",
            "Número de pasos del episodeo 11730 son episode_steps:52\n",
            "Total Steps: 718415 Episode Num: 11730 Reward: 40.94705287908355 avg_loss_c: 4.189566199596111 avg_loss_a: -55.41878348130446\n",
            "Número de pasos del episodeo 11731 son episode_steps:107\n",
            "Total Steps: 718522 Episode Num: 11731 Reward: 13.339762251326352 avg_loss_c: 5.047094645901261 avg_loss_a: -55.43387967403804\n",
            "Número de pasos del episodeo 11732 son episode_steps:54\n",
            "Total Steps: 718576 Episode Num: 11732 Reward: 84.27971810443422 avg_loss_c: 4.606883622981884 avg_loss_a: -55.978337888364436\n",
            "Número de pasos del episodeo 11733 son episode_steps:116\n",
            "Total Steps: 718692 Episode Num: 11733 Reward: 184.92683519475003 avg_loss_c: 4.232572021155522 avg_loss_a: -55.345437280062974\n",
            "Número de pasos del episodeo 11734 son episode_steps:61\n",
            "Total Steps: 718753 Episode Num: 11734 Reward: 60.607084684736044 avg_loss_c: 4.398394154720619 avg_loss_a: -54.85490598834929\n",
            "Número de pasos del episodeo 11735 son episode_steps:79\n",
            "Total Steps: 718832 Episode Num: 11735 Reward: 112.2554181219996 avg_loss_c: 4.392261444767819 avg_loss_a: -54.74859590168241\n",
            "Número de pasos del episodeo 11736 son episode_steps:48\n",
            "Total Steps: 718880 Episode Num: 11736 Reward: 40.135960799773436 avg_loss_c: 4.214687834183375 avg_loss_a: -54.15388266245524\n",
            "Número de pasos del episodeo 11737 son episode_steps:114\n",
            "Total Steps: 718994 Episode Num: 11737 Reward: 175.9714157749926 avg_loss_c: 4.592379768689473 avg_loss_a: -54.59005563300953\n",
            "Número de pasos del episodeo 11738 son episode_steps:97\n",
            "Total Steps: 719091 Episode Num: 11738 Reward: 130.82047854671052 avg_loss_c: 4.237430444697744 avg_loss_a: -54.744370607985665\n",
            "Número de pasos del episodeo 11739 son episode_steps:90\n",
            "Total Steps: 719181 Episode Num: 11739 Reward: 127.71080962552364 avg_loss_c: 4.357732396655613 avg_loss_a: -54.78227844238281\n",
            "Número de pasos del episodeo 11740 son episode_steps:96\n",
            "Total Steps: 719277 Episode Num: 11740 Reward: 108.37806617110448 avg_loss_c: 4.117824047803879 avg_loss_a: -54.261680603027344\n",
            "Número de pasos del episodeo 11741 son episode_steps:66\n",
            "Total Steps: 719343 Episode Num: 11741 Reward: 76.94979701780606 avg_loss_c: 4.783557866558884 avg_loss_a: -54.61332089973219\n",
            "Número de pasos del episodeo 11742 son episode_steps:92\n",
            "Total Steps: 719435 Episode Num: 11742 Reward: 130.43854751845555 avg_loss_c: 4.025965237099191 avg_loss_a: -54.2048455943232\n",
            "Número de pasos del episodeo 11743 son episode_steps:58\n",
            "Total Steps: 719493 Episode Num: 11743 Reward: 14.778862750446304 avg_loss_c: 4.972469309280658 avg_loss_a: -53.90752673971242\n",
            "Número de pasos del episodeo 11744 son episode_steps:142\n",
            "Total Steps: 719635 Episode Num: 11744 Reward: 239.05952061882348 avg_loss_c: 4.211982208238521 avg_loss_a: -54.02651375784001\n",
            "Número de pasos del episodeo 11745 son episode_steps:53\n",
            "Total Steps: 719688 Episode Num: 11745 Reward: 70.7492867634316 avg_loss_c: 4.112412407713117 avg_loss_a: -54.120705082731426\n",
            "Número de pasos del episodeo 11746 son episode_steps:250\n",
            "Total Steps: 719938 Episode Num: 11746 Reward: 389.07012706591695 avg_loss_c: 4.033976397514343 avg_loss_a: -54.85408862304688\n",
            "Número de pasos del episodeo 11747 son episode_steps:139\n",
            "Total Steps: 720077 Episode Num: 11747 Reward: 225.80493514245896 avg_loss_c: 3.9312964257576484 avg_loss_a: -54.2386955974771\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 178.483635\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11748 son episode_steps:158\n",
            "Total Steps: 720235 Episode Num: 11748 Reward: 221.66861125425 avg_loss_c: 4.319548190394534 avg_loss_a: -54.88369828236254\n",
            "Número de pasos del episodeo 11749 son episode_steps:47\n",
            "Total Steps: 720282 Episode Num: 11749 Reward: 42.59984637247453 avg_loss_c: 4.202524215617078 avg_loss_a: -54.28228086106321\n",
            "Número de pasos del episodeo 11750 son episode_steps:44\n",
            "Total Steps: 720326 Episode Num: 11750 Reward: 33.06833994486753 avg_loss_c: 4.0358862551775845 avg_loss_a: -54.42154797640714\n",
            "Número de pasos del episodeo 11751 son episode_steps:133\n",
            "Total Steps: 720459 Episode Num: 11751 Reward: 208.5600095652132 avg_loss_c: 4.622902721390688 avg_loss_a: -54.330010693772394\n",
            "Número de pasos del episodeo 11752 son episode_steps:95\n",
            "Total Steps: 720554 Episode Num: 11752 Reward: 132.1754178929027 avg_loss_c: 4.277866757543463 avg_loss_a: -55.15328084042198\n",
            "Número de pasos del episodeo 11753 son episode_steps:158\n",
            "Total Steps: 720712 Episode Num: 11753 Reward: 231.3631905403359 avg_loss_c: 4.118527622162541 avg_loss_a: -54.67118067681035\n",
            "Número de pasos del episodeo 11754 son episode_steps:133\n",
            "Total Steps: 720845 Episode Num: 11754 Reward: 215.42856341359536 avg_loss_c: 3.8926668436007392 avg_loss_a: -54.851740815585714\n",
            "Número de pasos del episodeo 11755 son episode_steps:156\n",
            "Total Steps: 721001 Episode Num: 11755 Reward: 250.8797724726154 avg_loss_c: 3.908283999333015 avg_loss_a: -54.99694726406\n",
            "Número de pasos del episodeo 11756 son episode_steps:66\n",
            "Total Steps: 721067 Episode Num: 11756 Reward: 93.35193540338206 avg_loss_c: 4.103845567414255 avg_loss_a: -54.980730345754914\n",
            "Número de pasos del episodeo 11757 son episode_steps:49\n",
            "Total Steps: 721116 Episode Num: 11757 Reward: 75.2054613886307 avg_loss_c: 3.948979669687699 avg_loss_a: -54.99596607441805\n",
            "Número de pasos del episodeo 11758 son episode_steps:75\n",
            "Total Steps: 721191 Episode Num: 11758 Reward: -4.656882355468534 avg_loss_c: 4.129180936813355 avg_loss_a: -54.559217580159505\n",
            "Número de pasos del episodeo 11759 son episode_steps:118\n",
            "Total Steps: 721309 Episode Num: 11759 Reward: 186.70580516326118 avg_loss_c: 4.074027206938146 avg_loss_a: -54.557745852712856\n",
            "Número de pasos del episodeo 11760 son episode_steps:63\n",
            "Total Steps: 721372 Episode Num: 11760 Reward: 77.29241908617469 avg_loss_c: 4.203152009419033 avg_loss_a: -54.23554169185578\n",
            "Número de pasos del episodeo 11761 son episode_steps:101\n",
            "Total Steps: 721473 Episode Num: 11761 Reward: 105.82378264828421 avg_loss_c: 3.8753724145417165 avg_loss_a: -54.07741795908107\n",
            "Número de pasos del episodeo 11762 son episode_steps:109\n",
            "Total Steps: 721582 Episode Num: 11762 Reward: 159.09315824712047 avg_loss_c: 4.024902138141317 avg_loss_a: -53.85815366692499\n",
            "Número de pasos del episodeo 11763 son episode_steps:66\n",
            "Total Steps: 721648 Episode Num: 11763 Reward: 92.04639369262364 avg_loss_c: 4.153154293696086 avg_loss_a: -54.47980164036606\n",
            "Número de pasos del episodeo 11764 son episode_steps:62\n",
            "Total Steps: 721710 Episode Num: 11764 Reward: 41.10016758195821 avg_loss_c: 4.053415290770992 avg_loss_a: -55.02527889128654\n",
            "Número de pasos del episodeo 11765 son episode_steps:64\n",
            "Total Steps: 721774 Episode Num: 11765 Reward: 98.71590412037567 avg_loss_c: 3.974603820592165 avg_loss_a: -53.56082081794739\n",
            "Número de pasos del episodeo 11766 son episode_steps:161\n",
            "Total Steps: 721935 Episode Num: 11766 Reward: 259.554572419113 avg_loss_c: 4.226341020986901 avg_loss_a: -54.355569187898816\n",
            "Número de pasos del episodeo 11767 son episode_steps:81\n",
            "Total Steps: 722016 Episode Num: 11767 Reward: 125.96206724799244 avg_loss_c: 4.085312381202792 avg_loss_a: -54.099567460425106\n",
            "Número de pasos del episodeo 11768 son episode_steps:116\n",
            "Total Steps: 722132 Episode Num: 11768 Reward: 174.27963987294982 avg_loss_c: 4.151824311963443 avg_loss_a: -54.25233788325869\n",
            "Número de pasos del episodeo 11769 son episode_steps:108\n",
            "Total Steps: 722240 Episode Num: 11769 Reward: 168.65231157267715 avg_loss_c: 3.911732115127422 avg_loss_a: -54.14854480602123\n",
            "Número de pasos del episodeo 11770 son episode_steps:183\n",
            "Total Steps: 722423 Episode Num: 11770 Reward: 296.2948632154705 avg_loss_c: 3.964404237726347 avg_loss_a: -54.71589883689672\n",
            "Número de pasos del episodeo 11771 son episode_steps:111\n",
            "Total Steps: 722534 Episode Num: 11771 Reward: 141.77748312979637 avg_loss_c: 4.0975536183194 avg_loss_a: -54.50142583761129\n",
            "Número de pasos del episodeo 11772 son episode_steps:96\n",
            "Total Steps: 722630 Episode Num: 11772 Reward: 150.40957476786244 avg_loss_c: 4.23134612540404 avg_loss_a: -54.595308780670166\n",
            "Número de pasos del episodeo 11773 son episode_steps:119\n",
            "Total Steps: 722749 Episode Num: 11773 Reward: 162.55318695098563 avg_loss_c: 3.9557437596200895 avg_loss_a: -54.75185714849905\n",
            "Número de pasos del episodeo 11774 son episode_steps:112\n",
            "Total Steps: 722861 Episode Num: 11774 Reward: 155.2156585592443 avg_loss_c: 3.783640367644174 avg_loss_a: -54.20681667327881\n",
            "Número de pasos del episodeo 11775 son episode_steps:262\n",
            "Total Steps: 723123 Episode Num: 11775 Reward: 444.14469154073356 avg_loss_c: 3.7538193910176516 avg_loss_a: -54.57326070770963\n",
            "Número de pasos del episodeo 11776 son episode_steps:75\n",
            "Total Steps: 723198 Episode Num: 11776 Reward: 107.38829959602238 avg_loss_c: 3.867781791687012 avg_loss_a: -55.34781951904297\n",
            "Número de pasos del episodeo 11777 son episode_steps:123\n",
            "Total Steps: 723321 Episode Num: 11777 Reward: 187.47812394829367 avg_loss_c: 3.8653879533938276 avg_loss_a: -54.688544854885194\n",
            "Número de pasos del episodeo 11778 son episode_steps:165\n",
            "Total Steps: 723486 Episode Num: 11778 Reward: 259.82822645992997 avg_loss_c: 4.025514877203739 avg_loss_a: -55.04496751265092\n",
            "Número de pasos del episodeo 11779 son episode_steps:53\n",
            "Total Steps: 723539 Episode Num: 11779 Reward: -20.021524689449407 avg_loss_c: 3.8669884879634067 avg_loss_a: -53.96043971799455\n",
            "Número de pasos del episodeo 11780 son episode_steps:174\n",
            "Total Steps: 723713 Episode Num: 11780 Reward: 261.84286511104904 avg_loss_c: 4.1261204782573655 avg_loss_a: -54.86669847334939\n",
            "Número de pasos del episodeo 11781 son episode_steps:75\n",
            "Total Steps: 723788 Episode Num: 11781 Reward: 46.567560853427665 avg_loss_c: 4.181764879226685 avg_loss_a: -54.62927825927734\n",
            "Número de pasos del episodeo 11782 son episode_steps:58\n",
            "Total Steps: 723846 Episode Num: 11782 Reward: 73.68301433150603 avg_loss_c: 3.9823250441715636 avg_loss_a: -53.511171669795594\n",
            "Número de pasos del episodeo 11783 son episode_steps:107\n",
            "Total Steps: 723953 Episode Num: 11783 Reward: 167.9911554440836 avg_loss_c: 3.9511670420102982 avg_loss_a: -54.39082154603762\n",
            "Número de pasos del episodeo 11784 son episode_steps:86\n",
            "Total Steps: 724039 Episode Num: 11784 Reward: 133.86929933491658 avg_loss_c: 4.042043960371683 avg_loss_a: -54.51091677643532\n",
            "Número de pasos del episodeo 11785 son episode_steps:69\n",
            "Total Steps: 724108 Episode Num: 11785 Reward: 119.24260141351587 avg_loss_c: 4.234723015107971 avg_loss_a: -53.603989974312164\n",
            "Número de pasos del episodeo 11786 son episode_steps:109\n",
            "Total Steps: 724217 Episode Num: 11786 Reward: 111.36071694897623 avg_loss_c: 3.7870721948256185 avg_loss_a: -54.22503875592433\n",
            "Número de pasos del episodeo 11787 son episode_steps:122\n",
            "Total Steps: 724339 Episode Num: 11787 Reward: 102.24363219208703 avg_loss_c: 3.9980541526294147 avg_loss_a: -54.768552686347334\n",
            "Número de pasos del episodeo 11788 son episode_steps:90\n",
            "Total Steps: 724429 Episode Num: 11788 Reward: 123.19487377847076 avg_loss_c: 4.056228335698446 avg_loss_a: -53.614937506781686\n",
            "Número de pasos del episodeo 11789 son episode_steps:150\n",
            "Total Steps: 724579 Episode Num: 11789 Reward: 213.91486389170495 avg_loss_c: 4.162831079165141 avg_loss_a: -54.152763519287106\n",
            "Número de pasos del episodeo 11790 son episode_steps:108\n",
            "Total Steps: 724687 Episode Num: 11790 Reward: 169.49881667603205 avg_loss_c: 3.900921951841425 avg_loss_a: -54.670599902117694\n",
            "Número de pasos del episodeo 11791 son episode_steps:162\n",
            "Total Steps: 724849 Episode Num: 11791 Reward: 278.18893696294356 avg_loss_c: 3.566636634461674 avg_loss_a: -53.96040744546019\n",
            "Número de pasos del episodeo 11792 son episode_steps:85\n",
            "Total Steps: 724934 Episode Num: 11792 Reward: 132.26567909068712 avg_loss_c: 3.9235812187194825 avg_loss_a: -53.65111133351046\n",
            "Número de pasos del episodeo 11793 son episode_steps:72\n",
            "Total Steps: 725006 Episode Num: 11793 Reward: 117.09423941786594 avg_loss_c: 3.801556693183051 avg_loss_a: -54.646206855773926\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 171.814429\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11794 son episode_steps:139\n",
            "Total Steps: 725145 Episode Num: 11794 Reward: 224.52409768480138 avg_loss_c: 3.815631473664757 avg_loss_a: -54.24709130705689\n",
            "Número de pasos del episodeo 11795 son episode_steps:76\n",
            "Total Steps: 725221 Episode Num: 11795 Reward: 23.63778607881151 avg_loss_c: 4.199032488622163 avg_loss_a: -54.1717213078549\n",
            "Número de pasos del episodeo 11796 son episode_steps:158\n",
            "Total Steps: 725379 Episode Num: 11796 Reward: 250.49211861849196 avg_loss_c: 3.8466845479192613 avg_loss_a: -54.04798396629623\n",
            "Número de pasos del episodeo 11797 son episode_steps:168\n",
            "Total Steps: 725547 Episode Num: 11797 Reward: 267.7011671012379 avg_loss_c: 3.6748926426683153 avg_loss_a: -54.34504027593704\n",
            "Número de pasos del episodeo 11798 son episode_steps:97\n",
            "Total Steps: 725644 Episode Num: 11798 Reward: 142.75046113178047 avg_loss_c: 3.815224089573339 avg_loss_a: -54.881307424958216\n",
            "Número de pasos del episodeo 11799 son episode_steps:102\n",
            "Total Steps: 725746 Episode Num: 11799 Reward: 151.3422350986458 avg_loss_c: 3.860135700188431 avg_loss_a: -54.380431829714304\n",
            "Número de pasos del episodeo 11800 son episode_steps:190\n",
            "Total Steps: 725936 Episode Num: 11800 Reward: 298.86275937003523 avg_loss_c: 3.8654956027081138 avg_loss_a: -54.76688589798777\n",
            "Número de pasos del episodeo 11801 son episode_steps:184\n",
            "Total Steps: 726120 Episode Num: 11801 Reward: 295.25164551439445 avg_loss_c: 3.72980124147042 avg_loss_a: -54.836340199346125\n",
            "Número de pasos del episodeo 11802 son episode_steps:82\n",
            "Total Steps: 726202 Episode Num: 11802 Reward: -12.631757257434954 avg_loss_c: 5.679710821407597 avg_loss_a: -54.084930419921875\n",
            "Número de pasos del episodeo 11803 son episode_steps:156\n",
            "Total Steps: 726358 Episode Num: 11803 Reward: 222.78612111315272 avg_loss_c: 4.128895554787073 avg_loss_a: -54.74552741417518\n",
            "Número de pasos del episodeo 11804 son episode_steps:206\n",
            "Total Steps: 726564 Episode Num: 11804 Reward: 350.2748040421893 avg_loss_c: 3.980787767947299 avg_loss_a: -54.90776336077347\n",
            "Número de pasos del episodeo 11805 son episode_steps:67\n",
            "Total Steps: 726631 Episode Num: 11805 Reward: 84.59749232170552 avg_loss_c: 3.830243776093668 avg_loss_a: -55.05043377093415\n",
            "Número de pasos del episodeo 11806 son episode_steps:134\n",
            "Total Steps: 726765 Episode Num: 11806 Reward: 189.80998839345582 avg_loss_c: 3.8855236181572304 avg_loss_a: -54.69234956200443\n",
            "Número de pasos del episodeo 11807 son episode_steps:57\n",
            "Total Steps: 726822 Episode Num: 11807 Reward: 77.25394836661201 avg_loss_c: 3.8183729481278803 avg_loss_a: -54.45444368061266\n",
            "Número de pasos del episodeo 11808 son episode_steps:194\n",
            "Total Steps: 727016 Episode Num: 11808 Reward: 283.6840364574144 avg_loss_c: 3.750163153274772 avg_loss_a: -54.80649452602741\n",
            "Número de pasos del episodeo 11809 son episode_steps:108\n",
            "Total Steps: 727124 Episode Num: 11809 Reward: 60.13716818477015 avg_loss_c: 4.021925729733926 avg_loss_a: -55.30780269481517\n",
            "Número de pasos del episodeo 11810 son episode_steps:116\n",
            "Total Steps: 727240 Episode Num: 11810 Reward: 167.6991820092725 avg_loss_c: 3.8101727551427382 avg_loss_a: -55.04737511996565\n",
            "Número de pasos del episodeo 11811 son episode_steps:251\n",
            "Total Steps: 727491 Episode Num: 11811 Reward: 402.217588350901 avg_loss_c: 3.7795218604494374 avg_loss_a: -55.04963395320087\n",
            "Número de pasos del episodeo 11812 son episode_steps:204\n",
            "Total Steps: 727695 Episode Num: 11812 Reward: 307.3499667730274 avg_loss_c: 3.7412191664471344 avg_loss_a: -55.010071249569165\n",
            "Número de pasos del episodeo 11813 son episode_steps:74\n",
            "Total Steps: 727769 Episode Num: 11813 Reward: 112.26780213226414 avg_loss_c: 3.7876198066247477 avg_loss_a: -54.53262133211703\n",
            "Número de pasos del episodeo 11814 son episode_steps:197\n",
            "Total Steps: 727966 Episode Num: 11814 Reward: 317.41396872210237 avg_loss_c: 3.823891597350842 avg_loss_a: -55.003606573579276\n",
            "Número de pasos del episodeo 11815 son episode_steps:54\n",
            "Total Steps: 728020 Episode Num: 11815 Reward: 56.09607704776226 avg_loss_c: 3.7320718235439725 avg_loss_a: -55.225601761429395\n",
            "Número de pasos del episodeo 11816 son episode_steps:141\n",
            "Total Steps: 728161 Episode Num: 11816 Reward: 225.8556541199073 avg_loss_c: 3.988299582866912 avg_loss_a: -54.852428490388476\n",
            "Número de pasos del episodeo 11817 son episode_steps:31\n",
            "Total Steps: 728192 Episode Num: 11817 Reward: 13.693032399069896 avg_loss_c: 3.5405776346883466 avg_loss_a: -54.28090200116557\n",
            "Número de pasos del episodeo 11818 son episode_steps:164\n",
            "Total Steps: 728356 Episode Num: 11818 Reward: 259.3473710976393 avg_loss_c: 3.7604004522649253 avg_loss_a: -54.53552781081781\n",
            "Número de pasos del episodeo 11819 son episode_steps:104\n",
            "Total Steps: 728460 Episode Num: 11819 Reward: 54.604234885990806 avg_loss_c: 4.088388039515569 avg_loss_a: -55.05816870469313\n",
            "Número de pasos del episodeo 11820 son episode_steps:248\n",
            "Total Steps: 728708 Episode Num: 11820 Reward: 412.7987907242513 avg_loss_c: 4.079355010101872 avg_loss_a: -55.13994318439114\n",
            "Número de pasos del episodeo 11821 son episode_steps:108\n",
            "Total Steps: 728816 Episode Num: 11821 Reward: 174.11009672004056 avg_loss_c: 4.101938446362813 avg_loss_a: -55.403181853117765\n",
            "Número de pasos del episodeo 11822 son episode_steps:44\n",
            "Total Steps: 728860 Episode Num: 11822 Reward: 27.860719473779564 avg_loss_c: 3.879905261776664 avg_loss_a: -55.93889045715332\n",
            "Número de pasos del episodeo 11823 son episode_steps:105\n",
            "Total Steps: 728965 Episode Num: 11823 Reward: 72.73469500052093 avg_loss_c: 4.047579996926444 avg_loss_a: -54.56740653628395\n",
            "Número de pasos del episodeo 11824 son episode_steps:83\n",
            "Total Steps: 729048 Episode Num: 11824 Reward: 129.0877719921203 avg_loss_c: 3.910090733723468 avg_loss_a: -55.068078650049415\n",
            "Número de pasos del episodeo 11825 son episode_steps:175\n",
            "Total Steps: 729223 Episode Num: 11825 Reward: 182.1963908952926 avg_loss_c: 4.2174663243974955 avg_loss_a: -55.17590031215123\n",
            "Número de pasos del episodeo 11826 son episode_steps:182\n",
            "Total Steps: 729405 Episode Num: 11826 Reward: 304.16089586628124 avg_loss_c: 4.096137658580319 avg_loss_a: -55.383480952336235\n",
            "Número de pasos del episodeo 11827 son episode_steps:189\n",
            "Total Steps: 729594 Episode Num: 11827 Reward: 292.6255973923211 avg_loss_c: 4.0596922730642655 avg_loss_a: -54.87762911357577\n",
            "Número de pasos del episodeo 11828 son episode_steps:108\n",
            "Total Steps: 729702 Episode Num: 11828 Reward: 153.39341688894552 avg_loss_c: 3.896135641468896 avg_loss_a: -54.73467085096571\n",
            "Número de pasos del episodeo 11829 son episode_steps:207\n",
            "Total Steps: 729909 Episode Num: 11829 Reward: 336.8289453609842 avg_loss_c: 3.8924826815508413 avg_loss_a: -55.12692166756892\n",
            "Número de pasos del episodeo 11830 son episode_steps:151\n",
            "Total Steps: 730060 Episode Num: 11830 Reward: 234.82072819129468 avg_loss_c: 3.7850794871121844 avg_loss_a: -55.56550335410415\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 176.012288\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11831 son episode_steps:91\n",
            "Total Steps: 730151 Episode Num: 11831 Reward: 29.958430361861698 avg_loss_c: 4.185340365210732 avg_loss_a: -55.43285340529222\n",
            "Número de pasos del episodeo 11832 son episode_steps:143\n",
            "Total Steps: 730294 Episode Num: 11832 Reward: 207.84500380090816 avg_loss_c: 4.0833328270411995 avg_loss_a: -54.99506895692198\n",
            "Número de pasos del episodeo 11833 son episode_steps:126\n",
            "Total Steps: 730420 Episode Num: 11833 Reward: 210.60603065967504 avg_loss_c: 4.033505623302762 avg_loss_a: -54.80331087869311\n",
            "Número de pasos del episodeo 11834 son episode_steps:95\n",
            "Total Steps: 730515 Episode Num: 11834 Reward: 48.42099976800958 avg_loss_c: 3.8793077594355534 avg_loss_a: -55.406509600187604\n",
            "Número de pasos del episodeo 11835 son episode_steps:153\n",
            "Total Steps: 730668 Episode Num: 11835 Reward: 125.03755979407026 avg_loss_c: 4.461424845496034 avg_loss_a: -55.197283825843165\n",
            "Número de pasos del episodeo 11836 son episode_steps:87\n",
            "Total Steps: 730755 Episode Num: 11836 Reward: 109.0348451201217 avg_loss_c: 4.123915661340472 avg_loss_a: -55.83033787519082\n",
            "Número de pasos del episodeo 11837 son episode_steps:151\n",
            "Total Steps: 730906 Episode Num: 11837 Reward: 227.0760571958778 avg_loss_c: 4.155521730713497 avg_loss_a: -55.03646211434674\n",
            "Número de pasos del episodeo 11838 son episode_steps:94\n",
            "Total Steps: 731000 Episode Num: 11838 Reward: 123.8749289121238 avg_loss_c: 4.306051487618304 avg_loss_a: -54.96814378778985\n",
            "Número de pasos del episodeo 11839 son episode_steps:139\n",
            "Total Steps: 731139 Episode Num: 11839 Reward: 195.38647469379922 avg_loss_c: 4.207729320731952 avg_loss_a: -54.9658272557979\n",
            "Número de pasos del episodeo 11840 son episode_steps:180\n",
            "Total Steps: 731319 Episode Num: 11840 Reward: 293.0096343196202 avg_loss_c: 4.091626295778487 avg_loss_a: -55.27131983439128\n",
            "Número de pasos del episodeo 11841 son episode_steps:86\n",
            "Total Steps: 731405 Episode Num: 11841 Reward: 137.75497796684846 avg_loss_c: 4.052318991616715 avg_loss_a: -55.379780436671055\n",
            "Número de pasos del episodeo 11842 son episode_steps:65\n",
            "Total Steps: 731470 Episode Num: 11842 Reward: 78.00472977451578 avg_loss_c: 3.9009591836195727 avg_loss_a: -54.96450523963341\n",
            "Número de pasos del episodeo 11843 son episode_steps:81\n",
            "Total Steps: 731551 Episode Num: 11843 Reward: 102.18527551013331 avg_loss_c: 4.243576844533284 avg_loss_a: -54.89471482641903\n",
            "Número de pasos del episodeo 11844 son episode_steps:391\n",
            "Total Steps: 731942 Episode Num: 11844 Reward: 661.2673823114445 avg_loss_c: 4.006690627168816 avg_loss_a: -55.80860602337381\n",
            "Número de pasos del episodeo 11845 son episode_steps:92\n",
            "Total Steps: 732034 Episode Num: 11845 Reward: 115.30094074739253 avg_loss_c: 3.9808632990588313 avg_loss_a: -55.559170100999914\n",
            "Número de pasos del episodeo 11846 son episode_steps:62\n",
            "Total Steps: 732096 Episode Num: 11846 Reward: -5.429609484049264 avg_loss_c: 4.1284435103016515 avg_loss_a: -55.65008261895949\n",
            "Número de pasos del episodeo 11847 son episode_steps:368\n",
            "Total Steps: 732464 Episode Num: 11847 Reward: 514.5535177178971 avg_loss_c: 4.016895697168682 avg_loss_a: -56.047156727832295\n",
            "Número de pasos del episodeo 11848 son episode_steps:229\n",
            "Total Steps: 732693 Episode Num: 11848 Reward: 332.4243700579271 avg_loss_c: 4.05970269832028 avg_loss_a: -56.39070898997211\n",
            "Número de pasos del episodeo 11849 son episode_steps:61\n",
            "Total Steps: 732754 Episode Num: 11849 Reward: 39.862163356704805 avg_loss_c: 4.08848961454923 avg_loss_a: -56.31447238609439\n",
            "Número de pasos del episodeo 11850 son episode_steps:153\n",
            "Total Steps: 732907 Episode Num: 11850 Reward: 233.03673270227424 avg_loss_c: 4.2176876426522245 avg_loss_a: -56.0011253107607\n",
            "Número de pasos del episodeo 11851 son episode_steps:238\n",
            "Total Steps: 733145 Episode Num: 11851 Reward: 382.104456321142 avg_loss_c: 4.0557935378130745 avg_loss_a: -56.73404087739832\n",
            "Número de pasos del episodeo 11852 son episode_steps:108\n",
            "Total Steps: 733253 Episode Num: 11852 Reward: 147.14447410361558 avg_loss_c: 3.98690457255752 avg_loss_a: -56.35416751437717\n",
            "Número de pasos del episodeo 11853 son episode_steps:117\n",
            "Total Steps: 733370 Episode Num: 11853 Reward: 181.0098295852374 avg_loss_c: 4.095968615295541 avg_loss_a: -56.65991426125551\n",
            "Número de pasos del episodeo 11854 son episode_steps:203\n",
            "Total Steps: 733573 Episode Num: 11854 Reward: 285.1891004303801 avg_loss_c: 4.1731302045249 avg_loss_a: -57.04111888490874\n",
            "Número de pasos del episodeo 11855 son episode_steps:193\n",
            "Total Steps: 733766 Episode Num: 11855 Reward: 266.99358051130514 avg_loss_c: 4.3255682312762795 avg_loss_a: -57.44395683960593\n",
            "Número de pasos del episodeo 11856 son episode_steps:165\n",
            "Total Steps: 733931 Episode Num: 11856 Reward: 231.87496030466713 avg_loss_c: 3.9590552922451137 avg_loss_a: -56.725744582667495\n",
            "Número de pasos del episodeo 11857 son episode_steps:98\n",
            "Total Steps: 734029 Episode Num: 11857 Reward: 88.26831410363332 avg_loss_c: 4.026844572047798 avg_loss_a: -56.95018542542749\n",
            "Número de pasos del episodeo 11858 son episode_steps:94\n",
            "Total Steps: 734123 Episode Num: 11858 Reward: 115.67645224750166 avg_loss_c: 4.212287540131427 avg_loss_a: -57.32646382108648\n",
            "Número de pasos del episodeo 11859 son episode_steps:80\n",
            "Total Steps: 734203 Episode Num: 11859 Reward: 102.8383540914895 avg_loss_c: 4.310683834552765 avg_loss_a: -56.61375408172607\n",
            "Número de pasos del episodeo 11860 son episode_steps:120\n",
            "Total Steps: 734323 Episode Num: 11860 Reward: 185.60705597144164 avg_loss_c: 4.054923719167709 avg_loss_a: -56.82621472676595\n",
            "Número de pasos del episodeo 11861 son episode_steps:146\n",
            "Total Steps: 734469 Episode Num: 11861 Reward: 85.18771302494066 avg_loss_c: 4.630030315216273 avg_loss_a: -57.13368831268728\n",
            "Número de pasos del episodeo 11862 son episode_steps:83\n",
            "Total Steps: 734552 Episode Num: 11862 Reward: 66.99653089348422 avg_loss_c: 4.268885497587273 avg_loss_a: -56.686796946697925\n",
            "Número de pasos del episodeo 11863 son episode_steps:139\n",
            "Total Steps: 734691 Episode Num: 11863 Reward: 181.04570937029092 avg_loss_c: 4.429135240239205 avg_loss_a: -57.65462578972467\n",
            "Número de pasos del episodeo 11864 son episode_steps:76\n",
            "Total Steps: 734767 Episode Num: 11864 Reward: 78.72599568306747 avg_loss_c: 4.033349404209538 avg_loss_a: -57.38412023845472\n",
            "Número de pasos del episodeo 11865 son episode_steps:187\n",
            "Total Steps: 734954 Episode Num: 11865 Reward: 182.73891698166312 avg_loss_c: 4.508670833659044 avg_loss_a: -56.84945725629674\n",
            "Número de pasos del episodeo 11866 son episode_steps:179\n",
            "Total Steps: 735133 Episode Num: 11866 Reward: 257.45500017675323 avg_loss_c: 4.34673453576072 avg_loss_a: -57.522273612421984\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 286.001455\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11867 son episode_steps:97\n",
            "Total Steps: 735230 Episode Num: 11867 Reward: 125.16088278762874 avg_loss_c: 4.1622971947660155 avg_loss_a: -57.56400649080572\n",
            "Número de pasos del episodeo 11868 son episode_steps:219\n",
            "Total Steps: 735449 Episode Num: 11868 Reward: 362.89137381923376 avg_loss_c: 4.256679514227392 avg_loss_a: -57.22291026703299\n",
            "Número de pasos del episodeo 11869 son episode_steps:38\n",
            "Total Steps: 735487 Episode Num: 11869 Reward: 15.67869911890816 avg_loss_c: 4.125173399322911 avg_loss_a: -58.31201432880602\n",
            "Número de pasos del episodeo 11870 son episode_steps:171\n",
            "Total Steps: 735658 Episode Num: 11870 Reward: 231.72634128369333 avg_loss_c: 4.167806434352496 avg_loss_a: -57.07159718295984\n",
            "Número de pasos del episodeo 11871 son episode_steps:121\n",
            "Total Steps: 735779 Episode Num: 11871 Reward: 144.55770893610887 avg_loss_c: 4.3196206802179 avg_loss_a: -57.00643983951285\n",
            "Número de pasos del episodeo 11872 son episode_steps:208\n",
            "Total Steps: 735987 Episode Num: 11872 Reward: 301.10026071349574 avg_loss_c: 4.1053010786955175 avg_loss_a: -57.49999611194317\n",
            "Número de pasos del episodeo 11873 son episode_steps:295\n",
            "Total Steps: 736282 Episode Num: 11873 Reward: 436.5341662128574 avg_loss_c: 4.057531921742326 avg_loss_a: -57.66290001303463\n",
            "Número de pasos del episodeo 11874 son episode_steps:74\n",
            "Total Steps: 736356 Episode Num: 11874 Reward: 92.24069061204537 avg_loss_c: 4.058435533497785 avg_loss_a: -57.62694291810732\n",
            "Número de pasos del episodeo 11875 son episode_steps:222\n",
            "Total Steps: 736578 Episode Num: 11875 Reward: 326.3556020240925 avg_loss_c: 3.988895302420264 avg_loss_a: -58.23939325143625\n",
            "Número de pasos del episodeo 11876 son episode_steps:170\n",
            "Total Steps: 736748 Episode Num: 11876 Reward: 262.8862177943204 avg_loss_c: 4.038093348110423 avg_loss_a: -58.178395035687615\n",
            "Número de pasos del episodeo 11877 son episode_steps:47\n",
            "Total Steps: 736795 Episode Num: 11877 Reward: 58.91756432811614 avg_loss_c: 4.212199033574855 avg_loss_a: -57.66717577995138\n",
            "Número de pasos del episodeo 11878 son episode_steps:41\n",
            "Total Steps: 736836 Episode Num: 11878 Reward: 32.2660412173025 avg_loss_c: 4.145604744190123 avg_loss_a: -58.375744145090984\n",
            "Número de pasos del episodeo 11879 son episode_steps:52\n",
            "Total Steps: 736888 Episode Num: 11879 Reward: 36.49279943965451 avg_loss_c: 4.600201519636007 avg_loss_a: -58.479697740994965\n",
            "Número de pasos del episodeo 11880 son episode_steps:208\n",
            "Total Steps: 737096 Episode Num: 11880 Reward: 338.2431543071508 avg_loss_c: 4.272002911338439 avg_loss_a: -58.66980857115526\n",
            "Número de pasos del episodeo 11881 son episode_steps:43\n",
            "Total Steps: 737139 Episode Num: 11881 Reward: 35.87644177014184 avg_loss_c: 4.53282875238463 avg_loss_a: -57.314005918281026\n",
            "Número de pasos del episodeo 11882 son episode_steps:214\n",
            "Total Steps: 737353 Episode Num: 11882 Reward: 241.8769784407168 avg_loss_c: 4.224990030315435 avg_loss_a: -58.2177639542339\n",
            "Número de pasos del episodeo 11883 son episode_steps:395\n",
            "Total Steps: 737748 Episode Num: 11883 Reward: 629.3947785661353 avg_loss_c: 4.087458318396459 avg_loss_a: -58.356226957297025\n",
            "Número de pasos del episodeo 11884 son episode_steps:347\n",
            "Total Steps: 738095 Episode Num: 11884 Reward: 515.1290434046032 avg_loss_c: 4.116284854817459 avg_loss_a: -58.58096498165076\n",
            "Número de pasos del episodeo 11885 son episode_steps:34\n",
            "Total Steps: 738129 Episode Num: 11885 Reward: 9.35832688134129 avg_loss_c: 4.198366515776691 avg_loss_a: -59.60341778923483\n",
            "Número de pasos del episodeo 11886 son episode_steps:96\n",
            "Total Steps: 738225 Episode Num: 11886 Reward: 100.19430469275244 avg_loss_c: 3.8908924957116446 avg_loss_a: -59.1612229347229\n",
            "Número de pasos del episodeo 11887 son episode_steps:103\n",
            "Total Steps: 738328 Episode Num: 11887 Reward: 71.34926860518132 avg_loss_c: 3.9724216854688033 avg_loss_a: -58.94779401612513\n",
            "Número de pasos del episodeo 11888 son episode_steps:42\n",
            "Total Steps: 738370 Episode Num: 11888 Reward: 35.52169694902739 avg_loss_c: 4.016373009908767 avg_loss_a: -58.591014498756046\n",
            "Número de pasos del episodeo 11889 son episode_steps:126\n",
            "Total Steps: 738496 Episode Num: 11889 Reward: 171.93517434896418 avg_loss_c: 4.0896949786988515 avg_loss_a: -59.16665498037187\n",
            "Número de pasos del episodeo 11890 son episode_steps:52\n",
            "Total Steps: 738548 Episode Num: 11890 Reward: 48.16186352372725 avg_loss_c: 4.174077685062702 avg_loss_a: -59.31736755371094\n",
            "Número de pasos del episodeo 11891 son episode_steps:48\n",
            "Total Steps: 738596 Episode Num: 11891 Reward: 28.269022833880882 avg_loss_c: 3.8618635336558023 avg_loss_a: -59.18578322728475\n",
            "Número de pasos del episodeo 11892 son episode_steps:236\n",
            "Total Steps: 738832 Episode Num: 11892 Reward: 368.3656337690727 avg_loss_c: 4.0142985905631114 avg_loss_a: -59.55996316166247\n",
            "Número de pasos del episodeo 11893 son episode_steps:108\n",
            "Total Steps: 738940 Episode Num: 11893 Reward: 152.3126808447115 avg_loss_c: 4.177745015532882 avg_loss_a: -59.65226222850658\n",
            "Número de pasos del episodeo 11894 son episode_steps:103\n",
            "Total Steps: 739043 Episode Num: 11894 Reward: 163.0879011845457 avg_loss_c: 4.234092638330552 avg_loss_a: -59.708210028490974\n",
            "Número de pasos del episodeo 11895 son episode_steps:119\n",
            "Total Steps: 739162 Episode Num: 11895 Reward: 188.8922752767016 avg_loss_c: 4.112335171018328 avg_loss_a: -59.47187407677915\n",
            "Número de pasos del episodeo 11896 son episode_steps:124\n",
            "Total Steps: 739286 Episode Num: 11896 Reward: 173.52270400904675 avg_loss_c: 3.8015953994566396 avg_loss_a: -59.5530687762845\n",
            "Número de pasos del episodeo 11897 son episode_steps:48\n",
            "Total Steps: 739334 Episode Num: 11897 Reward: 34.92130764678453 avg_loss_c: 4.497579038143158 avg_loss_a: -58.687929471333824\n",
            "Número de pasos del episodeo 11898 son episode_steps:165\n",
            "Total Steps: 739499 Episode Num: 11898 Reward: 243.0443821291645 avg_loss_c: 3.9363479498660925 avg_loss_a: -59.13707777081114\n",
            "Número de pasos del episodeo 11899 son episode_steps:91\n",
            "Total Steps: 739590 Episode Num: 11899 Reward: 87.47190470223181 avg_loss_c: 4.844791514532907 avg_loss_a: -58.877195714594244\n",
            "Número de pasos del episodeo 11900 son episode_steps:76\n",
            "Total Steps: 739666 Episode Num: 11900 Reward: 110.32882384878003 avg_loss_c: 3.9073789966733834 avg_loss_a: -59.808563232421875\n",
            "Número de pasos del episodeo 11901 son episode_steps:187\n",
            "Total Steps: 739853 Episode Num: 11901 Reward: 292.59813797254816 avg_loss_c: 4.5167691898855935 avg_loss_a: -59.949585409725415\n",
            "Número de pasos del episodeo 11902 son episode_steps:34\n",
            "Total Steps: 739887 Episode Num: 11902 Reward: -38.30526597618326 avg_loss_c: 4.5879639877992515 avg_loss_a: -58.851694892434516\n",
            "Número de pasos del episodeo 11903 son episode_steps:68\n",
            "Total Steps: 739955 Episode Num: 11903 Reward: -7.735430704590296 avg_loss_c: 4.436156507800607 avg_loss_a: -59.01402675404268\n",
            "Número de pasos del episodeo 11904 son episode_steps:70\n",
            "Total Steps: 740025 Episode Num: 11904 Reward: 84.14812410906929 avg_loss_c: 4.326914729390825 avg_loss_a: -58.92359368460519\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 268.219262\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11905 son episode_steps:86\n",
            "Total Steps: 740111 Episode Num: 11905 Reward: 108.22076480518813 avg_loss_c: 4.55010700503061 avg_loss_a: -59.33514413168264\n",
            "Número de pasos del episodeo 11906 son episode_steps:102\n",
            "Total Steps: 740213 Episode Num: 11906 Reward: 143.6844701926618 avg_loss_c: 4.357747627239601 avg_loss_a: -59.83340843051088\n",
            "Número de pasos del episodeo 11907 son episode_steps:244\n",
            "Total Steps: 740457 Episode Num: 11907 Reward: 368.9750832114638 avg_loss_c: 4.50835027069342 avg_loss_a: -59.57383074525927\n",
            "Número de pasos del episodeo 11908 son episode_steps:192\n",
            "Total Steps: 740649 Episode Num: 11908 Reward: 284.2889790320596 avg_loss_c: 4.120568326363961 avg_loss_a: -59.33474059899648\n",
            "Número de pasos del episodeo 11909 son episode_steps:145\n",
            "Total Steps: 740794 Episode Num: 11909 Reward: 215.80004656757157 avg_loss_c: 4.127232868918057 avg_loss_a: -59.62358308989426\n",
            "Número de pasos del episodeo 11910 son episode_steps:84\n",
            "Total Steps: 740878 Episode Num: 11910 Reward: 57.23702650754463 avg_loss_c: 4.539128155935378 avg_loss_a: -59.84876260303316\n",
            "Número de pasos del episodeo 11911 son episode_steps:332\n",
            "Total Steps: 741210 Episode Num: 11911 Reward: 532.0685111034126 avg_loss_c: 4.265626029077783 avg_loss_a: -60.003985025796545\n",
            "Número de pasos del episodeo 11912 son episode_steps:55\n",
            "Total Steps: 741265 Episode Num: 11912 Reward: 65.66861119521565 avg_loss_c: 3.9978522083976054 avg_loss_a: -59.8136211048473\n",
            "Número de pasos del episodeo 11913 son episode_steps:87\n",
            "Total Steps: 741352 Episode Num: 11913 Reward: 87.596838425478 avg_loss_c: 4.180347744075731 avg_loss_a: -60.46334711710612\n",
            "Número de pasos del episodeo 11914 son episode_steps:157\n",
            "Total Steps: 741509 Episode Num: 11914 Reward: 263.1359228345013 avg_loss_c: 4.0914203315783455 avg_loss_a: -59.74811342567395\n",
            "Número de pasos del episodeo 11915 son episode_steps:108\n",
            "Total Steps: 741617 Episode Num: 11915 Reward: 138.29577543421414 avg_loss_c: 4.15128959108282 avg_loss_a: -60.38512717352973\n",
            "Número de pasos del episodeo 11916 son episode_steps:131\n",
            "Total Steps: 741748 Episode Num: 11916 Reward: 183.2028699741221 avg_loss_c: 4.102224275356031 avg_loss_a: -60.68016387124098\n",
            "Número de pasos del episodeo 11917 son episode_steps:103\n",
            "Total Steps: 741851 Episode Num: 11917 Reward: 88.68409819728967 avg_loss_c: 4.08602152055907 avg_loss_a: -60.42802447717167\n",
            "Número de pasos del episodeo 11918 son episode_steps:251\n",
            "Total Steps: 742102 Episode Num: 11918 Reward: 385.86573047001434 avg_loss_c: 4.162613539106817 avg_loss_a: -60.505828659847914\n",
            "Número de pasos del episodeo 11919 son episode_steps:150\n",
            "Total Steps: 742252 Episode Num: 11919 Reward: 223.60850233348688 avg_loss_c: 4.204668855667114 avg_loss_a: -60.904131724039715\n",
            "Número de pasos del episodeo 11920 son episode_steps:217\n",
            "Total Steps: 742469 Episode Num: 11920 Reward: 335.65218513397593 avg_loss_c: 4.070632250078263 avg_loss_a: -60.57985522010909\n",
            "Número de pasos del episodeo 11921 son episode_steps:139\n",
            "Total Steps: 742608 Episode Num: 11921 Reward: 207.58348025555506 avg_loss_c: 3.9908613695515145 avg_loss_a: -60.5556595617061\n",
            "Número de pasos del episodeo 11922 son episode_steps:73\n",
            "Total Steps: 742681 Episode Num: 11922 Reward: -3.42162725107477 avg_loss_c: 4.492266432879722 avg_loss_a: -61.252002141247054\n",
            "Número de pasos del episodeo 11923 son episode_steps:451\n",
            "Total Steps: 743132 Episode Num: 11923 Reward: 697.7574028583772 avg_loss_c: 4.230071189926892 avg_loss_a: -60.765989933732875\n",
            "Número de pasos del episodeo 11924 son episode_steps:107\n",
            "Total Steps: 743239 Episode Num: 11924 Reward: 160.8275919093849 avg_loss_c: 4.0370823779952865 avg_loss_a: -60.81815929947612\n",
            "Número de pasos del episodeo 11925 son episode_steps:360\n",
            "Total Steps: 743599 Episode Num: 11925 Reward: 553.1610454628776 avg_loss_c: 4.029512543148464 avg_loss_a: -61.4125346077813\n",
            "Número de pasos del episodeo 11926 son episode_steps:314\n",
            "Total Steps: 743913 Episode Num: 11926 Reward: 485.4874466329334 avg_loss_c: 3.8651959356988312 avg_loss_a: -61.474762327352146\n",
            "Número de pasos del episodeo 11927 son episode_steps:250\n",
            "Total Steps: 744163 Episode Num: 11927 Reward: 396.02954315124344 avg_loss_c: 3.98591517162323 avg_loss_a: -62.08282678222656\n",
            "Número de pasos del episodeo 11928 son episode_steps:81\n",
            "Total Steps: 744244 Episode Num: 11928 Reward: 124.94441377784506 avg_loss_c: 3.8926059934828015 avg_loss_a: -62.28426120899342\n",
            "Número de pasos del episodeo 11929 son episode_steps:520\n",
            "Total Steps: 744764 Episode Num: 11929 Reward: 805.9488782542048 avg_loss_c: 3.8662395793658035 avg_loss_a: -62.48086066612831\n",
            "Número de pasos del episodeo 11930 son episode_steps:90\n",
            "Total Steps: 744854 Episode Num: 11930 Reward: 120.59784342667297 avg_loss_c: 3.8014473650190563 avg_loss_a: -63.3517327202691\n",
            "Número de pasos del episodeo 11931 son episode_steps:102\n",
            "Total Steps: 744956 Episode Num: 11931 Reward: 134.69333572258486 avg_loss_c: 3.690053257287717 avg_loss_a: -62.599905275831034\n",
            "Número de pasos del episodeo 11932 son episode_steps:114\n",
            "Total Steps: 745070 Episode Num: 11932 Reward: 181.1389670250478 avg_loss_c: 3.7907815523314894 avg_loss_a: -62.66491297671669\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 183.233378\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11933 son episode_steps:111\n",
            "Total Steps: 745181 Episode Num: 11933 Reward: 169.60360479191348 avg_loss_c: 3.639044007739505 avg_loss_a: -62.83560242524018\n",
            "Número de pasos del episodeo 11934 son episode_steps:165\n",
            "Total Steps: 745346 Episode Num: 11934 Reward: 240.47995350628267 avg_loss_c: 3.7985888654535467 avg_loss_a: -62.28542341752486\n",
            "Número de pasos del episodeo 11935 son episode_steps:473\n",
            "Total Steps: 745819 Episode Num: 11935 Reward: 755.9545026321775 avg_loss_c: 3.7132526915874844 avg_loss_a: -62.824890185108146\n",
            "Número de pasos del episodeo 11936 son episode_steps:60\n",
            "Total Steps: 745879 Episode Num: 11936 Reward: 89.33386139285588 avg_loss_c: 3.44407540957133 avg_loss_a: -63.00780131022135\n",
            "Número de pasos del episodeo 11937 son episode_steps:256\n",
            "Total Steps: 746135 Episode Num: 11937 Reward: 383.1567161093094 avg_loss_c: 3.6069740960374475 avg_loss_a: -63.094331204891205\n",
            "Número de pasos del episodeo 11938 son episode_steps:108\n",
            "Total Steps: 746243 Episode Num: 11938 Reward: 147.02278266048103 avg_loss_c: 3.914592135835577 avg_loss_a: -63.607627586082174\n",
            "Número de pasos del episodeo 11939 son episode_steps:127\n",
            "Total Steps: 746370 Episode Num: 11939 Reward: 183.48589372624693 avg_loss_c: 3.5902702808380127 avg_loss_a: -63.1040027948815\n",
            "Número de pasos del episodeo 11940 son episode_steps:52\n",
            "Total Steps: 746422 Episode Num: 11940 Reward: 66.00922745017436 avg_loss_c: 3.551947621198801 avg_loss_a: -63.86748900780311\n",
            "Número de pasos del episodeo 11941 son episode_steps:55\n",
            "Total Steps: 746477 Episode Num: 11941 Reward: 27.06959919420477 avg_loss_c: 3.8594745939428154 avg_loss_a: -63.28679851185192\n",
            "Número de pasos del episodeo 11942 son episode_steps:69\n",
            "Total Steps: 746546 Episode Num: 11942 Reward: 85.81030467828334 avg_loss_c: 3.7642974473428037 avg_loss_a: -63.454075688901156\n",
            "Número de pasos del episodeo 11943 son episode_steps:116\n",
            "Total Steps: 746662 Episode Num: 11943 Reward: 126.28257864490966 avg_loss_c: 3.937730084205496 avg_loss_a: -63.42938436310867\n",
            "Número de pasos del episodeo 11944 son episode_steps:118\n",
            "Total Steps: 746780 Episode Num: 11944 Reward: 146.6362102086454 avg_loss_c: 3.9494302495051237 avg_loss_a: -62.827252986067435\n",
            "Número de pasos del episodeo 11945 son episode_steps:233\n",
            "Total Steps: 747013 Episode Num: 11945 Reward: 358.05109676806745 avg_loss_c: 3.763137978033958 avg_loss_a: -62.7293536141195\n",
            "Número de pasos del episodeo 11946 son episode_steps:449\n",
            "Total Steps: 747462 Episode Num: 11946 Reward: 672.1880493437046 avg_loss_c: 3.722290623692468 avg_loss_a: -63.26888166397876\n",
            "Número de pasos del episodeo 11947 son episode_steps:190\n",
            "Total Steps: 747652 Episode Num: 11947 Reward: 271.83948317294437 avg_loss_c: 3.6230600482539126 avg_loss_a: -62.92883589895148\n",
            "Número de pasos del episodeo 11948 son episode_steps:75\n",
            "Total Steps: 747727 Episode Num: 11948 Reward: 107.47755410450806 avg_loss_c: 3.463692382176717 avg_loss_a: -63.986151936848955\n",
            "Número de pasos del episodeo 11949 son episode_steps:417\n",
            "Total Steps: 748144 Episode Num: 11949 Reward: 621.7667735162821 avg_loss_c: 3.737932455053718 avg_loss_a: -63.785526339670454\n",
            "Número de pasos del episodeo 11950 son episode_steps:317\n",
            "Total Steps: 748461 Episode Num: 11950 Reward: 473.3691340796012 avg_loss_c: 3.6806029295695692 avg_loss_a: -63.916963799894795\n",
            "Número de pasos del episodeo 11951 son episode_steps:65\n",
            "Total Steps: 748526 Episode Num: 11951 Reward: 93.74911008852344 avg_loss_c: 3.744424684231098 avg_loss_a: -64.2535618708684\n",
            "Número de pasos del episodeo 11952 son episode_steps:299\n",
            "Total Steps: 748825 Episode Num: 11952 Reward: 426.6920447612859 avg_loss_c: 3.6232991736868154 avg_loss_a: -64.52182940735068\n",
            "Número de pasos del episodeo 11953 son episode_steps:744\n",
            "Total Steps: 749569 Episode Num: 11953 Reward: 1147.3965580524448 avg_loss_c: 3.6072028083826906 avg_loss_a: -64.89525514007896\n",
            "Número de pasos del episodeo 11954 son episode_steps:64\n",
            "Total Steps: 749633 Episode Num: 11954 Reward: 70.3554592599751 avg_loss_c: 3.6230855025351048 avg_loss_a: -64.23714590072632\n",
            "Número de pasos del episodeo 11955 son episode_steps:91\n",
            "Total Steps: 749724 Episode Num: 11955 Reward: 30.10845470005302 avg_loss_c: 3.735770657822326 avg_loss_a: -65.33915865552295\n",
            "Número de pasos del episodeo 11956 son episode_steps:200\n",
            "Total Steps: 749924 Episode Num: 11956 Reward: 315.97569029527483 avg_loss_c: 3.8090104615688323 avg_loss_a: -64.7950129699707\n",
            "Número de pasos del episodeo 11957 son episode_steps:108\n",
            "Total Steps: 750032 Episode Num: 11957 Reward: 149.02093995068074 avg_loss_c: 3.6893994212150574 avg_loss_a: -64.56905350861726\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 141.905948\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11958 son episode_steps:18\n",
            "Total Steps: 750050 Episode Num: 11958 Reward: -33.568263494133184 avg_loss_c: 3.8811998234854803 avg_loss_a: -64.3086797926161\n",
            "Número de pasos del episodeo 11959 son episode_steps:119\n",
            "Total Steps: 750169 Episode Num: 11959 Reward: 170.0466061168871 avg_loss_c: 3.6903089294914437 avg_loss_a: -64.91056913488052\n",
            "Número de pasos del episodeo 11960 son episode_steps:185\n",
            "Total Steps: 750354 Episode Num: 11960 Reward: 271.51254042616 avg_loss_c: 3.838604274955956 avg_loss_a: -64.81328941551415\n",
            "Número de pasos del episodeo 11961 son episode_steps:110\n",
            "Total Steps: 750464 Episode Num: 11961 Reward: 94.3774058204386 avg_loss_c: 3.8062784975225274 avg_loss_a: -65.36846056851473\n",
            "Número de pasos del episodeo 11962 son episode_steps:436\n",
            "Total Steps: 750900 Episode Num: 11962 Reward: 688.1608985896156 avg_loss_c: 3.672818830253881 avg_loss_a: -65.61048528688764\n",
            "Número de pasos del episodeo 11963 son episode_steps:92\n",
            "Total Steps: 750992 Episode Num: 11963 Reward: 28.812478174892863 avg_loss_c: 4.041175510572351 avg_loss_a: -65.45160567242166\n",
            "Número de pasos del episodeo 11964 son episode_steps:35\n",
            "Total Steps: 751027 Episode Num: 11964 Reward: -5.328858687286612 avg_loss_c: 4.07846657208034 avg_loss_a: -65.13396323067802\n",
            "Número de pasos del episodeo 11965 son episode_steps:35\n",
            "Total Steps: 751062 Episode Num: 11965 Reward: 17.44232924001162 avg_loss_c: 4.279039887019566 avg_loss_a: -65.58331102643695\n",
            "Número de pasos del episodeo 11966 son episode_steps:122\n",
            "Total Steps: 751184 Episode Num: 11966 Reward: 145.94852304362942 avg_loss_c: 4.057817183557104 avg_loss_a: -65.00919292012199\n",
            "Número de pasos del episodeo 11967 son episode_steps:57\n",
            "Total Steps: 751241 Episode Num: 11967 Reward: -52.74756430622212 avg_loss_c: 4.189110613705819 avg_loss_a: -64.44857794778389\n",
            "Número de pasos del episodeo 11968 son episode_steps:57\n",
            "Total Steps: 751298 Episode Num: 11968 Reward: 58.89022546072141 avg_loss_c: 4.319017979136684 avg_loss_a: -65.3306955036364\n",
            "Número de pasos del episodeo 11969 son episode_steps:171\n",
            "Total Steps: 751469 Episode Num: 11969 Reward: 245.46960822338528 avg_loss_c: 4.184165522369028 avg_loss_a: -64.77949581927027\n",
            "Número de pasos del episodeo 11970 son episode_steps:35\n",
            "Total Steps: 751504 Episode Num: 11970 Reward: -8.682738916689484 avg_loss_c: 4.028603785378593 avg_loss_a: -64.93557979038783\n",
            "Número de pasos del episodeo 11971 son episode_steps:483\n",
            "Total Steps: 751987 Episode Num: 11971 Reward: 671.7297874146888 avg_loss_c: 4.114724060516673 avg_loss_a: -65.60577114571203\n",
            "Número de pasos del episodeo 11972 son episode_steps:74\n",
            "Total Steps: 752061 Episode Num: 11972 Reward: 79.96989775412501 avg_loss_c: 3.945945881508492 avg_loss_a: -65.28072264387801\n",
            "Número de pasos del episodeo 11973 son episode_steps:121\n",
            "Total Steps: 752182 Episode Num: 11973 Reward: 143.60973449347244 avg_loss_c: 4.05510806249193 avg_loss_a: -65.02040938700526\n",
            "Número de pasos del episodeo 11974 son episode_steps:395\n",
            "Total Steps: 752577 Episode Num: 11974 Reward: 568.879391152378 avg_loss_c: 3.972996184192126 avg_loss_a: -65.53100108858905\n",
            "Número de pasos del episodeo 11975 son episode_steps:149\n",
            "Total Steps: 752726 Episode Num: 11975 Reward: 93.88992494057022 avg_loss_c: 4.218465305814807 avg_loss_a: -65.20818502950988\n",
            "Número de pasos del episodeo 11976 son episode_steps:51\n",
            "Total Steps: 752777 Episode Num: 11976 Reward: 62.35198233632058 avg_loss_c: 4.017250435025084 avg_loss_a: -66.20137921501609\n",
            "Número de pasos del episodeo 11977 son episode_steps:111\n",
            "Total Steps: 752888 Episode Num: 11977 Reward: 104.24286485711107 avg_loss_c: 4.183276103423522 avg_loss_a: -65.15962789724539\n",
            "Número de pasos del episodeo 11978 son episode_steps:188\n",
            "Total Steps: 753076 Episode Num: 11978 Reward: 281.2427655055251 avg_loss_c: 4.424301695316396 avg_loss_a: -65.37614960366108\n",
            "Número de pasos del episodeo 11979 son episode_steps:92\n",
            "Total Steps: 753168 Episode Num: 11979 Reward: 110.18669114564707 avg_loss_c: 4.430780529975891 avg_loss_a: -64.94990663943084\n",
            "Número de pasos del episodeo 11980 son episode_steps:40\n",
            "Total Steps: 753208 Episode Num: 11980 Reward: 32.00052688669046 avg_loss_c: 4.491339266300201 avg_loss_a: -64.79310092926025\n",
            "Número de pasos del episodeo 11981 son episode_steps:100\n",
            "Total Steps: 753308 Episode Num: 11981 Reward: 82.4801231673853 avg_loss_c: 4.566767916679383 avg_loss_a: -64.63975875854493\n",
            "Número de pasos del episodeo 11982 son episode_steps:148\n",
            "Total Steps: 753456 Episode Num: 11982 Reward: 218.0670050265126 avg_loss_c: 4.476582826794805 avg_loss_a: -65.0277451180123\n",
            "Número de pasos del episodeo 11983 son episode_steps:185\n",
            "Total Steps: 753641 Episode Num: 11983 Reward: 234.30708365908785 avg_loss_c: 4.362700343776393 avg_loss_a: -65.23308765308278\n",
            "Número de pasos del episodeo 11984 son episode_steps:497\n",
            "Total Steps: 754138 Episode Num: 11984 Reward: 775.0692729260015 avg_loss_c: 4.092260990104445 avg_loss_a: -65.61348523268518\n",
            "Número de pasos del episodeo 11985 son episode_steps:99\n",
            "Total Steps: 754237 Episode Num: 11985 Reward: 43.783898560843795 avg_loss_c: 4.577132461046932 avg_loss_a: -64.93749314125138\n",
            "Número de pasos del episodeo 11986 son episode_steps:392\n",
            "Total Steps: 754629 Episode Num: 11986 Reward: 549.1170952592863 avg_loss_c: 4.234792137632565 avg_loss_a: -65.45673568881288\n",
            "Número de pasos del episodeo 11987 son episode_steps:123\n",
            "Total Steps: 754752 Episode Num: 11987 Reward: 121.62850884166359 avg_loss_c: 4.409315762481069 avg_loss_a: -66.07842205016594\n",
            "Número de pasos del episodeo 11988 son episode_steps:86\n",
            "Total Steps: 754838 Episode Num: 11988 Reward: 71.17235262371156 avg_loss_c: 4.461450665496116 avg_loss_a: -65.92410624304483\n",
            "Número de pasos del episodeo 11989 son episode_steps:92\n",
            "Total Steps: 754930 Episode Num: 11989 Reward: 23.55296875873762 avg_loss_c: 4.687941439773725 avg_loss_a: -66.1645044243854\n",
            "Número de pasos del episodeo 11990 son episode_steps:159\n",
            "Total Steps: 755089 Episode Num: 11990 Reward: 196.412034609934 avg_loss_c: 4.520060560238436 avg_loss_a: -65.53725687662761\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 212.663376\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 11991 son episode_steps:542\n",
            "Total Steps: 755631 Episode Num: 11991 Reward: 750.4871181078671 avg_loss_c: 4.248357503616502 avg_loss_a: -66.14243565802205\n",
            "Número de pasos del episodeo 11992 son episode_steps:49\n",
            "Total Steps: 755680 Episode Num: 11992 Reward: 13.319027183712082 avg_loss_c: 4.649568572336314 avg_loss_a: -66.92901206503109\n",
            "Número de pasos del episodeo 11993 son episode_steps:218\n",
            "Total Steps: 755898 Episode Num: 11993 Reward: 272.9073722691189 avg_loss_c: 4.307348370552063 avg_loss_a: -66.09880093915747\n",
            "Número de pasos del episodeo 11994 son episode_steps:66\n",
            "Total Steps: 755964 Episode Num: 11994 Reward: 78.62901171277613 avg_loss_c: 4.484717885653178 avg_loss_a: -66.38241542469372\n",
            "Número de pasos del episodeo 11995 son episode_steps:60\n",
            "Total Steps: 756024 Episode Num: 11995 Reward: 61.00690493166527 avg_loss_c: 4.327056586742401 avg_loss_a: -66.33860766092936\n",
            "Número de pasos del episodeo 11996 son episode_steps:129\n",
            "Total Steps: 756153 Episode Num: 11996 Reward: 98.59911558561348 avg_loss_c: 4.639585964439451 avg_loss_a: -66.21428730691126\n",
            "Número de pasos del episodeo 11997 son episode_steps:97\n",
            "Total Steps: 756250 Episode Num: 11997 Reward: 135.81476805184255 avg_loss_c: 4.146172988046076 avg_loss_a: -66.29866570541539\n",
            "Número de pasos del episodeo 11998 son episode_steps:112\n",
            "Total Steps: 756362 Episode Num: 11998 Reward: 87.77567692540646 avg_loss_c: 4.446111300161907 avg_loss_a: -65.61302246366229\n",
            "Número de pasos del episodeo 11999 son episode_steps:171\n",
            "Total Steps: 756533 Episode Num: 11999 Reward: 254.32873862534802 avg_loss_c: 4.467116838310197 avg_loss_a: -65.57254920647158\n",
            "Número de pasos del episodeo 12000 son episode_steps:84\n",
            "Total Steps: 756617 Episode Num: 12000 Reward: 39.47653527247217 avg_loss_c: 4.801271810418084 avg_loss_a: -65.88473574320476\n",
            "Número de pasos del episodeo 12001 son episode_steps:146\n",
            "Total Steps: 756763 Episode Num: 12001 Reward: 217.85968687887558 avg_loss_c: 4.374335418008778 avg_loss_a: -66.05501640006287\n",
            "Número de pasos del episodeo 12002 son episode_steps:220\n",
            "Total Steps: 756983 Episode Num: 12002 Reward: 278.2622293933372 avg_loss_c: 4.568421290137551 avg_loss_a: -66.2476649197665\n",
            "Número de pasos del episodeo 12003 son episode_steps:83\n",
            "Total Steps: 757066 Episode Num: 12003 Reward: 130.63871420603968 avg_loss_c: 4.339782298329365 avg_loss_a: -65.53119015980916\n",
            "Número de pasos del episodeo 12004 son episode_steps:274\n",
            "Total Steps: 757340 Episode Num: 12004 Reward: 416.8919802124067 avg_loss_c: 4.2845013324361645 avg_loss_a: -66.08915980540922\n",
            "Número de pasos del episodeo 12005 son episode_steps:98\n",
            "Total Steps: 757438 Episode Num: 12005 Reward: 77.7742692701515 avg_loss_c: 4.199917435646057 avg_loss_a: -65.65194725503727\n",
            "Número de pasos del episodeo 12006 son episode_steps:112\n",
            "Total Steps: 757550 Episode Num: 12006 Reward: 180.00461615373837 avg_loss_c: 4.326944710952895 avg_loss_a: -66.16861384255546\n",
            "Número de pasos del episodeo 12007 son episode_steps:241\n",
            "Total Steps: 757791 Episode Num: 12007 Reward: 321.8113524276574 avg_loss_c: 4.494943610860104 avg_loss_a: -66.10393726776249\n",
            "Número de pasos del episodeo 12008 son episode_steps:81\n",
            "Total Steps: 757872 Episode Num: 12008 Reward: 24.304725975760824 avg_loss_c: 4.696195620077628 avg_loss_a: -65.69858814757548\n",
            "Número de pasos del episodeo 12009 son episode_steps:82\n",
            "Total Steps: 757954 Episode Num: 12009 Reward: 112.78583145418432 avg_loss_c: 4.167645082241151 avg_loss_a: -64.61887341010862\n",
            "Número de pasos del episodeo 12010 son episode_steps:180\n",
            "Total Steps: 758134 Episode Num: 12010 Reward: 266.37549007290653 avg_loss_c: 4.453807384437985 avg_loss_a: -65.58313810560438\n",
            "Número de pasos del episodeo 12011 son episode_steps:233\n",
            "Total Steps: 758367 Episode Num: 12011 Reward: 364.5631522712316 avg_loss_c: 4.176205452931286 avg_loss_a: -66.61505300497292\n",
            "Número de pasos del episodeo 12012 son episode_steps:176\n",
            "Total Steps: 758543 Episode Num: 12012 Reward: 262.9333794592913 avg_loss_c: 4.2102055292237885 avg_loss_a: -66.90180214968595\n",
            "Número de pasos del episodeo 12013 son episode_steps:143\n",
            "Total Steps: 758686 Episode Num: 12013 Reward: 202.53305026749527 avg_loss_c: 4.333051238026652 avg_loss_a: -66.19634022746052\n",
            "Número de pasos del episodeo 12014 son episode_steps:42\n",
            "Total Steps: 758728 Episode Num: 12014 Reward: 19.35156806936872 avg_loss_c: 4.6279853241784235 avg_loss_a: -65.72481173560733\n",
            "Número de pasos del episodeo 12015 son episode_steps:40\n",
            "Total Steps: 758768 Episode Num: 12015 Reward: 23.796368671335873 avg_loss_c: 4.197694045305252 avg_loss_a: -66.37110595703125\n",
            "Número de pasos del episodeo 12016 son episode_steps:167\n",
            "Total Steps: 758935 Episode Num: 12016 Reward: 84.50792427708731 avg_loss_c: 5.2874869443699275 avg_loss_a: -66.34622174108813\n",
            "Número de pasos del episodeo 12017 son episode_steps:48\n",
            "Total Steps: 758983 Episode Num: 12017 Reward: 15.082440359800943 avg_loss_c: 4.92922680079937 avg_loss_a: -67.10648250579834\n",
            "Número de pasos del episodeo 12018 son episode_steps:187\n",
            "Total Steps: 759170 Episode Num: 12018 Reward: 292.3251226478408 avg_loss_c: 4.400617231022228 avg_loss_a: -66.60359595803654\n",
            "Número de pasos del episodeo 12019 son episode_steps:188\n",
            "Total Steps: 759358 Episode Num: 12019 Reward: 315.00776551123147 avg_loss_c: 4.392865680633707 avg_loss_a: -66.04967368917262\n",
            "Número de pasos del episodeo 12020 son episode_steps:229\n",
            "Total Steps: 759587 Episode Num: 12020 Reward: 353.2385243764067 avg_loss_c: 4.372835317553391 avg_loss_a: -66.51669108295025\n",
            "Número de pasos del episodeo 12021 son episode_steps:233\n",
            "Total Steps: 759820 Episode Num: 12021 Reward: 378.9634139341794 avg_loss_c: 4.366679530286993 avg_loss_a: -66.99012589352326\n",
            "Número de pasos del episodeo 12022 son episode_steps:170\n",
            "Total Steps: 759990 Episode Num: 12022 Reward: 245.6845390196104 avg_loss_c: 4.23211489424986 avg_loss_a: -66.85142781874713\n",
            "Número de pasos del episodeo 12023 son episode_steps:149\n",
            "Total Steps: 760139 Episode Num: 12023 Reward: 239.0064185629765 avg_loss_c: 4.174521231811319 avg_loss_a: -67.2848305926227\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 240.315698\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12024 son episode_steps:163\n",
            "Total Steps: 760302 Episode Num: 12024 Reward: 234.85129914274702 avg_loss_c: 4.064348557244049 avg_loss_a: -67.25393503575238\n",
            "Número de pasos del episodeo 12025 son episode_steps:305\n",
            "Total Steps: 760607 Episode Num: 12025 Reward: 472.78625336929497 avg_loss_c: 3.9944694057839816 avg_loss_a: -67.26443226298348\n",
            "Número de pasos del episodeo 12026 son episode_steps:110\n",
            "Total Steps: 760717 Episode Num: 12026 Reward: 175.42100953063138 avg_loss_c: 4.021505334160545 avg_loss_a: -68.14547701748934\n",
            "Número de pasos del episodeo 12027 son episode_steps:34\n",
            "Total Steps: 760751 Episode Num: 12027 Reward: 2.0373477645941174 avg_loss_c: 4.023054796106675 avg_loss_a: -67.56394352632411\n",
            "Número de pasos del episodeo 12028 son episode_steps:87\n",
            "Total Steps: 760838 Episode Num: 12028 Reward: 145.29502901920065 avg_loss_c: 4.141613551940041 avg_loss_a: -67.46674487234532\n",
            "Número de pasos del episodeo 12029 son episode_steps:23\n",
            "Total Steps: 760861 Episode Num: 12029 Reward: -19.63440456390827 avg_loss_c: 3.7549246497776196 avg_loss_a: -68.48466425356658\n",
            "Número de pasos del episodeo 12030 son episode_steps:95\n",
            "Total Steps: 760956 Episode Num: 12030 Reward: 16.335744808602033 avg_loss_c: 4.133706213298597 avg_loss_a: -67.6357854742753\n",
            "Número de pasos del episodeo 12031 son episode_steps:91\n",
            "Total Steps: 761047 Episode Num: 12031 Reward: 46.819788943062555 avg_loss_c: 4.426158616831015 avg_loss_a: -67.24425372448596\n",
            "Número de pasos del episodeo 12032 son episode_steps:217\n",
            "Total Steps: 761264 Episode Num: 12032 Reward: 313.0940294055245 avg_loss_c: 4.463581907035019 avg_loss_a: -67.44958907448202\n",
            "Número de pasos del episodeo 12033 son episode_steps:253\n",
            "Total Steps: 761517 Episode Num: 12033 Reward: 403.3559310350495 avg_loss_c: 4.005943043901044 avg_loss_a: -67.2776876758681\n",
            "Número de pasos del episodeo 12034 son episode_steps:184\n",
            "Total Steps: 761701 Episode Num: 12034 Reward: 265.5867055564242 avg_loss_c: 4.677697847718778 avg_loss_a: -67.12776557258938\n",
            "Número de pasos del episodeo 12035 son episode_steps:55\n",
            "Total Steps: 761756 Episode Num: 12035 Reward: 50.79027801550533 avg_loss_c: 4.158840985731645 avg_loss_a: -66.4776142467152\n",
            "Número de pasos del episodeo 12036 son episode_steps:36\n",
            "Total Steps: 761792 Episode Num: 12036 Reward: 16.975858611131716 avg_loss_c: 4.379407564798991 avg_loss_a: -67.21091249254015\n",
            "Número de pasos del episodeo 12037 son episode_steps:143\n",
            "Total Steps: 761935 Episode Num: 12037 Reward: 81.16642474827248 avg_loss_c: 4.664427607209532 avg_loss_a: -67.17145965149352\n",
            "Número de pasos del episodeo 12038 son episode_steps:706\n",
            "Total Steps: 762641 Episode Num: 12038 Reward: 1126.6806492823853 avg_loss_c: 4.174336200395319 avg_loss_a: -67.93794334779042\n",
            "Número de pasos del episodeo 12039 son episode_steps:323\n",
            "Total Steps: 762964 Episode Num: 12039 Reward: 483.3162701526416 avg_loss_c: 4.26471237427679 avg_loss_a: -68.27370183608112\n",
            "Número de pasos del episodeo 12040 son episode_steps:93\n",
            "Total Steps: 763057 Episode Num: 12040 Reward: 127.14444064904696 avg_loss_c: 4.3048796064110215 avg_loss_a: -67.06644275624265\n",
            "Número de pasos del episodeo 12041 son episode_steps:20\n",
            "Total Steps: 763077 Episode Num: 12041 Reward: -14.927965428964335 avg_loss_c: 3.5572420716285706 avg_loss_a: -66.92748565673828\n",
            "Número de pasos del episodeo 12042 son episode_steps:179\n",
            "Total Steps: 763256 Episode Num: 12042 Reward: 253.11933817299598 avg_loss_c: 4.376165405998017 avg_loss_a: -67.93090568840837\n",
            "Número de pasos del episodeo 12043 son episode_steps:251\n",
            "Total Steps: 763507 Episode Num: 12043 Reward: 394.2406551661175 avg_loss_c: 4.242354885040526 avg_loss_a: -68.0172103030748\n",
            "Número de pasos del episodeo 12044 son episode_steps:155\n",
            "Total Steps: 763662 Episode Num: 12044 Reward: 227.6639346013564 avg_loss_c: 4.307336422704881 avg_loss_a: -67.99412876252205\n",
            "Número de pasos del episodeo 12045 son episode_steps:552\n",
            "Total Steps: 764214 Episode Num: 12045 Reward: 823.175591722567 avg_loss_c: 4.319359522366869 avg_loss_a: -67.94915960837102\n",
            "Número de pasos del episodeo 12046 son episode_steps:520\n",
            "Total Steps: 764734 Episode Num: 12046 Reward: 820.7829997993541 avg_loss_c: 3.9976328157461607 avg_loss_a: -68.38595561981201\n",
            "Número de pasos del episodeo 12047 son episode_steps:175\n",
            "Total Steps: 764909 Episode Num: 12047 Reward: 215.36560606069227 avg_loss_c: 3.9772338104248046 avg_loss_a: -68.60180193219865\n",
            "Número de pasos del episodeo 12048 son episode_steps:185\n",
            "Total Steps: 765094 Episode Num: 12048 Reward: 283.31872341579344 avg_loss_c: 4.16047370240495 avg_loss_a: -68.84953485437342\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 336.763012\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12049 son episode_steps:68\n",
            "Total Steps: 765162 Episode Num: 12049 Reward: 87.68498656271335 avg_loss_c: 4.037546785438762 avg_loss_a: -68.12760689679314\n",
            "Número de pasos del episodeo 12050 son episode_steps:43\n",
            "Total Steps: 765205 Episode Num: 12050 Reward: 9.410471471169075 avg_loss_c: 5.0655189447624736 avg_loss_a: -68.07753239121548\n",
            "Número de pasos del episodeo 12051 son episode_steps:156\n",
            "Total Steps: 765361 Episode Num: 12051 Reward: 246.2364131016462 avg_loss_c: 4.249545785096975 avg_loss_a: -68.35190450228177\n",
            "Número de pasos del episodeo 12052 son episode_steps:84\n",
            "Total Steps: 765445 Episode Num: 12052 Reward: 122.5484823689111 avg_loss_c: 5.680003194581895 avg_loss_a: -69.15798659551712\n",
            "Número de pasos del episodeo 12053 son episode_steps:41\n",
            "Total Steps: 765486 Episode Num: 12053 Reward: 3.6165584261009975 avg_loss_c: 4.290440786175612 avg_loss_a: -68.89511071181879\n",
            "Número de pasos del episodeo 12054 son episode_steps:85\n",
            "Total Steps: 765571 Episode Num: 12054 Reward: 2.4432505527332804 avg_loss_c: 4.407808149562163 avg_loss_a: -68.06052331363453\n",
            "Número de pasos del episodeo 12055 son episode_steps:65\n",
            "Total Steps: 765636 Episode Num: 12055 Reward: 85.3129574690605 avg_loss_c: 4.330825992730948 avg_loss_a: -68.31208695631761\n",
            "Número de pasos del episodeo 12056 son episode_steps:512\n",
            "Total Steps: 766148 Episode Num: 12056 Reward: 683.6518375336751 avg_loss_c: 4.367447792552412 avg_loss_a: -68.35767705738544\n",
            "Número de pasos del episodeo 12057 son episode_steps:162\n",
            "Total Steps: 766310 Episode Num: 12057 Reward: 241.7106663233811 avg_loss_c: 4.605293956803687 avg_loss_a: -68.16038984133874\n",
            "Número de pasos del episodeo 12058 son episode_steps:192\n",
            "Total Steps: 766502 Episode Num: 12058 Reward: 270.17381060584114 avg_loss_c: 4.708065199355285 avg_loss_a: -68.80333689848582\n",
            "Número de pasos del episodeo 12059 son episode_steps:881\n",
            "Total Steps: 767383 Episode Num: 12059 Reward: 1339.6211873841387 avg_loss_c: 4.5482431868013 avg_loss_a: -69.23226192617254\n",
            "Número de pasos del episodeo 12060 son episode_steps:413\n",
            "Total Steps: 767796 Episode Num: 12060 Reward: 667.4736984601328 avg_loss_c: 4.2410841859859065 avg_loss_a: -69.46797656782026\n",
            "Número de pasos del episodeo 12061 son episode_steps:130\n",
            "Total Steps: 767926 Episode Num: 12061 Reward: 204.30040590399858 avg_loss_c: 4.365106866909907 avg_loss_a: -68.86419830322265\n",
            "Número de pasos del episodeo 12062 son episode_steps:97\n",
            "Total Steps: 768023 Episode Num: 12062 Reward: 124.99969546790128 avg_loss_c: 3.951400555286211 avg_loss_a: -69.4463882446289\n",
            "Número de pasos del episodeo 12063 son episode_steps:115\n",
            "Total Steps: 768138 Episode Num: 12063 Reward: 150.44973229257053 avg_loss_c: 4.459703710804815 avg_loss_a: -69.4551313980766\n",
            "Número de pasos del episodeo 12064 son episode_steps:54\n",
            "Total Steps: 768192 Episode Num: 12064 Reward: 49.74918256227298 avg_loss_c: 3.8583872009206703 avg_loss_a: -69.7628594857675\n",
            "Número de pasos del episodeo 12065 son episode_steps:477\n",
            "Total Steps: 768669 Episode Num: 12065 Reward: 762.8535583109584 avg_loss_c: 4.753768280117267 avg_loss_a: -69.05812411838107\n",
            "Número de pasos del episodeo 12066 son episode_steps:135\n",
            "Total Steps: 768804 Episode Num: 12066 Reward: 189.94324420304693 avg_loss_c: 4.2632601720315435 avg_loss_a: -69.2924831814236\n",
            "Número de pasos del episodeo 12067 son episode_steps:108\n",
            "Total Steps: 768912 Episode Num: 12067 Reward: 136.52886544781123 avg_loss_c: 4.157146261798011 avg_loss_a: -68.9519069812916\n",
            "Número de pasos del episodeo 12068 son episode_steps:104\n",
            "Total Steps: 769016 Episode Num: 12068 Reward: 68.78043357665962 avg_loss_c: 5.057184320229751 avg_loss_a: -68.58049774169922\n",
            "Número de pasos del episodeo 12069 son episode_steps:108\n",
            "Total Steps: 769124 Episode Num: 12069 Reward: 168.15875169434963 avg_loss_c: 4.348142740903078 avg_loss_a: -68.74572506657353\n",
            "Número de pasos del episodeo 12070 son episode_steps:66\n",
            "Total Steps: 769190 Episode Num: 12070 Reward: 82.89761640292416 avg_loss_c: 3.897648330890771 avg_loss_a: -68.52270276618727\n",
            "Número de pasos del episodeo 12071 son episode_steps:394\n",
            "Total Steps: 769584 Episode Num: 12071 Reward: 575.8872638134283 avg_loss_c: 4.466771160285485 avg_loss_a: -68.47155362821472\n",
            "Número de pasos del episodeo 12072 son episode_steps:89\n",
            "Total Steps: 769673 Episode Num: 12072 Reward: 26.693011919429832 avg_loss_c: 4.337401641888565 avg_loss_a: -68.32684737644838\n",
            "Número de pasos del episodeo 12073 son episode_steps:290\n",
            "Total Steps: 769963 Episode Num: 12073 Reward: 432.9422236671969 avg_loss_c: 4.486658116866803 avg_loss_a: -68.13575928786705\n",
            "Número de pasos del episodeo 12074 son episode_steps:1000\n",
            "Total Steps: 770963 Episode Num: 12074 Reward: 1543.2063134747962 avg_loss_c: 4.237518923759461 avg_loss_a: -69.15203003692626\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 248.810170\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12075 son episode_steps:107\n",
            "Total Steps: 771070 Episode Num: 12075 Reward: 128.71591274829328 avg_loss_c: 4.082363830548581 avg_loss_a: -69.35492848904333\n",
            "Número de pasos del episodeo 12076 son episode_steps:282\n",
            "Total Steps: 771352 Episode Num: 12076 Reward: 416.8427220795078 avg_loss_c: 4.284755071849688 avg_loss_a: -69.77956880068947\n",
            "Número de pasos del episodeo 12077 son episode_steps:93\n",
            "Total Steps: 771445 Episode Num: 12077 Reward: 126.87158033058328 avg_loss_c: 3.905690934068413 avg_loss_a: -69.71606486330751\n",
            "Número de pasos del episodeo 12078 son episode_steps:80\n",
            "Total Steps: 771525 Episode Num: 12078 Reward: 4.202666591722778 avg_loss_c: 4.157409656047821 avg_loss_a: -69.23269681930542\n",
            "Número de pasos del episodeo 12079 son episode_steps:113\n",
            "Total Steps: 771638 Episode Num: 12079 Reward: 98.63310502044568 avg_loss_c: 4.629156334210286 avg_loss_a: -69.30505458865545\n",
            "Número de pasos del episodeo 12080 son episode_steps:117\n",
            "Total Steps: 771755 Episode Num: 12080 Reward: 86.19892412586991 avg_loss_c: 4.500724672252296 avg_loss_a: -69.29496413010817\n",
            "Número de pasos del episodeo 12081 son episode_steps:520\n",
            "Total Steps: 772275 Episode Num: 12081 Reward: 800.0395479067109 avg_loss_c: 4.466150406232247 avg_loss_a: -69.23427878159742\n",
            "Número de pasos del episodeo 12082 son episode_steps:282\n",
            "Total Steps: 772557 Episode Num: 12082 Reward: 372.8320140604354 avg_loss_c: 4.255998966541696 avg_loss_a: -69.63358531437868\n",
            "Número de pasos del episodeo 12083 son episode_steps:135\n",
            "Total Steps: 772692 Episode Num: 12083 Reward: 146.3797574061161 avg_loss_c: 4.172509694982458 avg_loss_a: -69.42353956434462\n",
            "Número de pasos del episodeo 12084 son episode_steps:393\n",
            "Total Steps: 773085 Episode Num: 12084 Reward: 595.0756588183308 avg_loss_c: 4.363797031892772 avg_loss_a: -69.65453490046144\n",
            "Número de pasos del episodeo 12085 son episode_steps:267\n",
            "Total Steps: 773352 Episode Num: 12085 Reward: 409.8387703201462 avg_loss_c: 4.080473232805059 avg_loss_a: -69.78719272684961\n",
            "Número de pasos del episodeo 12086 son episode_steps:213\n",
            "Total Steps: 773565 Episode Num: 12086 Reward: 288.77291316235886 avg_loss_c: 4.40818307097529 avg_loss_a: -69.82323907126843\n",
            "Número de pasos del episodeo 12087 son episode_steps:78\n",
            "Total Steps: 773643 Episode Num: 12087 Reward: 102.86564906939448 avg_loss_c: 4.262762622955518 avg_loss_a: -70.3116697653746\n",
            "Número de pasos del episodeo 12088 son episode_steps:64\n",
            "Total Steps: 773707 Episode Num: 12088 Reward: 95.55039699882518 avg_loss_c: 4.330284871160984 avg_loss_a: -70.23373174667358\n",
            "Número de pasos del episodeo 12089 son episode_steps:140\n",
            "Total Steps: 773847 Episode Num: 12089 Reward: 208.08350239939284 avg_loss_c: 4.430606986795153 avg_loss_a: -69.75127830505372\n",
            "Número de pasos del episodeo 12090 son episode_steps:191\n",
            "Total Steps: 774038 Episode Num: 12090 Reward: 279.13360648321935 avg_loss_c: 4.433255039584575 avg_loss_a: -69.53580335047857\n",
            "Número de pasos del episodeo 12091 son episode_steps:139\n",
            "Total Steps: 774177 Episode Num: 12091 Reward: 198.67900724804838 avg_loss_c: 4.288069500339975 avg_loss_a: -68.69222188167434\n",
            "Número de pasos del episodeo 12092 son episode_steps:181\n",
            "Total Steps: 774358 Episode Num: 12092 Reward: 228.16831128163923 avg_loss_c: 4.487306133818231 avg_loss_a: -69.57149530906045\n",
            "Número de pasos del episodeo 12093 son episode_steps:123\n",
            "Total Steps: 774481 Episode Num: 12093 Reward: 188.21235760309858 avg_loss_c: 4.36228304568345 avg_loss_a: -69.03122661559563\n",
            "Número de pasos del episodeo 12094 son episode_steps:392\n",
            "Total Steps: 774873 Episode Num: 12094 Reward: 559.0860691959474 avg_loss_c: 4.469234262802163 avg_loss_a: -69.97985458374023\n",
            "Número de pasos del episodeo 12095 son episode_steps:184\n",
            "Total Steps: 775057 Episode Num: 12095 Reward: 248.91327881681326 avg_loss_c: 4.373300608085549 avg_loss_a: -69.84326457977295\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 282.706244\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12096 son episode_steps:394\n",
            "Total Steps: 775451 Episode Num: 12096 Reward: 563.1015051157971 avg_loss_c: 4.2679270294112 avg_loss_a: -69.76828188823565\n",
            "Número de pasos del episodeo 12097 son episode_steps:893\n",
            "Total Steps: 776344 Episode Num: 12097 Reward: 1421.6364012235083 avg_loss_c: 4.161918561909794 avg_loss_a: -71.34529160759084\n",
            "Número de pasos del episodeo 12098 son episode_steps:319\n",
            "Total Steps: 776663 Episode Num: 12098 Reward: 494.7503590277288 avg_loss_c: 4.0156050670109575 avg_loss_a: -71.72653212592145\n",
            "Número de pasos del episodeo 12099 son episode_steps:91\n",
            "Total Steps: 776754 Episode Num: 12099 Reward: 83.02056347181382 avg_loss_c: 3.856591263970176 avg_loss_a: -71.17323839795459\n",
            "Número de pasos del episodeo 12100 son episode_steps:418\n",
            "Total Steps: 777172 Episode Num: 12100 Reward: 626.9721978035082 avg_loss_c: 3.963855370380091 avg_loss_a: -71.50985626512737\n",
            "Número de pasos del episodeo 12101 son episode_steps:49\n",
            "Total Steps: 777221 Episode Num: 12101 Reward: 33.31557850627718 avg_loss_c: 4.037250854531113 avg_loss_a: -71.92029649384168\n",
            "Número de pasos del episodeo 12102 son episode_steps:526\n",
            "Total Steps: 777747 Episode Num: 12102 Reward: 805.4552163335073 avg_loss_c: 3.9526219041628528 avg_loss_a: -71.96530644521967\n",
            "Número de pasos del episodeo 12103 son episode_steps:74\n",
            "Total Steps: 777821 Episode Num: 12103 Reward: -14.037940919013325 avg_loss_c: 5.816157943493611 avg_loss_a: -72.90316813700908\n",
            "Número de pasos del episodeo 12104 son episode_steps:117\n",
            "Total Steps: 777938 Episode Num: 12104 Reward: 149.6446874234165 avg_loss_c: 5.077355486714942 avg_loss_a: -72.43798306456998\n",
            "Número de pasos del episodeo 12105 son episode_steps:338\n",
            "Total Steps: 778276 Episode Num: 12105 Reward: 479.11738734088027 avg_loss_c: 4.6306337223955865 avg_loss_a: -72.22770943726309\n",
            "Número de pasos del episodeo 12106 son episode_steps:433\n",
            "Total Steps: 778709 Episode Num: 12106 Reward: 673.3267558175891 avg_loss_c: 4.341455410038902 avg_loss_a: -72.48533288546027\n",
            "Número de pasos del episodeo 12107 son episode_steps:35\n",
            "Total Steps: 778744 Episode Num: 12107 Reward: 20.865614504586873 avg_loss_c: 4.0805824279785154 avg_loss_a: -72.45388466971261\n",
            "Número de pasos del episodeo 12108 son episode_steps:105\n",
            "Total Steps: 778849 Episode Num: 12108 Reward: 114.7136887435198 avg_loss_c: 4.4343710740407305 avg_loss_a: -73.12783675420852\n",
            "Número de pasos del episodeo 12109 son episode_steps:487\n",
            "Total Steps: 779336 Episode Num: 12109 Reward: 743.4078077911798 avg_loss_c: 4.275014832768842 avg_loss_a: -73.18597358844609\n",
            "Número de pasos del episodeo 12110 son episode_steps:94\n",
            "Total Steps: 779430 Episode Num: 12110 Reward: 127.73057342652199 avg_loss_c: 3.8851313413457667 avg_loss_a: -73.4952595487554\n",
            "Número de pasos del episodeo 12111 son episode_steps:219\n",
            "Total Steps: 779649 Episode Num: 12111 Reward: 344.63417785856836 avg_loss_c: 4.021701571059554 avg_loss_a: -73.48696150409576\n",
            "Número de pasos del episodeo 12112 son episode_steps:226\n",
            "Total Steps: 779875 Episode Num: 12112 Reward: 313.0688383570084 avg_loss_c: 4.148080671783042 avg_loss_a: -73.35844914259108\n",
            "Número de pasos del episodeo 12113 son episode_steps:55\n",
            "Total Steps: 779930 Episode Num: 12113 Reward: 78.67262461483313 avg_loss_c: 4.854543226415461 avg_loss_a: -73.76882476806641\n",
            "Número de pasos del episodeo 12114 son episode_steps:122\n",
            "Total Steps: 780052 Episode Num: 12114 Reward: 187.53989462550203 avg_loss_c: 4.198645474480801 avg_loss_a: -72.96643153956678\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 378.796353\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12115 son episode_steps:422\n",
            "Total Steps: 780474 Episode Num: 12115 Reward: 652.0115404645886 avg_loss_c: 4.166820587705097 avg_loss_a: -73.50627237473618\n",
            "Número de pasos del episodeo 12116 son episode_steps:589\n",
            "Total Steps: 781063 Episode Num: 12116 Reward: 932.9219558308099 avg_loss_c: 3.833878553581562 avg_loss_a: -74.63725594227505\n",
            "Número de pasos del episodeo 12117 son episode_steps:41\n",
            "Total Steps: 781104 Episode Num: 12117 Reward: 50.29454707585216 avg_loss_c: 3.7764923630691154 avg_loss_a: -74.92470029505287\n",
            "Número de pasos del episodeo 12118 son episode_steps:51\n",
            "Total Steps: 781155 Episode Num: 12118 Reward: 63.20609243380595 avg_loss_c: 3.865877291735481 avg_loss_a: -74.61950070250268\n",
            "Número de pasos del episodeo 12119 son episode_steps:76\n",
            "Total Steps: 781231 Episode Num: 12119 Reward: 101.45422480992812 avg_loss_c: 3.9491833103330514 avg_loss_a: -74.21186346756785\n",
            "Número de pasos del episodeo 12120 son episode_steps:147\n",
            "Total Steps: 781378 Episode Num: 12120 Reward: 197.23440937953484 avg_loss_c: 3.860984267020712 avg_loss_a: -74.634434239394\n",
            "Número de pasos del episodeo 12121 son episode_steps:180\n",
            "Total Steps: 781558 Episode Num: 12121 Reward: 294.7460687966691 avg_loss_c: 3.8581157035297817 avg_loss_a: -74.46880001491971\n",
            "Número de pasos del episodeo 12122 son episode_steps:222\n",
            "Total Steps: 781780 Episode Num: 12122 Reward: 350.32905001467964 avg_loss_c: 3.8940676364812763 avg_loss_a: -74.53258858070717\n",
            "Número de pasos del episodeo 12123 son episode_steps:495\n",
            "Total Steps: 782275 Episode Num: 12123 Reward: 775.9941086719273 avg_loss_c: 3.877608740450156 avg_loss_a: -75.14100525210603\n",
            "Número de pasos del episodeo 12124 son episode_steps:139\n",
            "Total Steps: 782414 Episode Num: 12124 Reward: 141.2505921864836 avg_loss_c: 4.040214919357848 avg_loss_a: -74.96119503323122\n",
            "Número de pasos del episodeo 12125 son episode_steps:44\n",
            "Total Steps: 782458 Episode Num: 12125 Reward: 38.56339256097329 avg_loss_c: 4.091342232444069 avg_loss_a: -74.26175308227539\n",
            "Número de pasos del episodeo 12126 son episode_steps:529\n",
            "Total Steps: 782987 Episode Num: 12126 Reward: 829.8328870504353 avg_loss_c: 3.965610392828294 avg_loss_a: -75.0296331740958\n",
            "Número de pasos del episodeo 12127 son episode_steps:602\n",
            "Total Steps: 783589 Episode Num: 12127 Reward: 963.5257047398707 avg_loss_c: 3.8419729938538763 avg_loss_a: -75.60142714795084\n",
            "Número de pasos del episodeo 12128 son episode_steps:45\n",
            "Total Steps: 783634 Episode Num: 12128 Reward: 33.39151549144036 avg_loss_c: 3.6696206198798285 avg_loss_a: -75.44390021430121\n",
            "Número de pasos del episodeo 12129 son episode_steps:121\n",
            "Total Steps: 783755 Episode Num: 12129 Reward: 179.52824570201878 avg_loss_c: 3.8976145697034097 avg_loss_a: -75.79189741907041\n",
            "Número de pasos del episodeo 12130 son episode_steps:60\n",
            "Total Steps: 783815 Episode Num: 12130 Reward: 54.13340769955837 avg_loss_c: 3.7829777002334595 avg_loss_a: -75.07393976847331\n",
            "Número de pasos del episodeo 12131 son episode_steps:169\n",
            "Total Steps: 783984 Episode Num: 12131 Reward: 244.77126862789194 avg_loss_c: 4.4380924744013495 avg_loss_a: -75.44870622623601\n",
            "Número de pasos del episodeo 12132 son episode_steps:95\n",
            "Total Steps: 784079 Episode Num: 12132 Reward: 104.89003799510621 avg_loss_c: 3.9563288161629124 avg_loss_a: -75.95375518798828\n",
            "Número de pasos del episodeo 12133 son episode_steps:300\n",
            "Total Steps: 784379 Episode Num: 12133 Reward: 471.0560093954559 avg_loss_c: 3.8196778512001037 avg_loss_a: -75.2602614847819\n",
            "Número de pasos del episodeo 12134 son episode_steps:490\n",
            "Total Steps: 784869 Episode Num: 12134 Reward: 793.12441467598 avg_loss_c: 4.047785177522776 avg_loss_a: -75.56934048399633\n",
            "Número de pasos del episodeo 12135 son episode_steps:55\n",
            "Total Steps: 784924 Episode Num: 12135 Reward: 33.888319784389374 avg_loss_c: 4.481639567288485 avg_loss_a: -75.64090534556996\n",
            "Número de pasos del episodeo 12136 son episode_steps:198\n",
            "Total Steps: 785122 Episode Num: 12136 Reward: 249.2373147948376 avg_loss_c: 4.159230786140519 avg_loss_a: -75.13517506917317\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 530.299303\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12137 son episode_steps:38\n",
            "Total Steps: 785160 Episode Num: 12137 Reward: 13.850706797867582 avg_loss_c: 4.526332629354377 avg_loss_a: -75.50732060482628\n",
            "Número de pasos del episodeo 12138 son episode_steps:562\n",
            "Total Steps: 785722 Episode Num: 12138 Reward: 857.9180537110105 avg_loss_c: 4.284406122787991 avg_loss_a: -76.13200736809456\n",
            "Número de pasos del episodeo 12139 son episode_steps:254\n",
            "Total Steps: 785976 Episode Num: 12139 Reward: 392.123353159585 avg_loss_c: 4.152337834591002 avg_loss_a: -76.34239455095427\n",
            "Número de pasos del episodeo 12140 son episode_steps:110\n",
            "Total Steps: 786086 Episode Num: 12140 Reward: 102.12797111858896 avg_loss_c: 3.9516875288703224 avg_loss_a: -75.86433549360795\n",
            "Número de pasos del episodeo 12141 son episode_steps:354\n",
            "Total Steps: 786440 Episode Num: 12141 Reward: 535.5087250016313 avg_loss_c: 4.104846173087083 avg_loss_a: -76.0233221107957\n",
            "Número de pasos del episodeo 12142 son episode_steps:51\n",
            "Total Steps: 786491 Episode Num: 12142 Reward: 40.41354308479822 avg_loss_c: 4.0195606409334665 avg_loss_a: -75.92395976945465\n",
            "Número de pasos del episodeo 12143 son episode_steps:94\n",
            "Total Steps: 786585 Episode Num: 12143 Reward: 110.32407242303489 avg_loss_c: 4.12982864836429 avg_loss_a: -76.28455320317694\n",
            "Número de pasos del episodeo 12144 son episode_steps:126\n",
            "Total Steps: 786711 Episode Num: 12144 Reward: 105.00722984171311 avg_loss_c: 4.201674635448153 avg_loss_a: -75.94127776130797\n",
            "Número de pasos del episodeo 12145 son episode_steps:80\n",
            "Total Steps: 786791 Episode Num: 12145 Reward: 73.38215846771293 avg_loss_c: 4.1908076912164685 avg_loss_a: -75.60660953521729\n",
            "Número de pasos del episodeo 12146 son episode_steps:340\n",
            "Total Steps: 787131 Episode Num: 12146 Reward: 530.7277417134455 avg_loss_c: 4.181797287744634 avg_loss_a: -75.5224889867446\n",
            "Número de pasos del episodeo 12147 son episode_steps:143\n",
            "Total Steps: 787274 Episode Num: 12147 Reward: 135.01388935054592 avg_loss_c: 4.337093600026377 avg_loss_a: -75.54881051870493\n",
            "Número de pasos del episodeo 12148 son episode_steps:73\n",
            "Total Steps: 787347 Episode Num: 12148 Reward: 63.35727648301678 avg_loss_c: 4.718515618206704 avg_loss_a: -75.08671099519077\n",
            "Número de pasos del episodeo 12149 son episode_steps:786\n",
            "Total Steps: 788133 Episode Num: 12149 Reward: 1169.0589987807264 avg_loss_c: 4.424782470285741 avg_loss_a: -76.21526886063981\n",
            "Número de pasos del episodeo 12150 son episode_steps:278\n",
            "Total Steps: 788411 Episode Num: 12150 Reward: 416.5293043658905 avg_loss_c: 4.209939460960223 avg_loss_a: -76.05235575943541\n",
            "Número de pasos del episodeo 12151 son episode_steps:286\n",
            "Total Steps: 788697 Episode Num: 12151 Reward: 415.98189893221655 avg_loss_c: 4.30009166093973 avg_loss_a: -76.09934480040224\n",
            "Número de pasos del episodeo 12152 son episode_steps:43\n",
            "Total Steps: 788740 Episode Num: 12152 Reward: 19.03911930965714 avg_loss_c: 3.8554904516353163 avg_loss_a: -75.99739944103152\n",
            "Número de pasos del episodeo 12153 son episode_steps:100\n",
            "Total Steps: 788840 Episode Num: 12153 Reward: 124.34840236029277 avg_loss_c: 4.101936233043671 avg_loss_a: -75.8094953918457\n",
            "Número de pasos del episodeo 12154 son episode_steps:150\n",
            "Total Steps: 788990 Episode Num: 12154 Reward: 75.78725393657068 avg_loss_c: 5.0153912194569905 avg_loss_a: -75.56927368164062\n",
            "Número de pasos del episodeo 12155 son episode_steps:65\n",
            "Total Steps: 789055 Episode Num: 12155 Reward: -42.240759314363 avg_loss_c: 4.573884769586416 avg_loss_a: -76.50088500976562\n",
            "Número de pasos del episodeo 12156 son episode_steps:452\n",
            "Total Steps: 789507 Episode Num: 12156 Reward: 623.2492781341558 avg_loss_c: 4.733909028821287 avg_loss_a: -76.20986023624387\n",
            "Número de pasos del episodeo 12157 son episode_steps:467\n",
            "Total Steps: 789974 Episode Num: 12157 Reward: 702.8682243180174 avg_loss_c: 4.281340878831753 avg_loss_a: -76.35800659375732\n",
            "Número de pasos del episodeo 12158 son episode_steps:224\n",
            "Total Steps: 790198 Episode Num: 12158 Reward: 187.62096297794062 avg_loss_c: 4.538990369864872 avg_loss_a: -76.13173144204276\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 577.073848\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12159 son episode_steps:301\n",
            "Total Steps: 790499 Episode Num: 12159 Reward: 446.7467844851618 avg_loss_c: 4.364430379233883 avg_loss_a: -76.36549782990618\n",
            "Número de pasos del episodeo 12160 son episode_steps:433\n",
            "Total Steps: 790932 Episode Num: 12160 Reward: 633.6448214193306 avg_loss_c: 4.230188081776573 avg_loss_a: -76.26509643977563\n",
            "Número de pasos del episodeo 12161 son episode_steps:1000\n",
            "Total Steps: 791932 Episode Num: 12161 Reward: 1538.5210340096014 avg_loss_c: 4.0589300563335415 avg_loss_a: -77.34552275085449\n",
            "Número de pasos del episodeo 12162 son episode_steps:130\n",
            "Total Steps: 792062 Episode Num: 12162 Reward: 163.79995899770213 avg_loss_c: 3.8037041664123534 avg_loss_a: -77.2673565204327\n",
            "Número de pasos del episodeo 12163 son episode_steps:593\n",
            "Total Steps: 792655 Episode Num: 12163 Reward: 864.9624875247443 avg_loss_c: 4.1054489021558584 avg_loss_a: -77.76919102789378\n",
            "Número de pasos del episodeo 12164 son episode_steps:61\n",
            "Total Steps: 792716 Episode Num: 12164 Reward: 40.98641129146079 avg_loss_c: 4.288781388861234 avg_loss_a: -78.09905493064005\n",
            "Número de pasos del episodeo 12165 son episode_steps:95\n",
            "Total Steps: 792811 Episode Num: 12165 Reward: 114.53491695911438 avg_loss_c: 4.0969953888341 avg_loss_a: -77.50624429803146\n",
            "Número de pasos del episodeo 12166 son episode_steps:762\n",
            "Total Steps: 793573 Episode Num: 12166 Reward: 1162.9716899549564 avg_loss_c: 4.199063139011853 avg_loss_a: -78.00831800245551\n",
            "Número de pasos del episodeo 12167 son episode_steps:368\n",
            "Total Steps: 793941 Episode Num: 12167 Reward: 524.0069108917099 avg_loss_c: 4.21301858904569 avg_loss_a: -78.25942027050516\n",
            "Número de pasos del episodeo 12168 son episode_steps:74\n",
            "Total Steps: 794015 Episode Num: 12168 Reward: 85.72819412905193 avg_loss_c: 4.193499961414853 avg_loss_a: -78.22382684656091\n",
            "Número de pasos del episodeo 12169 son episode_steps:75\n",
            "Total Steps: 794090 Episode Num: 12169 Reward: 91.20518724337028 avg_loss_c: 4.173696025212606 avg_loss_a: -78.11206553141277\n",
            "Número de pasos del episodeo 12170 son episode_steps:316\n",
            "Total Steps: 794406 Episode Num: 12170 Reward: 472.032929533838 avg_loss_c: 4.097134922878651 avg_loss_a: -78.6463879452476\n",
            "Número de pasos del episodeo 12171 son episode_steps:1000\n",
            "Total Steps: 795406 Episode Num: 12171 Reward: 1608.2107160181406 avg_loss_c: 3.94331671500206 avg_loss_a: -79.3581614074707\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 555.983979\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12172 son episode_steps:39\n",
            "Total Steps: 795445 Episode Num: 12172 Reward: 17.107033472136095 avg_loss_c: 3.7917561469933925 avg_loss_a: -80.22709479698769\n",
            "Número de pasos del episodeo 12173 son episode_steps:1000\n",
            "Total Steps: 796445 Episode Num: 12173 Reward: 1640.0461419678581 avg_loss_c: 3.822589472055435 avg_loss_a: -79.80228767395019\n",
            "Número de pasos del episodeo 12174 son episode_steps:821\n",
            "Total Steps: 797266 Episode Num: 12174 Reward: 1316.4529367495281 avg_loss_c: 3.635039647081447 avg_loss_a: -80.68742483048433\n",
            "Número de pasos del episodeo 12175 son episode_steps:185\n",
            "Total Steps: 797451 Episode Num: 12175 Reward: 223.80427930278094 avg_loss_c: 3.74596879160082 avg_loss_a: -81.0529373581345\n",
            "Número de pasos del episodeo 12176 son episode_steps:33\n",
            "Total Steps: 797484 Episode Num: 12176 Reward: 13.835572264746851 avg_loss_c: 3.431061860286828 avg_loss_a: -80.6023037072384\n",
            "Número de pasos del episodeo 12177 son episode_steps:1000\n",
            "Total Steps: 798484 Episode Num: 12177 Reward: 1690.7646615524473 avg_loss_c: 3.540781560540199 avg_loss_a: -81.82942620849609\n",
            "Número de pasos del episodeo 12178 son episode_steps:116\n",
            "Total Steps: 798600 Episode Num: 12178 Reward: 142.8482175512146 avg_loss_c: 3.5112981570178063 avg_loss_a: -81.92796496687264\n",
            "Número de pasos del episodeo 12179 son episode_steps:45\n",
            "Total Steps: 798645 Episode Num: 12179 Reward: 20.213920907461272 avg_loss_c: 3.4928498215145534 avg_loss_a: -81.08478647867838\n",
            "Número de pasos del episodeo 12180 son episode_steps:534\n",
            "Total Steps: 799179 Episode Num: 12180 Reward: 841.3773978247857 avg_loss_c: 3.638367561588573 avg_loss_a: -82.2000110640508\n",
            "Número de pasos del episodeo 12181 son episode_steps:1000\n",
            "Total Steps: 800179 Episode Num: 12181 Reward: 1675.0925627125646 avg_loss_c: 3.2720404472351072 avg_loss_a: -83.62636233520507\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 535.241751\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12182 son episode_steps:688\n",
            "Total Steps: 800867 Episode Num: 12182 Reward: 1110.35116589124 avg_loss_c: 3.1723252725462583 avg_loss_a: -84.4093853928322\n",
            "Número de pasos del episodeo 12183 son episode_steps:262\n",
            "Total Steps: 801129 Episode Num: 12183 Reward: 367.16545710463816 avg_loss_c: 3.0840935138345675 avg_loss_a: -84.21156270267399\n",
            "Número de pasos del episodeo 12184 son episode_steps:51\n",
            "Total Steps: 801180 Episode Num: 12184 Reward: 67.46571174811405 avg_loss_c: 3.0572045550626865 avg_loss_a: -84.95025260775697\n",
            "Número de pasos del episodeo 12185 son episode_steps:36\n",
            "Total Steps: 801216 Episode Num: 12185 Reward: -19.883760753368158 avg_loss_c: 3.317812422911326 avg_loss_a: -84.8667229546441\n",
            "Número de pasos del episodeo 12186 son episode_steps:494\n",
            "Total Steps: 801710 Episode Num: 12186 Reward: 716.911936925373 avg_loss_c: 3.3225252628326416 avg_loss_a: -84.45096569601823\n",
            "Número de pasos del episodeo 12187 son episode_steps:565\n",
            "Total Steps: 802275 Episode Num: 12187 Reward: 859.7416061116745 avg_loss_c: 3.1930445806115073 avg_loss_a: -84.60368113559959\n",
            "Número de pasos del episodeo 12188 son episode_steps:1000\n",
            "Total Steps: 803275 Episode Num: 12188 Reward: 1652.857450753938 avg_loss_c: 3.0420791701078413 avg_loss_a: -85.7045938873291\n",
            "Número de pasos del episodeo 12189 son episode_steps:629\n",
            "Total Steps: 803904 Episode Num: 12189 Reward: 1023.3541512239257 avg_loss_c: 2.92812365511453 avg_loss_a: -86.78482231540407\n",
            "Número de pasos del episodeo 12190 son episode_steps:1000\n",
            "Total Steps: 804904 Episode Num: 12190 Reward: 1603.0814794265434 avg_loss_c: 2.8798319827318193 avg_loss_a: -88.09554092407227\n",
            "Número de pasos del episodeo 12191 son episode_steps:757\n",
            "Total Steps: 805661 Episode Num: 12191 Reward: 1225.4279473055656 avg_loss_c: 2.794535365098376 avg_loss_a: -89.03453982112588\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 347.538041\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12192 son episode_steps:46\n",
            "Total Steps: 805707 Episode Num: 12192 Reward: 24.1936120057404 avg_loss_c: 2.7658034277998884 avg_loss_a: -88.94403043000594\n",
            "Número de pasos del episodeo 12193 son episode_steps:121\n",
            "Total Steps: 805828 Episode Num: 12193 Reward: 79.83900409398163 avg_loss_c: 3.0595396175857417 avg_loss_a: -89.03929869596624\n",
            "Número de pasos del episodeo 12194 son episode_steps:301\n",
            "Total Steps: 806129 Episode Num: 12194 Reward: 418.02870485956805 avg_loss_c: 2.9303493820551623 avg_loss_a: -89.57556818965266\n",
            "Número de pasos del episodeo 12195 son episode_steps:54\n",
            "Total Steps: 806183 Episode Num: 12195 Reward: 21.383094581842457 avg_loss_c: 3.383708503511217 avg_loss_a: -89.4125747680664\n",
            "Número de pasos del episodeo 12196 son episode_steps:474\n",
            "Total Steps: 806657 Episode Num: 12196 Reward: 700.0778669996329 avg_loss_c: 2.9112652565356547 avg_loss_a: -89.80177394046059\n",
            "Número de pasos del episodeo 12197 son episode_steps:1000\n",
            "Total Steps: 807657 Episode Num: 12197 Reward: 1594.7512690109731 avg_loss_c: 2.638539196372032 avg_loss_a: -91.22697009277344\n",
            "Número de pasos del episodeo 12198 son episode_steps:182\n",
            "Total Steps: 807839 Episode Num: 12198 Reward: 238.88854103760835 avg_loss_c: 2.6701066873885773 avg_loss_a: -91.19571040226863\n",
            "Número de pasos del episodeo 12199 son episode_steps:1000\n",
            "Total Steps: 808839 Episode Num: 12199 Reward: 1609.585458745559 avg_loss_c: 2.55136795437336 avg_loss_a: -92.63703025817871\n",
            "Número de pasos del episodeo 12200 son episode_steps:189\n",
            "Total Steps: 809028 Episode Num: 12200 Reward: 240.97654510360684 avg_loss_c: 2.4435971268901118 avg_loss_a: -93.76750703841921\n",
            "Número de pasos del episodeo 12201 son episode_steps:278\n",
            "Total Steps: 809306 Episode Num: 12201 Reward: 332.09143324303346 avg_loss_c: 2.632013965424874 avg_loss_a: -93.59309914129244\n",
            "Número de pasos del episodeo 12202 son episode_steps:437\n",
            "Total Steps: 809743 Episode Num: 12202 Reward: 653.7535230939448 avg_loss_c: 2.542375021177244 avg_loss_a: -93.87911290707795\n",
            "Número de pasos del episodeo 12203 son episode_steps:105\n",
            "Total Steps: 809848 Episode Num: 12203 Reward: 15.120911528593545 avg_loss_c: 3.1286267098926364 avg_loss_a: -93.86921619233631\n",
            "Número de pasos del episodeo 12204 son episode_steps:725\n",
            "Total Steps: 810573 Episode Num: 12204 Reward: 992.5796810917383 avg_loss_c: 2.7397785430118957 avg_loss_a: -94.29198415821996\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 404.684785\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12205 son episode_steps:51\n",
            "Total Steps: 810624 Episode Num: 12205 Reward: 23.46048074255014 avg_loss_c: 2.647709192014208 avg_loss_a: -94.44266136019837\n",
            "Número de pasos del episodeo 12206 son episode_steps:95\n",
            "Total Steps: 810719 Episode Num: 12206 Reward: 125.3667754404417 avg_loss_c: 3.140121118645919 avg_loss_a: -94.38920320209704\n",
            "Número de pasos del episodeo 12207 son episode_steps:18\n",
            "Total Steps: 810737 Episode Num: 12207 Reward: -40.75460460639597 avg_loss_c: 2.8680560257699756 avg_loss_a: -93.86109754774306\n",
            "Número de pasos del episodeo 12208 son episode_steps:43\n",
            "Total Steps: 810780 Episode Num: 12208 Reward: -32.74919731629563 avg_loss_c: 3.5668442332467367 avg_loss_a: -94.32804267351017\n",
            "Número de pasos del episodeo 12209 son episode_steps:38\n",
            "Total Steps: 810818 Episode Num: 12209 Reward: 2.7348454411425522 avg_loss_c: 2.9076876201127706 avg_loss_a: -94.43101862857216\n",
            "Número de pasos del episodeo 12210 son episode_steps:380\n",
            "Total Steps: 811198 Episode Num: 12210 Reward: 556.4897817992162 avg_loss_c: 3.1654809515727194 avg_loss_a: -94.4560327630294\n",
            "Número de pasos del episodeo 12211 son episode_steps:328\n",
            "Total Steps: 811526 Episode Num: 12211 Reward: 306.3295210953348 avg_loss_c: 3.2997998900529817 avg_loss_a: -94.45825158095941\n",
            "Número de pasos del episodeo 12212 son episode_steps:75\n",
            "Total Steps: 811601 Episode Num: 12212 Reward: 67.90006186459196 avg_loss_c: 3.329048260052999 avg_loss_a: -93.98370676676433\n",
            "Número de pasos del episodeo 12213 son episode_steps:90\n",
            "Total Steps: 811691 Episode Num: 12213 Reward: 64.78572979259363 avg_loss_c: 3.261688244342804 avg_loss_a: -93.77154829237196\n",
            "Número de pasos del episodeo 12214 son episode_steps:121\n",
            "Total Steps: 811812 Episode Num: 12214 Reward: 84.14746248458394 avg_loss_c: 3.432822038319485 avg_loss_a: -93.68237777583855\n",
            "Número de pasos del episodeo 12215 son episode_steps:819\n",
            "Total Steps: 812631 Episode Num: 12215 Reward: 1262.9534219017442 avg_loss_c: 3.249224069499853 avg_loss_a: -94.4139407464145\n",
            "Número de pasos del episodeo 12216 son episode_steps:250\n",
            "Total Steps: 812881 Episode Num: 12216 Reward: 312.6236003655703 avg_loss_c: 3.095629693508148 avg_loss_a: -94.7593941040039\n",
            "Número de pasos del episodeo 12217 son episode_steps:82\n",
            "Total Steps: 812963 Episode Num: 12217 Reward: 79.73537254569769 avg_loss_c: 3.299221131859756 avg_loss_a: -94.53595324260432\n",
            "Número de pasos del episodeo 12218 son episode_steps:50\n",
            "Total Steps: 813013 Episode Num: 12218 Reward: 9.08513486384743 avg_loss_c: 3.3395907878875732 avg_loss_a: -94.00413818359375\n",
            "Número de pasos del episodeo 12219 son episode_steps:95\n",
            "Total Steps: 813108 Episode Num: 12219 Reward: 96.18743451021166 avg_loss_c: 3.1628779210542377 avg_loss_a: -94.25701719585219\n",
            "Número de pasos del episodeo 12220 son episode_steps:65\n",
            "Total Steps: 813173 Episode Num: 12220 Reward: 50.303401266879426 avg_loss_c: 3.575325136918288 avg_loss_a: -94.25186556302585\n",
            "Número de pasos del episodeo 12221 son episode_steps:875\n",
            "Total Steps: 814048 Episode Num: 12221 Reward: 1282.261056120889 avg_loss_c: 3.243829900877816 avg_loss_a: -94.82830046735491\n",
            "Número de pasos del episodeo 12222 son episode_steps:76\n",
            "Total Steps: 814124 Episode Num: 12222 Reward: 96.24238337211811 avg_loss_c: 3.101229066911497 avg_loss_a: -94.95025313527961\n",
            "Número de pasos del episodeo 12223 son episode_steps:18\n",
            "Total Steps: 814142 Episode Num: 12223 Reward: -20.146189001672955 avg_loss_c: 3.4503670268588595 avg_loss_a: -92.37246195475261\n",
            "Número de pasos del episodeo 12224 son episode_steps:69\n",
            "Total Steps: 814211 Episode Num: 12224 Reward: 74.65004192834077 avg_loss_c: 3.301002003144527 avg_loss_a: -94.0957705732705\n",
            "Número de pasos del episodeo 12225 son episode_steps:1000\n",
            "Total Steps: 815211 Episode Num: 12225 Reward: 1646.870084584278 avg_loss_c: 3.1335468213558197 avg_loss_a: -95.33272541809082\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 397.225761\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12226 son episode_steps:1000\n",
            "Total Steps: 816211 Episode Num: 12226 Reward: 1604.9738407342752 avg_loss_c: 2.9917544354200363 avg_loss_a: -95.66141424560547\n",
            "Número de pasos del episodeo 12227 son episode_steps:893\n",
            "Total Steps: 817104 Episode Num: 12227 Reward: 1354.443747855006 avg_loss_c: 2.963551045665549 avg_loss_a: -96.21099287077935\n",
            "Número de pasos del episodeo 12228 son episode_steps:64\n",
            "Total Steps: 817168 Episode Num: 12228 Reward: 57.95879721266187 avg_loss_c: 3.381376737728715 avg_loss_a: -95.86649799346924\n",
            "Número de pasos del episodeo 12229 son episode_steps:120\n",
            "Total Steps: 817288 Episode Num: 12229 Reward: 140.1998309541337 avg_loss_c: 3.1986619512240093 avg_loss_a: -95.54114061991373\n",
            "Número de pasos del episodeo 12230 son episode_steps:627\n",
            "Total Steps: 817915 Episode Num: 12230 Reward: 904.3951845706559 avg_loss_c: 3.9784711842711844 avg_loss_a: -96.19977749667859\n",
            "Número de pasos del episodeo 12231 son episode_steps:392\n",
            "Total Steps: 818307 Episode Num: 12231 Reward: 585.0338852386421 avg_loss_c: 3.1525003843161525 avg_loss_a: -96.50669027834522\n",
            "Número de pasos del episodeo 12232 son episode_steps:101\n",
            "Total Steps: 818408 Episode Num: 12232 Reward: 93.03174887833993 avg_loss_c: 3.3720585119606246 avg_loss_a: -96.21537742992439\n",
            "Número de pasos del episodeo 12233 son episode_steps:105\n",
            "Total Steps: 818513 Episode Num: 12233 Reward: 97.11235989377766 avg_loss_c: 3.265675083796183 avg_loss_a: -96.40741373697917\n",
            "Número de pasos del episodeo 12234 son episode_steps:446\n",
            "Total Steps: 818959 Episode Num: 12234 Reward: 665.5532646799785 avg_loss_c: 3.3336372303321222 avg_loss_a: -96.06726423186572\n",
            "Número de pasos del episodeo 12235 son episode_steps:366\n",
            "Total Steps: 819325 Episode Num: 12235 Reward: 539.1783046033122 avg_loss_c: 3.406081138087101 avg_loss_a: -96.35582295402152\n",
            "Número de pasos del episodeo 12236 son episode_steps:69\n",
            "Total Steps: 819394 Episode Num: 12236 Reward: 71.66437850664941 avg_loss_c: 3.326138797013656 avg_loss_a: -95.92280180557914\n",
            "Número de pasos del episodeo 12237 son episode_steps:396\n",
            "Total Steps: 819790 Episode Num: 12237 Reward: 500.7182442888887 avg_loss_c: 3.638243168592453 avg_loss_a: -95.86485868511778\n",
            "Número de pasos del episodeo 12238 son episode_steps:682\n",
            "Total Steps: 820472 Episode Num: 12238 Reward: 1024.679397993344 avg_loss_c: 3.5813951294792714 avg_loss_a: -95.99600134706917\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 425.943951\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12239 son episode_steps:91\n",
            "Total Steps: 820563 Episode Num: 12239 Reward: 111.49219395456447 avg_loss_c: 3.513791044989785 avg_loss_a: -95.97774161873284\n",
            "Número de pasos del episodeo 12240 son episode_steps:100\n",
            "Total Steps: 820663 Episode Num: 12240 Reward: 85.1686342914702 avg_loss_c: 3.809117999076843 avg_loss_a: -95.69681457519532\n",
            "Número de pasos del episodeo 12241 son episode_steps:84\n",
            "Total Steps: 820747 Episode Num: 12241 Reward: 73.32574444347908 avg_loss_c: 3.8638008747782027 avg_loss_a: -95.2120475769043\n",
            "Número de pasos del episodeo 12242 son episode_steps:163\n",
            "Total Steps: 820910 Episode Num: 12242 Reward: 193.75047110636223 avg_loss_c: 3.6682584797677817 avg_loss_a: -95.43083485796407\n",
            "Número de pasos del episodeo 12243 son episode_steps:226\n",
            "Total Steps: 821136 Episode Num: 12243 Reward: 242.88087763253833 avg_loss_c: 4.028148173230939 avg_loss_a: -95.12504051005946\n",
            "Número de pasos del episodeo 12244 son episode_steps:314\n",
            "Total Steps: 821450 Episode Num: 12244 Reward: 448.31125480356684 avg_loss_c: 3.90538845927852 avg_loss_a: -95.40042235744987\n",
            "Número de pasos del episodeo 12245 son episode_steps:68\n",
            "Total Steps: 821518 Episode Num: 12245 Reward: 42.537006019541344 avg_loss_c: 4.06125448030584 avg_loss_a: -95.71556652293486\n",
            "Número de pasos del episodeo 12246 son episode_steps:251\n",
            "Total Steps: 821769 Episode Num: 12246 Reward: 326.1956367110056 avg_loss_c: 4.020112784260298 avg_loss_a: -95.50273630818523\n",
            "Número de pasos del episodeo 12247 son episode_steps:496\n",
            "Total Steps: 822265 Episode Num: 12247 Reward: 628.7731606190274 avg_loss_c: 4.380875430280162 avg_loss_a: -95.82698594370196\n",
            "Número de pasos del episodeo 12248 son episode_steps:58\n",
            "Total Steps: 822323 Episode Num: 12248 Reward: 45.80907159416636 avg_loss_c: 4.316256350484387 avg_loss_a: -95.13591266500539\n",
            "Número de pasos del episodeo 12249 son episode_steps:156\n",
            "Total Steps: 822479 Episode Num: 12249 Reward: 143.6966867336714 avg_loss_c: 4.6654163507314825 avg_loss_a: -95.06663826184395\n",
            "Número de pasos del episodeo 12250 son episode_steps:316\n",
            "Total Steps: 822795 Episode Num: 12250 Reward: 404.4737639596567 avg_loss_c: 4.37671755612651 avg_loss_a: -94.93648128268084\n",
            "Número de pasos del episodeo 12251 son episode_steps:484\n",
            "Total Steps: 823279 Episode Num: 12251 Reward: 642.472741071774 avg_loss_c: 4.6245819734147755 avg_loss_a: -94.73589406919874\n",
            "Número de pasos del episodeo 12252 son episode_steps:176\n",
            "Total Steps: 823455 Episode Num: 12252 Reward: 159.2904764524022 avg_loss_c: 4.684858250347051 avg_loss_a: -94.04244674335827\n",
            "Número de pasos del episodeo 12253 son episode_steps:544\n",
            "Total Steps: 823999 Episode Num: 12253 Reward: 815.88064186109 avg_loss_c: 4.437121957540512 avg_loss_a: -94.35035116532269\n",
            "Número de pasos del episodeo 12254 son episode_steps:884\n",
            "Total Steps: 824883 Episode Num: 12254 Reward: 1313.3909041387594 avg_loss_c: 4.360297581728767 avg_loss_a: -94.18647686712343\n",
            "Número de pasos del episodeo 12255 son episode_steps:137\n",
            "Total Steps: 825020 Episode Num: 12255 Reward: 165.4255101174206 avg_loss_c: 4.376736734905382 avg_loss_a: -93.85839615425054\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 324.460775\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12256 son episode_steps:133\n",
            "Total Steps: 825153 Episode Num: 12256 Reward: 155.34457420375082 avg_loss_c: 4.484941437728423 avg_loss_a: -94.06473828079109\n",
            "Número de pasos del episodeo 12257 son episode_steps:21\n",
            "Total Steps: 825174 Episode Num: 12257 Reward: -23.654660075061678 avg_loss_c: 4.318777538481212 avg_loss_a: -94.40353175571987\n",
            "Número de pasos del episodeo 12258 son episode_steps:147\n",
            "Total Steps: 825321 Episode Num: 12258 Reward: 178.45730665393214 avg_loss_c: 4.630364025531172 avg_loss_a: -93.57236049937553\n",
            "Número de pasos del episodeo 12259 son episode_steps:131\n",
            "Total Steps: 825452 Episode Num: 12259 Reward: 148.26015506335716 avg_loss_c: 4.4900612448918 avg_loss_a: -93.1773841217274\n",
            "Número de pasos del episodeo 12260 son episode_steps:224\n",
            "Total Steps: 825676 Episode Num: 12260 Reward: 273.8349456492454 avg_loss_c: 4.757344140538147 avg_loss_a: -93.56959213529315\n",
            "Número de pasos del episodeo 12261 son episode_steps:239\n",
            "Total Steps: 825915 Episode Num: 12261 Reward: 258.9932351413302 avg_loss_c: 4.802645060806594 avg_loss_a: -93.14830416116754\n",
            "Número de pasos del episodeo 12262 son episode_steps:19\n",
            "Total Steps: 825934 Episode Num: 12262 Reward: -9.0690566136361 avg_loss_c: 6.842947959899902 avg_loss_a: -94.22237998560855\n",
            "Número de pasos del episodeo 12263 son episode_steps:202\n",
            "Total Steps: 826136 Episode Num: 12263 Reward: 254.08058196285526 avg_loss_c: 5.039571567337112 avg_loss_a: -93.27932225595606\n",
            "Número de pasos del episodeo 12264 son episode_steps:52\n",
            "Total Steps: 826188 Episode Num: 12264 Reward: -26.236736288835914 avg_loss_c: 4.962287691923288 avg_loss_a: -93.68460200383113\n",
            "Número de pasos del episodeo 12265 son episode_steps:1000\n",
            "Total Steps: 827188 Episode Num: 12265 Reward: 1616.159145073929 avg_loss_c: 4.822749533414841 avg_loss_a: -93.58455795288086\n",
            "Número de pasos del episodeo 12266 son episode_steps:62\n",
            "Total Steps: 827250 Episode Num: 12266 Reward: 25.199265870214365 avg_loss_c: 4.625184593662139 avg_loss_a: -93.72470141995338\n",
            "Número de pasos del episodeo 12267 son episode_steps:128\n",
            "Total Steps: 827378 Episode Num: 12267 Reward: 99.43891355844303 avg_loss_c: 4.892208501696587 avg_loss_a: -93.14498960971832\n",
            "Número de pasos del episodeo 12268 son episode_steps:59\n",
            "Total Steps: 827437 Episode Num: 12268 Reward: -28.790466254588537 avg_loss_c: 4.951051994905633 avg_loss_a: -93.39936233779132\n",
            "Número de pasos del episodeo 12269 son episode_steps:280\n",
            "Total Steps: 827717 Episode Num: 12269 Reward: 414.5877867778237 avg_loss_c: 5.061764788627625 avg_loss_a: -92.88883176531111\n",
            "Número de pasos del episodeo 12270 son episode_steps:119\n",
            "Total Steps: 827836 Episode Num: 12270 Reward: 120.13886300870571 avg_loss_c: 4.849082137356286 avg_loss_a: -93.4619242563969\n",
            "Número de pasos del episodeo 12271 son episode_steps:574\n",
            "Total Steps: 828410 Episode Num: 12271 Reward: 874.6998146161657 avg_loss_c: 5.012779170627794 avg_loss_a: -92.8775788948511\n",
            "Número de pasos del episodeo 12272 son episode_steps:52\n",
            "Total Steps: 828462 Episode Num: 12272 Reward: -32.75628695211418 avg_loss_c: 5.030615027134235 avg_loss_a: -92.9311408996582\n",
            "Número de pasos del episodeo 12273 son episode_steps:56\n",
            "Total Steps: 828518 Episode Num: 12273 Reward: -53.32849329728619 avg_loss_c: 5.350929285798754 avg_loss_a: -91.9953727722168\n",
            "Número de pasos del episodeo 12274 son episode_steps:442\n",
            "Total Steps: 828960 Episode Num: 12274 Reward: 590.1120265116067 avg_loss_c: 5.380518147848311 avg_loss_a: -92.14991069810962\n",
            "Número de pasos del episodeo 12275 son episode_steps:217\n",
            "Total Steps: 829177 Episode Num: 12275 Reward: 223.89669392332402 avg_loss_c: 5.170622813536824 avg_loss_a: -92.14802146946779\n",
            "Número de pasos del episodeo 12276 son episode_steps:109\n",
            "Total Steps: 829286 Episode Num: 12276 Reward: 116.51763923986776 avg_loss_c: 5.2718351784102415 avg_loss_a: -91.92107027386307\n",
            "Número de pasos del episodeo 12277 son episode_steps:156\n",
            "Total Steps: 829442 Episode Num: 12277 Reward: 170.4647174587053 avg_loss_c: 5.411770223042904 avg_loss_a: -91.59707025381235\n",
            "Número de pasos del episodeo 12278 son episode_steps:194\n",
            "Total Steps: 829636 Episode Num: 12278 Reward: 248.0263369787202 avg_loss_c: 5.118700694792049 avg_loss_a: -91.56745643222455\n",
            "Número de pasos del episodeo 12279 son episode_steps:517\n",
            "Total Steps: 830153 Episode Num: 12279 Reward: 676.8978228470257 avg_loss_c: 5.363710837391866 avg_loss_a: -91.80940805874202\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 280.521519\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12280 son episode_steps:546\n",
            "Total Steps: 830699 Episode Num: 12280 Reward: 769.3847884366608 avg_loss_c: 5.185018114117912 avg_loss_a: -91.92671832409533\n",
            "Número de pasos del episodeo 12281 son episode_steps:42\n",
            "Total Steps: 830741 Episode Num: 12281 Reward: 1.9529521540470922 avg_loss_c: 5.064280561038426 avg_loss_a: -91.62564559209915\n",
            "Número de pasos del episodeo 12282 son episode_steps:42\n",
            "Total Steps: 830783 Episode Num: 12282 Reward: 22.374183628388813 avg_loss_c: 5.6893324454625445 avg_loss_a: -92.37025596981957\n",
            "Número de pasos del episodeo 12283 son episode_steps:606\n",
            "Total Steps: 831389 Episode Num: 12283 Reward: 933.8937541162609 avg_loss_c: 5.423657739123102 avg_loss_a: -91.84096076386203\n",
            "Número de pasos del episodeo 12284 son episode_steps:668\n",
            "Total Steps: 832057 Episode Num: 12284 Reward: 967.9490246114491 avg_loss_c: 5.104007293364245 avg_loss_a: -92.21658386870058\n",
            "Número de pasos del episodeo 12285 son episode_steps:108\n",
            "Total Steps: 832165 Episode Num: 12285 Reward: 109.01024178665257 avg_loss_c: 5.181842126228191 avg_loss_a: -92.13202116224501\n",
            "Número de pasos del episodeo 12286 son episode_steps:296\n",
            "Total Steps: 832461 Episode Num: 12286 Reward: 424.3407413437545 avg_loss_c: 4.97865034599562 avg_loss_a: -92.14857776744945\n",
            "Número de pasos del episodeo 12287 son episode_steps:230\n",
            "Total Steps: 832691 Episode Num: 12287 Reward: 287.23418357911186 avg_loss_c: 5.1094201626984965 avg_loss_a: -92.06790545919667\n",
            "Número de pasos del episodeo 12288 son episode_steps:23\n",
            "Total Steps: 832714 Episode Num: 12288 Reward: -12.881446048336416 avg_loss_c: 5.084805592246678 avg_loss_a: -91.55603060515031\n",
            "Número de pasos del episodeo 12289 son episode_steps:21\n",
            "Total Steps: 832735 Episode Num: 12289 Reward: -4.585282737250027 avg_loss_c: 5.548407191321964 avg_loss_a: -93.75936998639789\n",
            "Número de pasos del episodeo 12290 son episode_steps:91\n",
            "Total Steps: 832826 Episode Num: 12290 Reward: 96.59500225276275 avg_loss_c: 5.50932683787503 avg_loss_a: -91.76967285491608\n",
            "Número de pasos del episodeo 12291 son episode_steps:422\n",
            "Total Steps: 833248 Episode Num: 12291 Reward: 537.5100503213978 avg_loss_c: 5.661583899886687 avg_loss_a: -91.88372809966029\n",
            "Número de pasos del episodeo 12292 son episode_steps:84\n",
            "Total Steps: 833332 Episode Num: 12292 Reward: 93.35627817306234 avg_loss_c: 5.404667207172939 avg_loss_a: -92.0632059006464\n",
            "Número de pasos del episodeo 12293 son episode_steps:38\n",
            "Total Steps: 833370 Episode Num: 12293 Reward: -8.94782577749611 avg_loss_c: 5.630232233750193 avg_loss_a: -92.44147089907997\n",
            "Número de pasos del episodeo 12294 son episode_steps:142\n",
            "Total Steps: 833512 Episode Num: 12294 Reward: 169.1258144691153 avg_loss_c: 5.496765724370177 avg_loss_a: -91.76573105932961\n",
            "Número de pasos del episodeo 12295 son episode_steps:125\n",
            "Total Steps: 833637 Episode Num: 12295 Reward: 157.70417262831967 avg_loss_c: 5.576147762298584 avg_loss_a: -91.13500909423828\n",
            "Número de pasos del episodeo 12296 son episode_steps:145\n",
            "Total Steps: 833782 Episode Num: 12296 Reward: 172.44446271772784 avg_loss_c: 5.839271303703045 avg_loss_a: -90.77642848573882\n",
            "Número de pasos del episodeo 12297 son episode_steps:54\n",
            "Total Steps: 833836 Episode Num: 12297 Reward: 24.961342746884434 avg_loss_c: 5.652160940346895 avg_loss_a: -90.52778879801433\n",
            "Número de pasos del episodeo 12298 son episode_steps:116\n",
            "Total Steps: 833952 Episode Num: 12298 Reward: 128.55493488260475 avg_loss_c: 6.187517665583512 avg_loss_a: -90.25254782314958\n",
            "Número de pasos del episodeo 12299 son episode_steps:880\n",
            "Total Steps: 834832 Episode Num: 12299 Reward: 1372.194271388546 avg_loss_c: 5.570982532880523 avg_loss_a: -90.75408959822221\n",
            "Número de pasos del episodeo 12300 son episode_steps:50\n",
            "Total Steps: 834882 Episode Num: 12300 Reward: 45.260402863334136 avg_loss_c: 5.518975195884704 avg_loss_a: -89.80333465576172\n",
            "Número de pasos del episodeo 12301 son episode_steps:89\n",
            "Total Steps: 834971 Episode Num: 12301 Reward: 44.12541328005648 avg_loss_c: 5.788908398553227 avg_loss_a: -90.23531084382132\n",
            "Número de pasos del episodeo 12302 son episode_steps:176\n",
            "Total Steps: 835147 Episode Num: 12302 Reward: 237.77611120449043 avg_loss_c: 5.874001215804707 avg_loss_a: -90.14093251661821\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 310.974297\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12303 son episode_steps:1000\n",
            "Total Steps: 836147 Episode Num: 12303 Reward: 1566.4740627885053 avg_loss_c: 5.6761469526290895 avg_loss_a: -89.7254401550293\n",
            "Número de pasos del episodeo 12304 son episode_steps:130\n",
            "Total Steps: 836277 Episode Num: 12304 Reward: -10.715309123809876 avg_loss_c: 5.878977157519414 avg_loss_a: -89.43207761324369\n",
            "Número de pasos del episodeo 12305 son episode_steps:701\n",
            "Total Steps: 836978 Episode Num: 12305 Reward: 1014.2338797974663 avg_loss_c: 6.378011469834201 avg_loss_a: -88.76299538387892\n",
            "Número de pasos del episodeo 12306 son episode_steps:416\n",
            "Total Steps: 837394 Episode Num: 12306 Reward: 537.8605117452744 avg_loss_c: 6.074702588411478 avg_loss_a: -89.3491548391489\n",
            "Número de pasos del episodeo 12307 son episode_steps:1000\n",
            "Total Steps: 838394 Episode Num: 12307 Reward: 1591.8989165097048 avg_loss_c: 5.903328383684158 avg_loss_a: -89.71428077697755\n",
            "Número de pasos del episodeo 12308 son episode_steps:92\n",
            "Total Steps: 838486 Episode Num: 12308 Reward: 106.62639954028774 avg_loss_c: 5.5331397989521856 avg_loss_a: -89.13301716680112\n",
            "Número de pasos del episodeo 12309 son episode_steps:41\n",
            "Total Steps: 838527 Episode Num: 12309 Reward: 27.064452861770043 avg_loss_c: 5.530603257621207 avg_loss_a: -89.3363493012219\n",
            "Número de pasos del episodeo 12310 son episode_steps:342\n",
            "Total Steps: 838869 Episode Num: 12310 Reward: 469.8863533878247 avg_loss_c: 6.0817283154928194 avg_loss_a: -89.77972336261593\n",
            "Número de pasos del episodeo 12311 son episode_steps:39\n",
            "Total Steps: 838908 Episode Num: 12311 Reward: 13.681839867349932 avg_loss_c: 5.7960495215195875 avg_loss_a: -89.5769526163737\n",
            "Número de pasos del episodeo 12312 son episode_steps:479\n",
            "Total Steps: 839387 Episode Num: 12312 Reward: 739.661473545285 avg_loss_c: 5.848506541739924 avg_loss_a: -90.18838622027499\n",
            "Número de pasos del episodeo 12313 son episode_steps:1000\n",
            "Total Steps: 840387 Episode Num: 12313 Reward: 1643.4493643132548 avg_loss_c: 5.58678242111206 avg_loss_a: -90.44949385070801\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 761.901081\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12314 son episode_steps:1000\n",
            "Total Steps: 841387 Episode Num: 12314 Reward: 1616.5820552467121 avg_loss_c: 5.056500679016113 avg_loss_a: -92.10835678100585\n",
            "Número de pasos del episodeo 12315 son episode_steps:172\n",
            "Total Steps: 841559 Episode Num: 12315 Reward: 202.34787780982407 avg_loss_c: 5.0938847827356915 avg_loss_a: -92.3367840966513\n",
            "Número de pasos del episodeo 12316 son episode_steps:115\n",
            "Total Steps: 841674 Episode Num: 12316 Reward: 119.69884624659043 avg_loss_c: 5.197148640259453 avg_loss_a: -92.08744062340777\n",
            "Número de pasos del episodeo 12317 son episode_steps:105\n",
            "Total Steps: 841779 Episode Num: 12317 Reward: 15.504228963975809 avg_loss_c: 5.463625340234666 avg_loss_a: -91.79410051618304\n",
            "Número de pasos del episodeo 12318 son episode_steps:1000\n",
            "Total Steps: 842779 Episode Num: 12318 Reward: 1549.3247078129245 avg_loss_c: 4.832212459802627 avg_loss_a: -93.07027655029297\n",
            "Número de pasos del episodeo 12319 son episode_steps:271\n",
            "Total Steps: 843050 Episode Num: 12319 Reward: 378.6503862688175 avg_loss_c: 4.655713984007325 avg_loss_a: -93.22662046650679\n",
            "Número de pasos del episodeo 12320 son episode_steps:67\n",
            "Total Steps: 843117 Episode Num: 12320 Reward: 51.537859974750596 avg_loss_c: 4.56286601166227 avg_loss_a: -93.14608400259445\n",
            "Número de pasos del episodeo 12321 son episode_steps:80\n",
            "Total Steps: 843197 Episode Num: 12321 Reward: 87.5005153493674 avg_loss_c: 4.881921869516373 avg_loss_a: -93.45111103057862\n",
            "Número de pasos del episodeo 12322 son episode_steps:46\n",
            "Total Steps: 843243 Episode Num: 12322 Reward: 32.161194369578574 avg_loss_c: 5.1860940560050635 avg_loss_a: -92.5419865483823\n",
            "Número de pasos del episodeo 12323 son episode_steps:1000\n",
            "Total Steps: 844243 Episode Num: 12323 Reward: 1570.4758463755777 avg_loss_c: 4.672598611593246 avg_loss_a: -93.22680868530273\n",
            "Número de pasos del episodeo 12324 son episode_steps:100\n",
            "Total Steps: 844343 Episode Num: 12324 Reward: 56.61325808516038 avg_loss_c: 5.848639974594116 avg_loss_a: -92.71324462890625\n",
            "Número de pasos del episodeo 12325 son episode_steps:54\n",
            "Total Steps: 844397 Episode Num: 12325 Reward: -16.000204129110582 avg_loss_c: 4.8897175744727805 avg_loss_a: -92.07153518111618\n",
            "Número de pasos del episodeo 12326 son episode_steps:63\n",
            "Total Steps: 844460 Episode Num: 12326 Reward: 58.55307337867225 avg_loss_c: 6.653508167418223 avg_loss_a: -92.52466062515501\n",
            "Número de pasos del episodeo 12327 son episode_steps:123\n",
            "Total Steps: 844583 Episode Num: 12327 Reward: 90.55101746223838 avg_loss_c: 5.622633705294229 avg_loss_a: -92.93082241895722\n",
            "Número de pasos del episodeo 12328 son episode_steps:443\n",
            "Total Steps: 845026 Episode Num: 12328 Reward: 624.6594022793116 avg_loss_c: 5.071534122893288 avg_loss_a: -93.36244077660967\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 228.897029\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12329 son episode_steps:69\n",
            "Total Steps: 845095 Episode Num: 12329 Reward: 71.88484731205368 avg_loss_c: 5.158644434334575 avg_loss_a: -93.08776424242103\n",
            "Número de pasos del episodeo 12330 son episode_steps:56\n",
            "Total Steps: 845151 Episode Num: 12330 Reward: 52.2361690536764 avg_loss_c: 5.268014822687421 avg_loss_a: -92.92041397094727\n",
            "Número de pasos del episodeo 12331 son episode_steps:85\n",
            "Total Steps: 845236 Episode Num: 12331 Reward: 29.061842418773466 avg_loss_c: 5.331715028426227 avg_loss_a: -92.52991153492647\n",
            "Número de pasos del episodeo 12332 son episode_steps:122\n",
            "Total Steps: 845358 Episode Num: 12332 Reward: 100.94615273751586 avg_loss_c: 5.727385237568715 avg_loss_a: -93.48949845110783\n",
            "Número de pasos del episodeo 12333 son episode_steps:46\n",
            "Total Steps: 845404 Episode Num: 12333 Reward: 27.227610241097015 avg_loss_c: 5.826991988264996 avg_loss_a: -92.69140724513842\n",
            "Número de pasos del episodeo 12334 son episode_steps:119\n",
            "Total Steps: 845523 Episode Num: 12334 Reward: 61.25010520904005 avg_loss_c: 6.351221170745978 avg_loss_a: -92.0636000432888\n",
            "Número de pasos del episodeo 12335 son episode_steps:280\n",
            "Total Steps: 845803 Episode Num: 12335 Reward: 402.9779268122502 avg_loss_c: 5.340442824363708 avg_loss_a: -92.65823522295271\n",
            "Número de pasos del episodeo 12336 son episode_steps:832\n",
            "Total Steps: 846635 Episode Num: 12336 Reward: 1227.5130479534232 avg_loss_c: 5.43079757432525 avg_loss_a: -93.14343195695143\n",
            "Número de pasos del episodeo 12337 son episode_steps:707\n",
            "Total Steps: 847342 Episode Num: 12337 Reward: 1042.2719405998573 avg_loss_c: 5.201127883568511 avg_loss_a: -93.3471451237313\n",
            "Número de pasos del episodeo 12338 son episode_steps:57\n",
            "Total Steps: 847399 Episode Num: 12338 Reward: -32.37380513576952 avg_loss_c: 5.642027553759124 avg_loss_a: -93.06581758197986\n",
            "Número de pasos del episodeo 12339 son episode_steps:1000\n",
            "Total Steps: 848399 Episode Num: 12339 Reward: 1502.1440294317654 avg_loss_c: 5.107657367706299 avg_loss_a: -94.0456438293457\n",
            "Número de pasos del episodeo 12340 son episode_steps:1000\n",
            "Total Steps: 849399 Episode Num: 12340 Reward: 1598.0687120854084 avg_loss_c: 4.535186002254486 avg_loss_a: -95.56872383117675\n",
            "Número de pasos del episodeo 12341 son episode_steps:832\n",
            "Total Steps: 850231 Episode Num: 12341 Reward: 1235.0184149226473 avg_loss_c: 4.266272960087428 avg_loss_a: -96.66599581791804\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 191.240560\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12342 son episode_steps:185\n",
            "Total Steps: 850416 Episode Num: 12342 Reward: 245.20191512664996 avg_loss_c: 4.386193928847442 avg_loss_a: -96.68759827484956\n",
            "Número de pasos del episodeo 12343 son episode_steps:90\n",
            "Total Steps: 850506 Episode Num: 12343 Reward: 85.22709679178111 avg_loss_c: 4.179963517189026 avg_loss_a: -96.2797610812717\n",
            "Número de pasos del episodeo 12344 son episode_steps:816\n",
            "Total Steps: 851322 Episode Num: 12344 Reward: 1249.255445715433 avg_loss_c: 4.195598602294922 avg_loss_a: -96.98226328457103\n",
            "Número de pasos del episodeo 12345 son episode_steps:40\n",
            "Total Steps: 851362 Episode Num: 12345 Reward: 10.804522735653961 avg_loss_c: 3.742150956392288 avg_loss_a: -97.30123138427734\n",
            "Número de pasos del episodeo 12346 son episode_steps:105\n",
            "Total Steps: 851467 Episode Num: 12346 Reward: 69.3847524086804 avg_loss_c: 4.212153078260876 avg_loss_a: -96.71447143554687\n",
            "Número de pasos del episodeo 12347 son episode_steps:66\n",
            "Total Steps: 851533 Episode Num: 12347 Reward: 15.39061108486629 avg_loss_c: 4.363283616123778 avg_loss_a: -95.99859757856889\n",
            "Número de pasos del episodeo 12348 son episode_steps:1000\n",
            "Total Steps: 852533 Episode Num: 12348 Reward: 1630.3365214732405 avg_loss_c: 4.210234518647194 avg_loss_a: -97.52334223937989\n",
            "Número de pasos del episodeo 12349 son episode_steps:1000\n",
            "Total Steps: 853533 Episode Num: 12349 Reward: 1653.556267585843 avg_loss_c: 3.6769430001974106 avg_loss_a: -99.1600630645752\n",
            "Número de pasos del episodeo 12350 son episode_steps:1000\n",
            "Total Steps: 854533 Episode Num: 12350 Reward: 1543.4843206202897 avg_loss_c: 3.489821075797081 avg_loss_a: -100.4860924987793\n",
            "Número de pasos del episodeo 12351 son episode_steps:166\n",
            "Total Steps: 854699 Episode Num: 12351 Reward: 192.7474553246541 avg_loss_c: 3.3819532789379716 avg_loss_a: -100.8002626350127\n",
            "Número de pasos del episodeo 12352 son episode_steps:83\n",
            "Total Steps: 854782 Episode Num: 12352 Reward: 38.15444637070044 avg_loss_c: 3.752026241945933 avg_loss_a: -100.29579180981739\n",
            "Número de pasos del episodeo 12353 son episode_steps:807\n",
            "Total Steps: 855589 Episode Num: 12353 Reward: 1198.0418767712013 avg_loss_c: 3.465270896826535 avg_loss_a: -100.72072841450479\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 1091.447147\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12354 son episode_steps:1000\n",
            "Total Steps: 856589 Episode Num: 12354 Reward: 1577.03530186194 avg_loss_c: 3.0777294471263885 avg_loss_a: -101.47128274536132\n",
            "Número de pasos del episodeo 12355 son episode_steps:1000\n",
            "Total Steps: 857589 Episode Num: 12355 Reward: 1509.2239576540412 avg_loss_c: 2.8921718149185183 avg_loss_a: -102.18587121582031\n",
            "Número de pasos del episodeo 12356 son episode_steps:658\n",
            "Total Steps: 858247 Episode Num: 12356 Reward: 950.5797799159034 avg_loss_c: 2.9524861344088174 avg_loss_a: -101.88323309066448\n",
            "Número de pasos del episodeo 12357 son episode_steps:349\n",
            "Total Steps: 858596 Episode Num: 12357 Reward: 464.6110601431159 avg_loss_c: 3.0613567648097915 avg_loss_a: -102.47962735238936\n",
            "Número de pasos del episodeo 12358 son episode_steps:974\n",
            "Total Steps: 859570 Episode Num: 12358 Reward: 1253.9812356199202 avg_loss_c: 3.273783728939307 avg_loss_a: -101.99184906507175\n",
            "Número de pasos del episodeo 12359 son episode_steps:56\n",
            "Total Steps: 859626 Episode Num: 12359 Reward: 50.597174050353026 avg_loss_c: 3.1280773324625835 avg_loss_a: -101.87513678414481\n",
            "Número de pasos del episodeo 12360 son episode_steps:56\n",
            "Total Steps: 859682 Episode Num: 12360 Reward: 66.15176102423081 avg_loss_c: 3.19507030078343 avg_loss_a: -101.60119438171387\n",
            "Número de pasos del episodeo 12361 son episode_steps:399\n",
            "Total Steps: 860081 Episode Num: 12361 Reward: 507.895564270913 avg_loss_c: 3.319628125444092 avg_loss_a: -101.48361276803459\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 478.253647\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12362 son episode_steps:60\n",
            "Total Steps: 860141 Episode Num: 12362 Reward: 20.121976576907393 avg_loss_c: 3.552942667404811 avg_loss_a: -102.56895039876302\n",
            "Número de pasos del episodeo 12363 son episode_steps:280\n",
            "Total Steps: 860421 Episode Num: 12363 Reward: 353.10002393930716 avg_loss_c: 3.5879551444734847 avg_loss_a: -101.01552510942732\n",
            "Número de pasos del episodeo 12364 son episode_steps:291\n",
            "Total Steps: 860712 Episode Num: 12364 Reward: 381.9765756097842 avg_loss_c: 3.464414045982754 avg_loss_a: -101.03868965594629\n",
            "Número de pasos del episodeo 12365 son episode_steps:513\n",
            "Total Steps: 861225 Episode Num: 12365 Reward: 729.0453784033418 avg_loss_c: 3.4513770039783354 avg_loss_a: -100.45635550575182\n",
            "Número de pasos del episodeo 12366 son episode_steps:270\n",
            "Total Steps: 861495 Episode Num: 12366 Reward: 365.97286280641424 avg_loss_c: 3.443089426446844 avg_loss_a: -99.97736839011863\n",
            "Número de pasos del episodeo 12367 son episode_steps:90\n",
            "Total Steps: 861585 Episode Num: 12367 Reward: 99.30432867223175 avg_loss_c: 3.2130053096347386 avg_loss_a: -100.5156977335612\n",
            "Número de pasos del episodeo 12368 son episode_steps:502\n",
            "Total Steps: 862087 Episode Num: 12368 Reward: 651.941754963139 avg_loss_c: 3.205763536620425 avg_loss_a: -100.48145625505789\n",
            "Número de pasos del episodeo 12369 son episode_steps:109\n",
            "Total Steps: 862196 Episode Num: 12369 Reward: 118.2256104576513 avg_loss_c: 3.4564854201920534 avg_loss_a: -99.86380585836709\n",
            "Número de pasos del episodeo 12370 son episode_steps:46\n",
            "Total Steps: 862242 Episode Num: 12370 Reward: 26.22315805551107 avg_loss_c: 3.695457997529403 avg_loss_a: -99.9419001703677\n",
            "Número de pasos del episodeo 12371 son episode_steps:450\n",
            "Total Steps: 862692 Episode Num: 12371 Reward: 521.4618064016188 avg_loss_c: 3.6226794645521374 avg_loss_a: -99.95059492323134\n",
            "Número de pasos del episodeo 12372 son episode_steps:675\n",
            "Total Steps: 863367 Episode Num: 12372 Reward: 808.4108142027817 avg_loss_c: 3.49516617598357 avg_loss_a: -100.24709181043836\n",
            "Número de pasos del episodeo 12373 son episode_steps:1000\n",
            "Total Steps: 864367 Episode Num: 12373 Reward: 1456.4636642266626 avg_loss_c: 3.1693149973154067 avg_loss_a: -100.49628146362305\n",
            "Número de pasos del episodeo 12374 son episode_steps:45\n",
            "Total Steps: 864412 Episode Num: 12374 Reward: -30.575358479521434 avg_loss_c: 4.564023113250732 avg_loss_a: -100.18799421522353\n",
            "Número de pasos del episodeo 12375 son episode_steps:258\n",
            "Total Steps: 864670 Episode Num: 12375 Reward: 350.96135262920194 avg_loss_c: 3.425532056379688 avg_loss_a: -100.58127499365992\n",
            "Número de pasos del episodeo 12376 son episode_steps:35\n",
            "Total Steps: 864705 Episode Num: 12376 Reward: -12.803552072525717 avg_loss_c: 3.8138166087014334 avg_loss_a: -100.94364275251117\n",
            "Número de pasos del episodeo 12377 son episode_steps:1000\n",
            "Total Steps: 865705 Episode Num: 12377 Reward: 1527.2162399035121 avg_loss_c: 3.0722394000291824 avg_loss_a: -101.82588920593261\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 639.838922\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12378 son episode_steps:35\n",
            "Total Steps: 865740 Episode Num: 12378 Reward: 7.903618038799879 avg_loss_c: 2.7058810234069823 avg_loss_a: -102.39735804966517\n",
            "Número de pasos del episodeo 12379 son episode_steps:121\n",
            "Total Steps: 865861 Episode Num: 12379 Reward: 125.08487864300011 avg_loss_c: 3.336539004459854 avg_loss_a: -101.87695230531298\n",
            "Número de pasos del episodeo 12380 son episode_steps:856\n",
            "Total Steps: 866717 Episode Num: 12380 Reward: 1245.377473573649 avg_loss_c: 3.2459748175656684 avg_loss_a: -101.8178236774195\n",
            "Número de pasos del episodeo 12381 son episode_steps:687\n",
            "Total Steps: 867404 Episode Num: 12381 Reward: 1068.2827742580178 avg_loss_c: 3.177842373063644 avg_loss_a: -102.15399449777395\n",
            "Número de pasos del episodeo 12382 son episode_steps:306\n",
            "Total Steps: 867710 Episode Num: 12382 Reward: 445.16194530511217 avg_loss_c: 3.0579822819217357 avg_loss_a: -102.15152191959955\n",
            "Número de pasos del episodeo 12383 son episode_steps:142\n",
            "Total Steps: 867852 Episode Num: 12383 Reward: 154.88632353894675 avg_loss_c: 3.6087731173340702 avg_loss_a: -101.82431524572237\n",
            "Número de pasos del episodeo 12384 son episode_steps:121\n",
            "Total Steps: 867973 Episode Num: 12384 Reward: 88.01347768064291 avg_loss_c: 3.6537525900139296 avg_loss_a: -101.2934089849803\n",
            "Número de pasos del episodeo 12385 son episode_steps:104\n",
            "Total Steps: 868077 Episode Num: 12385 Reward: -34.53551539301082 avg_loss_c: 4.200289545150904 avg_loss_a: -101.31797350369968\n",
            "Número de pasos del episodeo 12386 son episode_steps:66\n",
            "Total Steps: 868143 Episode Num: 12386 Reward: 74.10983131320764 avg_loss_c: 4.813704924149946 avg_loss_a: -101.54873102361506\n",
            "Número de pasos del episodeo 12387 son episode_steps:85\n",
            "Total Steps: 868228 Episode Num: 12387 Reward: 24.757382769245588 avg_loss_c: 3.9521409399369185 avg_loss_a: -100.83978684369255\n",
            "Número de pasos del episodeo 12388 son episode_steps:43\n",
            "Total Steps: 868271 Episode Num: 12388 Reward: -13.55519064668513 avg_loss_c: 3.930211771366208 avg_loss_a: -100.33006676962209\n",
            "Número de pasos del episodeo 12389 son episode_steps:175\n",
            "Total Steps: 868446 Episode Num: 12389 Reward: 199.4172850154505 avg_loss_c: 4.2391061660221645 avg_loss_a: -100.9417728969029\n",
            "Número de pasos del episodeo 12390 son episode_steps:87\n",
            "Total Steps: 868533 Episode Num: 12390 Reward: 85.45870088569748 avg_loss_c: 4.029531196616162 avg_loss_a: -100.25411943457593\n",
            "Número de pasos del episodeo 12391 son episode_steps:157\n",
            "Total Steps: 868690 Episode Num: 12391 Reward: 143.48706099171912 avg_loss_c: 4.381210989253536 avg_loss_a: -99.40082671536003\n",
            "Número de pasos del episodeo 12392 son episode_steps:424\n",
            "Total Steps: 869114 Episode Num: 12392 Reward: 583.2424027059533 avg_loss_c: 4.34613376912081 avg_loss_a: -99.46742050602751\n",
            "Número de pasos del episodeo 12393 son episode_steps:262\n",
            "Total Steps: 869376 Episode Num: 12393 Reward: 286.8000932764076 avg_loss_c: 4.39022755258866 avg_loss_a: -99.3580661220405\n",
            "Número de pasos del episodeo 12394 son episode_steps:46\n",
            "Total Steps: 869422 Episode Num: 12394 Reward: 20.46183712131084 avg_loss_c: 4.341112660325092 avg_loss_a: -99.30830051587975\n",
            "Número de pasos del episodeo 12395 son episode_steps:107\n",
            "Total Steps: 869529 Episode Num: 12395 Reward: 120.6189575169647 avg_loss_c: 4.446200014274811 avg_loss_a: -99.19014383476471\n",
            "Número de pasos del episodeo 12396 son episode_steps:61\n",
            "Total Steps: 869590 Episode Num: 12396 Reward: 30.9255363298024 avg_loss_c: 4.710426537716975 avg_loss_a: -98.73190407674821\n",
            "Número de pasos del episodeo 12397 son episode_steps:104\n",
            "Total Steps: 869694 Episode Num: 12397 Reward: 77.80550281238301 avg_loss_c: 4.804194198204921 avg_loss_a: -98.86077690124512\n",
            "Número de pasos del episodeo 12398 son episode_steps:275\n",
            "Total Steps: 869969 Episode Num: 12398 Reward: 370.99644930403804 avg_loss_c: 4.817723920128563 avg_loss_a: -97.95469959605823\n",
            "Número de pasos del episodeo 12399 son episode_steps:236\n",
            "Total Steps: 870205 Episode Num: 12399 Reward: 251.41527897802766 avg_loss_c: 5.122937908617117 avg_loss_a: -98.4369980117022\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 180.541204\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12400 son episode_steps:90\n",
            "Total Steps: 870295 Episode Num: 12400 Reward: 99.03442476789023 avg_loss_c: 4.824537099732293 avg_loss_a: -98.14760250515408\n",
            "Número de pasos del episodeo 12401 son episode_steps:124\n",
            "Total Steps: 870419 Episode Num: 12401 Reward: 150.52745077423265 avg_loss_c: 4.693740612076175 avg_loss_a: -98.50761327435893\n",
            "Número de pasos del episodeo 12402 son episode_steps:228\n",
            "Total Steps: 870647 Episode Num: 12402 Reward: 253.22824654548722 avg_loss_c: 5.023607000970004 avg_loss_a: -98.2689996016653\n",
            "Número de pasos del episodeo 12403 son episode_steps:42\n",
            "Total Steps: 870689 Episode Num: 12403 Reward: -7.290055203318278 avg_loss_c: 5.799072577839806 avg_loss_a: -98.17565954299201\n",
            "Número de pasos del episodeo 12404 son episode_steps:193\n",
            "Total Steps: 870882 Episode Num: 12404 Reward: 249.0777654544563 avg_loss_c: 5.424945049335302 avg_loss_a: -97.44997844794871\n",
            "Número de pasos del episodeo 12405 son episode_steps:401\n",
            "Total Steps: 871283 Episode Num: 12405 Reward: 615.7960606144726 avg_loss_c: 4.984278493985868 avg_loss_a: -97.67794624766209\n",
            "Número de pasos del episodeo 12406 son episode_steps:110\n",
            "Total Steps: 871393 Episode Num: 12406 Reward: 156.99945480685741 avg_loss_c: 4.800203412229364 avg_loss_a: -97.69137490012429\n",
            "Número de pasos del episodeo 12407 son episode_steps:91\n",
            "Total Steps: 871484 Episode Num: 12407 Reward: 96.2098733623376 avg_loss_c: 4.739040998312143 avg_loss_a: -97.71673768431276\n",
            "Número de pasos del episodeo 12408 son episode_steps:114\n",
            "Total Steps: 871598 Episode Num: 12408 Reward: 129.88285263711646 avg_loss_c: 5.2920403145907216 avg_loss_a: -97.83346504077576\n",
            "Número de pasos del episodeo 12409 son episode_steps:308\n",
            "Total Steps: 871906 Episode Num: 12409 Reward: 348.1330842559431 avg_loss_c: 5.172996811278455 avg_loss_a: -97.0387974033108\n",
            "Número de pasos del episodeo 12410 son episode_steps:108\n",
            "Total Steps: 872014 Episode Num: 12410 Reward: 127.54026206751278 avg_loss_c: 5.3583077898731934 avg_loss_a: -97.21870747318974\n",
            "Número de pasos del episodeo 12411 son episode_steps:287\n",
            "Total Steps: 872301 Episode Num: 12411 Reward: 358.73000703148773 avg_loss_c: 4.912358026471288 avg_loss_a: -96.66182977231122\n",
            "Número de pasos del episodeo 12412 son episode_steps:165\n",
            "Total Steps: 872466 Episode Num: 12412 Reward: 166.91388606100622 avg_loss_c: 5.58494351271427 avg_loss_a: -96.83452005097361\n",
            "Número de pasos del episodeo 12413 son episode_steps:432\n",
            "Total Steps: 872898 Episode Num: 12413 Reward: 585.4666608339318 avg_loss_c: 5.318699044761835 avg_loss_a: -95.48000893769441\n",
            "Número de pasos del episodeo 12414 son episode_steps:771\n",
            "Total Steps: 873669 Episode Num: 12414 Reward: 1142.2821525871548 avg_loss_c: 5.188853954062852 avg_loss_a: -95.79308537781316\n",
            "Número de pasos del episodeo 12415 son episode_steps:1000\n",
            "Total Steps: 874669 Episode Num: 12415 Reward: 1562.3743152344564 avg_loss_c: 4.917275120258331 avg_loss_a: -96.52580041503906\n",
            "Número de pasos del episodeo 12416 son episode_steps:815\n",
            "Total Steps: 875484 Episode Num: 12416 Reward: 1343.2983298094175 avg_loss_c: 4.6582763522680555 avg_loss_a: -97.28234615208912\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 582.814651\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12417 son episode_steps:608\n",
            "Total Steps: 876092 Episode Num: 12417 Reward: 939.563692964755 avg_loss_c: 4.518564639514999 avg_loss_a: -97.0075427858453\n",
            "Número de pasos del episodeo 12418 son episode_steps:129\n",
            "Total Steps: 876221 Episode Num: 12418 Reward: 109.34877197844251 avg_loss_c: 4.645302791004033 avg_loss_a: -96.69335079932398\n",
            "Número de pasos del episodeo 12419 son episode_steps:20\n",
            "Total Steps: 876241 Episode Num: 12419 Reward: -39.416209419330194 avg_loss_c: 4.801629054546356 avg_loss_a: -97.0683090209961\n",
            "Número de pasos del episodeo 12420 son episode_steps:1000\n",
            "Total Steps: 877241 Episode Num: 12420 Reward: 1702.6035557974842 avg_loss_c: 4.642756048440933 avg_loss_a: -97.28860845947266\n",
            "Número de pasos del episodeo 12421 son episode_steps:287\n",
            "Total Steps: 877528 Episode Num: 12421 Reward: 415.1589279720663 avg_loss_c: 4.460499354771206 avg_loss_a: -97.18710045365921\n",
            "Número de pasos del episodeo 12422 son episode_steps:114\n",
            "Total Steps: 877642 Episode Num: 12422 Reward: 48.198317310297995 avg_loss_c: 4.676317026740627 avg_loss_a: -97.75488910340427\n",
            "Número de pasos del episodeo 12423 son episode_steps:839\n",
            "Total Steps: 878481 Episode Num: 12423 Reward: 1289.3452887558942 avg_loss_c: 4.5073118099012595 avg_loss_a: -97.43488478177494\n",
            "Número de pasos del episodeo 12424 son episode_steps:60\n",
            "Total Steps: 878541 Episode Num: 12424 Reward: 46.23433775999132 avg_loss_c: 4.216969255606333 avg_loss_a: -97.93948338826497\n",
            "Número de pasos del episodeo 12425 son episode_steps:462\n",
            "Total Steps: 879003 Episode Num: 12425 Reward: 668.0137700540034 avg_loss_c: 4.430294911066691 avg_loss_a: -97.4798226955133\n",
            "Número de pasos del episodeo 12426 son episode_steps:33\n",
            "Total Steps: 879036 Episode Num: 12426 Reward: -15.85577074586226 avg_loss_c: 4.190621556657733 avg_loss_a: -97.39132181803386\n",
            "Número de pasos del episodeo 12427 son episode_steps:261\n",
            "Total Steps: 879297 Episode Num: 12427 Reward: 353.96824049898 avg_loss_c: 4.7094359580584415 avg_loss_a: -97.66631267445298\n",
            "Número de pasos del episodeo 12428 son episode_steps:40\n",
            "Total Steps: 879337 Episode Num: 12428 Reward: 12.488226413851345 avg_loss_c: 4.829502958059311 avg_loss_a: -96.42327423095703\n",
            "Número de pasos del episodeo 12429 son episode_steps:394\n",
            "Total Steps: 879731 Episode Num: 12429 Reward: 512.6127313547821 avg_loss_c: 4.969315835062018 avg_loss_a: -97.55375632658827\n",
            "Número de pasos del episodeo 12430 son episode_steps:186\n",
            "Total Steps: 879917 Episode Num: 12430 Reward: 216.38976771677227 avg_loss_c: 5.030743971947701 avg_loss_a: -97.50889357700143\n",
            "Número de pasos del episodeo 12431 son episode_steps:39\n",
            "Total Steps: 879956 Episode Num: 12431 Reward: 3.1727670334631544 avg_loss_c: 4.6538454202505255 avg_loss_a: -97.29954215807793\n",
            "Número de pasos del episodeo 12432 son episode_steps:168\n",
            "Total Steps: 880124 Episode Num: 12432 Reward: 195.63520708574643 avg_loss_c: 5.157020452476683 avg_loss_a: -97.19222986130487\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 399.427485\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12433 son episode_steps:71\n",
            "Total Steps: 880195 Episode Num: 12433 Reward: -25.584859558119938 avg_loss_c: 6.027594878639974 avg_loss_a: -96.57398653701998\n",
            "Número de pasos del episodeo 12434 son episode_steps:84\n",
            "Total Steps: 880279 Episode Num: 12434 Reward: 73.39615570666959 avg_loss_c: 7.063764560790289 avg_loss_a: -97.32832681565057\n",
            "Número de pasos del episodeo 12435 son episode_steps:355\n",
            "Total Steps: 880634 Episode Num: 12435 Reward: 444.6038273136352 avg_loss_c: 6.091181782601585 avg_loss_a: -96.45168203434474\n",
            "Número de pasos del episodeo 12436 son episode_steps:38\n",
            "Total Steps: 880672 Episode Num: 12436 Reward: 17.169835951383384 avg_loss_c: 5.308519225371511 avg_loss_a: -95.77493808144017\n",
            "Número de pasos del episodeo 12437 son episode_steps:793\n",
            "Total Steps: 881465 Episode Num: 12437 Reward: 1124.1184579983546 avg_loss_c: 5.610884434939333 avg_loss_a: -97.21854449701489\n",
            "Número de pasos del episodeo 12438 son episode_steps:397\n",
            "Total Steps: 881862 Episode Num: 12438 Reward: 488.9016815935415 avg_loss_c: 5.625896812986667 avg_loss_a: -96.77746703102247\n",
            "Número de pasos del episodeo 12439 son episode_steps:156\n",
            "Total Steps: 882018 Episode Num: 12439 Reward: 194.5270844665195 avg_loss_c: 5.449359566737444 avg_loss_a: -96.80921212220804\n",
            "Número de pasos del episodeo 12440 son episode_steps:56\n",
            "Total Steps: 882074 Episode Num: 12440 Reward: 55.51132052621054 avg_loss_c: 5.18310438309397 avg_loss_a: -96.29412705557687\n",
            "Número de pasos del episodeo 12441 son episode_steps:268\n",
            "Total Steps: 882342 Episode Num: 12441 Reward: 346.2090335389643 avg_loss_c: 6.115337443885519 avg_loss_a: -96.7462689983311\n",
            "Número de pasos del episodeo 12442 son episode_steps:206\n",
            "Total Steps: 882548 Episode Num: 12442 Reward: 237.9844737370028 avg_loss_c: 5.984230857450985 avg_loss_a: -96.03002188969585\n",
            "Número de pasos del episodeo 12443 son episode_steps:243\n",
            "Total Steps: 882791 Episode Num: 12443 Reward: 341.03360336559814 avg_loss_c: 5.646796965304716 avg_loss_a: -96.69682745285976\n",
            "Número de pasos del episodeo 12444 son episode_steps:1000\n",
            "Total Steps: 883791 Episode Num: 12444 Reward: 1582.2015087090047 avg_loss_c: 5.565894880056382 avg_loss_a: -97.21352540588379\n",
            "Número de pasos del episodeo 12445 son episode_steps:754\n",
            "Total Steps: 884545 Episode Num: 12445 Reward: 1085.6657597638803 avg_loss_c: 5.632091414707093 avg_loss_a: -97.45015890591974\n",
            "Número de pasos del episodeo 12446 son episode_steps:404\n",
            "Total Steps: 884949 Episode Num: 12446 Reward: 592.4537196285897 avg_loss_c: 5.704984707997577 avg_loss_a: -96.99731177150613\n",
            "Número de pasos del episodeo 12447 son episode_steps:423\n",
            "Total Steps: 885372 Episode Num: 12447 Reward: 566.9144915155152 avg_loss_c: 5.944886655108585 avg_loss_a: -96.63855602724333\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 838.617487\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12448 son episode_steps:68\n",
            "Total Steps: 885440 Episode Num: 12448 Reward: 45.11402119995738 avg_loss_c: 5.976213504286373 avg_loss_a: -96.4717571034151\n",
            "Número de pasos del episodeo 12449 son episode_steps:259\n",
            "Total Steps: 885699 Episode Num: 12449 Reward: 364.8556559511705 avg_loss_c: 5.881468438733958 avg_loss_a: -96.77993341394372\n",
            "Número de pasos del episodeo 12450 son episode_steps:87\n",
            "Total Steps: 885786 Episode Num: 12450 Reward: 71.44892147755903 avg_loss_c: 6.236804153727389 avg_loss_a: -97.00430140002021\n",
            "Número de pasos del episodeo 12451 son episode_steps:39\n",
            "Total Steps: 885825 Episode Num: 12451 Reward: -0.6468017864426994 avg_loss_c: 6.686240049508902 avg_loss_a: -96.4284928150666\n",
            "Número de pasos del episodeo 12452 son episode_steps:324\n",
            "Total Steps: 886149 Episode Num: 12452 Reward: 469.11478477233527 avg_loss_c: 6.652842412760228 avg_loss_a: -96.4123860111943\n",
            "Número de pasos del episodeo 12453 son episode_steps:63\n",
            "Total Steps: 886212 Episode Num: 12453 Reward: 31.99109062470428 avg_loss_c: 6.510137928856744 avg_loss_a: -96.34728495279948\n",
            "Número de pasos del episodeo 12454 son episode_steps:392\n",
            "Total Steps: 886604 Episode Num: 12454 Reward: 613.9596220378351 avg_loss_c: 6.338323382090549 avg_loss_a: -95.47438816148407\n",
            "Número de pasos del episodeo 12455 son episode_steps:103\n",
            "Total Steps: 886707 Episode Num: 12455 Reward: 76.34915906398638 avg_loss_c: 6.756278366718478 avg_loss_a: -95.13518946379133\n",
            "Número de pasos del episodeo 12456 son episode_steps:1000\n",
            "Total Steps: 887707 Episode Num: 12456 Reward: 1481.645278560506 avg_loss_c: 6.354068359375 avg_loss_a: -95.2284923248291\n",
            "Número de pasos del episodeo 12457 son episode_steps:591\n",
            "Total Steps: 888298 Episode Num: 12457 Reward: 832.3431190652199 avg_loss_c: 5.988589438488439 avg_loss_a: -96.33018655018556\n",
            "Número de pasos del episodeo 12458 son episode_steps:121\n",
            "Total Steps: 888419 Episode Num: 12458 Reward: 67.43655329859304 avg_loss_c: 6.352455552944467 avg_loss_a: -96.52208949317617\n",
            "Número de pasos del episodeo 12459 son episode_steps:80\n",
            "Total Steps: 888499 Episode Num: 12459 Reward: 74.76181928309109 avg_loss_c: 6.247492033243179 avg_loss_a: -96.20800857543945\n",
            "Número de pasos del episodeo 12460 son episode_steps:867\n",
            "Total Steps: 889366 Episode Num: 12460 Reward: 1261.2351779627404 avg_loss_c: 6.209343437230023 avg_loss_a: -96.39503025816111\n",
            "Número de pasos del episodeo 12461 son episode_steps:143\n",
            "Total Steps: 889509 Episode Num: 12461 Reward: 131.47768074282573 avg_loss_c: 6.271177125143838 avg_loss_a: -96.10672290508563\n",
            "Número de pasos del episodeo 12462 son episode_steps:162\n",
            "Total Steps: 889671 Episode Num: 12462 Reward: 146.46888982324006 avg_loss_c: 6.3427497590029684 avg_loss_a: -96.26818160068842\n",
            "Número de pasos del episodeo 12463 son episode_steps:208\n",
            "Total Steps: 889879 Episode Num: 12463 Reward: 285.2868958881969 avg_loss_c: 6.372863803918545 avg_loss_a: -95.8492345076341\n",
            "Número de pasos del episodeo 12464 son episode_steps:873\n",
            "Total Steps: 890752 Episode Num: 12464 Reward: 1340.7361852618383 avg_loss_c: 5.817719158028409 avg_loss_a: -96.65338320912365\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 448.168835\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12465 son episode_steps:302\n",
            "Total Steps: 891054 Episode Num: 12465 Reward: 441.0383336342387 avg_loss_c: 5.915017952982163 avg_loss_a: -96.55436019392204\n",
            "Número de pasos del episodeo 12466 son episode_steps:99\n",
            "Total Steps: 891153 Episode Num: 12466 Reward: 30.752926703954316 avg_loss_c: 6.566661630013977 avg_loss_a: -95.70721450959793\n",
            "Número de pasos del episodeo 12467 son episode_steps:45\n",
            "Total Steps: 891198 Episode Num: 12467 Reward: -13.300131224836058 avg_loss_c: 6.102068498399523 avg_loss_a: -96.94177873399522\n",
            "Número de pasos del episodeo 12468 son episode_steps:358\n",
            "Total Steps: 891556 Episode Num: 12468 Reward: 470.81781923244745 avg_loss_c: 6.479297977586032 avg_loss_a: -96.58899782489797\n",
            "Número de pasos del episodeo 12469 son episode_steps:1000\n",
            "Total Steps: 892556 Episode Num: 12469 Reward: 1563.766991853434 avg_loss_c: 5.99735413813591 avg_loss_a: -98.033480178833\n",
            "Número de pasos del episodeo 12470 son episode_steps:638\n",
            "Total Steps: 893194 Episode Num: 12470 Reward: 927.8003013012382 avg_loss_c: 6.054446629969678 avg_loss_a: -97.92627928922168\n",
            "Número de pasos del episodeo 12471 son episode_steps:85\n",
            "Total Steps: 893279 Episode Num: 12471 Reward: 97.4015497015826 avg_loss_c: 6.059128085304709 avg_loss_a: -98.13819535199333\n",
            "Número de pasos del episodeo 12472 son episode_steps:281\n",
            "Total Steps: 893560 Episode Num: 12472 Reward: 363.71550853079395 avg_loss_c: 5.975871650349627 avg_loss_a: -97.05508276236863\n",
            "Número de pasos del episodeo 12473 son episode_steps:287\n",
            "Total Steps: 893847 Episode Num: 12473 Reward: 378.03580389219775 avg_loss_c: 5.959423475564565 avg_loss_a: -97.28576947255416\n",
            "Número de pasos del episodeo 12474 son episode_steps:144\n",
            "Total Steps: 893991 Episode Num: 12474 Reward: 130.692989281828 avg_loss_c: 6.560177842775981 avg_loss_a: -96.98579597473145\n",
            "Número de pasos del episodeo 12475 son episode_steps:115\n",
            "Total Steps: 894106 Episode Num: 12475 Reward: 71.02740164696161 avg_loss_c: 6.589296591800192 avg_loss_a: -96.45857762875764\n",
            "Número de pasos del episodeo 12476 son episode_steps:908\n",
            "Total Steps: 895014 Episode Num: 12476 Reward: 1404.6026628471961 avg_loss_c: 6.399566076663097 avg_loss_a: -96.32686729263104\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 688.116816\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12477 son episode_steps:1000\n",
            "Total Steps: 896014 Episode Num: 12477 Reward: 1503.974239705229 avg_loss_c: 6.049819091081619 avg_loss_a: -96.70548623657227\n",
            "Número de pasos del episodeo 12478 son episode_steps:1000\n",
            "Total Steps: 897014 Episode Num: 12478 Reward: 1546.2156063596326 avg_loss_c: 5.6682071702480314 avg_loss_a: -97.28416960144042\n",
            "Número de pasos del episodeo 12479 son episode_steps:1000\n",
            "Total Steps: 898014 Episode Num: 12479 Reward: 1498.5808975139469 avg_loss_c: 5.275253565788269 avg_loss_a: -97.84981457519531\n",
            "Número de pasos del episodeo 12480 son episode_steps:114\n",
            "Total Steps: 898128 Episode Num: 12480 Reward: 45.05541405359332 avg_loss_c: 5.6774904163260205 avg_loss_a: -97.54712984854714\n",
            "Número de pasos del episodeo 12481 son episode_steps:1000\n",
            "Total Steps: 899128 Episode Num: 12481 Reward: 1562.6979870921168 avg_loss_c: 5.148229832410812 avg_loss_a: -98.66137461853027\n",
            "Número de pasos del episodeo 12482 son episode_steps:101\n",
            "Total Steps: 899229 Episode Num: 12482 Reward: 94.35781761143473 avg_loss_c: 5.148066239781899 avg_loss_a: -100.04333118400952\n",
            "Número de pasos del episodeo 12483 son episode_steps:44\n",
            "Total Steps: 899273 Episode Num: 12483 Reward: -40.901200433480774 avg_loss_c: 6.023255667903206 avg_loss_a: -99.30266016179866\n",
            "Número de pasos del episodeo 12484 son episode_steps:39\n",
            "Total Steps: 899312 Episode Num: 12484 Reward: -7.879586102903092 avg_loss_c: 5.243825722963382 avg_loss_a: -97.7340821486253\n",
            "Número de pasos del episodeo 12485 son episode_steps:1000\n",
            "Total Steps: 900312 Episode Num: 12485 Reward: 1569.9819083862083 avg_loss_c: 4.881279041767121 avg_loss_a: -100.63958502197265\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 777.018442\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12486 son episode_steps:89\n",
            "Total Steps: 900401 Episode Num: 12486 Reward: 53.039633781214164 avg_loss_c: 4.950841239329135 avg_loss_a: -100.77117654178919\n",
            "Número de pasos del episodeo 12487 son episode_steps:79\n",
            "Total Steps: 900480 Episode Num: 12487 Reward: 89.66231242922555 avg_loss_c: 5.235893228386022 avg_loss_a: -100.18164390853688\n",
            "Número de pasos del episodeo 12488 son episode_steps:74\n",
            "Total Steps: 900554 Episode Num: 12488 Reward: 56.090425459879974 avg_loss_c: 5.383364468007474 avg_loss_a: -101.09035162023596\n",
            "Número de pasos del episodeo 12489 son episode_steps:99\n",
            "Total Steps: 900653 Episode Num: 12489 Reward: 122.04046734130773 avg_loss_c: 4.997149655313203 avg_loss_a: -101.11846630982679\n",
            "Número de pasos del episodeo 12490 son episode_steps:894\n",
            "Total Steps: 901547 Episode Num: 12490 Reward: 1288.8258819210569 avg_loss_c: 4.903891795433608 avg_loss_a: -101.28400738607317\n",
            "Número de pasos del episodeo 12491 son episode_steps:85\n",
            "Total Steps: 901632 Episode Num: 12491 Reward: 100.08459870297997 avg_loss_c: 4.957080484839047 avg_loss_a: -101.13576202392578\n",
            "Número de pasos del episodeo 12492 son episode_steps:98\n",
            "Total Steps: 901730 Episode Num: 12492 Reward: 106.1054611889849 avg_loss_c: 4.895303385598319 avg_loss_a: -101.01072864143215\n",
            "Número de pasos del episodeo 12493 son episode_steps:71\n",
            "Total Steps: 901801 Episode Num: 12493 Reward: 72.01214464514675 avg_loss_c: 5.256021583583993 avg_loss_a: -101.313644946461\n",
            "Número de pasos del episodeo 12494 son episode_steps:442\n",
            "Total Steps: 902243 Episode Num: 12494 Reward: 620.8564714687918 avg_loss_c: 4.898330413378202 avg_loss_a: -100.9904766859512\n",
            "Número de pasos del episodeo 12495 son episode_steps:54\n",
            "Total Steps: 902297 Episode Num: 12495 Reward: 38.55391991523994 avg_loss_c: 4.924571995381956 avg_loss_a: -101.5639464766891\n",
            "Número de pasos del episodeo 12496 son episode_steps:106\n",
            "Total Steps: 902403 Episode Num: 12496 Reward: 111.07715860582076 avg_loss_c: 5.10438110918369 avg_loss_a: -100.73244274787183\n",
            "Número de pasos del episodeo 12497 son episode_steps:413\n",
            "Total Steps: 902816 Episode Num: 12497 Reward: 571.8985624322667 avg_loss_c: 4.997935337824048 avg_loss_a: -101.18442099434989\n",
            "Número de pasos del episodeo 12498 son episode_steps:1000\n",
            "Total Steps: 903816 Episode Num: 12498 Reward: 1431.1504713311822 avg_loss_c: 4.8028243193626405 avg_loss_a: -100.57719711303712\n",
            "Número de pasos del episodeo 12499 son episode_steps:76\n",
            "Total Steps: 903892 Episode Num: 12499 Reward: 14.254210348676578 avg_loss_c: 5.0055468302024035 avg_loss_a: -99.98834248592979\n",
            "Número de pasos del episodeo 12500 son episode_steps:690\n",
            "Total Steps: 904582 Episode Num: 12500 Reward: 951.9384831232146 avg_loss_c: 4.91689966796101 avg_loss_a: -100.64080779587013\n",
            "Número de pasos del episodeo 12501 son episode_steps:1000\n",
            "Total Steps: 905582 Episode Num: 12501 Reward: 1580.4668236281457 avg_loss_c: 4.550072662353515 avg_loss_a: -101.15540759277344\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 402.797483\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12502 son episode_steps:48\n",
            "Total Steps: 905630 Episode Num: 12502 Reward: -14.986612853694842 avg_loss_c: 5.08156718313694 avg_loss_a: -100.05020968119304\n",
            "Número de pasos del episodeo 12503 son episode_steps:78\n",
            "Total Steps: 905708 Episode Num: 12503 Reward: 22.53758660411887 avg_loss_c: 6.046414418098254 avg_loss_a: -101.60056617932442\n",
            "Número de pasos del episodeo 12504 son episode_steps:44\n",
            "Total Steps: 905752 Episode Num: 12504 Reward: -1.119082786387236 avg_loss_c: 5.638246194882826 avg_loss_a: -100.92201510342684\n",
            "Número de pasos del episodeo 12505 son episode_steps:566\n",
            "Total Steps: 906318 Episode Num: 12505 Reward: 799.9389731502521 avg_loss_c: 5.25629383599379 avg_loss_a: -101.57814098668183\n",
            "Número de pasos del episodeo 12506 son episode_steps:86\n",
            "Total Steps: 906404 Episode Num: 12506 Reward: 41.419047322015324 avg_loss_c: 5.4938455099283265 avg_loss_a: -101.13201034900754\n",
            "Número de pasos del episodeo 12507 son episode_steps:44\n",
            "Total Steps: 906448 Episode Num: 12507 Reward: 28.88650880464878 avg_loss_c: 5.308673999526284 avg_loss_a: -100.78292950716886\n",
            "Número de pasos del episodeo 12508 son episode_steps:291\n",
            "Total Steps: 906739 Episode Num: 12508 Reward: 381.2276522361208 avg_loss_c: 5.421474968035197 avg_loss_a: -101.55058739521249\n",
            "Número de pasos del episodeo 12509 son episode_steps:186\n",
            "Total Steps: 906925 Episode Num: 12509 Reward: 205.68782089409248 avg_loss_c: 5.3602327621111305 avg_loss_a: -100.78204206241074\n",
            "Número de pasos del episodeo 12510 son episode_steps:541\n",
            "Total Steps: 907466 Episode Num: 12510 Reward: 746.7963180903031 avg_loss_c: 5.4456341451725985 avg_loss_a: -100.29176960943367\n",
            "Número de pasos del episodeo 12511 son episode_steps:1000\n",
            "Total Steps: 908466 Episode Num: 12511 Reward: 1473.1558018357343 avg_loss_c: 4.970790037631988 avg_loss_a: -100.97362850952149\n",
            "Número de pasos del episodeo 12512 son episode_steps:73\n",
            "Total Steps: 908539 Episode Num: 12512 Reward: 21.23470561322744 avg_loss_c: 4.84704016332757 avg_loss_a: -100.34256545811483\n",
            "Número de pasos del episodeo 12513 son episode_steps:1000\n",
            "Total Steps: 909539 Episode Num: 12513 Reward: 1608.4818339576427 avg_loss_c: 4.739029160499573 avg_loss_a: -101.8037866821289\n",
            "Número de pasos del episodeo 12514 son episode_steps:86\n",
            "Total Steps: 909625 Episode Num: 12514 Reward: 5.248290215978804 avg_loss_c: 4.50907196000565 avg_loss_a: -101.57217673368233\n",
            "Número de pasos del episodeo 12515 son episode_steps:68\n",
            "Total Steps: 909693 Episode Num: 12515 Reward: 28.941576745850593 avg_loss_c: 6.650506955735824 avg_loss_a: -101.47363640280331\n",
            "Número de pasos del episodeo 12516 son episode_steps:48\n",
            "Total Steps: 909741 Episode Num: 12516 Reward: 53.089925986450694 avg_loss_c: 4.8395669261614485 avg_loss_a: -101.63211377461751\n",
            "Número de pasos del episodeo 12517 son episode_steps:51\n",
            "Total Steps: 909792 Episode Num: 12517 Reward: 40.91801588732264 avg_loss_c: 4.995777448018392 avg_loss_a: -100.98310687495213\n",
            "Número de pasos del episodeo 12518 son episode_steps:362\n",
            "Total Steps: 910154 Episode Num: 12518 Reward: 473.2624098377063 avg_loss_c: 5.280090249704393 avg_loss_a: -101.23359962589834\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 997.633638\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12519 son episode_steps:1000\n",
            "Total Steps: 911154 Episode Num: 12519 Reward: 1571.392156441587 avg_loss_c: 4.909886470794678 avg_loss_a: -101.85888150024414\n",
            "Número de pasos del episodeo 12520 son episode_steps:75\n",
            "Total Steps: 911229 Episode Num: 12520 Reward: 66.80146689248885 avg_loss_c: 4.887129621505737 avg_loss_a: -101.23081370035807\n",
            "Número de pasos del episodeo 12521 son episode_steps:47\n",
            "Total Steps: 911276 Episode Num: 12521 Reward: -35.53004332644249 avg_loss_c: 5.3288346706552705 avg_loss_a: -102.10863381243766\n",
            "Número de pasos del episodeo 12522 son episode_steps:58\n",
            "Total Steps: 911334 Episode Num: 12522 Reward: 59.32849615053247 avg_loss_c: 5.827017738901335 avg_loss_a: -101.16548183046538\n",
            "Número de pasos del episodeo 12523 son episode_steps:37\n",
            "Total Steps: 911371 Episode Num: 12523 Reward: 7.4288166041187 avg_loss_c: 5.673207824294631 avg_loss_a: -101.26726037102776\n",
            "Número de pasos del episodeo 12524 son episode_steps:84\n",
            "Total Steps: 911455 Episode Num: 12524 Reward: 20.524607644736047 avg_loss_c: 5.715042883441562 avg_loss_a: -101.34739612397694\n",
            "Número de pasos del episodeo 12525 son episode_steps:1000\n",
            "Total Steps: 912455 Episode Num: 12525 Reward: 1662.2793959076675 avg_loss_c: 5.0180927877426145 avg_loss_a: -102.02593331909179\n",
            "Número de pasos del episodeo 12526 son episode_steps:1000\n",
            "Total Steps: 913455 Episode Num: 12526 Reward: 1497.0202429058172 avg_loss_c: 4.670241606235504 avg_loss_a: -102.44878382873536\n",
            "Número de pasos del episodeo 12527 son episode_steps:93\n",
            "Total Steps: 913548 Episode Num: 12527 Reward: 107.94430591154976 avg_loss_c: 4.616297783390168 avg_loss_a: -102.04030133319158\n",
            "Número de pasos del episodeo 12528 son episode_steps:112\n",
            "Total Steps: 913660 Episode Num: 12528 Reward: 64.40069560375316 avg_loss_c: 5.007951849273273 avg_loss_a: -102.14675726209369\n",
            "Número de pasos del episodeo 12529 son episode_steps:1000\n",
            "Total Steps: 914660 Episode Num: 12529 Reward: 1636.8796013077194 avg_loss_c: 4.630565536975861 avg_loss_a: -103.26078147888184\n",
            "Número de pasos del episodeo 12530 son episode_steps:136\n",
            "Total Steps: 914796 Episode Num: 12530 Reward: 165.9066520742069 avg_loss_c: 4.425061892060673 avg_loss_a: -102.40460653866039\n",
            "Número de pasos del episodeo 12531 son episode_steps:104\n",
            "Total Steps: 914900 Episode Num: 12531 Reward: 67.46485761810528 avg_loss_c: 4.726931342711816 avg_loss_a: -102.63799021794246\n",
            "Número de pasos del episodeo 12532 son episode_steps:391\n",
            "Total Steps: 915291 Episode Num: 12532 Reward: 553.2969452884885 avg_loss_c: 4.814936112869731 avg_loss_a: -102.61616664408417\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 529.356689\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12533 son episode_steps:102\n",
            "Total Steps: 915393 Episode Num: 12533 Reward: 55.56997753805775 avg_loss_c: 5.105036688785927 avg_loss_a: -101.9018466425877\n",
            "Número de pasos del episodeo 12534 son episode_steps:62\n",
            "Total Steps: 915455 Episode Num: 12534 Reward: -2.6970312970946995 avg_loss_c: 4.804176834321791 avg_loss_a: -102.471436039094\n",
            "Número de pasos del episodeo 12535 son episode_steps:148\n",
            "Total Steps: 915603 Episode Num: 12535 Reward: 192.31776130622015 avg_loss_c: 5.077823885389276 avg_loss_a: -101.50435648737727\n",
            "Número de pasos del episodeo 12536 son episode_steps:866\n",
            "Total Steps: 916469 Episode Num: 12536 Reward: 1403.9133607042672 avg_loss_c: 4.742061954722944 avg_loss_a: -101.6870433463786\n",
            "Número de pasos del episodeo 12537 son episode_steps:85\n",
            "Total Steps: 916554 Episode Num: 12537 Reward: 38.21770525828432 avg_loss_c: 4.8569776170394 avg_loss_a: -102.02897392721736\n",
            "Número de pasos del episodeo 12538 son episode_steps:65\n",
            "Total Steps: 916619 Episode Num: 12538 Reward: 24.997180420704943 avg_loss_c: 5.701752603971041 avg_loss_a: -100.84073404165414\n",
            "Número de pasos del episodeo 12539 son episode_steps:480\n",
            "Total Steps: 917099 Episode Num: 12539 Reward: 690.2065313168197 avg_loss_c: 5.345407512784004 avg_loss_a: -101.36250139872233\n",
            "Número de pasos del episodeo 12540 son episode_steps:20\n",
            "Total Steps: 917119 Episode Num: 12540 Reward: -52.85658649205873 avg_loss_c: 4.993198895454407 avg_loss_a: -101.8374038696289\n",
            "Número de pasos del episodeo 12541 son episode_steps:88\n",
            "Total Steps: 917207 Episode Num: 12541 Reward: 95.7290938859999 avg_loss_c: 5.3201243796131825 avg_loss_a: -100.37260870500045\n",
            "Número de pasos del episodeo 12542 son episode_steps:85\n",
            "Total Steps: 917292 Episode Num: 12542 Reward: 38.370509017057415 avg_loss_c: 5.841917775659001 avg_loss_a: -101.50731219123392\n",
            "Número de pasos del episodeo 12543 son episode_steps:165\n",
            "Total Steps: 917457 Episode Num: 12543 Reward: 191.0391451008935 avg_loss_c: 5.60863289977565 avg_loss_a: -100.75386861165364\n",
            "Número de pasos del episodeo 12544 son episode_steps:37\n",
            "Total Steps: 917494 Episode Num: 12544 Reward: -18.737196406313558 avg_loss_c: 6.8079547495455355 avg_loss_a: -100.24736930228569\n",
            "Número de pasos del episodeo 12545 son episode_steps:132\n",
            "Total Steps: 917626 Episode Num: 12545 Reward: 153.39294981101258 avg_loss_c: 5.989932815233867 avg_loss_a: -100.08514727968158\n",
            "Número de pasos del episodeo 12546 son episode_steps:66\n",
            "Total Steps: 917692 Episode Num: 12546 Reward: 37.857898684251516 avg_loss_c: 6.280920747554664 avg_loss_a: -99.50726942582564\n",
            "Número de pasos del episodeo 12547 son episode_steps:779\n",
            "Total Steps: 918471 Episode Num: 12547 Reward: 1176.3270119340496 avg_loss_c: 6.13017779014842 avg_loss_a: -100.07939329135097\n",
            "Número de pasos del episodeo 12548 son episode_steps:255\n",
            "Total Steps: 918726 Episode Num: 12548 Reward: 312.2701619196874 avg_loss_c: 6.16577345717187 avg_loss_a: -99.58011262183096\n",
            "Número de pasos del episodeo 12549 son episode_steps:155\n",
            "Total Steps: 918881 Episode Num: 12549 Reward: 79.02300754900179 avg_loss_c: 6.377112434756372 avg_loss_a: -99.25740513955394\n",
            "Número de pasos del episodeo 12550 son episode_steps:57\n",
            "Total Steps: 918938 Episode Num: 12550 Reward: 49.4613379536706 avg_loss_c: 6.67254292337518 avg_loss_a: -98.1753641764323\n",
            "Número de pasos del episodeo 12551 son episode_steps:196\n",
            "Total Steps: 919134 Episode Num: 12551 Reward: 235.23377530592288 avg_loss_c: 6.657090794066994 avg_loss_a: -98.71008067228357\n",
            "Número de pasos del episodeo 12552 son episode_steps:211\n",
            "Total Steps: 919345 Episode Num: 12552 Reward: 287.5927121643686 avg_loss_c: 6.277384257429584 avg_loss_a: -99.9279563144485\n",
            "Número de pasos del episodeo 12553 son episode_steps:335\n",
            "Total Steps: 919680 Episode Num: 12553 Reward: 469.35684007770755 avg_loss_c: 6.4968553279762835 avg_loss_a: -98.71246228573928\n",
            "Número de pasos del episodeo 12554 son episode_steps:116\n",
            "Total Steps: 919796 Episode Num: 12554 Reward: 132.0355269481502 avg_loss_c: 6.579916349772749 avg_loss_a: -99.22447270360486\n",
            "Número de pasos del episodeo 12555 son episode_steps:145\n",
            "Total Steps: 919941 Episode Num: 12555 Reward: 143.58186422224549 avg_loss_c: 6.5536525940072945 avg_loss_a: -98.51910695043104\n",
            "Número de pasos del episodeo 12556 son episode_steps:43\n",
            "Total Steps: 919984 Episode Num: 12556 Reward: 7.798928374925698 avg_loss_c: 6.529536058736402 avg_loss_a: -97.61914293156114\n",
            "Número de pasos del episodeo 12557 son episode_steps:76\n",
            "Total Steps: 920060 Episode Num: 12557 Reward: 60.61032965288922 avg_loss_c: 7.922002142981479 avg_loss_a: -98.41009340788189\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 257.639394\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12558 son episode_steps:261\n",
            "Total Steps: 920321 Episode Num: 12558 Reward: 305.45492969476487 avg_loss_c: 7.431532942015549 avg_loss_a: -97.6317296521417\n",
            "Número de pasos del episodeo 12559 son episode_steps:275\n",
            "Total Steps: 920596 Episode Num: 12559 Reward: 343.1667488565507 avg_loss_c: 7.158679657849398 avg_loss_a: -97.88389182350852\n",
            "Número de pasos del episodeo 12560 son episode_steps:45\n",
            "Total Steps: 920641 Episode Num: 12560 Reward: 21.308466692325865 avg_loss_c: 7.2366916338602705 avg_loss_a: -97.87268388536242\n",
            "Número de pasos del episodeo 12561 son episode_steps:40\n",
            "Total Steps: 920681 Episode Num: 12561 Reward: -55.91565512158656 avg_loss_c: 7.281199848651886 avg_loss_a: -97.61443786621093\n",
            "Número de pasos del episodeo 12562 son episode_steps:52\n",
            "Total Steps: 920733 Episode Num: 12562 Reward: 36.366086646515384 avg_loss_c: 7.880861694996174 avg_loss_a: -96.58607336191031\n",
            "Número de pasos del episodeo 12563 son episode_steps:117\n",
            "Total Steps: 920850 Episode Num: 12563 Reward: 107.28679241024 avg_loss_c: 8.351939863628811 avg_loss_a: -96.86493943695329\n",
            "Número de pasos del episodeo 12564 son episode_steps:41\n",
            "Total Steps: 920891 Episode Num: 12564 Reward: -17.301150970301652 avg_loss_c: 8.508095450517608 avg_loss_a: -96.22528299471227\n",
            "Número de pasos del episodeo 12565 son episode_steps:234\n",
            "Total Steps: 921125 Episode Num: 12565 Reward: 164.38671007933308 avg_loss_c: 8.281925950294886 avg_loss_a: -96.95228850535857\n",
            "Número de pasos del episodeo 12566 son episode_steps:324\n",
            "Total Steps: 921449 Episode Num: 12566 Reward: 456.407390196912 avg_loss_c: 8.337899131539427 avg_loss_a: -95.62364714822651\n",
            "Número de pasos del episodeo 12567 son episode_steps:732\n",
            "Total Steps: 922181 Episode Num: 12567 Reward: 954.9470492312191 avg_loss_c: 8.145557940657673 avg_loss_a: -96.89927072994044\n",
            "Número de pasos del episodeo 12568 son episode_steps:69\n",
            "Total Steps: 922250 Episode Num: 12568 Reward: 16.718234072835664 avg_loss_c: 8.193679574607074 avg_loss_a: -96.43370509493178\n",
            "Número de pasos del episodeo 12569 son episode_steps:96\n",
            "Total Steps: 922346 Episode Num: 12569 Reward: 72.22344082300172 avg_loss_c: 9.162277057766914 avg_loss_a: -96.91952244440715\n",
            "Número de pasos del episodeo 12570 son episode_steps:1000\n",
            "Total Steps: 923346 Episode Num: 12570 Reward: 1687.2857015282223 avg_loss_c: 7.683311056375503 avg_loss_a: -98.1813080291748\n",
            "Número de pasos del episodeo 12571 son episode_steps:69\n",
            "Total Steps: 923415 Episode Num: 12571 Reward: 57.44221447071573 avg_loss_c: 8.16636131811833 avg_loss_a: -97.94635142450747\n",
            "Número de pasos del episodeo 12572 son episode_steps:97\n",
            "Total Steps: 923512 Episode Num: 12572 Reward: 40.467131794575735 avg_loss_c: 8.170406513607379 avg_loss_a: -97.61255582829112\n",
            "Número de pasos del episodeo 12573 son episode_steps:187\n",
            "Total Steps: 923699 Episode Num: 12573 Reward: 188.49030871155415 avg_loss_c: 8.621760284199434 avg_loss_a: -97.21533823268298\n",
            "Número de pasos del episodeo 12574 son episode_steps:373\n",
            "Total Steps: 924072 Episode Num: 12574 Reward: 531.8640172552234 avg_loss_c: 8.148869896702088 avg_loss_a: -97.75063458971938\n",
            "Número de pasos del episodeo 12575 son episode_steps:1000\n",
            "Total Steps: 925072 Episode Num: 12575 Reward: 1624.5471656131879 avg_loss_c: 7.775632106781006 avg_loss_a: -97.9169370880127\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 556.160060\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12576 son episode_steps:52\n",
            "Total Steps: 925124 Episode Num: 12576 Reward: 23.584839237250513 avg_loss_c: 8.238451251616844 avg_loss_a: -97.81172737708458\n",
            "Número de pasos del episodeo 12577 son episode_steps:786\n",
            "Total Steps: 925910 Episode Num: 12577 Reward: 1181.3198466826286 avg_loss_c: 7.503613075833891 avg_loss_a: -98.78575155631883\n",
            "Número de pasos del episodeo 12578 son episode_steps:53\n",
            "Total Steps: 925963 Episode Num: 12578 Reward: 5.077060446951519 avg_loss_c: 7.466813357371204 avg_loss_a: -98.85836504090507\n",
            "Número de pasos del episodeo 12579 son episode_steps:45\n",
            "Total Steps: 926008 Episode Num: 12579 Reward: 14.92315415976459 avg_loss_c: 6.87631262673272 avg_loss_a: -98.49709065755208\n",
            "Número de pasos del episodeo 12580 son episode_steps:54\n",
            "Total Steps: 926062 Episode Num: 12580 Reward: 15.024107841544438 avg_loss_c: 9.712555558593184 avg_loss_a: -98.34366748951099\n",
            "Número de pasos del episodeo 12581 son episode_steps:74\n",
            "Total Steps: 926136 Episode Num: 12581 Reward: 91.43582552343514 avg_loss_c: 8.535192373636606 avg_loss_a: -98.50778404442039\n",
            "Número de pasos del episodeo 12582 son episode_steps:187\n",
            "Total Steps: 926323 Episode Num: 12582 Reward: 214.76901667706446 avg_loss_c: 8.443067407863026 avg_loss_a: -97.66884882309857\n",
            "Número de pasos del episodeo 12583 son episode_steps:79\n",
            "Total Steps: 926402 Episode Num: 12583 Reward: -13.451605494567612 avg_loss_c: 8.656900261021867 avg_loss_a: -98.2336803387992\n",
            "Número de pasos del episodeo 12584 son episode_steps:72\n",
            "Total Steps: 926474 Episode Num: 12584 Reward: 58.932057717383756 avg_loss_c: 8.112906522221035 avg_loss_a: -97.69114303588867\n",
            "Número de pasos del episodeo 12585 son episode_steps:1000\n",
            "Total Steps: 927474 Episode Num: 12585 Reward: 1597.3445239329974 avg_loss_c: 7.674749576330185 avg_loss_a: -99.54591334533691\n",
            "Número de pasos del episodeo 12586 son episode_steps:229\n",
            "Total Steps: 927703 Episode Num: 12586 Reward: 303.75162243856556 avg_loss_c: 7.685961288135645 avg_loss_a: -99.674317405734\n",
            "Número de pasos del episodeo 12587 son episode_steps:128\n",
            "Total Steps: 927831 Episode Num: 12587 Reward: 113.16150633343074 avg_loss_c: 7.699256636202335 avg_loss_a: -100.14842307567596\n",
            "Número de pasos del episodeo 12588 son episode_steps:36\n",
            "Total Steps: 927867 Episode Num: 12588 Reward: -2.9622370164873812 avg_loss_c: 6.916196346282959 avg_loss_a: -100.3367067972819\n",
            "Número de pasos del episodeo 12589 son episode_steps:105\n",
            "Total Steps: 927972 Episode Num: 12589 Reward: 79.47935104157797 avg_loss_c: 7.987408551715669 avg_loss_a: -99.11258871895926\n",
            "Número de pasos del episodeo 12590 son episode_steps:184\n",
            "Total Steps: 928156 Episode Num: 12590 Reward: 128.21034882272488 avg_loss_c: 8.420316211555315 avg_loss_a: -99.38462763247283\n",
            "Número de pasos del episodeo 12591 son episode_steps:1000\n",
            "Total Steps: 929156 Episode Num: 12591 Reward: 1592.7759525946935 avg_loss_c: 7.666086884737015 avg_loss_a: -99.87628051757812\n",
            "Número de pasos del episodeo 12592 son episode_steps:57\n",
            "Total Steps: 929213 Episode Num: 12592 Reward: -80.58985279654587 avg_loss_c: 8.978631412773801 avg_loss_a: -99.76035215143571\n",
            "Número de pasos del episodeo 12593 son episode_steps:1000\n",
            "Total Steps: 930213 Episode Num: 12593 Reward: 1672.4123945357974 avg_loss_c: 7.63165140414238 avg_loss_a: -101.20724842834473\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 62.164230\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12594 son episode_steps:1000\n",
            "Total Steps: 931213 Episode Num: 12594 Reward: 1610.999043970177 avg_loss_c: 6.837215173959732 avg_loss_a: -102.14311784362793\n",
            "Número de pasos del episodeo 12595 son episode_steps:49\n",
            "Total Steps: 931262 Episode Num: 12595 Reward: 31.437632042180393 avg_loss_c: 6.913174638942796 avg_loss_a: -101.98511038021165\n",
            "Número de pasos del episodeo 12596 son episode_steps:1000\n",
            "Total Steps: 932262 Episode Num: 12596 Reward: 1609.549139998442 avg_loss_c: 6.417561657905579 avg_loss_a: -103.21858424377442\n",
            "Número de pasos del episodeo 12597 son episode_steps:251\n",
            "Total Steps: 932513 Episode Num: 12597 Reward: 287.08000713418704 avg_loss_c: 6.689008019359938 avg_loss_a: -103.29911475922482\n",
            "Número de pasos del episodeo 12598 son episode_steps:55\n",
            "Total Steps: 932568 Episode Num: 12598 Reward: -29.413172801815797 avg_loss_c: 7.519314713911577 avg_loss_a: -103.28493971391158\n",
            "Número de pasos del episodeo 12599 son episode_steps:82\n",
            "Total Steps: 932650 Episode Num: 12599 Reward: -16.962373663196118 avg_loss_c: 9.338812618720823 avg_loss_a: -102.09852227932069\n",
            "Número de pasos del episodeo 12600 son episode_steps:629\n",
            "Total Steps: 933279 Episode Num: 12600 Reward: 851.5489968310499 avg_loss_c: 7.425465326809542 avg_loss_a: -102.59443252151077\n",
            "Número de pasos del episodeo 12601 son episode_steps:53\n",
            "Total Steps: 933332 Episode Num: 12601 Reward: -41.826011931469765 avg_loss_c: 6.906677507004648 avg_loss_a: -102.36809136732569\n",
            "Número de pasos del episodeo 12602 son episode_steps:171\n",
            "Total Steps: 933503 Episode Num: 12602 Reward: 200.32676853264343 avg_loss_c: 7.262258556154039 avg_loss_a: -102.2074501082214\n",
            "Número de pasos del episodeo 12603 son episode_steps:51\n",
            "Total Steps: 933554 Episode Num: 12603 Reward: -33.426390503602626 avg_loss_c: 7.809984436222151 avg_loss_a: -102.64803029976639\n",
            "Número de pasos del episodeo 12604 son episode_steps:52\n",
            "Total Steps: 933606 Episode Num: 12604 Reward: 25.92397889114392 avg_loss_c: 8.233424186706543 avg_loss_a: -101.12689326359676\n",
            "Número de pasos del episodeo 12605 son episode_steps:66\n",
            "Total Steps: 933672 Episode Num: 12605 Reward: 51.980562330565085 avg_loss_c: 9.046639507467097 avg_loss_a: -102.7493105801669\n",
            "Número de pasos del episodeo 12606 son episode_steps:92\n",
            "Total Steps: 933764 Episode Num: 12606 Reward: 94.14592854669345 avg_loss_c: 7.435958800108536 avg_loss_a: -101.36778060249661\n",
            "Número de pasos del episodeo 12607 son episode_steps:271\n",
            "Total Steps: 934035 Episode Num: 12607 Reward: 333.04920077419126 avg_loss_c: 8.32832592087918 avg_loss_a: -101.51880195307996\n",
            "Número de pasos del episodeo 12608 son episode_steps:1000\n",
            "Total Steps: 935035 Episode Num: 12608 Reward: 1720.3036349552053 avg_loss_c: 7.722144866466523 avg_loss_a: -102.30540153503418\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 77.313557\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12609 son episode_steps:546\n",
            "Total Steps: 935581 Episode Num: 12609 Reward: 823.1812743130315 avg_loss_c: 7.856835819426037 avg_loss_a: -103.12145241538246\n",
            "Número de pasos del episodeo 12610 son episode_steps:56\n",
            "Total Steps: 935637 Episode Num: 12610 Reward: 8.350015278946412 avg_loss_c: 7.8950181518282205 avg_loss_a: -102.73290143694196\n",
            "Número de pasos del episodeo 12611 son episode_steps:106\n",
            "Total Steps: 935743 Episode Num: 12611 Reward: 68.65193453128215 avg_loss_c: 7.3402208247274725 avg_loss_a: -103.13527521097436\n",
            "Número de pasos del episodeo 12612 son episode_steps:65\n",
            "Total Steps: 935808 Episode Num: 12612 Reward: 47.77258254216441 avg_loss_c: 8.93864594239455 avg_loss_a: -102.18861142672026\n",
            "Número de pasos del episodeo 12613 son episode_steps:53\n",
            "Total Steps: 935861 Episode Num: 12613 Reward: -7.161586228804267 avg_loss_c: 7.9662275314331055 avg_loss_a: -102.74858582694576\n",
            "Número de pasos del episodeo 12614 son episode_steps:91\n",
            "Total Steps: 935952 Episode Num: 12614 Reward: -12.380724430178276 avg_loss_c: 8.668790419023116 avg_loss_a: -102.04007234678164\n",
            "Número de pasos del episodeo 12615 son episode_steps:53\n",
            "Total Steps: 936005 Episode Num: 12615 Reward: 41.34053195275329 avg_loss_c: 8.676844884764474 avg_loss_a: -101.933028886903\n",
            "Número de pasos del episodeo 12616 son episode_steps:90\n",
            "Total Steps: 936095 Episode Num: 12616 Reward: 83.59065998717335 avg_loss_c: 8.0422128200531 avg_loss_a: -101.75053320990668\n",
            "Número de pasos del episodeo 12617 son episode_steps:323\n",
            "Total Steps: 936418 Episode Num: 12617 Reward: 475.29397059432824 avg_loss_c: 8.525030063770872 avg_loss_a: -101.79835203188492\n",
            "Número de pasos del episodeo 12618 son episode_steps:209\n",
            "Total Steps: 936627 Episode Num: 12618 Reward: 260.9670272837494 avg_loss_c: 8.20713686144523 avg_loss_a: -102.22472892651717\n",
            "Número de pasos del episodeo 12619 son episode_steps:215\n",
            "Total Steps: 936842 Episode Num: 12619 Reward: 259.8795669860694 avg_loss_c: 8.12536738639654 avg_loss_a: -101.71144497893577\n",
            "Número de pasos del episodeo 12620 son episode_steps:68\n",
            "Total Steps: 936910 Episode Num: 12620 Reward: -28.713980673339094 avg_loss_c: 9.233289557344774 avg_loss_a: -101.40200020285214\n",
            "Número de pasos del episodeo 12621 son episode_steps:126\n",
            "Total Steps: 937036 Episode Num: 12621 Reward: 63.565969871421004 avg_loss_c: 9.867397834384253 avg_loss_a: -101.26984005882626\n",
            "Número de pasos del episodeo 12622 son episode_steps:739\n",
            "Total Steps: 937775 Episode Num: 12622 Reward: 1089.0969730196944 avg_loss_c: 8.400441948228663 avg_loss_a: -102.42864815759724\n",
            "Número de pasos del episodeo 12623 son episode_steps:84\n",
            "Total Steps: 937859 Episode Num: 12623 Reward: 57.09757232214183 avg_loss_c: 8.150604951949347 avg_loss_a: -101.88612910679409\n",
            "Número de pasos del episodeo 12624 son episode_steps:1000\n",
            "Total Steps: 938859 Episode Num: 12624 Reward: 1646.3536917607423 avg_loss_c: 7.24479544377327 avg_loss_a: -103.35971768188476\n",
            "Número de pasos del episodeo 12625 son episode_steps:1000\n",
            "Total Steps: 939859 Episode Num: 12625 Reward: 1706.6748445031326 avg_loss_c: 6.310425083398819 avg_loss_a: -104.65136343383789\n",
            "Número de pasos del episodeo 12626 son episode_steps:1000\n",
            "Total Steps: 940859 Episode Num: 12626 Reward: 1618.1212638161078 avg_loss_c: 5.635581839084625 avg_loss_a: -106.68113540649414\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 545.699174\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12627 son episode_steps:57\n",
            "Total Steps: 940916 Episode Num: 12627 Reward: 45.54170374372967 avg_loss_c: 6.1810396554177265 avg_loss_a: -106.6577408104612\n",
            "Número de pasos del episodeo 12628 son episode_steps:63\n",
            "Total Steps: 940979 Episode Num: 12628 Reward: 54.75649501702193 avg_loss_c: 5.670149689628964 avg_loss_a: -106.86669958205451\n",
            "Número de pasos del episodeo 12629 son episode_steps:133\n",
            "Total Steps: 941112 Episode Num: 12629 Reward: 97.81344517661753 avg_loss_c: 5.468693437432885 avg_loss_a: -106.95332640454285\n",
            "Número de pasos del episodeo 12630 son episode_steps:47\n",
            "Total Steps: 941159 Episode Num: 12630 Reward: 12.926148608382267 avg_loss_c: 6.413064028354401 avg_loss_a: -105.68219237631939\n",
            "Número de pasos del episodeo 12631 son episode_steps:193\n",
            "Total Steps: 941352 Episode Num: 12631 Reward: 231.87374166217916 avg_loss_c: 6.369932821995236 avg_loss_a: -106.50196103110832\n",
            "Número de pasos del episodeo 12632 son episode_steps:73\n",
            "Total Steps: 941425 Episode Num: 12632 Reward: 31.49737853374801 avg_loss_c: 5.995451574456202 avg_loss_a: -106.8228231978743\n",
            "Número de pasos del episodeo 12633 son episode_steps:1000\n",
            "Total Steps: 942425 Episode Num: 12633 Reward: 1671.8707646017388 avg_loss_c: 5.367129481554032 avg_loss_a: -108.0550940246582\n",
            "Número de pasos del episodeo 12634 son episode_steps:1000\n",
            "Total Steps: 943425 Episode Num: 12634 Reward: 1679.8375907618363 avg_loss_c: 4.902261932611466 avg_loss_a: -107.87378137207031\n",
            "Número de pasos del episodeo 12635 son episode_steps:111\n",
            "Total Steps: 943536 Episode Num: 12635 Reward: -3.4542129303049465 avg_loss_c: 4.755289488010578 avg_loss_a: -108.21360655088682\n",
            "Número de pasos del episodeo 12636 son episode_steps:1000\n",
            "Total Steps: 944536 Episode Num: 12636 Reward: 1720.3381957086044 avg_loss_c: 4.390801808476448 avg_loss_a: -108.75956214904785\n",
            "Número de pasos del episodeo 12637 son episode_steps:108\n",
            "Total Steps: 944644 Episode Num: 12637 Reward: 126.92668653859079 avg_loss_c: 4.520000804353644 avg_loss_a: -108.62516035857024\n",
            "Número de pasos del episodeo 12638 son episode_steps:46\n",
            "Total Steps: 944690 Episode Num: 12638 Reward: 25.32869527210196 avg_loss_c: 4.524994051974753 avg_loss_a: -108.16912874968156\n",
            "Número de pasos del episodeo 12639 son episode_steps:1000\n",
            "Total Steps: 945690 Episode Num: 12639 Reward: 1624.8694146547286 avg_loss_c: 4.396002447247505 avg_loss_a: -108.98677291870118\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 1101.400408\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12640 son episode_steps:71\n",
            "Total Steps: 945761 Episode Num: 12640 Reward: -9.141708389905773 avg_loss_c: 5.023928437434452 avg_loss_a: -108.60337464238556\n",
            "Número de pasos del episodeo 12641 son episode_steps:1000\n",
            "Total Steps: 946761 Episode Num: 12641 Reward: 1744.6891854864573 avg_loss_c: 4.1366661669015885 avg_loss_a: -110.75586921691894\n",
            "Número de pasos del episodeo 12642 son episode_steps:1000\n",
            "Total Steps: 947761 Episode Num: 12642 Reward: 1677.366101288302 avg_loss_c: 3.7422798619270323 avg_loss_a: -111.51505232238769\n",
            "Número de pasos del episodeo 12643 son episode_steps:882\n",
            "Total Steps: 948643 Episode Num: 12643 Reward: 1386.2362431477238 avg_loss_c: 3.661258242973665 avg_loss_a: -112.50373245204658\n",
            "Número de pasos del episodeo 12644 son episode_steps:31\n",
            "Total Steps: 948674 Episode Num: 12644 Reward: -40.18973300431255 avg_loss_c: 3.7012359865250124 avg_loss_a: -113.00804581180695\n",
            "Número de pasos del episodeo 12645 son episode_steps:73\n",
            "Total Steps: 948747 Episode Num: 12645 Reward: 77.04913076159689 avg_loss_c: 4.614300682120128 avg_loss_a: -112.24969942275791\n",
            "Número de pasos del episodeo 12646 son episode_steps:128\n",
            "Total Steps: 948875 Episode Num: 12646 Reward: 132.4700784124806 avg_loss_c: 4.203153667971492 avg_loss_a: -112.60149776935577\n",
            "Número de pasos del episodeo 12647 son episode_steps:93\n",
            "Total Steps: 948968 Episode Num: 12647 Reward: 92.01044670323526 avg_loss_c: 4.002288321013092 avg_loss_a: -112.67836704049058\n",
            "Número de pasos del episodeo 12648 son episode_steps:1000\n",
            "Total Steps: 949968 Episode Num: 12648 Reward: 1584.1392247509764 avg_loss_c: 3.8954718593358995 avg_loss_a: -112.35984519958497\n",
            "Número de pasos del episodeo 12649 son episode_steps:49\n",
            "Total Steps: 950017 Episode Num: 12649 Reward: 13.62544124368289 avg_loss_c: 4.080338969522593 avg_loss_a: -112.85257144850128\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 840.141770\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12650 son episode_steps:130\n",
            "Total Steps: 950147 Episode Num: 12650 Reward: -48.38482824393115 avg_loss_c: 5.142578031466558 avg_loss_a: -111.69597437931941\n",
            "Número de pasos del episodeo 12651 son episode_steps:263\n",
            "Total Steps: 950410 Episode Num: 12651 Reward: 336.29570839720236 avg_loss_c: 4.647487042521343 avg_loss_a: -111.53616855171697\n",
            "Número de pasos del episodeo 12652 son episode_steps:62\n",
            "Total Steps: 950472 Episode Num: 12652 Reward: -29.808613144711504 avg_loss_c: 4.961015432111679 avg_loss_a: -111.91427710748488\n",
            "Número de pasos del episodeo 12653 son episode_steps:180\n",
            "Total Steps: 950652 Episode Num: 12653 Reward: 131.41243968006307 avg_loss_c: 4.725677446524302 avg_loss_a: -111.2078505622016\n",
            "Número de pasos del episodeo 12654 son episode_steps:1000\n",
            "Total Steps: 951652 Episode Num: 12654 Reward: 1683.9176034119002 avg_loss_c: 4.359826757550239 avg_loss_a: -111.86303370666504\n",
            "Número de pasos del episodeo 12655 son episode_steps:54\n",
            "Total Steps: 951706 Episode Num: 12655 Reward: -54.69291423198486 avg_loss_c: 4.288799378607008 avg_loss_a: -111.8682782208478\n",
            "Número de pasos del episodeo 12656 son episode_steps:1000\n",
            "Total Steps: 952706 Episode Num: 12656 Reward: 1693.144649812797 avg_loss_c: 3.990703977942467 avg_loss_a: -112.61303242492676\n",
            "Número de pasos del episodeo 12657 son episode_steps:1000\n",
            "Total Steps: 953706 Episode Num: 12657 Reward: 1669.8180466827077 avg_loss_c: 3.4878643510341645 avg_loss_a: -114.33847230529786\n",
            "Número de pasos del episodeo 12658 son episode_steps:1000\n",
            "Total Steps: 954706 Episode Num: 12658 Reward: 1684.5021913666085 avg_loss_c: 3.0511440831422805 avg_loss_a: -115.29583419799805\n",
            "Número de pasos del episodeo 12659 son episode_steps:1000\n",
            "Total Steps: 955706 Episode Num: 12659 Reward: 1648.6074416390852 avg_loss_c: 2.8703604891300203 avg_loss_a: -116.38736215209961\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 326.286110\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12660 son episode_steps:139\n",
            "Total Steps: 955845 Episode Num: 12660 Reward: 115.83381752146406 avg_loss_c: 3.3189525655705294 avg_loss_a: -116.80939994098472\n",
            "Número de pasos del episodeo 12661 son episode_steps:172\n",
            "Total Steps: 956017 Episode Num: 12661 Reward: 96.81078072095337 avg_loss_c: 3.173711752475694 avg_loss_a: -117.56307619671489\n",
            "Número de pasos del episodeo 12662 son episode_steps:1000\n",
            "Total Steps: 957017 Episode Num: 12662 Reward: 1678.6884078016146 avg_loss_c: 2.8501666008234023 avg_loss_a: -118.8817193145752\n",
            "Número de pasos del episodeo 12663 son episode_steps:1000\n",
            "Total Steps: 958017 Episode Num: 12663 Reward: 1583.656632021738 avg_loss_c: 2.5030771982073783 avg_loss_a: -120.07098861694335\n",
            "Número de pasos del episodeo 12664 son episode_steps:64\n",
            "Total Steps: 958081 Episode Num: 12664 Reward: 21.10131895939638 avg_loss_c: 2.833887092769146 avg_loss_a: -120.71642994880676\n",
            "Número de pasos del episodeo 12665 son episode_steps:54\n",
            "Total Steps: 958135 Episode Num: 12665 Reward: 38.50785370887133 avg_loss_c: 2.7230038907792835 avg_loss_a: -119.91867404513889\n",
            "Número de pasos del episodeo 12666 son episode_steps:100\n",
            "Total Steps: 958235 Episode Num: 12666 Reward: 37.55269822558087 avg_loss_c: 3.431988763809204 avg_loss_a: -119.77577377319336\n",
            "Número de pasos del episodeo 12667 son episode_steps:419\n",
            "Total Steps: 958654 Episode Num: 12667 Reward: 551.9376857632774 avg_loss_c: 3.243401460260651 avg_loss_a: -119.38946553232562\n",
            "Número de pasos del episodeo 12668 son episode_steps:1000\n",
            "Total Steps: 959654 Episode Num: 12668 Reward: 1653.9434664937137 avg_loss_c: 3.005778799891472 avg_loss_a: -119.56223376464844\n",
            "Número de pasos del episodeo 12669 son episode_steps:230\n",
            "Total Steps: 959884 Episode Num: 12669 Reward: 190.8483472737391 avg_loss_c: 3.5245797069176383 avg_loss_a: -119.38758339259935\n",
            "Número de pasos del episodeo 12670 son episode_steps:1000\n",
            "Total Steps: 960884 Episode Num: 12670 Reward: 1687.5419406583787 avg_loss_c: 3.1329812240600585 avg_loss_a: -119.80040995788575\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 68.727531\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12671 son episode_steps:682\n",
            "Total Steps: 961566 Episode Num: 12671 Reward: 914.1410522232567 avg_loss_c: 3.8407769764273745 avg_loss_a: -120.44072862104936\n",
            "Número de pasos del episodeo 12672 son episode_steps:98\n",
            "Total Steps: 961664 Episode Num: 12672 Reward: 54.114175019077045 avg_loss_c: 3.6768495957462157 avg_loss_a: -120.7353766305106\n",
            "Número de pasos del episodeo 12673 son episode_steps:277\n",
            "Total Steps: 961941 Episode Num: 12673 Reward: 273.11962835481336 avg_loss_c: 4.6264494192729355 avg_loss_a: -120.08949706700734\n",
            "Número de pasos del episodeo 12674 son episode_steps:109\n",
            "Total Steps: 962050 Episode Num: 12674 Reward: 81.5294553852974 avg_loss_c: 4.489856335001254 avg_loss_a: -119.9557670803245\n",
            "Número de pasos del episodeo 12675 son episode_steps:80\n",
            "Total Steps: 962130 Episode Num: 12675 Reward: 17.711962880580064 avg_loss_c: 4.60836443901062 avg_loss_a: -119.98723678588867\n",
            "Número de pasos del episodeo 12676 son episode_steps:227\n",
            "Total Steps: 962357 Episode Num: 12676 Reward: 275.04417140652663 avg_loss_c: 4.920252461790513 avg_loss_a: -119.59079305505962\n",
            "Número de pasos del episodeo 12677 son episode_steps:79\n",
            "Total Steps: 962436 Episode Num: 12677 Reward: 19.322784048716443 avg_loss_c: 4.98614014854914 avg_loss_a: -119.3612829280805\n",
            "Número de pasos del episodeo 12678 son episode_steps:67\n",
            "Total Steps: 962503 Episode Num: 12678 Reward: 65.29829471180413 avg_loss_c: 5.298698400383565 avg_loss_a: -118.37772494643482\n",
            "Número de pasos del episodeo 12679 son episode_steps:54\n",
            "Total Steps: 962557 Episode Num: 12679 Reward: 11.776120360603699 avg_loss_c: 5.160531044006348 avg_loss_a: -119.3232517948857\n",
            "Número de pasos del episodeo 12680 son episode_steps:190\n",
            "Total Steps: 962747 Episode Num: 12680 Reward: 273.9038607897566 avg_loss_c: 5.357974350452423 avg_loss_a: -118.31247839676706\n",
            "Número de pasos del episodeo 12681 son episode_steps:850\n",
            "Total Steps: 963597 Episode Num: 12681 Reward: 1395.193155469143 avg_loss_c: 4.979958353603587 avg_loss_a: -118.28147670970243\n",
            "Número de pasos del episodeo 12682 son episode_steps:385\n",
            "Total Steps: 963982 Episode Num: 12682 Reward: 504.5535058530825 avg_loss_c: 5.0466093633082005 avg_loss_a: -117.88595789129084\n",
            "Número de pasos del episodeo 12683 son episode_steps:355\n",
            "Total Steps: 964337 Episode Num: 12683 Reward: 509.06652221390516 avg_loss_c: 4.986958555772271 avg_loss_a: -118.21693974884462\n",
            "Número de pasos del episodeo 12684 son episode_steps:1000\n",
            "Total Steps: 965337 Episode Num: 12684 Reward: 1643.9038498367556 avg_loss_c: 4.476527065396309 avg_loss_a: -118.71694136047363\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 375.109013\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12685 son episode_steps:1000\n",
            "Total Steps: 966337 Episode Num: 12685 Reward: 1581.9831270354812 avg_loss_c: 4.140469707965851 avg_loss_a: -119.04670753479004\n",
            "Número de pasos del episodeo 12686 son episode_steps:1000\n",
            "Total Steps: 967337 Episode Num: 12686 Reward: 1633.3051536761157 avg_loss_c: 3.8527550609111785 avg_loss_a: -119.51533345031739\n",
            "Número de pasos del episodeo 12687 son episode_steps:61\n",
            "Total Steps: 967398 Episode Num: 12687 Reward: -9.479400290563435 avg_loss_c: 4.041724619318227 avg_loss_a: -120.81643051397604\n",
            "Número de pasos del episodeo 12688 son episode_steps:54\n",
            "Total Steps: 967452 Episode Num: 12688 Reward: 23.347176939214926 avg_loss_c: 4.180871208508809 avg_loss_a: -119.36010459617331\n",
            "Número de pasos del episodeo 12689 son episode_steps:129\n",
            "Total Steps: 967581 Episode Num: 12689 Reward: 103.95989319315649 avg_loss_c: 4.607542472292287 avg_loss_a: -119.3665542602539\n",
            "Número de pasos del episodeo 12690 son episode_steps:546\n",
            "Total Steps: 968127 Episode Num: 12690 Reward: 867.6734619502228 avg_loss_c: 4.578120583361322 avg_loss_a: -119.06885559305603\n",
            "Número de pasos del episodeo 12691 son episode_steps:1000\n",
            "Total Steps: 969127 Episode Num: 12691 Reward: 1644.085447452405 avg_loss_c: 3.8684748373031614 avg_loss_a: -120.35770610046387\n",
            "Número de pasos del episodeo 12692 son episode_steps:1000\n",
            "Total Steps: 970127 Episode Num: 12692 Reward: 1645.5108673276577 avg_loss_c: 3.5356147567033767 avg_loss_a: -121.28683020019531\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 595.094123\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12693 son episode_steps:166\n",
            "Total Steps: 970293 Episode Num: 12693 Reward: 214.52565877734125 avg_loss_c: 3.576210448540837 avg_loss_a: -121.43756066747459\n",
            "Número de pasos del episodeo 12694 son episode_steps:105\n",
            "Total Steps: 970398 Episode Num: 12694 Reward: 104.48058890325541 avg_loss_c: 3.8130951245625813 avg_loss_a: -121.43280632382347\n",
            "Número de pasos del episodeo 12695 son episode_steps:131\n",
            "Total Steps: 970529 Episode Num: 12695 Reward: 67.57033472877382 avg_loss_c: 4.113491129329186 avg_loss_a: -121.76962519056015\n",
            "Número de pasos del episodeo 12696 son episode_steps:1000\n",
            "Total Steps: 971529 Episode Num: 12696 Reward: 1634.7098710915593 avg_loss_c: 3.582322720050812 avg_loss_a: -121.93712875366211\n",
            "Número de pasos del episodeo 12697 son episode_steps:1000\n",
            "Total Steps: 972529 Episode Num: 12697 Reward: 1678.1324189421396 avg_loss_c: 3.3738290927410124 avg_loss_a: -122.50151535034179\n",
            "Número de pasos del episodeo 12698 son episode_steps:530\n",
            "Total Steps: 973059 Episode Num: 12698 Reward: 811.4768214164072 avg_loss_c: 3.4595253328107436 avg_loss_a: -122.61958082666936\n",
            "Número de pasos del episodeo 12699 son episode_steps:216\n",
            "Total Steps: 973275 Episode Num: 12699 Reward: 306.87632999889104 avg_loss_c: 3.5441136763051704 avg_loss_a: -122.66974159523294\n",
            "Número de pasos del episodeo 12700 son episode_steps:19\n",
            "Total Steps: 973294 Episode Num: 12700 Reward: -22.157880719627922 avg_loss_c: 4.413824733934905 avg_loss_a: -122.37144590678967\n",
            "Número de pasos del episodeo 12701 son episode_steps:89\n",
            "Total Steps: 973383 Episode Num: 12701 Reward: 86.53178235274594 avg_loss_c: 4.434652194548189 avg_loss_a: -122.55259636011016\n",
            "Número de pasos del episodeo 12702 son episode_steps:362\n",
            "Total Steps: 973745 Episode Num: 12702 Reward: 539.0689216711398 avg_loss_c: 3.943210338360697 avg_loss_a: -122.3685719189723\n",
            "Número de pasos del episodeo 12703 son episode_steps:356\n",
            "Total Steps: 974101 Episode Num: 12703 Reward: 540.8239020850065 avg_loss_c: 4.1403058717090095 avg_loss_a: -122.19959464769686\n",
            "Número de pasos del episodeo 12704 son episode_steps:1000\n",
            "Total Steps: 975101 Episode Num: 12704 Reward: 1755.1009021942002 avg_loss_c: 3.7211666001081465 avg_loss_a: -122.31479594421387\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 655.585859\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12705 son episode_steps:430\n",
            "Total Steps: 975531 Episode Num: 12705 Reward: 704.4451282522887 avg_loss_c: 3.7678941441136735 avg_loss_a: -122.44592686143032\n",
            "Número de pasos del episodeo 12706 son episode_steps:52\n",
            "Total Steps: 975583 Episode Num: 12706 Reward: 22.28784216628926 avg_loss_c: 3.7974608219586887 avg_loss_a: -121.56023759108324\n",
            "Número de pasos del episodeo 12707 son episode_steps:70\n",
            "Total Steps: 975653 Episode Num: 12707 Reward: 65.39768418265693 avg_loss_c: 3.7782503468649726 avg_loss_a: -122.97226061139789\n",
            "Número de pasos del episodeo 12708 son episode_steps:284\n",
            "Total Steps: 975937 Episode Num: 12708 Reward: 382.13490382058137 avg_loss_c: 3.7673701144440073 avg_loss_a: -121.82950495330381\n",
            "Número de pasos del episodeo 12709 son episode_steps:47\n",
            "Total Steps: 975984 Episode Num: 12709 Reward: 27.88329862662773 avg_loss_c: 4.09798149352378 avg_loss_a: -123.26049772221991\n",
            "Número de pasos del episodeo 12710 son episode_steps:411\n",
            "Total Steps: 976395 Episode Num: 12710 Reward: 653.8634977430213 avg_loss_c: 4.064512991267109 avg_loss_a: -122.42740148465418\n",
            "Número de pasos del episodeo 12711 son episode_steps:178\n",
            "Total Steps: 976573 Episode Num: 12711 Reward: 266.0605266617828 avg_loss_c: 4.072629932607158 avg_loss_a: -122.61492062686534\n",
            "Número de pasos del episodeo 12712 son episode_steps:147\n",
            "Total Steps: 976720 Episode Num: 12712 Reward: 110.04478234046057 avg_loss_c: 5.553969655718122 avg_loss_a: -121.66075424920945\n",
            "Número de pasos del episodeo 12713 son episode_steps:322\n",
            "Total Steps: 977042 Episode Num: 12713 Reward: 456.2833491637228 avg_loss_c: 5.153032690841959 avg_loss_a: -121.83954615622574\n",
            "Número de pasos del episodeo 12714 son episode_steps:119\n",
            "Total Steps: 977161 Episode Num: 12714 Reward: 152.32809266747756 avg_loss_c: 4.576190269293905 avg_loss_a: -121.65848130939388\n",
            "Número de pasos del episodeo 12715 son episode_steps:149\n",
            "Total Steps: 977310 Episode Num: 12715 Reward: 196.29370586238275 avg_loss_c: 4.6216407982295 avg_loss_a: -120.77292110775942\n",
            "Número de pasos del episodeo 12716 son episode_steps:544\n",
            "Total Steps: 977854 Episode Num: 12716 Reward: 882.4257976363119 avg_loss_c: 4.986902786090093 avg_loss_a: -121.5941263367148\n",
            "Número de pasos del episodeo 12717 son episode_steps:170\n",
            "Total Steps: 978024 Episode Num: 12717 Reward: 221.18478769737317 avg_loss_c: 4.8979460365632 avg_loss_a: -121.70035023408778\n",
            "Número de pasos del episodeo 12718 son episode_steps:265\n",
            "Total Steps: 978289 Episode Num: 12718 Reward: 327.4708938439038 avg_loss_c: 5.018656041487208 avg_loss_a: -121.85429022447119\n",
            "Número de pasos del episodeo 12719 son episode_steps:554\n",
            "Total Steps: 978843 Episode Num: 12719 Reward: 901.4952805512988 avg_loss_c: 4.807534604296357 avg_loss_a: -122.2310550565754\n",
            "Número de pasos del episodeo 12720 son episode_steps:779\n",
            "Total Steps: 979622 Episode Num: 12720 Reward: 1190.8910159880058 avg_loss_c: 4.977289639327278 avg_loss_a: -121.61921414729107\n",
            "Número de pasos del episodeo 12721 son episode_steps:1000\n",
            "Total Steps: 980622 Episode Num: 12721 Reward: 1601.1933025621868 avg_loss_c: 4.777002504825592 avg_loss_a: -121.75621350097656\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 782.436184\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12722 son episode_steps:302\n",
            "Total Steps: 980924 Episode Num: 12722 Reward: 444.0455246367135 avg_loss_c: 4.775327523023088 avg_loss_a: -121.36806200040097\n",
            "Número de pasos del episodeo 12723 son episode_steps:1000\n",
            "Total Steps: 981924 Episode Num: 12723 Reward: 1588.0557465054765 avg_loss_c: 4.430252081632614 avg_loss_a: -122.47364497375489\n",
            "Número de pasos del episodeo 12724 son episode_steps:149\n",
            "Total Steps: 982073 Episode Num: 12724 Reward: 162.13729578538815 avg_loss_c: 4.429869290166253 avg_loss_a: -122.55990513539155\n",
            "Número de pasos del episodeo 12725 son episode_steps:884\n",
            "Total Steps: 982957 Episode Num: 12725 Reward: 1414.9739178306481 avg_loss_c: 4.2620019711790045 avg_loss_a: -123.68575021044701\n",
            "Número de pasos del episodeo 12726 son episode_steps:398\n",
            "Total Steps: 983355 Episode Num: 12726 Reward: 612.0943059175811 avg_loss_c: 4.331344843509808 avg_loss_a: -123.60956577320195\n",
            "Número de pasos del episodeo 12727 son episode_steps:1000\n",
            "Total Steps: 984355 Episode Num: 12727 Reward: 1655.2307464154646 avg_loss_c: 3.9546689929962158 avg_loss_a: -124.8364246673584\n",
            "Número de pasos del episodeo 12728 son episode_steps:104\n",
            "Total Steps: 984459 Episode Num: 12728 Reward: 109.51541167521124 avg_loss_c: 4.414869478115668 avg_loss_a: -124.86485026432918\n",
            "Número de pasos del episodeo 12729 son episode_steps:53\n",
            "Total Steps: 984512 Episode Num: 12729 Reward: 3.4641346172607683 avg_loss_c: 5.13438092537646 avg_loss_a: -124.61460948440264\n",
            "Número de pasos del episodeo 12730 son episode_steps:113\n",
            "Total Steps: 984625 Episode Num: 12730 Reward: 112.5102061815558 avg_loss_c: 5.2074245879080445 avg_loss_a: -124.38357091582982\n",
            "Número de pasos del episodeo 12731 son episode_steps:1000\n",
            "Total Steps: 985625 Episode Num: 12731 Reward: 1645.813628698501 avg_loss_c: 4.333957987427712 avg_loss_a: -124.32627743530273\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 743.393483\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12732 son episode_steps:74\n",
            "Total Steps: 985699 Episode Num: 12732 Reward: -21.401319151149323 avg_loss_c: 5.400316902109094 avg_loss_a: -124.26251220703125\n",
            "Número de pasos del episodeo 12733 son episode_steps:131\n",
            "Total Steps: 985830 Episode Num: 12733 Reward: 123.46969974183607 avg_loss_c: 4.812562405608083 avg_loss_a: -124.34330132171398\n",
            "Número de pasos del episodeo 12734 son episode_steps:1000\n",
            "Total Steps: 986830 Episode Num: 12734 Reward: 1663.6928807191193 avg_loss_c: 4.500069148659706 avg_loss_a: -124.45559181213379\n",
            "Número de pasos del episodeo 12735 son episode_steps:71\n",
            "Total Steps: 986901 Episode Num: 12735 Reward: -1.4265601092472622 avg_loss_c: 4.7940484100664165 avg_loss_a: -124.38788164165658\n",
            "Número de pasos del episodeo 12736 son episode_steps:57\n",
            "Total Steps: 986958 Episode Num: 12736 Reward: -13.330881702733743 avg_loss_c: 5.49121340115865 avg_loss_a: -123.40753535220497\n",
            "Número de pasos del episodeo 12737 son episode_steps:86\n",
            "Total Steps: 987044 Episode Num: 12737 Reward: 31.372693540139164 avg_loss_c: 5.7962108795032945 avg_loss_a: -124.13341788358467\n",
            "Número de pasos del episodeo 12738 son episode_steps:135\n",
            "Total Steps: 987179 Episode Num: 12738 Reward: 94.27367604455327 avg_loss_c: 6.423463116751777 avg_loss_a: -123.52364032886646\n",
            "Número de pasos del episodeo 12739 son episode_steps:77\n",
            "Total Steps: 987256 Episode Num: 12739 Reward: -2.339321206820426 avg_loss_c: 5.688009977340698 avg_loss_a: -123.93400890796215\n",
            "Número de pasos del episodeo 12740 son episode_steps:171\n",
            "Total Steps: 987427 Episode Num: 12740 Reward: 41.16865791166035 avg_loss_c: 6.755225756014997 avg_loss_a: -123.74717440242655\n",
            "Número de pasos del episodeo 12741 son episode_steps:94\n",
            "Total Steps: 987521 Episode Num: 12741 Reward: 97.47575912957103 avg_loss_c: 6.209672849229041 avg_loss_a: -123.45098730858336\n",
            "Número de pasos del episodeo 12742 son episode_steps:88\n",
            "Total Steps: 987609 Episode Num: 12742 Reward: 35.94359325887133 avg_loss_c: 6.323331878943876 avg_loss_a: -123.46583383733577\n",
            "Número de pasos del episodeo 12743 son episode_steps:1000\n",
            "Total Steps: 988609 Episode Num: 12743 Reward: 1673.377971032329 avg_loss_c: 5.450570325374604 avg_loss_a: -123.86552659606933\n",
            "Número de pasos del episodeo 12744 son episode_steps:46\n",
            "Total Steps: 988655 Episode Num: 12744 Reward: -10.380630467421055 avg_loss_c: 5.329327033913654 avg_loss_a: -124.04396919582202\n",
            "Número de pasos del episodeo 12745 son episode_steps:312\n",
            "Total Steps: 988967 Episode Num: 12745 Reward: 430.0127106379241 avg_loss_c: 5.326770794697297 avg_loss_a: -123.25703596457457\n",
            "Número de pasos del episodeo 12746 son episode_steps:1000\n",
            "Total Steps: 989967 Episode Num: 12746 Reward: 1632.5208987066014 avg_loss_c: 4.924199369430542 avg_loss_a: -123.61865980529785\n",
            "Número de pasos del episodeo 12747 son episode_steps:66\n",
            "Total Steps: 990033 Episode Num: 12747 Reward: 33.83469968928798 avg_loss_c: 4.889743794094432 avg_loss_a: -124.03082437226267\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 186.848414\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12748 son episode_steps:493\n",
            "Total Steps: 990526 Episode Num: 12748 Reward: 787.65629205211 avg_loss_c: 5.0082058969424175 avg_loss_a: -124.28749332079781\n",
            "Número de pasos del episodeo 12749 son episode_steps:64\n",
            "Total Steps: 990590 Episode Num: 12749 Reward: 44.587228239322044 avg_loss_c: 4.7738463170826435 avg_loss_a: -124.9783148765564\n",
            "Número de pasos del episodeo 12750 son episode_steps:104\n",
            "Total Steps: 990694 Episode Num: 12750 Reward: 94.46310325914598 avg_loss_c: 5.237131863832474 avg_loss_a: -123.79642853370079\n",
            "Número de pasos del episodeo 12751 son episode_steps:272\n",
            "Total Steps: 990966 Episode Num: 12751 Reward: 352.8753934077039 avg_loss_c: 5.014187477967319 avg_loss_a: -123.91807814205394\n",
            "Número de pasos del episodeo 12752 son episode_steps:42\n",
            "Total Steps: 991008 Episode Num: 12752 Reward: -9.140927094149948 avg_loss_c: 5.407390787487938 avg_loss_a: -124.66404905773345\n",
            "Número de pasos del episodeo 12753 son episode_steps:181\n",
            "Total Steps: 991189 Episode Num: 12753 Reward: 180.3696157564047 avg_loss_c: 5.960215825402275 avg_loss_a: -123.13676284031315\n",
            "Número de pasos del episodeo 12754 son episode_steps:261\n",
            "Total Steps: 991450 Episode Num: 12754 Reward: 330.14754475894205 avg_loss_c: 5.9447061741489104 avg_loss_a: -122.78942184155929\n",
            "Número de pasos del episodeo 12755 son episode_steps:107\n",
            "Total Steps: 991557 Episode Num: 12755 Reward: 88.2999856487718 avg_loss_c: 6.302331839766458 avg_loss_a: -122.44451070054669\n",
            "Número de pasos del episodeo 12756 son episode_steps:93\n",
            "Total Steps: 991650 Episode Num: 12756 Reward: 78.6133029817881 avg_loss_c: 6.242178327293806 avg_loss_a: -123.23550127911311\n",
            "Número de pasos del episodeo 12757 son episode_steps:85\n",
            "Total Steps: 991735 Episode Num: 12757 Reward: 62.84346606326088 avg_loss_c: 6.015779829025268 avg_loss_a: -122.22388512106502\n",
            "Número de pasos del episodeo 12758 son episode_steps:58\n",
            "Total Steps: 991793 Episode Num: 12758 Reward: 11.562395509131335 avg_loss_c: 6.817041146344152 avg_loss_a: -121.47874029751482\n",
            "Número de pasos del episodeo 12759 son episode_steps:47\n",
            "Total Steps: 991840 Episode Num: 12759 Reward: -21.6447421154283 avg_loss_c: 6.961992563085353 avg_loss_a: -122.19732065403716\n",
            "Número de pasos del episodeo 12760 son episode_steps:118\n",
            "Total Steps: 991958 Episode Num: 12760 Reward: 99.78041955480109 avg_loss_c: 7.316547175585213 avg_loss_a: -120.73112914521815\n",
            "Número de pasos del episodeo 12761 son episode_steps:202\n",
            "Total Steps: 992160 Episode Num: 12761 Reward: 176.46616063302122 avg_loss_c: 7.860487586200827 avg_loss_a: -120.75908313411297\n",
            "Número de pasos del episodeo 12762 son episode_steps:89\n",
            "Total Steps: 992249 Episode Num: 12762 Reward: 42.451764152732274 avg_loss_c: 8.03832312916102 avg_loss_a: -120.24589392844211\n",
            "Número de pasos del episodeo 12763 son episode_steps:102\n",
            "Total Steps: 992351 Episode Num: 12763 Reward: 105.79276311143022 avg_loss_c: 7.061055407804601 avg_loss_a: -120.03981287339154\n",
            "Número de pasos del episodeo 12764 son episode_steps:182\n",
            "Total Steps: 992533 Episode Num: 12764 Reward: 214.04520584142793 avg_loss_c: 7.791182489185543 avg_loss_a: -120.14676993233817\n",
            "Número de pasos del episodeo 12765 son episode_steps:120\n",
            "Total Steps: 992653 Episode Num: 12765 Reward: 131.9040656235431 avg_loss_c: 7.710648850599925 avg_loss_a: -120.2414363861084\n",
            "Número de pasos del episodeo 12766 son episode_steps:132\n",
            "Total Steps: 992785 Episode Num: 12766 Reward: 124.0176402953024 avg_loss_c: 7.71127555587075 avg_loss_a: -120.25841811209014\n",
            "Número de pasos del episodeo 12767 son episode_steps:195\n",
            "Total Steps: 992980 Episode Num: 12767 Reward: 96.38800365718136 avg_loss_c: 8.851632849375408 avg_loss_a: -118.93451064672226\n",
            "Número de pasos del episodeo 12768 son episode_steps:373\n",
            "Total Steps: 993353 Episode Num: 12768 Reward: 387.60897535008064 avg_loss_c: 8.407965890204299 avg_loss_a: -120.13084350258671\n",
            "Número de pasos del episodeo 12769 son episode_steps:132\n",
            "Total Steps: 993485 Episode Num: 12769 Reward: 137.29560732497308 avg_loss_c: 8.541323593168547 avg_loss_a: -119.74143172755386\n",
            "Número de pasos del episodeo 12770 son episode_steps:239\n",
            "Total Steps: 993724 Episode Num: 12770 Reward: 349.833849717297 avg_loss_c: 8.80294478787538 avg_loss_a: -119.47730248742522\n",
            "Número de pasos del episodeo 12771 son episode_steps:134\n",
            "Total Steps: 993858 Episode Num: 12771 Reward: 172.72158554405647 avg_loss_c: 8.958897277490417 avg_loss_a: -118.95701542185314\n",
            "Número de pasos del episodeo 12772 son episode_steps:117\n",
            "Total Steps: 993975 Episode Num: 12772 Reward: 143.9122386706526 avg_loss_c: 8.999021456791805 avg_loss_a: -118.9400385017069\n",
            "Número de pasos del episodeo 12773 son episode_steps:48\n",
            "Total Steps: 994023 Episode Num: 12773 Reward: -12.530566987279963 avg_loss_c: 8.719185481468836 avg_loss_a: -119.16902414957683\n",
            "Número de pasos del episodeo 12774 son episode_steps:101\n",
            "Total Steps: 994124 Episode Num: 12774 Reward: 82.71525983185406 avg_loss_c: 8.99982784762241 avg_loss_a: -118.62624767039082\n",
            "Número de pasos del episodeo 12775 son episode_steps:143\n",
            "Total Steps: 994267 Episode Num: 12775 Reward: 196.4347164346066 avg_loss_c: 9.035872776191551 avg_loss_a: -118.54188793689221\n",
            "Número de pasos del episodeo 12776 son episode_steps:169\n",
            "Total Steps: 994436 Episode Num: 12776 Reward: 212.06753994617716 avg_loss_c: 9.72198464038104 avg_loss_a: -118.0838315162433\n",
            "Número de pasos del episodeo 12777 son episode_steps:232\n",
            "Total Steps: 994668 Episode Num: 12777 Reward: 313.20129971236446 avg_loss_c: 9.067530925931601 avg_loss_a: -117.94388284354375\n",
            "Número de pasos del episodeo 12778 son episode_steps:75\n",
            "Total Steps: 994743 Episode Num: 12778 Reward: 37.99528855478608 avg_loss_c: 9.747495034535726 avg_loss_a: -116.38489552815756\n",
            "Número de pasos del episodeo 12779 son episode_steps:237\n",
            "Total Steps: 994980 Episode Num: 12779 Reward: 202.6479869240212 avg_loss_c: 9.649976098587745 avg_loss_a: -117.54516170195889\n",
            "Número de pasos del episodeo 12780 son episode_steps:45\n",
            "Total Steps: 995025 Episode Num: 12780 Reward: 34.93372929849283 avg_loss_c: 10.261761569976807 avg_loss_a: -116.13705037434896\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 180.743122\n",
            "-------------------------------------------------\n",
            "Object serialized and saved to './results/replay_buffer_memory_v1_1.pickle'.\n",
            "Set of lists converted into a serializable object and saved to './results/serialized_list_train_metrics_V1_1.pickle'.\n",
            "Número de pasos del episodeo 12781 son episode_steps:109\n",
            "Total Steps: 995134 Episode Num: 12781 Reward: 122.27687132083719 avg_loss_c: 9.433319415521185 avg_loss_a: -116.57638983770248\n",
            "Número de pasos del episodeo 12782 son episode_steps:625\n",
            "Total Steps: 995759 Episode Num: 12782 Reward: 906.1431146130664 avg_loss_c: 9.561291381835938 avg_loss_a: -116.70166622314453\n",
            "Número de pasos del episodeo 12783 son episode_steps:50\n",
            "Total Steps: 995809 Episode Num: 12783 Reward: 29.548435811213317 avg_loss_c: 9.129212512969971 avg_loss_a: -116.84837493896484\n",
            "Número de pasos del episodeo 12784 son episode_steps:44\n",
            "Total Steps: 995853 Episode Num: 12784 Reward: -4.579455908920602 avg_loss_c: 9.389319506558506 avg_loss_a: -116.81847797740589\n",
            "Número de pasos del episodeo 12785 son episode_steps:94\n",
            "Total Steps: 995947 Episode Num: 12785 Reward: 92.24243017905822 avg_loss_c: 9.334174237352736 avg_loss_a: -116.24913917703832\n",
            "Número de pasos del episodeo 12786 son episode_steps:21\n",
            "Total Steps: 995968 Episode Num: 12786 Reward: -20.267416602966172 avg_loss_c: 11.126718203226725 avg_loss_a: -116.6920402163551\n",
            "Número de pasos del episodeo 12787 son episode_steps:35\n",
            "Total Steps: 996003 Episode Num: 12787 Reward: -47.22469517936664 avg_loss_c: 10.999814510345459 avg_loss_a: -116.61651262555803\n",
            "Número de pasos del episodeo 12788 son episode_steps:53\n",
            "Total Steps: 996056 Episode Num: 12788 Reward: 43.157907503815586 avg_loss_c: 10.081300915412182 avg_loss_a: -116.53466984011092\n",
            "Número de pasos del episodeo 12789 son episode_steps:721\n",
            "Total Steps: 996777 Episode Num: 12789 Reward: 1037.2642034835142 avg_loss_c: 10.217379470804032 avg_loss_a: -116.13344763386762\n",
            "Número de pasos del episodeo 12790 son episode_steps:153\n",
            "Total Steps: 996930 Episode Num: 12790 Reward: 198.88299080608454 avg_loss_c: 9.62264357361139 avg_loss_a: -116.08710225423177\n",
            "Número de pasos del episodeo 12791 son episode_steps:316\n",
            "Total Steps: 997246 Episode Num: 12791 Reward: 349.12649523589005 avg_loss_c: 10.512626527230951 avg_loss_a: -116.00890292397028\n",
            "Número de pasos del episodeo 12792 son episode_steps:50\n",
            "Total Steps: 997296 Episode Num: 12792 Reward: 40.001782424412745 avg_loss_c: 9.9894268989563 avg_loss_a: -115.77765533447266\n",
            "Número de pasos del episodeo 12793 son episode_steps:54\n",
            "Total Steps: 997350 Episode Num: 12793 Reward: 0.8601448311738196 avg_loss_c: 10.26505716641744 avg_loss_a: -116.90579930058232\n",
            "Número de pasos del episodeo 12794 son episode_steps:247\n",
            "Total Steps: 997597 Episode Num: 12794 Reward: 300.58279093140715 avg_loss_c: 11.051977182689466 avg_loss_a: -115.09330854531724\n",
            "Número de pasos del episodeo 12795 son episode_steps:253\n",
            "Total Steps: 997850 Episode Num: 12795 Reward: 274.8447848450949 avg_loss_c: 10.597337298713654 avg_loss_a: -115.04219781928383\n",
            "Número de pasos del episodeo 12796 son episode_steps:432\n",
            "Total Steps: 998282 Episode Num: 12796 Reward: 578.223028753947 avg_loss_c: 10.842920976656455 avg_loss_a: -114.79233445061578\n",
            "Número de pasos del episodeo 12797 son episode_steps:887\n",
            "Total Steps: 999169 Episode Num: 12797 Reward: 1322.2423070109905 avg_loss_c: 10.429596451788369 avg_loss_a: -114.68102529325776\n",
            "Número de pasos del episodeo 12798 son episode_steps:163\n",
            "Total Steps: 999332 Episode Num: 12798 Reward: 153.33200087953037 avg_loss_c: 10.308083730241272 avg_loss_a: -114.59760705678741\n",
            "Datos de entrenamiento serializados correctamente en './results/datos_entrenamiento_v1.pkl'.\n",
            "-------------------------------------------------\n",
            "Recompensa promedio en el paso de Evaluación: 374.350613\n",
            "-------------------------------------------------\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (201,) + inhomogeneous part.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-5bb9b025953d>\u001b[0m in \u001b[0;36m<cell line: 205>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0mevaluations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mevaluate_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msave_models\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfile_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./pytorch_models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"./results/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfile_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[1;32m    547\u001b[0m                            pickle_kwargs=dict(fix_imports=fix_imports))\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (201,) + inhomogeneous part."
          ]
        }
      ],
      "source": [
        "def calc_memory_prob (total_steps, start_steps, initial_memory_prob):\n",
        "    \"\"\"\n",
        "    Define una función para calcular la probabilidad de tomar una acción de la memoria de repetición en función\n",
        "    del número total de pasos.\n",
        "\n",
        "    Args:\n",
        "        total_steps (int): El número total de pasos realizados en el entrenamiento.\n",
        "        start_steps (int): El número de pasos antes de comenzar a utilizar la red de políticas en lugar de la\n",
        "                           memoria de repetición.\n",
        "\n",
        "    Returns:\n",
        "        float: La probabilidad de tomar una acción de la memoria de repetición en el rango [0, 1].\n",
        "    \"\"\"\n",
        "    if total_steps < start_steps:\n",
        "        # Probabilidad decreciente de tomar una acción de la memoria de repetición a medida que total_steps aumenta\n",
        "        return initial_memory_prob * (1 - total_steps / start_steps)\n",
        "    else:\n",
        "        # Probabilidad creciente de tomar una acción de la memoria de repetición a medida que total_steps supera start_steps\n",
        "        return initial_memory_prob + (1 - initial_memory_prob) * (total_steps - start_steps) / (max_timesteps - start_steps)\n",
        "\n",
        "def select_action (policy, env, total_steps, start_steps, memory_prob, obs):\n",
        "    \"\"\"\n",
        "    Selecciona una acción para el agente, ya sea del entorno real o de la experiencia del agente,\n",
        "    en función del número total de pasos, los pasos iniciales y la probabilidad de tomar una acción\n",
        "    de la experiencia. Hay que tener en cuetna la difrencia entre exploracion Vs explotación:\n",
        "\n",
        "    * Exploración: Se refiere a probar acciones desconocidas para descubrir información sobre\n",
        "      el entorno y mejorar la política del agente.\n",
        "\n",
        "    * Explotación: Se refiere a aprovechar al máximo el conocimiento adquirido hasta el momento,\n",
        "      es decir, elegir las acciones que el agente considera óptimas según su conocimiento actual.\n",
        "\n",
        "    Args:\n",
        "        policy      (TD3): plotica a entrenar\n",
        "        env         (gym): entorno sobre el cual se aplica el modelo\n",
        "        total_steps (int): El número total de pasos que ha realizado el agente.\n",
        "        start_steps (int): El número de pasos iniciales antes de que el agente comience a utilizar su política.\n",
        "        memory_prob (float): La probabilidad de tomar una acción de la experiencia del agente.\n",
        "        obs (array): La observación actual del entorno.\n",
        "\n",
        "    Returns:\n",
        "        array: La acción seleccionada para ser ejecutada en el entorno.\n",
        "    \"\"\"\n",
        "   #print (f'total_steps:{total_steps} - tart_steps:{start_steps}  ')\n",
        "\n",
        "    # Tomar acciones aleatorias antes de alcanzar el número de pasos iniciales\n",
        "    if total_steps < start_steps:\n",
        "        # Si estamos en los primeros pasos, acceder al entorno real (exploración)\n",
        "        action = env.action_space.sample()\n",
        "    # Después de superar los primeros pasos, usar el modelo entrenado con una probabilidad inversamente proporcional\n",
        "    # a la probabilidad de tomar una acción de la experiencia\n",
        "    else:\n",
        "      # Acceder a la experiencai del agente\n",
        "      action = policy.select_action(np.array(obs))\n",
        "      # print('Acción de la experiencia del agente:', action)\n",
        "      current_explore_noise = max_explore_noise * max(1 - total_steps / max_timesteps, 0)\n",
        "      if current_explore_noise != 0:\n",
        "          action = (action + np.random.normal(0, max_explore_noise, size=action_dim)).clip(env.action_space.low, env.action_space.high)\n",
        "          # print('Acción seleccionada por el modelo:', action)\n",
        "\n",
        "    return action\n",
        "\n",
        "# Creamos el objeto DDPG TD3 con los hiperparámetros definidos anteriormente\n",
        "policy = TD3 (state_dim, action_dim, max_action,max_timesteps, initial_lr =  1e-4) # Notar que realmente el objeto entrenado definira la politica a seguir por el agente\n",
        "\n",
        "# Nos creamos la memoroa de repetición de experiencias\n",
        "replay_buff = ReplayBuffer ( max_capacity = 2e4) # Notar que la máxima  capacidad de la memoria por defecto es: max_capacity = 1e4\n",
        "# replay_buff = SimplePrioritizedReplayBuffer ()\n",
        "# replay_buff = PrioritizedReplayBuffer ( max_capacity = int(1e10))\n",
        "# Lista donde se guardarán las evaluaciones de la política durante el entrenamiento\n",
        "evaluations = [evaluate_train_policy (policy, env)]\n",
        "\n",
        "# Inicialización de variables utilizadas en el entrenamiento\n",
        "explore_prob_steps  = 0\n",
        "total_steps         = 0     # Número total de pasos de entrenamiento\n",
        "episode_steps       = 0     # Número de pasos realizados (número de episodios)\n",
        "steps_since_eval    = 0     # Número de pasos desde la última evaluación de la política\n",
        "episode_num         = 0     # Número de episodios completados durante el entrenamiento\n",
        "done                = True  # Indica si el episodio actual ha finalizado\n",
        "\n",
        "t0 = time.time()  # Tiempo inicial de referencia para medir el tiempo de entrenamiento\n",
        "n_steps_epochs = []\n",
        "all_rewards    = []\n",
        "avg_losses_c   = []\n",
        "avg_losses_a   = []\n",
        "all_losses_c   = []\n",
        "all_losses_a   = []\n",
        "target_qs_c1   = []\n",
        "target_qs_c2   = []\n",
        "target_qs      = []\n",
        "all_exploration_factor =  []\n",
        "\n",
        "############################################################################\n",
        "# step 0: Bucle principal del entrenameinto de nuestro modelo.\n",
        "##  REalizamos tantos pasos como indica el hiperparámetro \"max_timesteps\"\n",
        "## A no ser que se estanque en un maximo local (mínimo) el humanoide aprenderá\n",
        "## mejor cuantos más pasos realiza. Esta implementacición V1 utiliza una estrategia\n",
        "## balanceada de exploracion y explotación pero con decaimiento en la capacida de\n",
        "## explorar una vez pasamos a explotar.\n",
        "#############################################################################\n",
        "\n",
        "while total_steps < max_timesteps: #son pasos de tiempo\n",
        "    # step 1: Se comprueba si el episodio ha concluido. Si lo ha hehco, realiamso el entrenamiento del modelo\n",
        "    # con las acciones almacenadas en ReplayBuffer\n",
        "    if done:\n",
        "        # Comienza el entrenamiento del modelo si no es la primera iteración\n",
        "        if total_steps != 0:\n",
        "\n",
        "            # , expl_fact\n",
        "            print (f'Número de pasos del episodeo {episode_num} son episode_steps:{episode_steps}')\n",
        "            n_steps_epochs.append (episode_steps)\n",
        "            rewards, losses_c,losses_a, target_qs_critic1, target_qs_critic2, target_qs = policy.train (replay_buff, episode_steps, batch_size, gamma,\n",
        "                                                                                                          target_update_freq, policy_noise, noise_clip, policy_freq)\n",
        "            #############\n",
        "            # Nos guardamos las métricas del entrenamiento a estudio\n",
        "            #############\n",
        "            avg_reward    = np.mean (rewards)\n",
        "            avg_loss_c    = np.mean (losses_c)\n",
        "            avg_loss_a    = np.mean (losses_a)\n",
        "            #avg_expl_fact = np.mean (expl_fact)\n",
        "\n",
        "            all_rewards.append (avg_reward)\n",
        "            avg_losses_c.append (avg_loss_c)\n",
        "            avg_losses_a.append (avg_loss_a)\n",
        "            all_losses_c.append (losses_c.copy())\n",
        "            all_losses_a.append (losses_a.copy())\n",
        "\n",
        "            target_qs_c1.append (target_qs_critic1.copy())\n",
        "            target_qs_c2.append (target_qs_critic2.copy())\n",
        "            target_qs.append (target_qs.copy())\n",
        "\n",
        "            #all_exploration_factor.append (avg_expl_fact)\n",
        "\n",
        "            print (\"Total Steps: {} Episode Num: {} Reward: {} avg_loss_c: {} avg_loss_a: {}\".format(total_steps, episode_num, episode_reward, avg_loss_c, avg_loss_a))\n",
        "\n",
        "        # step 2: se evalúa el rendimiento del episodio actual y se guarda la política\n",
        "        # si se cumplen ciertas condiciones o criterios predefinidos.\n",
        "        if steps_since_eval >= eval_frequency:\n",
        "            steps_since_eval %= eval_frequency\n",
        "            evaluations.append (evaluate_train_policy (policy, env))\n",
        "            policy.save (file_model_name, directory=\"./pytorch_models\")\n",
        "            np.save(\"./results/%s\" % (file_model_name), evaluations)\n",
        "            save_env (file_model_name, directory = \"./results\", env = env) # Guardamos el entorno en el estado actual\n",
        "            # Serializar el ReplayBufferMemory y guardarlo en un archivo\n",
        "            serialize_object (replay_buff, './results/replay_buffer_memory_v1_1.pickle')\n",
        "            # Serializamos las metricas del entrenamiento\n",
        "            lists_train_metrics = [all_rewards, avg_losses_c,avg_losses_a, all_losses_c, all_losses_a]\n",
        "            attribute_names     = ['rewards', 'losses']\n",
        "            lists_to_serializable_object (lists_train_metrics, attribute_names, './results/serialized_list_train_metrics_V1_1.pickle')\n",
        "\n",
        "        # step 3: Reiniciar el entorno cuando finaliza el episodio de entrenamiento\n",
        "        # en el primer ciclo es el primer paso que se realiza\n",
        "        obs = env.reset ()\n",
        "\n",
        "        # Establecer \"done\" a Falso para parar el episodeo\n",
        "        done = False\n",
        "\n",
        "        # step 4: Restablecer la recompensa del episodio y el contador de pasos del episodio\n",
        "        episode_reward = 0\n",
        "        episode_steps  = 0\n",
        "        episode_num += 1\n",
        "\n",
        "    # step 4: Seleccionamso la acción bien sea pro exploración o explotación\n",
        "    start_steps = max_start_steps * max(1 - total_steps / max_timesteps, 0)  # Decaimiento lineal\n",
        "    memory_prob = calc_memory_prob (total_steps, start_steps, initial_memory_prob)                # Probabilidad de tomar la acción en otro entorno\n",
        "    action      = select_action (policy, env, total_steps, start_steps, memory_prob, obs)\n",
        "\n",
        "    # step 5: El agente ejecuta una acción en el entorno, lo que resulta en una transición\n",
        "    # de estado. Además, el agente recibe una recompensa del entorno como resultado\n",
        "    # de su acción. Esta acción puede cambiar el estado del entorno y, por lo tanto,\n",
        "    # influir en las futuras observaciones y recompensas del agente.\n",
        "    #print (f' * nueva action:{action} -- tamaño:{len (action)}')\n",
        "    new_obs, reward, done, _ = env.step(action)\n",
        "    # print (f' * nuevo reward:{reward}')\n",
        "    # Comprueba si el episodio ha terminado\n",
        "    done_bool = 0 if episode_steps + 1 == max_episode_steps else float(done)\n",
        "\n",
        "    # Aumenta la recompensa total del episodio\n",
        "    episode_reward += reward\n",
        "\n",
        "    # step 6: Almacenar nueva transición en el búfer de repetición de experiencias\n",
        "    replay_buff.add ((obs, new_obs, action, reward, done_bool))\n",
        "    #error_explora = 0.01 # añadimos un error muy bajo para asegurarnos que almenos se utiliza una vez\n",
        "    #replay_buff.add (error_explora, (obs, new_obs, action, reward, done_bool))\n",
        "\n",
        "    # Actualizar estado, tiempo de paso del episodio, tiempo total de pasos y pasos desde la última evaluación de la política\n",
        "    obs = new_obs\n",
        "    episode_steps    += 1\n",
        "    total_steps      += 1\n",
        "    steps_since_eval += 1\n",
        "    create__metrics_imagen (evaluations, all_rewards,  avg_losses_c,avg_losses_a, all_losses_c,\n",
        "                                                    all_losses_a, target_qs_c1,\n",
        "                                                    target_qs_c2, target_qs,\n",
        "                                                    n_steps_epochs,  \"v1_1\", episode_num, total_steps  )\n",
        "tf = time.time()  # Tiempo final de referencia para medir el tiempo de entrenamiento\n",
        "serialize_training (t0, tf, total_steps,\"v1_1\")\n",
        "\n",
        "# Añadimos la última actualización de la política a la lista de evaluaciones previa y guardamos nuestro modelo\n",
        "evaluations.append (evaluate_train_policy(policy, env))\n",
        "if save_models:\n",
        "  policy.save (\"%s\" % (file_model_name), directory=\"./pytorch_models\")\n",
        "np.save (\"./results/%s\" % (file_model_name), evaluations)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba69f560-ac18-462b-858e-d2c915ee91e0",
      "metadata": {
        "id": "ba69f560-ac18-462b-858e-d2c915ee91e0"
      },
      "source": [
        "# **Step 4:** Evaluación de la política para extraeer videos  de su rendimiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ab85407-30d3-483d-ac18-529f25a2e251",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ab85407-30d3-483d-ac18-529f25a2e251",
        "outputId": "67513ddc-577d-470f-b8ee-5e2d9cdd4cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------------\n",
            "Fichero de los modelos entrenados: TD3_HumanoidBulletEnv-v0_0_v1_1\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "Configuración: TD3_HumanoidBulletEnv-v0_0_v1_1\n",
            "---------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pybullet_envs\n",
        "import gym\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from gym import wrappers\n",
        "from torch.autograd import Variable\n",
        "from collections import deque\n",
        "#import mujoco_py\n",
        "from TD3 import TD3, evaluate_policy, created_models_directory\n",
        "import pybullet as p\n",
        "\n",
        "# Iniciar el servidor de física de PyBullet\n",
        "p.connect(p.DIRECT)\n",
        "\n",
        "\n",
        "\n",
        "#######################################\n",
        "###\n",
        "######################################\n",
        "env_name           = \"HumanoidBulletEnv-v0\"  # Nombre del entorno que vamos a entrena. Con forme se ha implementado el modelo TD3 poría ser cuaalquier entorno (preferiblemente de estados de acciones continuos)\n",
        "seed               = 0        # Semilla utilizada para garantizar la reproducibilidad de los resultados\n",
        "start_steps        = 1e4      # Número de iteraciones/timesteps antes de que el modelo comience a utilizar la red de políticas en lugar de elegir acciones al azar\n",
        "eval_frequency     = 5e3      # Frecuencia de evaluación, es decir, cada cuántos pasos/timesteps se evalúa el desempeño del modelo\n",
        "max_timesteps      = 5e12     # Número máximo de iteraciones/timesteps permitidos\n",
        "save_models        = True     # Booleano que indica si se deben guardar los modelos pre-entrenados o no\n",
        "explore_noise      = 0.1      # Desviación estándar del ruido gaussiano utilizado para la exploración\n",
        "batch_size         = 100      # Tamaño del lote de muestras utilizadas en cada iteración de entrenamiento\n",
        "gamma              = 0.99     # Factor de descuento gamma que afecta la importancia de las recompensas futuras en la función de pérdida\n",
        "target_update_freq = 0.005    # Tasa de actualización para suavizar los parámetros de la red objetivo\n",
        "policy_noise       = 0.2      # Desviación estándar del ruido gaussiano agregado a las acciones para promover la exploración\n",
        "noise_clip         = 0.5      # Valor máximo permitido para el ruido gaussiano agregado a las acciones (política)\n",
        "policy_freq        = 2        # Número de iteraciones entre actualizaciones de la red de políticas (modelo actor)\n",
        "\n",
        "env_name = \"HumanoidBulletEnv-v0\"\n",
        "seed = 0\n",
        "\n",
        "work_dir = os.path.join('exp', 'brs')\n",
        "monitor_dir = os.path.join(work_dir, 'monitor')\n",
        "\n",
        "\n",
        "file_model_name = created_models_directory (env_name, seed, save_models, \"v1_1\")\n",
        "print (\"---------------------------------------\")\n",
        "print (\"Configuración: %s\" % (file_model_name))\n",
        "print (\"---------------------------------------\")\n",
        "\n",
        "eval_episodes = 1000000\n",
        "save_env_vid  = True\n",
        "\n",
        "env = gym.make (env_name)\n",
        "max_episode_steps = env._max_episode_steps\n",
        "if save_env_vid:\n",
        "  env = wrappers.Monitor (env, monitor_dir, force = True)\n",
        "  # env = RecordEpisodeStatistics (env)\n",
        "  env.reset ()\n",
        "env.seed (seed)\n",
        "\n",
        "torch.manual_seed (seed)\n",
        "np.random.seed (seed)\n",
        "\n",
        "state_dim  = env.observation_space.shape [0]\n",
        "action_dim = env.action_space.shape [0]\n",
        "max_action = float (env.action_space.high [0])\n",
        "\n",
        "policy = TD3 (state_dim, action_dim, max_action,max_timesteps, initial_lr =  1e-4) # Notar que realmente el objeto entrenado definirá la política a seguir por el agente\n",
        "policy.load (file_model_name, './pytorch_models/')\n",
        "avg_reward, episode_rewards = evaluate_policy (policy, env, eval_episodes = eval_episodes)\n",
        "\n",
        "# Graficar las recompensas por episodio\n",
        "plt.plot(episode_rewards)\n",
        "plt.xlabel('Episodio')\n",
        "plt.ylabel('Recompensa')\n",
        "plt.title('Recompensa por Episodio durante la Evaluación')\n",
        "\n",
        "# Guardar la gráfica en un archivo de imagen (por ejemplo, en formato PNG)\n",
        "plt.savefig('./results/recompensas_por_episodio_evaluacion_v1_1.png')\n",
        "\n",
        "# Mostrar la gráfica en la ventana\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}